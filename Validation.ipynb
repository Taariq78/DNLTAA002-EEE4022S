{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Validation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IXPGr7M7Wui"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMbJM8d77mOM",
        "outputId": "3a16f73f-dbde-40dd-cd42-b630704dd0a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z91eOLdr7pka",
        "outputId": "eaf04343-9ae7-4544-f6d9-b5f1615ba4f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! git clone https://github.com/Taariq78/voxelmorph.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'voxelmorph'...\n",
            "remote: Enumerating objects: 2124, done.\u001b[K\n",
            "remote: Total 2124 (delta 0), reused 0 (delta 0), pack-reused 2124\u001b[K\n",
            "Receiving objects: 100% (2124/2124), 128.88 MiB | 32.56 MiB/s, done.\n",
            "Resolving deltas: 100% (1337/1337), done.\n",
            "Checking out files: 100% (75/75), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN7H_DUr7ria"
      },
      "source": [
        "from voxelmorph.pytorch.model import SpatialTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz2Uy8Ey7thN"
      },
      "source": [
        "import validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV7La_3l7wOt"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "#'''unet_start'''\n",
        "#        '''encoder'''\n",
        "        self.conv_0=nn.Conv2d(2,16,kernel_size=(4,4), stride= (2,2), padding=(1,1))\n",
        "        self.conv_1=nn.Conv2d(16,32,kernel_size=(4,4), stride= (2,2), padding=(1,1))\n",
        "        self.conv_2=nn.Conv2d(32,32,kernel_size=(4,4), stride= (2,2), padding=(1,1))\n",
        "        self.conv_3=nn.Conv2d(32,32,kernel_size=(4,4), stride= (2,2), padding=(1,1))\n",
        "\n",
        "        self.activation=nn.LeakyReLU(negative_slope=0.2)\n",
        "        \n",
        "\n",
        "#        '''decoder'''\n",
        "        self.conv_0_dec=nn.Conv2d(32,32,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "        self.conv_1_dec=nn.Conv2d(64,32,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "        self.conv_2_dec=nn.Conv2d(64,32,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "        self.conv_3_dec=nn.Conv2d(48,32,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "        self.conv_4_dec=nn.Conv2d(32,32,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "        self.conv_5_dec=nn.Conv2d(34,16,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "\n",
        "#        '''upsample'''\n",
        "        self.upsample=nn.Upsample(scale_factor=2.0, mode='nearest')\n",
        "#'''unet_end'''\n",
        "\n",
        "        self.conv_vm2=nn.Conv2d(16,16,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "\n",
        "        self.conv_flow=nn.Conv2d(16,2,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "\n",
        "        self.spatial_transform = SpatialTransformer((256,256))\n",
        "\n",
        "    def Unet(self, image_pair):\n",
        "#          '''encode'''\n",
        "      x1=self.conv_0(image_pair)\n",
        "      x1=self.activation(x1)\n",
        "\n",
        "      x2=self.conv_1(x1)\n",
        "      x2=self.activation(x2)\n",
        "\n",
        "      x3=self.conv_2(x2)\n",
        "      x3=self.activation(x3)\n",
        "\n",
        "      x4=self.conv_3(x3)\n",
        "      x4=self.activation(x4)\n",
        "\n",
        "#          '''decode'''\n",
        "      y=self.conv_0_dec(x4)\n",
        "      y=self.activation(y)\n",
        "      y=self.upsample(y)\n",
        "      y=torch.cat([y,x3],1)\n",
        "\n",
        "      y=self.conv_1_dec(y)\n",
        "      y=self.activation(y)\n",
        "      y=self.upsample(y)\n",
        "      y=torch.cat([y,x2],1)\n",
        "\n",
        "      y=self.conv_2_dec(y)\n",
        "      y=self.activation(y)\n",
        "      y=self.upsample(y)\n",
        "      y=torch.cat([y,x1],1)\n",
        "\n",
        "      y=self.conv_3_dec(y)\n",
        "      y=self.activation(y)          \n",
        "      y=self.conv_4_dec(y)\n",
        "      y=self.activation(y)\n",
        "\n",
        "      y=self.upsample(y)\n",
        "      y=torch.cat([y,image_pair],1)\n",
        "      y=self.conv_5_dec(y)\n",
        "      y=self.activation(y)\n",
        "\n",
        "      y=self.conv_vm2(y)\n",
        "      y=self.activation(y)\n",
        "\n",
        "      return y\n",
        "\n",
        "    def forward(self,mov,fix):\n",
        "      z = torch.cat([mov, fix], dim=1)\n",
        "      z = self.Unet(z)\n",
        "      #print(z.shape)\n",
        "      flow = self.conv_flow(z)\n",
        "      #print(flow.shape)\n",
        "\n",
        "      z=self.spatial_transform(mov,flow)   \n",
        "\n",
        "      return z, flow  \n",
        "\n",
        "\n",
        "\n",
        "model=Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9WMynAJ7ywG",
        "outputId": "3ebb5e85-34b2-42d6-c528-930b1c6b8b7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model=Net()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv_0): Conv2d(2, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv_1): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv_2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (conv_3): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "  (activation): LeakyReLU(negative_slope=0.2)\n",
              "  (conv_0_dec): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_1_dec): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_2_dec): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_3_dec): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_4_dec): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_5_dec): Conv2d(34, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
              "  (conv_vm2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv_flow): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (spatial_transform): SpatialTransformer()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmgbZYPiBkIQ"
      },
      "source": [
        "data_dir='/content/drive/My Drive/2020/Thesis/Data/Voxel_Training/Siddon/Chest/Patient_X'\n",
        "train_vol_names = glob.glob(os.path.join(data_dir, '*.npz'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0AGSytZC8I5"
      },
      "source": [
        "random.shuffle(train_vol_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHZQ8UGnDLBJ"
      },
      "source": [
        "ten_split = np.array_split(train_vol_names, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A75yv3oKEdei"
      },
      "source": [
        "fold_0 = ten_split[0]\n",
        "fold_1 = ten_split[1]\n",
        "fold_2 = ten_split[2]\n",
        "fold_3 = ten_split[3]\n",
        "fold_4 = ten_split[4]\n",
        "fold_5 = ten_split[5]\n",
        "fold_6 = ten_split[6]\n",
        "fold_7 = ten_split[7]\n",
        "fold_8 = ten_split[8]\n",
        "fold_9 = ten_split[9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZwK-3-UFcIi"
      },
      "source": [
        "set_0 = []\n",
        "'''holdout - fold 0'''\n",
        "for g in range(0,10):\n",
        "  if g == 0:\n",
        "    continue\n",
        "  set_0.extend(ten_split[g]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DolBfaOFHIPE"
      },
      "source": [
        "set_1 = []\n",
        "'''holdout - fold 1'''\n",
        "for g in range(0,10):\n",
        "  if g == 1:\n",
        "    continue\n",
        "  set_1.extend(ten_split[g]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkRzqoWLHS9W"
      },
      "source": [
        "set_2 = []\n",
        "'''holdout - fold 2'''\n",
        "for g in range(0,10):\n",
        "  if g == 2:\n",
        "    continue\n",
        "  set_2.extend(ten_split[g]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj7UprdYHXS-"
      },
      "source": [
        "set_3 = []\n",
        "'''holdout - fold 3'''\n",
        "for g in range(0,10):\n",
        "  if g == 3:\n",
        "    continue\n",
        "  set_3.extend(ten_split[g]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtWbcwB4HbW5"
      },
      "source": [
        "set_4 = []\n",
        "'''holdout - fold 4'''\n",
        "for g in range(0,10):\n",
        "  if g == 4:\n",
        "    continue\n",
        "  set_4.extend(ten_split[g]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q3H9L2dHepi"
      },
      "source": [
        "set_5 = []\n",
        "'''holdout - fold 5'''\n",
        "for g in range(0,10):\n",
        "  if g == 5:\n",
        "    continue\n",
        "  set_5.extend(ten_split[g]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HDWybH5Hhxv"
      },
      "source": [
        "set_6 = []\n",
        "'''holdout - fold 6'''\n",
        "for g in range(0,10):\n",
        "  if g == 6:\n",
        "    continue\n",
        "  set_6.extend(ten_split[g]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyXicp-EHqTA"
      },
      "source": [
        "set_7 = []\n",
        "'''holdout - fold 7'''\n",
        "for g in range(0,10):\n",
        "  if g == 7:\n",
        "    continue\n",
        "  set_7.extend(ten_split[g]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJnPe81vHuZN"
      },
      "source": [
        "set_8 = []\n",
        "'''holdout - fold 8'''\n",
        "for g in range(0,10):\n",
        "  if g == 8:\n",
        "    continue\n",
        "  set_8.extend(ten_split[g]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HNLC-sxHxx1"
      },
      "source": [
        "set_9 = []\n",
        "'''holdout - fold 9'''\n",
        "for g in range(0,10):\n",
        "  if g == 9:\n",
        "    continue\n",
        "  set_9.extend(ten_split[g]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owmASZXqH58E"
      },
      "source": [
        "'''Training - hold out fold 0 for validation'''\n",
        "#Training\n",
        "gpu='0'\n",
        "atlas_file='/content/drive/My Drive/2020/Thesis/Data/atlas.npz'\n",
        "lr=1e-4\n",
        "n_iter=5000\n",
        "data_loss='mse'\n",
        "model='vm2'\n",
        "reg_param=0.01\n",
        "batch_size=10\n",
        "n_save_iter=100\n",
        "model_dir='/content/drive/My Drive/2020/Thesis/Data/validation_0/'\n",
        "valid = fold_0\n",
        "train_names = set_0\n",
        "EPOCH=30\n",
        "data_dir='/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg49WkYAJlf9",
        "outputId": "6c4360cf-e2e7-4a92-897e-740dd235d2d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses_0, validation_0=validate.train(data_dir,\n",
        "          train_names,\n",
        "          atlas_file,\n",
        "          lr,\n",
        "          data_loss,\n",
        "          model,\n",
        "          reg_param, \n",
        "          batch_size,\n",
        "          n_save_iter,\n",
        "          model_dir,Net(),EPOCH, valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch_number:185\n",
            "loss(total):-0.003469\n",
            "recons_loss:0.004283\n",
            "grad_loss:0.113557\n",
            "dice_loss:-0.888769\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:186\n",
            "loss(total):-0.003714\n",
            "recons_loss:0.003970\n",
            "grad_loss:0.105562\n",
            "dice_loss:-0.874011\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:187\n",
            "loss(total):-0.002782\n",
            "recons_loss:0.004843\n",
            "grad_loss:0.116594\n",
            "dice_loss:-0.879142\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:188\n",
            "loss(total):-0.003987\n",
            "recons_loss:0.004115\n",
            "grad_loss:0.091201\n",
            "dice_loss:-0.901437\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:189\n",
            "loss(total):-0.003118\n",
            "recons_loss:0.004882\n",
            "grad_loss:0.105018\n",
            "dice_loss:-0.905044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:190\n",
            "loss(total):-0.002819\n",
            "recons_loss:0.004865\n",
            "grad_loss:0.119839\n",
            "dice_loss:-0.888241\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:191\n",
            "loss(total):-0.002978\n",
            "recons_loss:0.004786\n",
            "grad_loss:0.109291\n",
            "dice_loss:-0.885757\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:192\n",
            "loss(total):-0.003472\n",
            "recons_loss:0.004466\n",
            "grad_loss:0.092577\n",
            "dice_loss:-0.886323\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:193\n",
            "loss(total):-0.003920\n",
            "recons_loss:0.004248\n",
            "grad_loss:0.075273\n",
            "dice_loss:-0.892111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:194\n",
            "loss(total):-0.003707\n",
            "recons_loss:0.004196\n",
            "grad_loss:0.096597\n",
            "dice_loss:-0.886941\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:195\n",
            "loss(total):-0.002552\n",
            "recons_loss:0.004916\n",
            "grad_loss:0.141328\n",
            "dice_loss:-0.888164\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:196\n",
            "loss(total):-0.004414\n",
            "recons_loss:0.003659\n",
            "grad_loss:0.094468\n",
            "dice_loss:-0.901683\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:197\n",
            "loss(total):-0.002959\n",
            "recons_loss:0.004753\n",
            "grad_loss:0.122012\n",
            "dice_loss:-0.893230\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:198\n",
            "loss(total):-0.003489\n",
            "recons_loss:0.004496\n",
            "grad_loss:0.095579\n",
            "dice_loss:-0.894093\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:199\n",
            "loss(total):-0.003769\n",
            "recons_loss:0.004307\n",
            "grad_loss:0.090513\n",
            "dice_loss:-0.898115\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:200\n",
            "loss(total):-0.004410\n",
            "recons_loss:0.003743\n",
            "grad_loss:0.072415\n",
            "dice_loss:-0.887624\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:201\n",
            "loss(total):-0.004400\n",
            "recons_loss:0.003852\n",
            "grad_loss:0.073660\n",
            "dice_loss:-0.898785\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:202\n",
            "loss(total):-0.004093\n",
            "recons_loss:0.003909\n",
            "grad_loss:0.089026\n",
            "dice_loss:-0.889283\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:203\n",
            "loss(total):-0.002897\n",
            "recons_loss:0.004543\n",
            "grad_loss:0.128160\n",
            "dice_loss:-0.872187\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:204\n",
            "loss(total):-0.003923\n",
            "recons_loss:0.003955\n",
            "grad_loss:0.105464\n",
            "dice_loss:-0.893241\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:205\n",
            "loss(total):-0.003535\n",
            "recons_loss:0.004266\n",
            "grad_loss:0.111453\n",
            "dice_loss:-0.891538\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:206\n",
            "loss(total):-0.001186\n",
            "recons_loss:0.006199\n",
            "grad_loss:0.152726\n",
            "dice_loss:-0.891246\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:207\n",
            "loss(total):-0.003301\n",
            "recons_loss:0.004652\n",
            "grad_loss:0.092085\n",
            "dice_loss:-0.887373\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:208\n",
            "loss(total):-0.003025\n",
            "recons_loss:0.004779\n",
            "grad_loss:0.106140\n",
            "dice_loss:-0.886552\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:209\n",
            "loss(total):-0.004095\n",
            "recons_loss:0.003926\n",
            "grad_loss:0.091038\n",
            "dice_loss:-0.893106\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:210\n",
            "loss(total):-0.003686\n",
            "recons_loss:0.004092\n",
            "grad_loss:0.109191\n",
            "dice_loss:-0.887050\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:211\n",
            "loss(total):-0.004212\n",
            "recons_loss:0.003952\n",
            "grad_loss:0.076495\n",
            "dice_loss:-0.892879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:212\n",
            "loss(total):-0.003404\n",
            "recons_loss:0.004524\n",
            "grad_loss:0.106179\n",
            "dice_loss:-0.899003\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:213\n",
            "loss(total):-0.003783\n",
            "recons_loss:0.003991\n",
            "grad_loss:0.117187\n",
            "dice_loss:-0.894533\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:214\n",
            "loss(total):-0.004910\n",
            "recons_loss:0.003174\n",
            "grad_loss:0.082795\n",
            "dice_loss:-0.891186\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:215\n",
            "loss(total):-0.004222\n",
            "recons_loss:0.003781\n",
            "grad_loss:0.096014\n",
            "dice_loss:-0.896303\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:216\n",
            "loss(total):-0.004484\n",
            "recons_loss:0.003399\n",
            "grad_loss:0.107234\n",
            "dice_loss:-0.895593\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:217\n",
            "loss(total):-0.003729\n",
            "recons_loss:0.004097\n",
            "grad_loss:0.097726\n",
            "dice_loss:-0.880424\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:218\n",
            "loss(total):-0.004245\n",
            "recons_loss:0.003726\n",
            "grad_loss:0.090879\n",
            "dice_loss:-0.888026\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:219\n",
            "loss(total):-0.004783\n",
            "recons_loss:0.003365\n",
            "grad_loss:0.078201\n",
            "dice_loss:-0.892970\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:220\n",
            "loss(total):-0.004069\n",
            "recons_loss:0.003921\n",
            "grad_loss:0.098521\n",
            "dice_loss:-0.897541\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:221\n",
            "loss(total):-0.003926\n",
            "recons_loss:0.004144\n",
            "grad_loss:0.096124\n",
            "dice_loss:-0.903110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:222\n",
            "loss(total):-0.003978\n",
            "recons_loss:0.003948\n",
            "grad_loss:0.096628\n",
            "dice_loss:-0.889286\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:223\n",
            "loss(total):-0.003761\n",
            "recons_loss:0.004278\n",
            "grad_loss:0.091862\n",
            "dice_loss:-0.895809\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:224\n",
            "loss(total):-0.004417\n",
            "recons_loss:0.003812\n",
            "grad_loss:0.071055\n",
            "dice_loss:-0.893987\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:225\n",
            "loss(total):-0.002178\n",
            "recons_loss:0.005523\n",
            "grad_loss:0.122080\n",
            "dice_loss:-0.892151\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:226\n",
            "loss(total):-0.003400\n",
            "recons_loss:0.004441\n",
            "grad_loss:0.103698\n",
            "dice_loss:-0.887786\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:227\n",
            "loss(total):-0.003699\n",
            "recons_loss:0.004282\n",
            "grad_loss:0.096852\n",
            "dice_loss:-0.894947\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:228\n",
            "loss(total):-0.004444\n",
            "recons_loss:0.003741\n",
            "grad_loss:0.097060\n",
            "dice_loss:-0.915555\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:229\n",
            "loss(total):-0.005240\n",
            "recons_loss:0.003145\n",
            "grad_loss:0.064283\n",
            "dice_loss:-0.902825\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:230\n",
            "loss(total):-0.004103\n",
            "recons_loss:0.003960\n",
            "grad_loss:0.100154\n",
            "dice_loss:-0.906388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:231\n",
            "loss(total):-0.002830\n",
            "recons_loss:0.005111\n",
            "grad_loss:0.103863\n",
            "dice_loss:-0.898018\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:232\n",
            "loss(total):-0.003949\n",
            "recons_loss:0.004134\n",
            "grad_loss:0.090956\n",
            "dice_loss:-0.899228\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:233\n",
            "loss(total):-0.004303\n",
            "recons_loss:0.003583\n",
            "grad_loss:0.100549\n",
            "dice_loss:-0.889101\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:234\n",
            "loss(total):-0.003816\n",
            "recons_loss:0.004150\n",
            "grad_loss:0.089883\n",
            "dice_loss:-0.886478\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:235\n",
            "loss(total):-0.003848\n",
            "recons_loss:0.004252\n",
            "grad_loss:0.094510\n",
            "dice_loss:-0.904498\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:236\n",
            "loss(total):-0.003639\n",
            "recons_loss:0.004333\n",
            "grad_loss:0.097325\n",
            "dice_loss:-0.894487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:237\n",
            "loss(total):-0.003385\n",
            "recons_loss:0.004558\n",
            "grad_loss:0.104841\n",
            "dice_loss:-0.899120\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:238\n",
            "loss(total):-0.003055\n",
            "recons_loss:0.004841\n",
            "grad_loss:0.101745\n",
            "dice_loss:-0.891380\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:239\n",
            "loss(total):-0.005178\n",
            "recons_loss:0.002993\n",
            "grad_loss:0.078110\n",
            "dice_loss:-0.895244\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:240\n",
            "loss(total):-0.003355\n",
            "recons_loss:0.004621\n",
            "grad_loss:0.091691\n",
            "dice_loss:-0.889256\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:241\n",
            "loss(total):-0.003272\n",
            "recons_loss:0.004435\n",
            "grad_loss:0.134326\n",
            "dice_loss:-0.905081\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:242\n",
            "loss(total):-0.004315\n",
            "recons_loss:0.003788\n",
            "grad_loss:0.081319\n",
            "dice_loss:-0.891649\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:243\n",
            "loss(total):-0.003517\n",
            "recons_loss:0.004169\n",
            "grad_loss:0.112010\n",
            "dice_loss:-0.880644\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:244\n",
            "loss(total):-0.003589\n",
            "recons_loss:0.004232\n",
            "grad_loss:0.107895\n",
            "dice_loss:-0.889951\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:245\n",
            "loss(total):-0.002260\n",
            "recons_loss:0.005393\n",
            "grad_loss:0.123924\n",
            "dice_loss:-0.889223\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:246\n",
            "loss(total):-0.003166\n",
            "recons_loss:0.004701\n",
            "grad_loss:0.107368\n",
            "dice_loss:-0.893994\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:247\n",
            "loss(total):-0.003891\n",
            "recons_loss:0.004125\n",
            "grad_loss:0.089077\n",
            "dice_loss:-0.890684\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:248\n",
            "loss(total):-0.003912\n",
            "recons_loss:0.004098\n",
            "grad_loss:0.088159\n",
            "dice_loss:-0.889114\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:249\n",
            "loss(total):-0.004540\n",
            "recons_loss:0.003580\n",
            "grad_loss:0.089379\n",
            "dice_loss:-0.901350\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:250\n",
            "loss(total):-0.002968\n",
            "recons_loss:0.004740\n",
            "grad_loss:0.115825\n",
            "dice_loss:-0.886644\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:251\n",
            "loss(total):-0.004752\n",
            "recons_loss:0.003526\n",
            "grad_loss:0.069802\n",
            "dice_loss:-0.897553\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:252\n",
            "loss(total):-0.003906\n",
            "recons_loss:0.004096\n",
            "grad_loss:0.094527\n",
            "dice_loss:-0.894717\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:253\n",
            "loss(total):-0.003407\n",
            "recons_loss:0.004492\n",
            "grad_loss:0.089286\n",
            "dice_loss:-0.879122\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:254\n",
            "loss(total):-0.003078\n",
            "recons_loss:0.004807\n",
            "grad_loss:0.103546\n",
            "dice_loss:-0.892049\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:255\n",
            "loss(total):-0.004378\n",
            "recons_loss:0.003867\n",
            "grad_loss:0.073152\n",
            "dice_loss:-0.897597\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:256\n",
            "loss(total):-0.003253\n",
            "recons_loss:0.004659\n",
            "grad_loss:0.100227\n",
            "dice_loss:-0.891422\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:257\n",
            "loss(total):-0.003808\n",
            "recons_loss:0.004212\n",
            "grad_loss:0.092147\n",
            "dice_loss:-0.894120\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:258\n",
            "loss(total):-0.003839\n",
            "recons_loss:0.004113\n",
            "grad_loss:0.093974\n",
            "dice_loss:-0.889098\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:259\n",
            "loss(total):-0.003464\n",
            "recons_loss:0.004393\n",
            "grad_loss:0.099643\n",
            "dice_loss:-0.885285\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:260\n",
            "loss(total):-0.003883\n",
            "recons_loss:0.004056\n",
            "grad_loss:0.107054\n",
            "dice_loss:-0.900936\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:261\n",
            "loss(total):-0.003717\n",
            "recons_loss:0.004083\n",
            "grad_loss:0.113241\n",
            "dice_loss:-0.893250\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:262\n",
            "loss(total):-0.004309\n",
            "recons_loss:0.003883\n",
            "grad_loss:0.082321\n",
            "dice_loss:-0.901603\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:263\n",
            "loss(total):-0.004798\n",
            "recons_loss:0.003321\n",
            "grad_loss:0.076173\n",
            "dice_loss:-0.888124\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:264\n",
            "loss(total):-0.004396\n",
            "recons_loss:0.003844\n",
            "grad_loss:0.072159\n",
            "dice_loss:-0.896161\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:265\n",
            "loss(total):-0.001935\n",
            "recons_loss:0.005395\n",
            "grad_loss:0.151810\n",
            "dice_loss:-0.884765\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:266\n",
            "loss(total):-0.003424\n",
            "recons_loss:0.004615\n",
            "grad_loss:0.087211\n",
            "dice_loss:-0.891184\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:267\n",
            "loss(total):-0.004649\n",
            "recons_loss:0.003462\n",
            "grad_loss:0.068620\n",
            "dice_loss:-0.879695\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:268\n",
            "loss(total):-0.003284\n",
            "recons_loss:0.004651\n",
            "grad_loss:0.098277\n",
            "dice_loss:-0.891850\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:269\n",
            "loss(total):-0.004152\n",
            "recons_loss:0.003961\n",
            "grad_loss:0.078721\n",
            "dice_loss:-0.889994\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:0\n",
            "loss(total):-0.004167\n",
            "recons_loss:0.003972\n",
            "grad_loss:0.087506\n",
            "dice_loss:-0.901333\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:1\n",
            "loss(total):-0.002680\n",
            "recons_loss:0.004940\n",
            "grad_loss:0.115627\n",
            "dice_loss:-0.877627\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:2\n",
            "loss(total):-0.004154\n",
            "recons_loss:0.003964\n",
            "grad_loss:0.082498\n",
            "dice_loss:-0.894293\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:3\n",
            "loss(total):-0.002899\n",
            "recons_loss:0.004862\n",
            "grad_loss:0.115467\n",
            "dice_loss:-0.891630\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:4\n",
            "loss(total):-0.003621\n",
            "recons_loss:0.004377\n",
            "grad_loss:0.100488\n",
            "dice_loss:-0.900242\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:5\n",
            "loss(total):-0.002963\n",
            "recons_loss:0.004853\n",
            "grad_loss:0.110807\n",
            "dice_loss:-0.892378\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:6\n",
            "loss(total):-0.003743\n",
            "recons_loss:0.004401\n",
            "grad_loss:0.080360\n",
            "dice_loss:-0.894806\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:7\n",
            "loss(total):-0.003179\n",
            "recons_loss:0.004832\n",
            "grad_loss:0.100221\n",
            "dice_loss:-0.901372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:8\n",
            "loss(total):-0.003429\n",
            "recons_loss:0.004474\n",
            "grad_loss:0.097198\n",
            "dice_loss:-0.887536\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:9\n",
            "loss(total):-0.003563\n",
            "recons_loss:0.004402\n",
            "grad_loss:0.096058\n",
            "dice_loss:-0.892464\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:10\n",
            "loss(total):-0.004243\n",
            "recons_loss:0.003834\n",
            "grad_loss:0.092946\n",
            "dice_loss:-0.900621\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:11\n",
            "loss(total):-0.005481\n",
            "recons_loss:0.002986\n",
            "grad_loss:0.067344\n",
            "dice_loss:-0.914089\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:12\n",
            "loss(total):-0.003273\n",
            "recons_loss:0.004497\n",
            "grad_loss:0.103872\n",
            "dice_loss:-0.880880\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:13\n",
            "loss(total):-0.001444\n",
            "recons_loss:0.005975\n",
            "grad_loss:0.127013\n",
            "dice_loss:-0.868938\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:14\n",
            "loss(total):-0.002367\n",
            "recons_loss:0.005290\n",
            "grad_loss:0.114043\n",
            "dice_loss:-0.879696\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:15\n",
            "loss(total):-0.003503\n",
            "recons_loss:0.004429\n",
            "grad_loss:0.101717\n",
            "dice_loss:-0.894943\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:16\n",
            "loss(total):-0.004719\n",
            "recons_loss:0.003429\n",
            "grad_loss:0.082618\n",
            "dice_loss:-0.897418\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:17\n",
            "loss(total):-0.003918\n",
            "recons_loss:0.004033\n",
            "grad_loss:0.097016\n",
            "dice_loss:-0.892115\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:18\n",
            "loss(total):-0.004104\n",
            "recons_loss:0.003864\n",
            "grad_loss:0.096509\n",
            "dice_loss:-0.893306\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:19\n",
            "loss(total):-0.004747\n",
            "recons_loss:0.003412\n",
            "grad_loss:0.090855\n",
            "dice_loss:-0.906745\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:20\n",
            "loss(total):-0.004023\n",
            "recons_loss:0.003934\n",
            "grad_loss:0.108932\n",
            "dice_loss:-0.904683\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:21\n",
            "loss(total):-0.004304\n",
            "recons_loss:0.003728\n",
            "grad_loss:0.087071\n",
            "dice_loss:-0.890206\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:22\n",
            "loss(total):-0.002856\n",
            "recons_loss:0.004792\n",
            "grad_loss:0.120634\n",
            "dice_loss:-0.885460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:23\n",
            "loss(total):-0.004187\n",
            "recons_loss:0.003787\n",
            "grad_loss:0.096564\n",
            "dice_loss:-0.893970\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:24\n",
            "loss(total):-0.003284\n",
            "recons_loss:0.004558\n",
            "grad_loss:0.103433\n",
            "dice_loss:-0.887692\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:25\n",
            "loss(total):-0.004281\n",
            "recons_loss:0.003737\n",
            "grad_loss:0.082668\n",
            "dice_loss:-0.884445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:26\n",
            "loss(total):-0.003243\n",
            "recons_loss:0.004529\n",
            "grad_loss:0.102900\n",
            "dice_loss:-0.880120\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:27\n",
            "loss(total):-0.003077\n",
            "recons_loss:0.004725\n",
            "grad_loss:0.104475\n",
            "dice_loss:-0.884614\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:28\n",
            "loss(total):-0.003288\n",
            "recons_loss:0.004587\n",
            "grad_loss:0.094675\n",
            "dice_loss:-0.882231\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:29\n",
            "loss(total):-0.003647\n",
            "recons_loss:0.004180\n",
            "grad_loss:0.099851\n",
            "dice_loss:-0.882467\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:30\n",
            "loss(total):-0.004033\n",
            "recons_loss:0.003968\n",
            "grad_loss:0.089604\n",
            "dice_loss:-0.889620\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:31\n",
            "loss(total):-0.003553\n",
            "recons_loss:0.004487\n",
            "grad_loss:0.103531\n",
            "dice_loss:-0.907471\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:32\n",
            "loss(total):-0.004098\n",
            "recons_loss:0.004235\n",
            "grad_loss:0.072270\n",
            "dice_loss:-0.905567\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:33\n",
            "loss(total):-0.003000\n",
            "recons_loss:0.004723\n",
            "grad_loss:0.110292\n",
            "dice_loss:-0.882569\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:34\n",
            "loss(total):-0.002897\n",
            "recons_loss:0.004970\n",
            "grad_loss:0.110275\n",
            "dice_loss:-0.897038\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:35\n",
            "loss(total):-0.003810\n",
            "recons_loss:0.004116\n",
            "grad_loss:0.096666\n",
            "dice_loss:-0.889210\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:36\n",
            "loss(total):-0.003601\n",
            "recons_loss:0.004218\n",
            "grad_loss:0.108135\n",
            "dice_loss:-0.889956\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:37\n",
            "loss(total):-0.004872\n",
            "recons_loss:0.003433\n",
            "grad_loss:0.071673\n",
            "dice_loss:-0.902230\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:38\n",
            "loss(total):-0.002940\n",
            "recons_loss:0.004828\n",
            "grad_loss:0.119234\n",
            "dice_loss:-0.896061\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:39\n",
            "loss(total):-0.003639\n",
            "recons_loss:0.004250\n",
            "grad_loss:0.102289\n",
            "dice_loss:-0.891228\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:40\n",
            "loss(total):-0.003828\n",
            "recons_loss:0.004133\n",
            "grad_loss:0.099060\n",
            "dice_loss:-0.895145\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:41\n",
            "loss(total):-0.004394\n",
            "recons_loss:0.003754\n",
            "grad_loss:0.085585\n",
            "dice_loss:-0.900392\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:42\n",
            "loss(total):-0.004183\n",
            "recons_loss:0.003929\n",
            "grad_loss:0.088522\n",
            "dice_loss:-0.899712\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:43\n",
            "loss(total):-0.002579\n",
            "recons_loss:0.005201\n",
            "grad_loss:0.105059\n",
            "dice_loss:-0.883140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:44\n",
            "loss(total):-0.003570\n",
            "recons_loss:0.004200\n",
            "grad_loss:0.113931\n",
            "dice_loss:-0.890849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:45\n",
            "loss(total):-0.003471\n",
            "recons_loss:0.004212\n",
            "grad_loss:0.106133\n",
            "dice_loss:-0.874451\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:46\n",
            "loss(total):-0.003631\n",
            "recons_loss:0.004258\n",
            "grad_loss:0.102948\n",
            "dice_loss:-0.891862\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:47\n",
            "loss(total):-0.003576\n",
            "recons_loss:0.004138\n",
            "grad_loss:0.117006\n",
            "dice_loss:-0.888429\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:48\n",
            "loss(total):-0.004301\n",
            "recons_loss:0.003664\n",
            "grad_loss:0.104249\n",
            "dice_loss:-0.900734\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:49\n",
            "loss(total):-0.003138\n",
            "recons_loss:0.004612\n",
            "grad_loss:0.115581\n",
            "dice_loss:-0.890571\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:50\n",
            "loss(total):-0.003893\n",
            "recons_loss:0.003980\n",
            "grad_loss:0.095737\n",
            "dice_loss:-0.883065\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:51\n",
            "loss(total):-0.002324\n",
            "recons_loss:0.005142\n",
            "grad_loss:0.124672\n",
            "dice_loss:-0.871257\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:52\n",
            "loss(total):-0.003809\n",
            "recons_loss:0.003959\n",
            "grad_loss:0.099164\n",
            "dice_loss:-0.875988\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:53\n",
            "loss(total):-0.004221\n",
            "recons_loss:0.003676\n",
            "grad_loss:0.101848\n",
            "dice_loss:-0.891518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:54\n",
            "loss(total):-0.004260\n",
            "recons_loss:0.003787\n",
            "grad_loss:0.086803\n",
            "dice_loss:-0.891516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:55\n",
            "loss(total):-0.003598\n",
            "recons_loss:0.004250\n",
            "grad_loss:0.106178\n",
            "dice_loss:-0.891051\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:56\n",
            "loss(total):-0.003455\n",
            "recons_loss:0.004627\n",
            "grad_loss:0.088438\n",
            "dice_loss:-0.896620\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:57\n",
            "loss(total):-0.003921\n",
            "recons_loss:0.004208\n",
            "grad_loss:0.087325\n",
            "dice_loss:-0.900288\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:58\n",
            "loss(total):-0.004105\n",
            "recons_loss:0.004090\n",
            "grad_loss:0.074473\n",
            "dice_loss:-0.893936\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:59\n",
            "loss(total):-0.003086\n",
            "recons_loss:0.004576\n",
            "grad_loss:0.133040\n",
            "dice_loss:-0.899251\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:60\n",
            "loss(total):-0.005953\n",
            "recons_loss:0.002522\n",
            "grad_loss:0.058214\n",
            "dice_loss:-0.905732\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:61\n",
            "loss(total):-0.004442\n",
            "recons_loss:0.003750\n",
            "grad_loss:0.086961\n",
            "dice_loss:-0.906172\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:62\n",
            "loss(total):-0.003201\n",
            "recons_loss:0.004863\n",
            "grad_loss:0.094684\n",
            "dice_loss:-0.901177\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:63\n",
            "loss(total):-0.004145\n",
            "recons_loss:0.003963\n",
            "grad_loss:0.092671\n",
            "dice_loss:-0.903394\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:64\n",
            "loss(total):-0.003082\n",
            "recons_loss:0.004741\n",
            "grad_loss:0.112108\n",
            "dice_loss:-0.894487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:65\n",
            "loss(total):-0.003890\n",
            "recons_loss:0.004003\n",
            "grad_loss:0.104030\n",
            "dice_loss:-0.893315\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:66\n",
            "loss(total):-0.003454\n",
            "recons_loss:0.004314\n",
            "grad_loss:0.114726\n",
            "dice_loss:-0.891489\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:67\n",
            "loss(total):-0.004018\n",
            "recons_loss:0.004072\n",
            "grad_loss:0.082380\n",
            "dice_loss:-0.891427\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:68\n",
            "loss(total):-0.003930\n",
            "recons_loss:0.004169\n",
            "grad_loss:0.094008\n",
            "dice_loss:-0.903872\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:69\n",
            "loss(total):-0.003210\n",
            "recons_loss:0.004573\n",
            "grad_loss:0.128116\n",
            "dice_loss:-0.906402\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:70\n",
            "loss(total):-0.003739\n",
            "recons_loss:0.004171\n",
            "grad_loss:0.107923\n",
            "dice_loss:-0.898878\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:71\n",
            "loss(total):-0.004050\n",
            "recons_loss:0.003782\n",
            "grad_loss:0.105357\n",
            "dice_loss:-0.888532\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:72\n",
            "loss(total):-0.002822\n",
            "recons_loss:0.004774\n",
            "grad_loss:0.124499\n",
            "dice_loss:-0.884156\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:73\n",
            "loss(total):-0.004468\n",
            "recons_loss:0.003486\n",
            "grad_loss:0.097589\n",
            "dice_loss:-0.893025\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:74\n",
            "loss(total):-0.003835\n",
            "recons_loss:0.004066\n",
            "grad_loss:0.086526\n",
            "dice_loss:-0.876648\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:75\n",
            "loss(total):-0.003345\n",
            "recons_loss:0.004625\n",
            "grad_loss:0.095275\n",
            "dice_loss:-0.892279\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:76\n",
            "loss(total):-0.002605\n",
            "recons_loss:0.005158\n",
            "grad_loss:0.105038\n",
            "dice_loss:-0.881387\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:77\n",
            "loss(total):-0.004567\n",
            "recons_loss:0.003496\n",
            "grad_loss:0.093769\n",
            "dice_loss:-0.900103\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:78\n",
            "loss(total):-0.003567\n",
            "recons_loss:0.004303\n",
            "grad_loss:0.106322\n",
            "dice_loss:-0.893324\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:79\n",
            "loss(total):-0.004854\n",
            "recons_loss:0.003374\n",
            "grad_loss:0.079758\n",
            "dice_loss:-0.902487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:80\n",
            "loss(total):-0.004197\n",
            "recons_loss:0.003797\n",
            "grad_loss:0.108324\n",
            "dice_loss:-0.907705\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:81\n",
            "loss(total):-0.004027\n",
            "recons_loss:0.003926\n",
            "grad_loss:0.098755\n",
            "dice_loss:-0.894103\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:82\n",
            "loss(total):-0.002884\n",
            "recons_loss:0.004754\n",
            "grad_loss:0.120213\n",
            "dice_loss:-0.884000\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:83\n",
            "loss(total):-0.002496\n",
            "recons_loss:0.005140\n",
            "grad_loss:0.124021\n",
            "dice_loss:-0.887548\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:84\n",
            "loss(total):-0.003938\n",
            "recons_loss:0.004007\n",
            "grad_loss:0.097939\n",
            "dice_loss:-0.892418\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:85\n",
            "loss(total):-0.002844\n",
            "recons_loss:0.004779\n",
            "grad_loss:0.123308\n",
            "dice_loss:-0.885552\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:86\n",
            "loss(total):-0.003098\n",
            "recons_loss:0.004561\n",
            "grad_loss:0.111127\n",
            "dice_loss:-0.877043\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:87\n",
            "loss(total):-0.004529\n",
            "recons_loss:0.003566\n",
            "grad_loss:0.084142\n",
            "dice_loss:-0.893697\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:88\n",
            "loss(total):-0.003693\n",
            "recons_loss:0.004371\n",
            "grad_loss:0.087111\n",
            "dice_loss:-0.893522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:89\n",
            "loss(total):-0.003866\n",
            "recons_loss:0.004169\n",
            "grad_loss:0.097216\n",
            "dice_loss:-0.900773\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:90\n",
            "loss(total):-0.004632\n",
            "recons_loss:0.003576\n",
            "grad_loss:0.084183\n",
            "dice_loss:-0.905069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:91\n",
            "loss(total):-0.004781\n",
            "recons_loss:0.003556\n",
            "grad_loss:0.067875\n",
            "dice_loss:-0.901632\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:92\n",
            "loss(total):-0.003640\n",
            "recons_loss:0.004569\n",
            "grad_loss:0.080780\n",
            "dice_loss:-0.901658\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:93\n",
            "loss(total):-0.004475\n",
            "recons_loss:0.003660\n",
            "grad_loss:0.082655\n",
            "dice_loss:-0.896152\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:94\n",
            "loss(total):-0.002882\n",
            "recons_loss:0.004879\n",
            "grad_loss:0.121758\n",
            "dice_loss:-0.897822\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:95\n",
            "loss(total):-0.001478\n",
            "recons_loss:0.006095\n",
            "grad_loss:0.126051\n",
            "dice_loss:-0.883377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:96\n",
            "loss(total):-0.003176\n",
            "recons_loss:0.004443\n",
            "grad_loss:0.118191\n",
            "dice_loss:-0.880082\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:97\n",
            "loss(total):-0.003589\n",
            "recons_loss:0.004239\n",
            "grad_loss:0.115268\n",
            "dice_loss:-0.898066\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:98\n",
            "loss(total):-0.004136\n",
            "recons_loss:0.004110\n",
            "grad_loss:0.089121\n",
            "dice_loss:-0.913678\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:99\n",
            "loss(total):-0.003797\n",
            "recons_loss:0.004174\n",
            "grad_loss:0.093640\n",
            "dice_loss:-0.890729\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:100\n",
            "loss(total):-0.001750\n",
            "recons_loss:0.005781\n",
            "grad_loss:0.140622\n",
            "dice_loss:-0.893691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:101\n",
            "loss(total):-0.003014\n",
            "recons_loss:0.004775\n",
            "grad_loss:0.103454\n",
            "dice_loss:-0.882323\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:102\n",
            "loss(total):-0.004397\n",
            "recons_loss:0.003500\n",
            "grad_loss:0.094755\n",
            "dice_loss:-0.884444\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:103\n",
            "loss(total):-0.003887\n",
            "recons_loss:0.004037\n",
            "grad_loss:0.103421\n",
            "dice_loss:-0.895832\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:104\n",
            "loss(total):-0.004791\n",
            "recons_loss:0.003316\n",
            "grad_loss:0.091649\n",
            "dice_loss:-0.902347\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:105\n",
            "loss(total):-0.005206\n",
            "recons_loss:0.003078\n",
            "grad_loss:0.073158\n",
            "dice_loss:-0.901579\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:106\n",
            "loss(total):-0.003707\n",
            "recons_loss:0.004201\n",
            "grad_loss:0.106328\n",
            "dice_loss:-0.897155\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:107\n",
            "loss(total):-0.004213\n",
            "recons_loss:0.003946\n",
            "grad_loss:0.080625\n",
            "dice_loss:-0.896510\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:108\n",
            "loss(total):-0.002964\n",
            "recons_loss:0.004700\n",
            "grad_loss:0.111891\n",
            "dice_loss:-0.878358\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:109\n",
            "loss(total):-0.003795\n",
            "recons_loss:0.004169\n",
            "grad_loss:0.080782\n",
            "dice_loss:-0.877112\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:110\n",
            "loss(total):-0.004779\n",
            "recons_loss:0.003273\n",
            "grad_loss:0.078603\n",
            "dice_loss:-0.883818\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:111\n",
            "loss(total):-0.005035\n",
            "recons_loss:0.003178\n",
            "grad_loss:0.079875\n",
            "dice_loss:-0.901172\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:112\n",
            "loss(total):-0.004073\n",
            "recons_loss:0.003994\n",
            "grad_loss:0.091579\n",
            "dice_loss:-0.898274\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:113\n",
            "loss(total):-0.004066\n",
            "recons_loss:0.004085\n",
            "grad_loss:0.094788\n",
            "dice_loss:-0.909879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:114\n",
            "loss(total):-0.003338\n",
            "recons_loss:0.004518\n",
            "grad_loss:0.101415\n",
            "dice_loss:-0.887026\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:115\n",
            "loss(total):-0.004048\n",
            "recons_loss:0.003913\n",
            "grad_loss:0.080864\n",
            "dice_loss:-0.877018\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:116\n",
            "loss(total):-0.004313\n",
            "recons_loss:0.003712\n",
            "grad_loss:0.086777\n",
            "dice_loss:-0.889324\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:117\n",
            "loss(total):-0.004487\n",
            "recons_loss:0.003509\n",
            "grad_loss:0.091384\n",
            "dice_loss:-0.891042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:118\n",
            "loss(total):-0.004679\n",
            "recons_loss:0.003382\n",
            "grad_loss:0.093957\n",
            "dice_loss:-0.900011\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:119\n",
            "loss(total):-0.004170\n",
            "recons_loss:0.003938\n",
            "grad_loss:0.083127\n",
            "dice_loss:-0.893906\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:120\n",
            "loss(total):-0.003654\n",
            "recons_loss:0.004778\n",
            "grad_loss:0.069318\n",
            "dice_loss:-0.912500\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:121\n",
            "loss(total):-0.003178\n",
            "recons_loss:0.004672\n",
            "grad_loss:0.109136\n",
            "dice_loss:-0.894101\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:122\n",
            "loss(total):-0.002226\n",
            "recons_loss:0.005553\n",
            "grad_loss:0.110805\n",
            "dice_loss:-0.888729\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:123\n",
            "loss(total):-0.004404\n",
            "recons_loss:0.003699\n",
            "grad_loss:0.096371\n",
            "dice_loss:-0.906645\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:124\n",
            "loss(total):-0.003049\n",
            "recons_loss:0.004715\n",
            "grad_loss:0.106389\n",
            "dice_loss:-0.882750\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:125\n",
            "loss(total):-0.003763\n",
            "recons_loss:0.004160\n",
            "grad_loss:0.106636\n",
            "dice_loss:-0.898912\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:126\n",
            "loss(total):-0.002187\n",
            "recons_loss:0.005389\n",
            "grad_loss:0.118696\n",
            "dice_loss:-0.876260\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:127\n",
            "loss(total):-0.004927\n",
            "recons_loss:0.003506\n",
            "grad_loss:0.062152\n",
            "dice_loss:-0.905480\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:128\n",
            "loss(total):-0.003834\n",
            "recons_loss:0.004150\n",
            "grad_loss:0.099976\n",
            "dice_loss:-0.898362\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:129\n",
            "loss(total):-0.003450\n",
            "recons_loss:0.004540\n",
            "grad_loss:0.099771\n",
            "dice_loss:-0.898759\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:130\n",
            "loss(total):-0.004576\n",
            "recons_loss:0.003395\n",
            "grad_loss:0.087313\n",
            "dice_loss:-0.884400\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:131\n",
            "loss(total):-0.003992\n",
            "recons_loss:0.003936\n",
            "grad_loss:0.098581\n",
            "dice_loss:-0.891355\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:132\n",
            "loss(total):-0.003386\n",
            "recons_loss:0.004479\n",
            "grad_loss:0.101958\n",
            "dice_loss:-0.888509\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:133\n",
            "loss(total):-0.002304\n",
            "recons_loss:0.005337\n",
            "grad_loss:0.121241\n",
            "dice_loss:-0.885333\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:134\n",
            "loss(total):-0.002984\n",
            "recons_loss:0.004988\n",
            "grad_loss:0.097290\n",
            "dice_loss:-0.894411\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:135\n",
            "loss(total):-0.004213\n",
            "recons_loss:0.003662\n",
            "grad_loss:0.108797\n",
            "dice_loss:-0.896311\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:136\n",
            "loss(total):-0.005059\n",
            "recons_loss:0.003283\n",
            "grad_loss:0.072410\n",
            "dice_loss:-0.906594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:137\n",
            "loss(total):-0.004086\n",
            "recons_loss:0.003830\n",
            "grad_loss:0.102737\n",
            "dice_loss:-0.894359\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:138\n",
            "loss(total):-0.003498\n",
            "recons_loss:0.004381\n",
            "grad_loss:0.108754\n",
            "dice_loss:-0.896579\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:139\n",
            "loss(total):-0.003382\n",
            "recons_loss:0.004641\n",
            "grad_loss:0.079815\n",
            "dice_loss:-0.882062\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:140\n",
            "loss(total):-0.004221\n",
            "recons_loss:0.003871\n",
            "grad_loss:0.068553\n",
            "dice_loss:-0.877764\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:141\n",
            "loss(total):-0.003976\n",
            "recons_loss:0.004171\n",
            "grad_loss:0.076482\n",
            "dice_loss:-0.891174\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:142\n",
            "loss(total):-0.004466\n",
            "recons_loss:0.003680\n",
            "grad_loss:0.092597\n",
            "dice_loss:-0.907267\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:143\n",
            "loss(total):-0.003937\n",
            "recons_loss:0.004034\n",
            "grad_loss:0.097649\n",
            "dice_loss:-0.894758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:144\n",
            "loss(total):-0.004345\n",
            "recons_loss:0.003854\n",
            "grad_loss:0.073388\n",
            "dice_loss:-0.893359\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:145\n",
            "loss(total):-0.003524\n",
            "recons_loss:0.004172\n",
            "grad_loss:0.110725\n",
            "dice_loss:-0.880345\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:146\n",
            "loss(total):-0.004612\n",
            "recons_loss:0.003621\n",
            "grad_loss:0.092450\n",
            "dice_loss:-0.915777\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:147\n",
            "loss(total):-0.005182\n",
            "recons_loss:0.003101\n",
            "grad_loss:0.064449\n",
            "dice_loss:-0.892743\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:148\n",
            "loss(total):-0.004095\n",
            "recons_loss:0.003904\n",
            "grad_loss:0.094615\n",
            "dice_loss:-0.894445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:149\n",
            "loss(total):-0.005434\n",
            "recons_loss:0.003045\n",
            "grad_loss:0.063764\n",
            "dice_loss:-0.911631\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:150\n",
            "loss(total):-0.003188\n",
            "recons_loss:0.004803\n",
            "grad_loss:0.099526\n",
            "dice_loss:-0.898555\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:151\n",
            "loss(total):-0.004652\n",
            "recons_loss:0.003555\n",
            "grad_loss:0.079437\n",
            "dice_loss:-0.900108\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:152\n",
            "loss(total):-0.002874\n",
            "recons_loss:0.004634\n",
            "grad_loss:0.126722\n",
            "dice_loss:-0.877511\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:153\n",
            "loss(total):-0.004120\n",
            "recons_loss:0.003909\n",
            "grad_loss:0.087755\n",
            "dice_loss:-0.890656\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:154\n",
            "loss(total):-0.003744\n",
            "recons_loss:0.004262\n",
            "grad_loss:0.081799\n",
            "dice_loss:-0.882377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:155\n",
            "loss(total):-0.003949\n",
            "recons_loss:0.004285\n",
            "grad_loss:0.072428\n",
            "dice_loss:-0.895777\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:156\n",
            "loss(total):-0.003745\n",
            "recons_loss:0.004168\n",
            "grad_loss:0.109681\n",
            "dice_loss:-0.900941\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:157\n",
            "loss(total):-0.003349\n",
            "recons_loss:0.004770\n",
            "grad_loss:0.085748\n",
            "dice_loss:-0.897661\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:158\n",
            "loss(total):-0.003980\n",
            "recons_loss:0.004033\n",
            "grad_loss:0.085693\n",
            "dice_loss:-0.886996\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:159\n",
            "loss(total):-0.005037\n",
            "recons_loss:0.002985\n",
            "grad_loss:0.080935\n",
            "dice_loss:-0.883194\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:160\n",
            "loss(total):-0.002972\n",
            "recons_loss:0.004877\n",
            "grad_loss:0.110878\n",
            "dice_loss:-0.895748\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:161\n",
            "loss(total):-0.004393\n",
            "recons_loss:0.003718\n",
            "grad_loss:0.082779\n",
            "dice_loss:-0.893899\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:162\n",
            "loss(total):-0.002394\n",
            "recons_loss:0.005228\n",
            "grad_loss:0.114081\n",
            "dice_loss:-0.876267\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:163\n",
            "loss(total):-0.004305\n",
            "recons_loss:0.003868\n",
            "grad_loss:0.086384\n",
            "dice_loss:-0.903676\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:164\n",
            "loss(total):-0.004531\n",
            "recons_loss:0.003614\n",
            "grad_loss:0.079388\n",
            "dice_loss:-0.893940\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:165\n",
            "loss(total):-0.004557\n",
            "recons_loss:0.003359\n",
            "grad_loss:0.095170\n",
            "dice_loss:-0.886750\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:166\n",
            "loss(total):-0.003195\n",
            "recons_loss:0.004670\n",
            "grad_loss:0.101603\n",
            "dice_loss:-0.888058\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:167\n",
            "loss(total):-0.003368\n",
            "recons_loss:0.004665\n",
            "grad_loss:0.092383\n",
            "dice_loss:-0.895681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:168\n",
            "loss(total):-0.004570\n",
            "recons_loss:0.003328\n",
            "grad_loss:0.105588\n",
            "dice_loss:-0.895470\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:169\n",
            "loss(total):-0.003265\n",
            "recons_loss:0.004545\n",
            "grad_loss:0.124506\n",
            "dice_loss:-0.905471\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:170\n",
            "loss(total):-0.003950\n",
            "recons_loss:0.004122\n",
            "grad_loss:0.088615\n",
            "dice_loss:-0.895765\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:171\n",
            "loss(total):-0.005098\n",
            "recons_loss:0.003184\n",
            "grad_loss:0.077474\n",
            "dice_loss:-0.905687\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:172\n",
            "loss(total):-0.004299\n",
            "recons_loss:0.003801\n",
            "grad_loss:0.094594\n",
            "dice_loss:-0.904587\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:173\n",
            "loss(total):-0.003320\n",
            "recons_loss:0.004518\n",
            "grad_loss:0.116660\n",
            "dice_loss:-0.900457\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:174\n",
            "loss(total):-0.004489\n",
            "recons_loss:0.003608\n",
            "grad_loss:0.091653\n",
            "dice_loss:-0.901302\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:175\n",
            "loss(total):-0.005084\n",
            "recons_loss:0.003198\n",
            "grad_loss:0.077917\n",
            "dice_loss:-0.906195\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:176\n",
            "loss(total):-0.004253\n",
            "recons_loss:0.003864\n",
            "grad_loss:0.084883\n",
            "dice_loss:-0.896523\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:177\n",
            "loss(total):-0.004265\n",
            "recons_loss:0.003904\n",
            "grad_loss:0.085203\n",
            "dice_loss:-0.902111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:178\n",
            "loss(total):-0.004284\n",
            "recons_loss:0.003849\n",
            "grad_loss:0.081833\n",
            "dice_loss:-0.895154\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:179\n",
            "loss(total):-0.004317\n",
            "recons_loss:0.003766\n",
            "grad_loss:0.081453\n",
            "dice_loss:-0.889747\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:180\n",
            "loss(total):-0.002665\n",
            "recons_loss:0.005114\n",
            "grad_loss:0.103122\n",
            "dice_loss:-0.881014\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:181\n",
            "loss(total):-0.004661\n",
            "recons_loss:0.003371\n",
            "grad_loss:0.081286\n",
            "dice_loss:-0.884439\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:182\n",
            "loss(total):-0.003526\n",
            "recons_loss:0.004313\n",
            "grad_loss:0.100519\n",
            "dice_loss:-0.884390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:183\n",
            "loss(total):-0.003978\n",
            "recons_loss:0.004078\n",
            "grad_loss:0.089038\n",
            "dice_loss:-0.894671\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:184\n",
            "loss(total):-0.003411\n",
            "recons_loss:0.004477\n",
            "grad_loss:0.119714\n",
            "dice_loss:-0.908515\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:185\n",
            "loss(total):-0.003515\n",
            "recons_loss:0.004194\n",
            "grad_loss:0.113755\n",
            "dice_loss:-0.884683\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:186\n",
            "loss(total):-0.004336\n",
            "recons_loss:0.003844\n",
            "grad_loss:0.086822\n",
            "dice_loss:-0.904797\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:187\n",
            "loss(total):-0.003556\n",
            "recons_loss:0.004369\n",
            "grad_loss:0.089518\n",
            "dice_loss:-0.882070\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:188\n",
            "loss(total):-0.002209\n",
            "recons_loss:0.005313\n",
            "grad_loss:0.124894\n",
            "dice_loss:-0.877070\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:189\n",
            "loss(total):-0.002934\n",
            "recons_loss:0.004921\n",
            "grad_loss:0.098885\n",
            "dice_loss:-0.884422\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:190\n",
            "loss(total):-0.004480\n",
            "recons_loss:0.003684\n",
            "grad_loss:0.089947\n",
            "dice_loss:-0.906344\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:191\n",
            "loss(total):-0.002089\n",
            "recons_loss:0.005575\n",
            "grad_loss:0.103855\n",
            "dice_loss:-0.870208\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:192\n",
            "loss(total):-0.003328\n",
            "recons_loss:0.004435\n",
            "grad_loss:0.105044\n",
            "dice_loss:-0.881276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:193\n",
            "loss(total):-0.004122\n",
            "recons_loss:0.004011\n",
            "grad_loss:0.083241\n",
            "dice_loss:-0.896591\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:194\n",
            "loss(total):-0.003683\n",
            "recons_loss:0.004145\n",
            "grad_loss:0.088199\n",
            "dice_loss:-0.871069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:195\n",
            "loss(total):-0.003656\n",
            "recons_loss:0.004273\n",
            "grad_loss:0.102062\n",
            "dice_loss:-0.895009\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:196\n",
            "loss(total):-0.004126\n",
            "recons_loss:0.003844\n",
            "grad_loss:0.100410\n",
            "dice_loss:-0.897381\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:197\n",
            "loss(total):-0.002392\n",
            "recons_loss:0.005376\n",
            "grad_loss:0.117028\n",
            "dice_loss:-0.893868\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:198\n",
            "loss(total):-0.004606\n",
            "recons_loss:0.003572\n",
            "grad_loss:0.080375\n",
            "dice_loss:-0.898181\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:199\n",
            "loss(total):-0.002959\n",
            "recons_loss:0.004729\n",
            "grad_loss:0.115622\n",
            "dice_loss:-0.884496\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:200\n",
            "loss(total):-0.002681\n",
            "recons_loss:0.004950\n",
            "grad_loss:0.125453\n",
            "dice_loss:-0.888564\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:201\n",
            "loss(total):-0.002953\n",
            "recons_loss:0.004858\n",
            "grad_loss:0.109422\n",
            "dice_loss:-0.890546\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:202\n",
            "loss(total):-0.002594\n",
            "recons_loss:0.004981\n",
            "grad_loss:0.126910\n",
            "dice_loss:-0.884403\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:203\n",
            "loss(total):-0.004562\n",
            "recons_loss:0.003703\n",
            "grad_loss:0.091174\n",
            "dice_loss:-0.917680\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:204\n",
            "loss(total):-0.005093\n",
            "recons_loss:0.003202\n",
            "grad_loss:0.068071\n",
            "dice_loss:-0.897539\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:205\n",
            "loss(total):-0.003588\n",
            "recons_loss:0.004064\n",
            "grad_loss:0.117792\n",
            "dice_loss:-0.882996\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:206\n",
            "loss(total):-0.003143\n",
            "recons_loss:0.004703\n",
            "grad_loss:0.110036\n",
            "dice_loss:-0.894641\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:207\n",
            "loss(total):-0.003998\n",
            "recons_loss:0.004032\n",
            "grad_loss:0.090677\n",
            "dice_loss:-0.893671\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:208\n",
            "loss(total):-0.004087\n",
            "recons_loss:0.003781\n",
            "grad_loss:0.089908\n",
            "dice_loss:-0.876704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:209\n",
            "loss(total):-0.004411\n",
            "recons_loss:0.003690\n",
            "grad_loss:0.077460\n",
            "dice_loss:-0.887527\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:210\n",
            "loss(total):-0.004100\n",
            "recons_loss:0.003975\n",
            "grad_loss:0.087755\n",
            "dice_loss:-0.895259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:211\n",
            "loss(total):-0.004840\n",
            "recons_loss:0.003428\n",
            "grad_loss:0.072728\n",
            "dice_loss:-0.899605\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:212\n",
            "loss(total):-0.005069\n",
            "recons_loss:0.003089\n",
            "grad_loss:0.078404\n",
            "dice_loss:-0.894241\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:213\n",
            "loss(total):-0.003780\n",
            "recons_loss:0.004176\n",
            "grad_loss:0.093450\n",
            "dice_loss:-0.889083\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:214\n",
            "loss(total):-0.003295\n",
            "recons_loss:0.004529\n",
            "grad_loss:0.105340\n",
            "dice_loss:-0.887813\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:215\n",
            "loss(total):-0.003930\n",
            "recons_loss:0.003927\n",
            "grad_loss:0.088884\n",
            "dice_loss:-0.874494\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:216\n",
            "loss(total):-0.004586\n",
            "recons_loss:0.003326\n",
            "grad_loss:0.097399\n",
            "dice_loss:-0.888524\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:217\n",
            "loss(total):-0.004584\n",
            "recons_loss:0.003672\n",
            "grad_loss:0.074335\n",
            "dice_loss:-0.900014\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:218\n",
            "loss(total):-0.003375\n",
            "recons_loss:0.004501\n",
            "grad_loss:0.114853\n",
            "dice_loss:-0.902465\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:219\n",
            "loss(total):-0.003854\n",
            "recons_loss:0.004249\n",
            "grad_loss:0.098903\n",
            "dice_loss:-0.909133\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:220\n",
            "loss(total):-0.003410\n",
            "recons_loss:0.004390\n",
            "grad_loss:0.119570\n",
            "dice_loss:-0.899560\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:221\n",
            "loss(total):-0.002377\n",
            "recons_loss:0.005348\n",
            "grad_loss:0.116360\n",
            "dice_loss:-0.888818\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:222\n",
            "loss(total):-0.003221\n",
            "recons_loss:0.004530\n",
            "grad_loss:0.131839\n",
            "dice_loss:-0.906957\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:223\n",
            "loss(total):-0.002955\n",
            "recons_loss:0.004658\n",
            "grad_loss:0.130674\n",
            "dice_loss:-0.891982\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:224\n",
            "loss(total):-0.004692\n",
            "recons_loss:0.003513\n",
            "grad_loss:0.085923\n",
            "dice_loss:-0.906426\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:225\n",
            "loss(total):-0.003022\n",
            "recons_loss:0.004745\n",
            "grad_loss:0.109084\n",
            "dice_loss:-0.885767\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:226\n",
            "loss(total):-0.003779\n",
            "recons_loss:0.004029\n",
            "grad_loss:0.099163\n",
            "dice_loss:-0.880037\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:227\n",
            "loss(total):-0.004085\n",
            "recons_loss:0.003986\n",
            "grad_loss:0.082478\n",
            "dice_loss:-0.889575\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:228\n",
            "loss(total):-0.004347\n",
            "recons_loss:0.003742\n",
            "grad_loss:0.093601\n",
            "dice_loss:-0.902495\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:229\n",
            "loss(total):-0.005099\n",
            "recons_loss:0.003038\n",
            "grad_loss:0.089109\n",
            "dice_loss:-0.902780\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:230\n",
            "loss(total):-0.004421\n",
            "recons_loss:0.003534\n",
            "grad_loss:0.093311\n",
            "dice_loss:-0.888807\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:231\n",
            "loss(total):-0.004085\n",
            "recons_loss:0.003967\n",
            "grad_loss:0.100607\n",
            "dice_loss:-0.905745\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:232\n",
            "loss(total):-0.003322\n",
            "recons_loss:0.004529\n",
            "grad_loss:0.110197\n",
            "dice_loss:-0.895275\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:233\n",
            "loss(total):-0.003930\n",
            "recons_loss:0.003990\n",
            "grad_loss:0.106040\n",
            "dice_loss:-0.898094\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:234\n",
            "loss(total):-0.002431\n",
            "recons_loss:0.005233\n",
            "grad_loss:0.117038\n",
            "dice_loss:-0.883525\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:235\n",
            "loss(total):-0.004359\n",
            "recons_loss:0.003594\n",
            "grad_loss:0.091800\n",
            "dice_loss:-0.887052\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:236\n",
            "loss(total):-0.003781\n",
            "recons_loss:0.004027\n",
            "grad_loss:0.110810\n",
            "dice_loss:-0.891610\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:237\n",
            "loss(total):-0.002262\n",
            "recons_loss:0.005310\n",
            "grad_loss:0.113154\n",
            "dice_loss:-0.870442\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:238\n",
            "loss(total):-0.003780\n",
            "recons_loss:0.004258\n",
            "grad_loss:0.098401\n",
            "dice_loss:-0.902189\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:239\n",
            "loss(total):-0.003763\n",
            "recons_loss:0.004279\n",
            "grad_loss:0.086019\n",
            "dice_loss:-0.890211\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:240\n",
            "loss(total):-0.004069\n",
            "recons_loss:0.003906\n",
            "grad_loss:0.092793\n",
            "dice_loss:-0.890235\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:241\n",
            "loss(total):-0.003393\n",
            "recons_loss:0.004498\n",
            "grad_loss:0.087210\n",
            "dice_loss:-0.876273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:242\n",
            "loss(total):-0.002977\n",
            "recons_loss:0.004774\n",
            "grad_loss:0.107615\n",
            "dice_loss:-0.882709\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:243\n",
            "loss(total):-0.005271\n",
            "recons_loss:0.002983\n",
            "grad_loss:0.069774\n",
            "dice_loss:-0.895241\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:244\n",
            "loss(total):-0.004364\n",
            "recons_loss:0.003616\n",
            "grad_loss:0.099683\n",
            "dice_loss:-0.897713\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:245\n",
            "loss(total):-0.003165\n",
            "recons_loss:0.004610\n",
            "grad_loss:0.118892\n",
            "dice_loss:-0.896406\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:246\n",
            "loss(total):-0.003893\n",
            "recons_loss:0.004035\n",
            "grad_loss:0.094896\n",
            "dice_loss:-0.887687\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:247\n",
            "loss(total):-0.004036\n",
            "recons_loss:0.004083\n",
            "grad_loss:0.088324\n",
            "dice_loss:-0.900250\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:248\n",
            "loss(total):-0.002332\n",
            "recons_loss:0.005448\n",
            "grad_loss:0.106602\n",
            "dice_loss:-0.884557\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:249\n",
            "loss(total):-0.003911\n",
            "recons_loss:0.004313\n",
            "grad_loss:0.066361\n",
            "dice_loss:-0.888828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:250\n",
            "loss(total):-0.003832\n",
            "recons_loss:0.004229\n",
            "grad_loss:0.086370\n",
            "dice_loss:-0.892431\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:251\n",
            "loss(total):-0.003208\n",
            "recons_loss:0.004606\n",
            "grad_loss:0.106710\n",
            "dice_loss:-0.888155\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:252\n",
            "loss(total):-0.004591\n",
            "recons_loss:0.003683\n",
            "grad_loss:0.076549\n",
            "dice_loss:-0.903960\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:253\n",
            "loss(total):-0.003371\n",
            "recons_loss:0.004393\n",
            "grad_loss:0.127657\n",
            "dice_loss:-0.904066\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:254\n",
            "loss(total):-0.003696\n",
            "recons_loss:0.004112\n",
            "grad_loss:0.115039\n",
            "dice_loss:-0.895888\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:255\n",
            "loss(total):-0.002322\n",
            "recons_loss:0.005196\n",
            "grad_loss:0.135924\n",
            "dice_loss:-0.887715\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:256\n",
            "loss(total):-0.003453\n",
            "recons_loss:0.004448\n",
            "grad_loss:0.104112\n",
            "dice_loss:-0.894159\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:257\n",
            "loss(total):-0.002576\n",
            "recons_loss:0.005023\n",
            "grad_loss:0.112867\n",
            "dice_loss:-0.872733\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:258\n",
            "loss(total):-0.004805\n",
            "recons_loss:0.003409\n",
            "grad_loss:0.086934\n",
            "dice_loss:-0.908329\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:259\n",
            "loss(total):-0.004389\n",
            "recons_loss:0.003527\n",
            "grad_loss:0.102672\n",
            "dice_loss:-0.894291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:260\n",
            "loss(total):-0.003930\n",
            "recons_loss:0.004017\n",
            "grad_loss:0.092964\n",
            "dice_loss:-0.887748\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:261\n",
            "loss(total):-0.004293\n",
            "recons_loss:0.003727\n",
            "grad_loss:0.093820\n",
            "dice_loss:-0.895809\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:262\n",
            "loss(total):-0.003546\n",
            "recons_loss:0.004206\n",
            "grad_loss:0.124536\n",
            "dice_loss:-0.899711\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:263\n",
            "loss(total):-0.004271\n",
            "recons_loss:0.003789\n",
            "grad_loss:0.090724\n",
            "dice_loss:-0.896762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:264\n",
            "loss(total):-0.004326\n",
            "recons_loss:0.003770\n",
            "grad_loss:0.088190\n",
            "dice_loss:-0.897754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:265\n",
            "loss(total):-0.004331\n",
            "recons_loss:0.003721\n",
            "grad_loss:0.091265\n",
            "dice_loss:-0.896533\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:266\n",
            "loss(total):-0.003933\n",
            "recons_loss:0.003953\n",
            "grad_loss:0.105768\n",
            "dice_loss:-0.894393\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:267\n",
            "loss(total):-0.004662\n",
            "recons_loss:0.003427\n",
            "grad_loss:0.082538\n",
            "dice_loss:-0.891406\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:268\n",
            "loss(total):-0.004509\n",
            "recons_loss:0.003519\n",
            "grad_loss:0.094497\n",
            "dice_loss:-0.897333\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:269\n",
            "loss(total):-0.003891\n",
            "recons_loss:0.004173\n",
            "grad_loss:0.079294\n",
            "dice_loss:-0.885665\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:0\n",
            "loss(total):-0.004220\n",
            "recons_loss:0.003713\n",
            "grad_loss:0.099046\n",
            "dice_loss:-0.892317\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:1\n",
            "loss(total):-0.004826\n",
            "recons_loss:0.003288\n",
            "grad_loss:0.089332\n",
            "dice_loss:-0.900755\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:2\n",
            "loss(total):-0.005364\n",
            "recons_loss:0.002828\n",
            "grad_loss:0.082962\n",
            "dice_loss:-0.902125\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:3\n",
            "loss(total):-0.003792\n",
            "recons_loss:0.004402\n",
            "grad_loss:0.076246\n",
            "dice_loss:-0.895578\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:4\n",
            "loss(total):-0.003990\n",
            "recons_loss:0.003951\n",
            "grad_loss:0.099110\n",
            "dice_loss:-0.893214\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:5\n",
            "loss(total):-0.004136\n",
            "recons_loss:0.003858\n",
            "grad_loss:0.092405\n",
            "dice_loss:-0.891772\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:6\n",
            "loss(total):-0.003600\n",
            "recons_loss:0.004278\n",
            "grad_loss:0.110351\n",
            "dice_loss:-0.898097\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:7\n",
            "loss(total):-0.003415\n",
            "recons_loss:0.004468\n",
            "grad_loss:0.098132\n",
            "dice_loss:-0.886401\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:8\n",
            "loss(total):-0.004150\n",
            "recons_loss:0.003816\n",
            "grad_loss:0.088562\n",
            "dice_loss:-0.885146\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:9\n",
            "loss(total):-0.003643\n",
            "recons_loss:0.004396\n",
            "grad_loss:0.083286\n",
            "dice_loss:-0.887261\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:10\n",
            "loss(total):-0.003463\n",
            "recons_loss:0.004395\n",
            "grad_loss:0.090220\n",
            "dice_loss:-0.875977\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:11\n",
            "loss(total):-0.003505\n",
            "recons_loss:0.004250\n",
            "grad_loss:0.112298\n",
            "dice_loss:-0.887824\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:12\n",
            "loss(total):-0.004074\n",
            "recons_loss:0.003828\n",
            "grad_loss:0.098805\n",
            "dice_loss:-0.889044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:13\n",
            "loss(total):-0.004333\n",
            "recons_loss:0.003663\n",
            "grad_loss:0.099983\n",
            "dice_loss:-0.899597\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:14\n",
            "loss(total):-0.004707\n",
            "recons_loss:0.003356\n",
            "grad_loss:0.094501\n",
            "dice_loss:-0.900828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:15\n",
            "loss(total):-0.003245\n",
            "recons_loss:0.004510\n",
            "grad_loss:0.104705\n",
            "dice_loss:-0.880289\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:16\n",
            "loss(total):-0.004919\n",
            "recons_loss:0.003231\n",
            "grad_loss:0.087755\n",
            "dice_loss:-0.902740\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:17\n",
            "loss(total):-0.003636\n",
            "recons_loss:0.004197\n",
            "grad_loss:0.098888\n",
            "dice_loss:-0.882160\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:18\n",
            "loss(total):-0.004473\n",
            "recons_loss:0.003763\n",
            "grad_loss:0.077284\n",
            "dice_loss:-0.900939\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:19\n",
            "loss(total):-0.003995\n",
            "recons_loss:0.004074\n",
            "grad_loss:0.089996\n",
            "dice_loss:-0.896904\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:20\n",
            "loss(total):-0.003799\n",
            "recons_loss:0.004164\n",
            "grad_loss:0.096008\n",
            "dice_loss:-0.892270\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:21\n",
            "loss(total):-0.003285\n",
            "recons_loss:0.004581\n",
            "grad_loss:0.089777\n",
            "dice_loss:-0.876405\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:22\n",
            "loss(total):-0.004450\n",
            "recons_loss:0.003530\n",
            "grad_loss:0.092692\n",
            "dice_loss:-0.890653\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:23\n",
            "loss(total):-0.003714\n",
            "recons_loss:0.004155\n",
            "grad_loss:0.102409\n",
            "dice_loss:-0.889225\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:24\n",
            "loss(total):-0.004491\n",
            "recons_loss:0.003792\n",
            "grad_loss:0.085603\n",
            "dice_loss:-0.913902\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:25\n",
            "loss(total):-0.003133\n",
            "recons_loss:0.004787\n",
            "grad_loss:0.101003\n",
            "dice_loss:-0.892991\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:26\n",
            "loss(total):-0.003641\n",
            "recons_loss:0.004349\n",
            "grad_loss:0.101797\n",
            "dice_loss:-0.900743\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:27\n",
            "loss(total):-0.003527\n",
            "recons_loss:0.004329\n",
            "grad_loss:0.095980\n",
            "dice_loss:-0.881661\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:28\n",
            "loss(total):-0.004256\n",
            "recons_loss:0.003825\n",
            "grad_loss:0.081825\n",
            "dice_loss:-0.889843\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:29\n",
            "loss(total):-0.003835\n",
            "recons_loss:0.003999\n",
            "grad_loss:0.106958\n",
            "dice_loss:-0.890364\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:30\n",
            "loss(total):-0.003531\n",
            "recons_loss:0.004286\n",
            "grad_loss:0.107283\n",
            "dice_loss:-0.889002\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:31\n",
            "loss(total):-0.003006\n",
            "recons_loss:0.004807\n",
            "grad_loss:0.111947\n",
            "dice_loss:-0.893277\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:32\n",
            "loss(total):-0.004372\n",
            "recons_loss:0.003789\n",
            "grad_loss:0.096156\n",
            "dice_loss:-0.912316\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:33\n",
            "loss(total):-0.005220\n",
            "recons_loss:0.003229\n",
            "grad_loss:0.060547\n",
            "dice_loss:-0.905499\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:34\n",
            "loss(total):-0.003784\n",
            "recons_loss:0.004179\n",
            "grad_loss:0.085160\n",
            "dice_loss:-0.881453\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:35\n",
            "loss(total):-0.004084\n",
            "recons_loss:0.003914\n",
            "grad_loss:0.090755\n",
            "dice_loss:-0.890581\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:36\n",
            "loss(total):-0.004450\n",
            "recons_loss:0.003521\n",
            "grad_loss:0.088100\n",
            "dice_loss:-0.885210\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:37\n",
            "loss(total):-0.004336\n",
            "recons_loss:0.003766\n",
            "grad_loss:0.090605\n",
            "dice_loss:-0.900797\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:38\n",
            "loss(total):-0.003895\n",
            "recons_loss:0.004128\n",
            "grad_loss:0.094180\n",
            "dice_loss:-0.896454\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:39\n",
            "loss(total):-0.004639\n",
            "recons_loss:0.003581\n",
            "grad_loss:0.077243\n",
            "dice_loss:-0.899216\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:40\n",
            "loss(total):-0.002268\n",
            "recons_loss:0.005191\n",
            "grad_loss:0.135779\n",
            "dice_loss:-0.881690\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:41\n",
            "loss(total):-0.003713\n",
            "recons_loss:0.004278\n",
            "grad_loss:0.095656\n",
            "dice_loss:-0.894807\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:42\n",
            "loss(total):-0.003059\n",
            "recons_loss:0.004864\n",
            "grad_loss:0.104135\n",
            "dice_loss:-0.896370\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:43\n",
            "loss(total):-0.003089\n",
            "recons_loss:0.004950\n",
            "grad_loss:0.091171\n",
            "dice_loss:-0.895094\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:44\n",
            "loss(total):-0.003881\n",
            "recons_loss:0.004039\n",
            "grad_loss:0.087294\n",
            "dice_loss:-0.879317\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:45\n",
            "loss(total):-0.003370\n",
            "recons_loss:0.004472\n",
            "grad_loss:0.107553\n",
            "dice_loss:-0.891827\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:46\n",
            "loss(total):-0.004639\n",
            "recons_loss:0.003569\n",
            "grad_loss:0.081780\n",
            "dice_loss:-0.902505\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:47\n",
            "loss(total):-0.004927\n",
            "recons_loss:0.003348\n",
            "grad_loss:0.076452\n",
            "dice_loss:-0.903977\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:48\n",
            "loss(total):-0.003984\n",
            "recons_loss:0.003894\n",
            "grad_loss:0.116619\n",
            "dice_loss:-0.904460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:49\n",
            "loss(total):-0.003113\n",
            "recons_loss:0.004681\n",
            "grad_loss:0.114066\n",
            "dice_loss:-0.893461\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:50\n",
            "loss(total):-0.003379\n",
            "recons_loss:0.004545\n",
            "grad_loss:0.097931\n",
            "dice_loss:-0.890369\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:51\n",
            "loss(total):-0.003592\n",
            "recons_loss:0.004209\n",
            "grad_loss:0.122691\n",
            "dice_loss:-0.902828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:52\n",
            "loss(total):-0.003572\n",
            "recons_loss:0.004372\n",
            "grad_loss:0.095301\n",
            "dice_loss:-0.889701\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:53\n",
            "loss(total):-0.004042\n",
            "recons_loss:0.004132\n",
            "grad_loss:0.073924\n",
            "dice_loss:-0.891307\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:54\n",
            "loss(total):-0.003370\n",
            "recons_loss:0.004507\n",
            "grad_loss:0.097533\n",
            "dice_loss:-0.885190\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:55\n",
            "loss(total):-0.004031\n",
            "recons_loss:0.004088\n",
            "grad_loss:0.087762\n",
            "dice_loss:-0.899684\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:56\n",
            "loss(total):-0.002929\n",
            "recons_loss:0.004969\n",
            "grad_loss:0.109611\n",
            "dice_loss:-0.899442\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:57\n",
            "loss(total):-0.004161\n",
            "recons_loss:0.004103\n",
            "grad_loss:0.085542\n",
            "dice_loss:-0.911937\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:58\n",
            "loss(total):-0.002198\n",
            "recons_loss:0.005302\n",
            "grad_loss:0.141666\n",
            "dice_loss:-0.891667\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:59\n",
            "loss(total):-0.003447\n",
            "recons_loss:0.004437\n",
            "grad_loss:0.112324\n",
            "dice_loss:-0.900698\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:60\n",
            "loss(total):-0.003381\n",
            "recons_loss:0.004591\n",
            "grad_loss:0.089208\n",
            "dice_loss:-0.886432\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:61\n",
            "loss(total):-0.004402\n",
            "recons_loss:0.003758\n",
            "grad_loss:0.082938\n",
            "dice_loss:-0.898942\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:62\n",
            "loss(total):-0.002981\n",
            "recons_loss:0.004931\n",
            "grad_loss:0.100500\n",
            "dice_loss:-0.891659\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:63\n",
            "loss(total):-0.003702\n",
            "recons_loss:0.004104\n",
            "grad_loss:0.117747\n",
            "dice_loss:-0.898376\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:64\n",
            "loss(total):-0.005100\n",
            "recons_loss:0.003026\n",
            "grad_loss:0.081266\n",
            "dice_loss:-0.893884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:65\n",
            "loss(total):-0.004520\n",
            "recons_loss:0.003505\n",
            "grad_loss:0.098378\n",
            "dice_loss:-0.900895\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:66\n",
            "loss(total):-0.003541\n",
            "recons_loss:0.004380\n",
            "grad_loss:0.090282\n",
            "dice_loss:-0.882363\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:67\n",
            "loss(total):-0.003681\n",
            "recons_loss:0.004303\n",
            "grad_loss:0.084262\n",
            "dice_loss:-0.882739\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:68\n",
            "loss(total):-0.004542\n",
            "recons_loss:0.003509\n",
            "grad_loss:0.079200\n",
            "dice_loss:-0.884284\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:69\n",
            "loss(total):-0.003912\n",
            "recons_loss:0.004167\n",
            "grad_loss:0.083321\n",
            "dice_loss:-0.891255\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:70\n",
            "loss(total):-0.003740\n",
            "recons_loss:0.004108\n",
            "grad_loss:0.100837\n",
            "dice_loss:-0.885618\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:71\n",
            "loss(total):-0.003789\n",
            "recons_loss:0.004092\n",
            "grad_loss:0.095731\n",
            "dice_loss:-0.883765\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:72\n",
            "loss(total):-0.004033\n",
            "recons_loss:0.003967\n",
            "grad_loss:0.088486\n",
            "dice_loss:-0.888522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:73\n",
            "loss(total):-0.004510\n",
            "recons_loss:0.003693\n",
            "grad_loss:0.089991\n",
            "dice_loss:-0.910257\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:74\n",
            "loss(total):-0.004352\n",
            "recons_loss:0.003708\n",
            "grad_loss:0.098067\n",
            "dice_loss:-0.904116\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:75\n",
            "loss(total):-0.003015\n",
            "recons_loss:0.004758\n",
            "grad_loss:0.111276\n",
            "dice_loss:-0.888586\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:76\n",
            "loss(total):-0.003521\n",
            "recons_loss:0.004260\n",
            "grad_loss:0.108616\n",
            "dice_loss:-0.886724\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:77\n",
            "loss(total):-0.004535\n",
            "recons_loss:0.003528\n",
            "grad_loss:0.089285\n",
            "dice_loss:-0.895590\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:78\n",
            "loss(total):-0.003885\n",
            "recons_loss:0.004255\n",
            "grad_loss:0.074511\n",
            "dice_loss:-0.888492\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:79\n",
            "loss(total):-0.004139\n",
            "recons_loss:0.003937\n",
            "grad_loss:0.088536\n",
            "dice_loss:-0.896127\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:80\n",
            "loss(total):-0.003510\n",
            "recons_loss:0.004377\n",
            "grad_loss:0.094997\n",
            "dice_loss:-0.883700\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:81\n",
            "loss(total):-0.005266\n",
            "recons_loss:0.003014\n",
            "grad_loss:0.070529\n",
            "dice_loss:-0.898574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:82\n",
            "loss(total):-0.002194\n",
            "recons_loss:0.005491\n",
            "grad_loss:0.125461\n",
            "dice_loss:-0.893897\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:83\n",
            "loss(total):-0.004002\n",
            "recons_loss:0.003999\n",
            "grad_loss:0.105258\n",
            "dice_loss:-0.905321\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:84\n",
            "loss(total):-0.003017\n",
            "recons_loss:0.004783\n",
            "grad_loss:0.114476\n",
            "dice_loss:-0.894500\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:85\n",
            "loss(total):-0.004264\n",
            "recons_loss:0.003802\n",
            "grad_loss:0.094604\n",
            "dice_loss:-0.901241\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:86\n",
            "loss(total):-0.003791\n",
            "recons_loss:0.004194\n",
            "grad_loss:0.106207\n",
            "dice_loss:-0.904713\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:87\n",
            "loss(total):-0.003306\n",
            "recons_loss:0.004554\n",
            "grad_loss:0.098620\n",
            "dice_loss:-0.884609\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:88\n",
            "loss(total):-0.004638\n",
            "recons_loss:0.003310\n",
            "grad_loss:0.094456\n",
            "dice_loss:-0.889190\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:89\n",
            "loss(total):-0.004733\n",
            "recons_loss:0.003297\n",
            "grad_loss:0.091084\n",
            "dice_loss:-0.893992\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:90\n",
            "loss(total):-0.003487\n",
            "recons_loss:0.004193\n",
            "grad_loss:0.119615\n",
            "dice_loss:-0.887523\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:91\n",
            "loss(total):-0.004460\n",
            "recons_loss:0.003567\n",
            "grad_loss:0.096905\n",
            "dice_loss:-0.899605\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:92\n",
            "loss(total):-0.004459\n",
            "recons_loss:0.003670\n",
            "grad_loss:0.098289\n",
            "dice_loss:-0.911201\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:93\n",
            "loss(total):-0.005080\n",
            "recons_loss:0.003277\n",
            "grad_loss:0.071426\n",
            "dice_loss:-0.907097\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:94\n",
            "loss(total):-0.004593\n",
            "recons_loss:0.003561\n",
            "grad_loss:0.078567\n",
            "dice_loss:-0.893964\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:95\n",
            "loss(total):-0.003301\n",
            "recons_loss:0.004493\n",
            "grad_loss:0.111949\n",
            "dice_loss:-0.891384\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:96\n",
            "loss(total):-0.005100\n",
            "recons_loss:0.003103\n",
            "grad_loss:0.081755\n",
            "dice_loss:-0.902074\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:97\n",
            "loss(total):-0.003529\n",
            "recons_loss:0.004507\n",
            "grad_loss:0.101678\n",
            "dice_loss:-0.905290\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:98\n",
            "loss(total):-0.003926\n",
            "recons_loss:0.003934\n",
            "grad_loss:0.102882\n",
            "dice_loss:-0.888808\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:99\n",
            "loss(total):-0.003744\n",
            "recons_loss:0.004115\n",
            "grad_loss:0.111243\n",
            "dice_loss:-0.897149\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:100\n",
            "loss(total):-0.004310\n",
            "recons_loss:0.003879\n",
            "grad_loss:0.074799\n",
            "dice_loss:-0.893697\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:101\n",
            "loss(total):-0.004760\n",
            "recons_loss:0.003419\n",
            "grad_loss:0.074950\n",
            "dice_loss:-0.892903\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:102\n",
            "loss(total):-0.002593\n",
            "recons_loss:0.004991\n",
            "grad_loss:0.116033\n",
            "dice_loss:-0.874424\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:103\n",
            "loss(total):-0.004485\n",
            "recons_loss:0.003606\n",
            "grad_loss:0.078317\n",
            "dice_loss:-0.887369\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:104\n",
            "loss(total):-0.004319\n",
            "recons_loss:0.003672\n",
            "grad_loss:0.100905\n",
            "dice_loss:-0.899936\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:105\n",
            "loss(total):-0.003846\n",
            "recons_loss:0.004130\n",
            "grad_loss:0.111774\n",
            "dice_loss:-0.909323\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:106\n",
            "loss(total):-0.003206\n",
            "recons_loss:0.004722\n",
            "grad_loss:0.099591\n",
            "dice_loss:-0.892466\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:107\n",
            "loss(total):-0.003609\n",
            "recons_loss:0.004352\n",
            "grad_loss:0.091547\n",
            "dice_loss:-0.887634\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:108\n",
            "loss(total):-0.004637\n",
            "recons_loss:0.003515\n",
            "grad_loss:0.083178\n",
            "dice_loss:-0.898372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:109\n",
            "loss(total):-0.002570\n",
            "recons_loss:0.005167\n",
            "grad_loss:0.103084\n",
            "dice_loss:-0.876797\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:110\n",
            "loss(total):-0.003208\n",
            "recons_loss:0.004705\n",
            "grad_loss:0.089843\n",
            "dice_loss:-0.881140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:111\n",
            "loss(total):-0.002579\n",
            "recons_loss:0.004986\n",
            "grad_loss:0.117346\n",
            "dice_loss:-0.873833\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:112\n",
            "loss(total):-0.005988\n",
            "recons_loss:0.002505\n",
            "grad_loss:0.056848\n",
            "dice_loss:-0.906180\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:113\n",
            "loss(total):-0.004257\n",
            "recons_loss:0.003657\n",
            "grad_loss:0.098981\n",
            "dice_loss:-0.890449\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:114\n",
            "loss(total):-0.004173\n",
            "recons_loss:0.003919\n",
            "grad_loss:0.087809\n",
            "dice_loss:-0.897006\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:115\n",
            "loss(total):-0.002501\n",
            "recons_loss:0.005232\n",
            "grad_loss:0.115794\n",
            "dice_loss:-0.889113\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:116\n",
            "loss(total):-0.003427\n",
            "recons_loss:0.004334\n",
            "grad_loss:0.102214\n",
            "dice_loss:-0.878306\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:117\n",
            "loss(total):-0.003153\n",
            "recons_loss:0.004482\n",
            "grad_loss:0.123599\n",
            "dice_loss:-0.887162\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:118\n",
            "loss(total):-0.004232\n",
            "recons_loss:0.003856\n",
            "grad_loss:0.084677\n",
            "dice_loss:-0.893470\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:119\n",
            "loss(total):-0.002257\n",
            "recons_loss:0.005489\n",
            "grad_loss:0.105913\n",
            "dice_loss:-0.880534\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:120\n",
            "loss(total):-0.002990\n",
            "recons_loss:0.004838\n",
            "grad_loss:0.109013\n",
            "dice_loss:-0.891807\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:121\n",
            "loss(total):-0.004190\n",
            "recons_loss:0.003824\n",
            "grad_loss:0.092182\n",
            "dice_loss:-0.893590\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:122\n",
            "loss(total):-0.004618\n",
            "recons_loss:0.003445\n",
            "grad_loss:0.090828\n",
            "dice_loss:-0.897042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:123\n",
            "loss(total):-0.003969\n",
            "recons_loss:0.004042\n",
            "grad_loss:0.095360\n",
            "dice_loss:-0.896520\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:124\n",
            "loss(total):-0.004412\n",
            "recons_loss:0.003704\n",
            "grad_loss:0.082610\n",
            "dice_loss:-0.894186\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:125\n",
            "loss(total):-0.003538\n",
            "recons_loss:0.004235\n",
            "grad_loss:0.107859\n",
            "dice_loss:-0.885133\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:126\n",
            "loss(total):-0.002888\n",
            "recons_loss:0.004834\n",
            "grad_loss:0.121182\n",
            "dice_loss:-0.893389\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:127\n",
            "loss(total):-0.004166\n",
            "recons_loss:0.003814\n",
            "grad_loss:0.092247\n",
            "dice_loss:-0.890224\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:128\n",
            "loss(total):-0.004254\n",
            "recons_loss:0.004056\n",
            "grad_loss:0.073017\n",
            "dice_loss:-0.904056\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:129\n",
            "loss(total):-0.003230\n",
            "recons_loss:0.004743\n",
            "grad_loss:0.096635\n",
            "dice_loss:-0.893962\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:130\n",
            "loss(total):-0.003557\n",
            "recons_loss:0.004322\n",
            "grad_loss:0.100583\n",
            "dice_loss:-0.888444\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:131\n",
            "loss(total):-0.004979\n",
            "recons_loss:0.003330\n",
            "grad_loss:0.076820\n",
            "dice_loss:-0.907735\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:132\n",
            "loss(total):-0.003882\n",
            "recons_loss:0.004174\n",
            "grad_loss:0.090342\n",
            "dice_loss:-0.895934\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:133\n",
            "loss(total):-0.001970\n",
            "recons_loss:0.005717\n",
            "grad_loss:0.118022\n",
            "dice_loss:-0.886762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:134\n",
            "loss(total):-0.004118\n",
            "recons_loss:0.004020\n",
            "grad_loss:0.076888\n",
            "dice_loss:-0.890640\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:135\n",
            "loss(total):-0.004831\n",
            "recons_loss:0.003532\n",
            "grad_loss:0.067872\n",
            "dice_loss:-0.904229\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:136\n",
            "loss(total):-0.002070\n",
            "recons_loss:0.005595\n",
            "grad_loss:0.121513\n",
            "dice_loss:-0.888068\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:137\n",
            "loss(total):-0.002759\n",
            "recons_loss:0.005103\n",
            "grad_loss:0.109444\n",
            "dice_loss:-0.895708\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:138\n",
            "loss(total):-0.003923\n",
            "recons_loss:0.004122\n",
            "grad_loss:0.098275\n",
            "dice_loss:-0.902766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:139\n",
            "loss(total):-0.003359\n",
            "recons_loss:0.004514\n",
            "grad_loss:0.101174\n",
            "dice_loss:-0.888466\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:140\n",
            "loss(total):-0.003327\n",
            "recons_loss:0.004441\n",
            "grad_loss:0.100936\n",
            "dice_loss:-0.877689\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:141\n",
            "loss(total):-0.004262\n",
            "recons_loss:0.003791\n",
            "grad_loss:0.077365\n",
            "dice_loss:-0.882708\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:142\n",
            "loss(total):-0.003778\n",
            "recons_loss:0.004123\n",
            "grad_loss:0.105485\n",
            "dice_loss:-0.895562\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:143\n",
            "loss(total):-0.004259\n",
            "recons_loss:0.003837\n",
            "grad_loss:0.078868\n",
            "dice_loss:-0.888484\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:144\n",
            "loss(total):-0.002492\n",
            "recons_loss:0.005111\n",
            "grad_loss:0.124203\n",
            "dice_loss:-0.884513\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:145\n",
            "loss(total):-0.004196\n",
            "recons_loss:0.003780\n",
            "grad_loss:0.084257\n",
            "dice_loss:-0.881878\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:146\n",
            "loss(total):-0.001489\n",
            "recons_loss:0.006118\n",
            "grad_loss:0.131865\n",
            "dice_loss:-0.892519\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:147\n",
            "loss(total):-0.004318\n",
            "recons_loss:0.003719\n",
            "grad_loss:0.086578\n",
            "dice_loss:-0.890325\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:148\n",
            "loss(total):-0.003207\n",
            "recons_loss:0.004540\n",
            "grad_loss:0.114771\n",
            "dice_loss:-0.889421\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:149\n",
            "loss(total):-0.002782\n",
            "recons_loss:0.004931\n",
            "grad_loss:0.123897\n",
            "dice_loss:-0.895205\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:150\n",
            "loss(total):-0.004140\n",
            "recons_loss:0.004094\n",
            "grad_loss:0.080578\n",
            "dice_loss:-0.903979\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:151\n",
            "loss(total):-0.004103\n",
            "recons_loss:0.003874\n",
            "grad_loss:0.081438\n",
            "dice_loss:-0.879150\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:152\n",
            "loss(total):-0.002732\n",
            "recons_loss:0.005232\n",
            "grad_loss:0.103342\n",
            "dice_loss:-0.899741\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:153\n",
            "loss(total):-0.003845\n",
            "recons_loss:0.004136\n",
            "grad_loss:0.091592\n",
            "dice_loss:-0.889776\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:154\n",
            "loss(total):-0.003676\n",
            "recons_loss:0.004502\n",
            "grad_loss:0.079079\n",
            "dice_loss:-0.896931\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:155\n",
            "loss(total):-0.003661\n",
            "recons_loss:0.004433\n",
            "grad_loss:0.078122\n",
            "dice_loss:-0.887587\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:156\n",
            "loss(total):-0.002834\n",
            "recons_loss:0.004870\n",
            "grad_loss:0.110998\n",
            "dice_loss:-0.881474\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:157\n",
            "loss(total):-0.003657\n",
            "recons_loss:0.004496\n",
            "grad_loss:0.074726\n",
            "dice_loss:-0.890037\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:158\n",
            "loss(total):-0.003215\n",
            "recons_loss:0.004703\n",
            "grad_loss:0.092178\n",
            "dice_loss:-0.884039\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:159\n",
            "loss(total):-0.004059\n",
            "recons_loss:0.003805\n",
            "grad_loss:0.115445\n",
            "dice_loss:-0.901806\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:160\n",
            "loss(total):-0.004206\n",
            "recons_loss:0.003684\n",
            "grad_loss:0.104236\n",
            "dice_loss:-0.893171\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:161\n",
            "loss(total):-0.004371\n",
            "recons_loss:0.003707\n",
            "grad_loss:0.093396\n",
            "dice_loss:-0.901223\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:162\n",
            "loss(total):-0.003765\n",
            "recons_loss:0.004170\n",
            "grad_loss:0.098528\n",
            "dice_loss:-0.892028\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:163\n",
            "loss(total):-0.004521\n",
            "recons_loss:0.003651\n",
            "grad_loss:0.084170\n",
            "dice_loss:-0.901359\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:164\n",
            "loss(total):-0.004098\n",
            "recons_loss:0.003902\n",
            "grad_loss:0.095688\n",
            "dice_loss:-0.895651\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:165\n",
            "loss(total):-0.003954\n",
            "recons_loss:0.004052\n",
            "grad_loss:0.098656\n",
            "dice_loss:-0.899261\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:166\n",
            "loss(total):-0.004179\n",
            "recons_loss:0.003852\n",
            "grad_loss:0.084161\n",
            "dice_loss:-0.887273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:167\n",
            "loss(total):-0.004265\n",
            "recons_loss:0.003888\n",
            "grad_loss:0.086185\n",
            "dice_loss:-0.901498\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:168\n",
            "loss(total):-0.003714\n",
            "recons_loss:0.004336\n",
            "grad_loss:0.085684\n",
            "dice_loss:-0.890753\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:169\n",
            "loss(total):-0.002121\n",
            "recons_loss:0.005265\n",
            "grad_loss:0.146736\n",
            "dice_loss:-0.885320\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:170\n",
            "loss(total):-0.003574\n",
            "recons_loss:0.004286\n",
            "grad_loss:0.114945\n",
            "dice_loss:-0.900885\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:171\n",
            "loss(total):-0.004989\n",
            "recons_loss:0.003133\n",
            "grad_loss:0.078686\n",
            "dice_loss:-0.890922\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:172\n",
            "loss(total):-0.003705\n",
            "recons_loss:0.004238\n",
            "grad_loss:0.093310\n",
            "dice_loss:-0.887653\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:173\n",
            "loss(total):-0.003098\n",
            "recons_loss:0.004619\n",
            "grad_loss:0.115300\n",
            "dice_loss:-0.887038\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:174\n",
            "loss(total):-0.003347\n",
            "recons_loss:0.004353\n",
            "grad_loss:0.121032\n",
            "dice_loss:-0.890994\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:175\n",
            "loss(total):-0.004081\n",
            "recons_loss:0.003827\n",
            "grad_loss:0.101621\n",
            "dice_loss:-0.892399\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:176\n",
            "loss(total):-0.003708\n",
            "recons_loss:0.004172\n",
            "grad_loss:0.094554\n",
            "dice_loss:-0.882563\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:177\n",
            "loss(total):-0.003867\n",
            "recons_loss:0.004092\n",
            "grad_loss:0.097845\n",
            "dice_loss:-0.893821\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:178\n",
            "loss(total):-0.004264\n",
            "recons_loss:0.004013\n",
            "grad_loss:0.071294\n",
            "dice_loss:-0.898963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:179\n",
            "loss(total):-0.004186\n",
            "recons_loss:0.004065\n",
            "grad_loss:0.075632\n",
            "dice_loss:-0.900790\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:180\n",
            "loss(total):-0.004293\n",
            "recons_loss:0.003868\n",
            "grad_loss:0.081704\n",
            "dice_loss:-0.897798\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:181\n",
            "loss(total):-0.003622\n",
            "recons_loss:0.004300\n",
            "grad_loss:0.083732\n",
            "dice_loss:-0.875922\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:182\n",
            "loss(total):-0.004258\n",
            "recons_loss:0.003810\n",
            "grad_loss:0.091261\n",
            "dice_loss:-0.898002\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:183\n",
            "loss(total):-0.002741\n",
            "recons_loss:0.004958\n",
            "grad_loss:0.117481\n",
            "dice_loss:-0.887395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:184\n",
            "loss(total):-0.004925\n",
            "recons_loss:0.003318\n",
            "grad_loss:0.081939\n",
            "dice_loss:-0.906218\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:185\n",
            "loss(total):-0.003580\n",
            "recons_loss:0.004257\n",
            "grad_loss:0.112584\n",
            "dice_loss:-0.896336\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:186\n",
            "loss(total):-0.002348\n",
            "recons_loss:0.005152\n",
            "grad_loss:0.122455\n",
            "dice_loss:-0.872468\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:187\n",
            "loss(total):-0.004663\n",
            "recons_loss:0.003400\n",
            "grad_loss:0.093225\n",
            "dice_loss:-0.899484\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:188\n",
            "loss(total):-0.005187\n",
            "recons_loss:0.002874\n",
            "grad_loss:0.088597\n",
            "dice_loss:-0.894691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:189\n",
            "loss(total):-0.002577\n",
            "recons_loss:0.005067\n",
            "grad_loss:0.134879\n",
            "dice_loss:-0.899288\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:190\n",
            "loss(total):-0.002846\n",
            "recons_loss:0.004708\n",
            "grad_loss:0.137996\n",
            "dice_loss:-0.893370\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:191\n",
            "loss(total):-0.004267\n",
            "recons_loss:0.003760\n",
            "grad_loss:0.089870\n",
            "dice_loss:-0.892506\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:192\n",
            "loss(total):-0.003276\n",
            "recons_loss:0.004375\n",
            "grad_loss:0.131916\n",
            "dice_loss:-0.897003\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:193\n",
            "loss(total):-0.003648\n",
            "recons_loss:0.004460\n",
            "grad_loss:0.088892\n",
            "dice_loss:-0.899660\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:194\n",
            "loss(total):-0.004359\n",
            "recons_loss:0.003740\n",
            "grad_loss:0.079094\n",
            "dice_loss:-0.889060\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:195\n",
            "loss(total):-0.004328\n",
            "recons_loss:0.003720\n",
            "grad_loss:0.101693\n",
            "dice_loss:-0.906410\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:196\n",
            "loss(total):-0.004029\n",
            "recons_loss:0.003909\n",
            "grad_loss:0.095223\n",
            "dice_loss:-0.888977\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:197\n",
            "loss(total):-0.004340\n",
            "recons_loss:0.003652\n",
            "grad_loss:0.090204\n",
            "dice_loss:-0.889387\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:198\n",
            "loss(total):-0.002902\n",
            "recons_loss:0.004762\n",
            "grad_loss:0.120508\n",
            "dice_loss:-0.886831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:199\n",
            "loss(total):-0.003416\n",
            "recons_loss:0.004433\n",
            "grad_loss:0.107475\n",
            "dice_loss:-0.892354\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:200\n",
            "loss(total):-0.003271\n",
            "recons_loss:0.004672\n",
            "grad_loss:0.092373\n",
            "dice_loss:-0.886623\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:201\n",
            "loss(total):-0.004177\n",
            "recons_loss:0.003796\n",
            "grad_loss:0.090398\n",
            "dice_loss:-0.887719\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:202\n",
            "loss(total):-0.004003\n",
            "recons_loss:0.003982\n",
            "grad_loss:0.096980\n",
            "dice_loss:-0.895481\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:203\n",
            "loss(total):-0.003608\n",
            "recons_loss:0.004356\n",
            "grad_loss:0.095419\n",
            "dice_loss:-0.891856\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:204\n",
            "loss(total):-0.003718\n",
            "recons_loss:0.004047\n",
            "grad_loss:0.111171\n",
            "dice_loss:-0.887683\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:205\n",
            "loss(total):-0.003934\n",
            "recons_loss:0.003929\n",
            "grad_loss:0.100446\n",
            "dice_loss:-0.886716\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:206\n",
            "loss(total):-0.003921\n",
            "recons_loss:0.003953\n",
            "grad_loss:0.092129\n",
            "dice_loss:-0.879523\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:207\n",
            "loss(total):-0.004313\n",
            "recons_loss:0.003777\n",
            "grad_loss:0.088032\n",
            "dice_loss:-0.897066\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:208\n",
            "loss(total):-0.003827\n",
            "recons_loss:0.004221\n",
            "grad_loss:0.094731\n",
            "dice_loss:-0.899490\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:209\n",
            "loss(total):-0.003549\n",
            "recons_loss:0.004432\n",
            "grad_loss:0.099617\n",
            "dice_loss:-0.897712\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:210\n",
            "loss(total):-0.003442\n",
            "recons_loss:0.004506\n",
            "grad_loss:0.104794\n",
            "dice_loss:-0.899538\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:211\n",
            "loss(total):-0.001925\n",
            "recons_loss:0.005641\n",
            "grad_loss:0.128409\n",
            "dice_loss:-0.885072\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:212\n",
            "loss(total):-0.004758\n",
            "recons_loss:0.003325\n",
            "grad_loss:0.091914\n",
            "dice_loss:-0.900245\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:213\n",
            "loss(total):-0.004191\n",
            "recons_loss:0.003881\n",
            "grad_loss:0.088014\n",
            "dice_loss:-0.895203\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:214\n",
            "loss(total):-0.003834\n",
            "recons_loss:0.004061\n",
            "grad_loss:0.096977\n",
            "dice_loss:-0.886491\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:215\n",
            "loss(total):-0.005013\n",
            "recons_loss:0.003273\n",
            "grad_loss:0.074002\n",
            "dice_loss:-0.902623\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:216\n",
            "loss(total):-0.002744\n",
            "recons_loss:0.004885\n",
            "grad_loss:0.108465\n",
            "dice_loss:-0.871365\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:217\n",
            "loss(total):-0.004251\n",
            "recons_loss:0.003844\n",
            "grad_loss:0.077701\n",
            "dice_loss:-0.887165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:218\n",
            "loss(total):-0.003212\n",
            "recons_loss:0.004581\n",
            "grad_loss:0.103293\n",
            "dice_loss:-0.882644\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:219\n",
            "loss(total):-0.005089\n",
            "recons_loss:0.003037\n",
            "grad_loss:0.081980\n",
            "dice_loss:-0.894519\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:220\n",
            "loss(total):-0.004012\n",
            "recons_loss:0.003998\n",
            "grad_loss:0.094283\n",
            "dice_loss:-0.895230\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:221\n",
            "loss(total):-0.004762\n",
            "recons_loss:0.003258\n",
            "grad_loss:0.086349\n",
            "dice_loss:-0.888346\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:222\n",
            "loss(total):-0.004134\n",
            "recons_loss:0.003866\n",
            "grad_loss:0.090428\n",
            "dice_loss:-0.890443\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:223\n",
            "loss(total):-0.004862\n",
            "recons_loss:0.003299\n",
            "grad_loss:0.085703\n",
            "dice_loss:-0.901750\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:224\n",
            "loss(total):-0.002503\n",
            "recons_loss:0.005300\n",
            "grad_loss:0.111416\n",
            "dice_loss:-0.891733\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:225\n",
            "loss(total):-0.004015\n",
            "recons_loss:0.004056\n",
            "grad_loss:0.086264\n",
            "dice_loss:-0.893396\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:226\n",
            "loss(total):-0.003857\n",
            "recons_loss:0.004142\n",
            "grad_loss:0.096027\n",
            "dice_loss:-0.895935\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:227\n",
            "loss(total):-0.002894\n",
            "recons_loss:0.004710\n",
            "grad_loss:0.120719\n",
            "dice_loss:-0.881037\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:228\n",
            "loss(total):-0.003156\n",
            "recons_loss:0.004795\n",
            "grad_loss:0.092172\n",
            "dice_loss:-0.887295\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:229\n",
            "loss(total):-0.004622\n",
            "recons_loss:0.003458\n",
            "grad_loss:0.093622\n",
            "dice_loss:-0.901610\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:230\n",
            "loss(total):-0.004681\n",
            "recons_loss:0.003460\n",
            "grad_loss:0.088253\n",
            "dice_loss:-0.902426\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:231\n",
            "loss(total):-0.004728\n",
            "recons_loss:0.003400\n",
            "grad_loss:0.082007\n",
            "dice_loss:-0.894851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:232\n",
            "loss(total):-0.003532\n",
            "recons_loss:0.004335\n",
            "grad_loss:0.104037\n",
            "dice_loss:-0.890788\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:233\n",
            "loss(total):-0.002881\n",
            "recons_loss:0.005090\n",
            "grad_loss:0.096126\n",
            "dice_loss:-0.893305\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:234\n",
            "loss(total):-0.004163\n",
            "recons_loss:0.003939\n",
            "grad_loss:0.096707\n",
            "dice_loss:-0.906851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:235\n",
            "loss(total):-0.002408\n",
            "recons_loss:0.005398\n",
            "grad_loss:0.122551\n",
            "dice_loss:-0.903184\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:236\n",
            "loss(total):-0.003370\n",
            "recons_loss:0.004565\n",
            "grad_loss:0.099993\n",
            "dice_loss:-0.893552\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:237\n",
            "loss(total):-0.005017\n",
            "recons_loss:0.003225\n",
            "grad_loss:0.080410\n",
            "dice_loss:-0.904627\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:238\n",
            "loss(total):-0.003163\n",
            "recons_loss:0.004397\n",
            "grad_loss:0.107481\n",
            "dice_loss:-0.863455\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:239\n",
            "loss(total):-0.002928\n",
            "recons_loss:0.004898\n",
            "grad_loss:0.107917\n",
            "dice_loss:-0.890548\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:240\n",
            "loss(total):-0.003843\n",
            "recons_loss:0.004060\n",
            "grad_loss:0.098638\n",
            "dice_loss:-0.888884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:241\n",
            "loss(total):-0.003041\n",
            "recons_loss:0.004761\n",
            "grad_loss:0.116821\n",
            "dice_loss:-0.896999\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:242\n",
            "loss(total):-0.003312\n",
            "recons_loss:0.004533\n",
            "grad_loss:0.097086\n",
            "dice_loss:-0.881566\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:243\n",
            "loss(total):-0.003238\n",
            "recons_loss:0.004517\n",
            "grad_loss:0.119500\n",
            "dice_loss:-0.894994\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:244\n",
            "loss(total):-0.004933\n",
            "recons_loss:0.003158\n",
            "grad_loss:0.095236\n",
            "dice_loss:-0.904323\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:245\n",
            "loss(total):-0.001846\n",
            "recons_loss:0.005695\n",
            "grad_loss:0.135013\n",
            "dice_loss:-0.889158\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:246\n",
            "loss(total):-0.001983\n",
            "recons_loss:0.005492\n",
            "grad_loss:0.132086\n",
            "dice_loss:-0.879540\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:247\n",
            "loss(total):-0.004254\n",
            "recons_loss:0.003688\n",
            "grad_loss:0.103403\n",
            "dice_loss:-0.897635\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:248\n",
            "loss(total):-0.002390\n",
            "recons_loss:0.005505\n",
            "grad_loss:0.111100\n",
            "dice_loss:-0.900610\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:249\n",
            "loss(total):-0.003305\n",
            "recons_loss:0.004694\n",
            "grad_loss:0.092412\n",
            "dice_loss:-0.892375\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:250\n",
            "loss(total):-0.003829\n",
            "recons_loss:0.004086\n",
            "grad_loss:0.092941\n",
            "dice_loss:-0.884492\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:251\n",
            "loss(total):-0.003332\n",
            "recons_loss:0.004549\n",
            "grad_loss:0.100418\n",
            "dice_loss:-0.888516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:252\n",
            "loss(total):-0.004567\n",
            "recons_loss:0.003552\n",
            "grad_loss:0.087926\n",
            "dice_loss:-0.899817\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:253\n",
            "loss(total):-0.002911\n",
            "recons_loss:0.004903\n",
            "grad_loss:0.110464\n",
            "dice_loss:-0.891868\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:254\n",
            "loss(total):-0.004485\n",
            "recons_loss:0.003710\n",
            "grad_loss:0.085675\n",
            "dice_loss:-0.905165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:255\n",
            "loss(total):-0.003663\n",
            "recons_loss:0.004463\n",
            "grad_loss:0.088010\n",
            "dice_loss:-0.900637\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:256\n",
            "loss(total):-0.004253\n",
            "recons_loss:0.003766\n",
            "grad_loss:0.100442\n",
            "dice_loss:-0.902306\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:257\n",
            "loss(total):-0.002230\n",
            "recons_loss:0.005331\n",
            "grad_loss:0.132642\n",
            "dice_loss:-0.888745\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:258\n",
            "loss(total):-0.003968\n",
            "recons_loss:0.004009\n",
            "grad_loss:0.095484\n",
            "dice_loss:-0.893205\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:259\n",
            "loss(total):-0.002448\n",
            "recons_loss:0.005308\n",
            "grad_loss:0.112037\n",
            "dice_loss:-0.887630\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:260\n",
            "loss(total):-0.003325\n",
            "recons_loss:0.004473\n",
            "grad_loss:0.115920\n",
            "dice_loss:-0.895730\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:261\n",
            "loss(total):-0.003759\n",
            "recons_loss:0.004143\n",
            "grad_loss:0.099409\n",
            "dice_loss:-0.889608\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:262\n",
            "loss(total):-0.001663\n",
            "recons_loss:0.005801\n",
            "grad_loss:0.143827\n",
            "dice_loss:-0.890273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:263\n",
            "loss(total):-0.004100\n",
            "recons_loss:0.003994\n",
            "grad_loss:0.081878\n",
            "dice_loss:-0.891215\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:264\n",
            "loss(total):-0.004404\n",
            "recons_loss:0.003789\n",
            "grad_loss:0.079838\n",
            "dice_loss:-0.899152\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:265\n",
            "loss(total):-0.004354\n",
            "recons_loss:0.003864\n",
            "grad_loss:0.080466\n",
            "dice_loss:-0.902295\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:266\n",
            "loss(total):-0.004692\n",
            "recons_loss:0.003361\n",
            "grad_loss:0.091537\n",
            "dice_loss:-0.896865\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:267\n",
            "loss(total):-0.003946\n",
            "recons_loss:0.004006\n",
            "grad_loss:0.107346\n",
            "dice_loss:-0.902574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:268\n",
            "loss(total):-0.003179\n",
            "recons_loss:0.004702\n",
            "grad_loss:0.096920\n",
            "dice_loss:-0.885019\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:269\n",
            "loss(total):-0.003411\n",
            "recons_loss:0.004357\n",
            "grad_loss:0.110881\n",
            "dice_loss:-0.887708\n",
            "---------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdUKTXGrb2F2",
        "outputId": "411c04dd-3881-4412-923b-3ff9663f38de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(losses_0[1:])\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcRDv__Hb8DE",
        "outputId": "a89b6999-086f-4ed6-fa67-b43fcbf120ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(validation_0)\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTVWRcRptEIQ"
      },
      "source": [
        "import csv\n",
        "with open('validation_0.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTdkkG4qJ7Ze"
      },
      "source": [
        "import csv\n",
        "with open('loss_0.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srA3gh6fnXyl"
      },
      "source": [
        "for h in range(0,len(validation_0)):\n",
        "  with open('validation_0.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, validation_0[h].numpy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElwHcJ6hJ-4J"
      },
      "source": [
        "for h in range(0,len(losses_0)):\n",
        "  with open('loss_0.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h, losses_0[h].numpy()])"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRRfaNbJtlVI"
      },
      "source": [
        "import pandas as pd\n",
        "v = pd.read_csv(\"/content/loss_0.csv\")"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFebEcg2twVB",
        "outputId": "78a6fc2f-297e-44df-d8b1-7a9233604518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "v"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.006466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.018512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.028288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.013895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.015791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8096</th>\n",
              "      <td>8096</td>\n",
              "      <td>-0.004354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8097</th>\n",
              "      <td>8097</td>\n",
              "      <td>-0.004692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8098</th>\n",
              "      <td>8098</td>\n",
              "      <td>-0.003946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8099</th>\n",
              "      <td>8099</td>\n",
              "      <td>-0.003179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8100</th>\n",
              "      <td>8100</td>\n",
              "      <td>-0.003411</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8101 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      batch      loss\n",
              "0         0 -0.006466\n",
              "1         1  0.018512\n",
              "2         2  0.028288\n",
              "3         3  0.013895\n",
              "4         4  0.015791\n",
              "...     ...       ...\n",
              "8096   8096 -0.004354\n",
              "8097   8097 -0.004692\n",
              "8098   8098 -0.003946\n",
              "8099   8099 -0.003179\n",
              "8100   8100 -0.003411\n",
              "\n",
              "[8101 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6crM0dQt6jN"
      },
      "source": [
        "'''Training - hold out fold 1 for validation'''\n",
        "#Training\n",
        "atlas_file='/content/drive/My Drive/2020/Thesis/Data/atlas.npz'\n",
        "lr=1e-4\n",
        "data_loss='mse'\n",
        "model='vm2'\n",
        "reg_param=0.01\n",
        "batch_size=10\n",
        "n_save_iter=100\n",
        "model_dir='/content/drive/My Drive/2020/Thesis/Data/validation_0/'\n",
        "valid = fold_1\n",
        "train_names = set_1\n",
        "EPOCH=30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aieHImwYt9yJ",
        "outputId": "daf59ebe-57bc-4aea-bf30-36d3bc4e20fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses_1, validation_1=validate.train(data_dir,\n",
        "          train_names,\n",
        "          atlas_file,\n",
        "          lr,\n",
        "          data_loss,\n",
        "          model,\n",
        "          reg_param, \n",
        "          batch_size,\n",
        "          n_save_iter,\n",
        "          model_dir,Net(),EPOCH, valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch_number:185\n",
            "loss(total):-0.003956\n",
            "recons_loss:0.003948\n",
            "grad_loss:0.104285\n",
            "dice_loss:-0.894721\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:186\n",
            "loss(total):-0.002350\n",
            "recons_loss:0.005475\n",
            "grad_loss:0.114040\n",
            "dice_loss:-0.896521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:187\n",
            "loss(total):-0.004727\n",
            "recons_loss:0.003420\n",
            "grad_loss:0.086971\n",
            "dice_loss:-0.901687\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:188\n",
            "loss(total):-0.004575\n",
            "recons_loss:0.003699\n",
            "grad_loss:0.082821\n",
            "dice_loss:-0.910167\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:189\n",
            "loss(total):-0.003985\n",
            "recons_loss:0.003924\n",
            "grad_loss:0.092507\n",
            "dice_loss:-0.883442\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:190\n",
            "loss(total):-0.002917\n",
            "recons_loss:0.004785\n",
            "grad_loss:0.118586\n",
            "dice_loss:-0.888793\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:191\n",
            "loss(total):-0.004062\n",
            "recons_loss:0.003999\n",
            "grad_loss:0.091208\n",
            "dice_loss:-0.897296\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:192\n",
            "loss(total):-0.003203\n",
            "recons_loss:0.004704\n",
            "grad_loss:0.107056\n",
            "dice_loss:-0.897714\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:193\n",
            "loss(total):-0.002626\n",
            "recons_loss:0.005044\n",
            "grad_loss:0.120320\n",
            "dice_loss:-0.887336\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:194\n",
            "loss(total):-0.004078\n",
            "recons_loss:0.004076\n",
            "grad_loss:0.087314\n",
            "dice_loss:-0.902770\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:195\n",
            "loss(total):-0.004020\n",
            "recons_loss:0.003965\n",
            "grad_loss:0.078268\n",
            "dice_loss:-0.876760\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:196\n",
            "loss(total):-0.003568\n",
            "recons_loss:0.004420\n",
            "grad_loss:0.098998\n",
            "dice_loss:-0.897766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:197\n",
            "loss(total):-0.003545\n",
            "recons_loss:0.004207\n",
            "grad_loss:0.102329\n",
            "dice_loss:-0.877494\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:198\n",
            "loss(total):-0.004540\n",
            "recons_loss:0.003600\n",
            "grad_loss:0.085900\n",
            "dice_loss:-0.899852\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:199\n",
            "loss(total):-0.004547\n",
            "recons_loss:0.003598\n",
            "grad_loss:0.079164\n",
            "dice_loss:-0.893647\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:200\n",
            "loss(total):-0.003337\n",
            "recons_loss:0.004442\n",
            "grad_loss:0.115768\n",
            "dice_loss:-0.893681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:201\n",
            "loss(total):-0.004119\n",
            "recons_loss:0.003873\n",
            "grad_loss:0.092953\n",
            "dice_loss:-0.892056\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:202\n",
            "loss(total):-0.003719\n",
            "recons_loss:0.004063\n",
            "grad_loss:0.092712\n",
            "dice_loss:-0.870901\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:203\n",
            "loss(total):-0.003379\n",
            "recons_loss:0.004504\n",
            "grad_loss:0.095821\n",
            "dice_loss:-0.884136\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:204\n",
            "loss(total):-0.004018\n",
            "recons_loss:0.003913\n",
            "grad_loss:0.091605\n",
            "dice_loss:-0.884743\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:205\n",
            "loss(total):-0.004417\n",
            "recons_loss:0.003585\n",
            "grad_loss:0.081372\n",
            "dice_loss:-0.881580\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:206\n",
            "loss(total):-0.003515\n",
            "recons_loss:0.004345\n",
            "grad_loss:0.104314\n",
            "dice_loss:-0.890297\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:207\n",
            "loss(total):-0.003567\n",
            "recons_loss:0.004227\n",
            "grad_loss:0.108028\n",
            "dice_loss:-0.887510\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:208\n",
            "loss(total):-0.004067\n",
            "recons_loss:0.003900\n",
            "grad_loss:0.102947\n",
            "dice_loss:-0.899677\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:209\n",
            "loss(total):-0.004517\n",
            "recons_loss:0.003441\n",
            "grad_loss:0.094962\n",
            "dice_loss:-0.890804\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:210\n",
            "loss(total):-0.003762\n",
            "recons_loss:0.004194\n",
            "grad_loss:0.108577\n",
            "dice_loss:-0.904186\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:211\n",
            "loss(total):-0.002989\n",
            "recons_loss:0.004656\n",
            "grad_loss:0.123037\n",
            "dice_loss:-0.887509\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:212\n",
            "loss(total):-0.004215\n",
            "recons_loss:0.003930\n",
            "grad_loss:0.082609\n",
            "dice_loss:-0.897138\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:213\n",
            "loss(total):-0.004246\n",
            "recons_loss:0.003906\n",
            "grad_loss:0.083104\n",
            "dice_loss:-0.898266\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:214\n",
            "loss(total):-0.005171\n",
            "recons_loss:0.002991\n",
            "grad_loss:0.086577\n",
            "dice_loss:-0.902805\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:215\n",
            "loss(total):-0.002632\n",
            "recons_loss:0.004990\n",
            "grad_loss:0.122384\n",
            "dice_loss:-0.884568\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:216\n",
            "loss(total):-0.003885\n",
            "recons_loss:0.004053\n",
            "grad_loss:0.098298\n",
            "dice_loss:-0.892142\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:217\n",
            "loss(total):-0.003895\n",
            "recons_loss:0.003939\n",
            "grad_loss:0.105709\n",
            "dice_loss:-0.889041\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:218\n",
            "loss(total):-0.003911\n",
            "recons_loss:0.003913\n",
            "grad_loss:0.101463\n",
            "dice_loss:-0.883852\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:219\n",
            "loss(total):-0.004780\n",
            "recons_loss:0.003381\n",
            "grad_loss:0.092018\n",
            "dice_loss:-0.908084\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:220\n",
            "loss(total):-0.003774\n",
            "recons_loss:0.004010\n",
            "grad_loss:0.114145\n",
            "dice_loss:-0.892616\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:221\n",
            "loss(total):-0.003702\n",
            "recons_loss:0.004147\n",
            "grad_loss:0.103023\n",
            "dice_loss:-0.887906\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:222\n",
            "loss(total):-0.005119\n",
            "recons_loss:0.003308\n",
            "grad_loss:0.064969\n",
            "dice_loss:-0.907607\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:223\n",
            "loss(total):-0.005107\n",
            "recons_loss:0.003212\n",
            "grad_loss:0.083484\n",
            "dice_loss:-0.915361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:224\n",
            "loss(total):-0.003865\n",
            "recons_loss:0.003807\n",
            "grad_loss:0.112025\n",
            "dice_loss:-0.879246\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:225\n",
            "loss(total):-0.003117\n",
            "recons_loss:0.004618\n",
            "grad_loss:0.113986\n",
            "dice_loss:-0.887511\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:226\n",
            "loss(total):-0.003759\n",
            "recons_loss:0.004202\n",
            "grad_loss:0.104208\n",
            "dice_loss:-0.900300\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:227\n",
            "loss(total):-0.002779\n",
            "recons_loss:0.004748\n",
            "grad_loss:0.120286\n",
            "dice_loss:-0.873052\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:228\n",
            "loss(total):-0.004947\n",
            "recons_loss:0.003100\n",
            "grad_loss:0.083377\n",
            "dice_loss:-0.888025\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:229\n",
            "loss(total):-0.003429\n",
            "recons_loss:0.004430\n",
            "grad_loss:0.099383\n",
            "dice_loss:-0.885333\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:230\n",
            "loss(total):-0.003680\n",
            "recons_loss:0.004264\n",
            "grad_loss:0.098063\n",
            "dice_loss:-0.892495\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:231\n",
            "loss(total):-0.004337\n",
            "recons_loss:0.003646\n",
            "grad_loss:0.088266\n",
            "dice_loss:-0.886488\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:232\n",
            "loss(total):-0.001966\n",
            "recons_loss:0.005493\n",
            "grad_loss:0.139820\n",
            "dice_loss:-0.885699\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:233\n",
            "loss(total):-0.002828\n",
            "recons_loss:0.004684\n",
            "grad_loss:0.121967\n",
            "dice_loss:-0.873163\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:234\n",
            "loss(total):-0.003691\n",
            "recons_loss:0.004202\n",
            "grad_loss:0.092094\n",
            "dice_loss:-0.881410\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:235\n",
            "loss(total):-0.004843\n",
            "recons_loss:0.003460\n",
            "grad_loss:0.081554\n",
            "dice_loss:-0.911857\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:236\n",
            "loss(total):-0.004778\n",
            "recons_loss:0.003394\n",
            "grad_loss:0.083051\n",
            "dice_loss:-0.900169\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:237\n",
            "loss(total):-0.003341\n",
            "recons_loss:0.004739\n",
            "grad_loss:0.097972\n",
            "dice_loss:-0.905945\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:238\n",
            "loss(total):-0.003897\n",
            "recons_loss:0.004198\n",
            "grad_loss:0.081212\n",
            "dice_loss:-0.890773\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:239\n",
            "loss(total):-0.002629\n",
            "recons_loss:0.005124\n",
            "grad_loss:0.107299\n",
            "dice_loss:-0.882637\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:240\n",
            "loss(total):-0.003382\n",
            "recons_loss:0.004508\n",
            "grad_loss:0.112115\n",
            "dice_loss:-0.901120\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:241\n",
            "loss(total):-0.004606\n",
            "recons_loss:0.003503\n",
            "grad_loss:0.075708\n",
            "dice_loss:-0.886560\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:242\n",
            "loss(total):-0.005494\n",
            "recons_loss:0.002733\n",
            "grad_loss:0.078473\n",
            "dice_loss:-0.901160\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:243\n",
            "loss(total):-0.003232\n",
            "recons_loss:0.004672\n",
            "grad_loss:0.104682\n",
            "dice_loss:-0.895007\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:244\n",
            "loss(total):-0.003769\n",
            "recons_loss:0.003993\n",
            "grad_loss:0.107655\n",
            "dice_loss:-0.883855\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:245\n",
            "loss(total):-0.002706\n",
            "recons_loss:0.004767\n",
            "grad_loss:0.129944\n",
            "dice_loss:-0.877259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:246\n",
            "loss(total):-0.003834\n",
            "recons_loss:0.003968\n",
            "grad_loss:0.103543\n",
            "dice_loss:-0.883740\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:247\n",
            "loss(total):-0.002567\n",
            "recons_loss:0.005009\n",
            "grad_loss:0.116052\n",
            "dice_loss:-0.873704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:248\n",
            "loss(total):-0.005003\n",
            "recons_loss:0.003166\n",
            "grad_loss:0.076344\n",
            "dice_loss:-0.893330\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:249\n",
            "loss(total):-0.002091\n",
            "recons_loss:0.005829\n",
            "grad_loss:0.106200\n",
            "dice_loss:-0.898142\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:250\n",
            "loss(total):-0.003677\n",
            "recons_loss:0.004351\n",
            "grad_loss:0.090195\n",
            "dice_loss:-0.892926\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:251\n",
            "loss(total):-0.004206\n",
            "recons_loss:0.003792\n",
            "grad_loss:0.096814\n",
            "dice_loss:-0.896592\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:252\n",
            "loss(total):-0.002587\n",
            "recons_loss:0.005104\n",
            "grad_loss:0.120472\n",
            "dice_loss:-0.889597\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:253\n",
            "loss(total):-0.003569\n",
            "recons_loss:0.004389\n",
            "grad_loss:0.097886\n",
            "dice_loss:-0.893666\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:254\n",
            "loss(total):-0.004091\n",
            "recons_loss:0.003769\n",
            "grad_loss:0.097044\n",
            "dice_loss:-0.883033\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:255\n",
            "loss(total):-0.004076\n",
            "recons_loss:0.004029\n",
            "grad_loss:0.086140\n",
            "dice_loss:-0.896572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:256\n",
            "loss(total):-0.004231\n",
            "recons_loss:0.003986\n",
            "grad_loss:0.075379\n",
            "dice_loss:-0.897086\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:257\n",
            "loss(total):-0.004228\n",
            "recons_loss:0.003841\n",
            "grad_loss:0.096100\n",
            "dice_loss:-0.902970\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:258\n",
            "loss(total):-0.003252\n",
            "recons_loss:0.004698\n",
            "grad_loss:0.104828\n",
            "dice_loss:-0.899815\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:259\n",
            "loss(total):-0.004378\n",
            "recons_loss:0.003866\n",
            "grad_loss:0.076563\n",
            "dice_loss:-0.900895\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:260\n",
            "loss(total):-0.002384\n",
            "recons_loss:0.005145\n",
            "grad_loss:0.119043\n",
            "dice_loss:-0.871963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:261\n",
            "loss(total):-0.004155\n",
            "recons_loss:0.004024\n",
            "grad_loss:0.076643\n",
            "dice_loss:-0.894612\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:262\n",
            "loss(total):-0.003637\n",
            "recons_loss:0.004239\n",
            "grad_loss:0.103214\n",
            "dice_loss:-0.890778\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:263\n",
            "loss(total):-0.004300\n",
            "recons_loss:0.003568\n",
            "grad_loss:0.088606\n",
            "dice_loss:-0.875448\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:264\n",
            "loss(total):-0.003542\n",
            "recons_loss:0.004550\n",
            "grad_loss:0.085916\n",
            "dice_loss:-0.895105\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:265\n",
            "loss(total):-0.003529\n",
            "recons_loss:0.004315\n",
            "grad_loss:0.107629\n",
            "dice_loss:-0.891977\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:266\n",
            "loss(total):-0.003176\n",
            "recons_loss:0.004783\n",
            "grad_loss:0.107774\n",
            "dice_loss:-0.903681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:267\n",
            "loss(total):-0.002050\n",
            "recons_loss:0.005322\n",
            "grad_loss:0.143615\n",
            "dice_loss:-0.880782\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:268\n",
            "loss(total):-0.003717\n",
            "recons_loss:0.004062\n",
            "grad_loss:0.097327\n",
            "dice_loss:-0.875280\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:269\n",
            "loss(total):-0.003451\n",
            "recons_loss:0.004578\n",
            "grad_loss:0.088062\n",
            "dice_loss:-0.890948\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:0\n",
            "loss(total):-0.003539\n",
            "recons_loss:0.004393\n",
            "grad_loss:0.101551\n",
            "dice_loss:-0.894721\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:1\n",
            "loss(total):-0.005100\n",
            "recons_loss:0.003248\n",
            "grad_loss:0.075862\n",
            "dice_loss:-0.910584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:2\n",
            "loss(total):-0.004229\n",
            "recons_loss:0.004033\n",
            "grad_loss:0.071095\n",
            "dice_loss:-0.897268\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:3\n",
            "loss(total):-0.003738\n",
            "recons_loss:0.004283\n",
            "grad_loss:0.105188\n",
            "dice_loss:-0.907259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:4\n",
            "loss(total):-0.002905\n",
            "recons_loss:0.005126\n",
            "grad_loss:0.099448\n",
            "dice_loss:-0.902556\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:5\n",
            "loss(total):-0.003685\n",
            "recons_loss:0.004335\n",
            "grad_loss:0.102879\n",
            "dice_loss:-0.904828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:6\n",
            "loss(total):-0.003171\n",
            "recons_loss:0.004820\n",
            "grad_loss:0.083257\n",
            "dice_loss:-0.882334\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:7\n",
            "loss(total):-0.003947\n",
            "recons_loss:0.003977\n",
            "grad_loss:0.087147\n",
            "dice_loss:-0.879588\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:8\n",
            "loss(total):-0.003647\n",
            "recons_loss:0.004368\n",
            "grad_loss:0.088175\n",
            "dice_loss:-0.889730\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:9\n",
            "loss(total):-0.004261\n",
            "recons_loss:0.003642\n",
            "grad_loss:0.088562\n",
            "dice_loss:-0.878928\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:10\n",
            "loss(total):-0.003721\n",
            "recons_loss:0.004134\n",
            "grad_loss:0.103416\n",
            "dice_loss:-0.888956\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:11\n",
            "loss(total):-0.005165\n",
            "recons_loss:0.003090\n",
            "grad_loss:0.079819\n",
            "dice_loss:-0.905264\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:12\n",
            "loss(total):-0.003761\n",
            "recons_loss:0.004206\n",
            "grad_loss:0.100865\n",
            "dice_loss:-0.897551\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:13\n",
            "loss(total):-0.003601\n",
            "recons_loss:0.004400\n",
            "grad_loss:0.089252\n",
            "dice_loss:-0.889356\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:14\n",
            "loss(total):-0.002963\n",
            "recons_loss:0.004894\n",
            "grad_loss:0.093784\n",
            "dice_loss:-0.879446\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:15\n",
            "loss(total):-0.004188\n",
            "recons_loss:0.003790\n",
            "grad_loss:0.093342\n",
            "dice_loss:-0.891153\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:16\n",
            "loss(total):-0.003943\n",
            "recons_loss:0.004097\n",
            "grad_loss:0.081193\n",
            "dice_loss:-0.885170\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:17\n",
            "loss(total):-0.004022\n",
            "recons_loss:0.003911\n",
            "grad_loss:0.094362\n",
            "dice_loss:-0.887618\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:18\n",
            "loss(total):-0.004602\n",
            "recons_loss:0.003489\n",
            "grad_loss:0.080939\n",
            "dice_loss:-0.890078\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:19\n",
            "loss(total):-0.002828\n",
            "recons_loss:0.004890\n",
            "grad_loss:0.120457\n",
            "dice_loss:-0.892280\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:20\n",
            "loss(total):-0.004144\n",
            "recons_loss:0.004027\n",
            "grad_loss:0.081481\n",
            "dice_loss:-0.898550\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:21\n",
            "loss(total):-0.002001\n",
            "recons_loss:0.005734\n",
            "grad_loss:0.129599\n",
            "dice_loss:-0.903099\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:22\n",
            "loss(total):-0.004177\n",
            "recons_loss:0.003949\n",
            "grad_loss:0.080595\n",
            "dice_loss:-0.893177\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:23\n",
            "loss(total):-0.004226\n",
            "recons_loss:0.003745\n",
            "grad_loss:0.094321\n",
            "dice_loss:-0.891465\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:24\n",
            "loss(total):-0.003804\n",
            "recons_loss:0.004065\n",
            "grad_loss:0.098410\n",
            "dice_loss:-0.885230\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:25\n",
            "loss(total):-0.003807\n",
            "recons_loss:0.004173\n",
            "grad_loss:0.083583\n",
            "dice_loss:-0.881563\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:26\n",
            "loss(total):-0.003356\n",
            "recons_loss:0.004622\n",
            "grad_loss:0.095710\n",
            "dice_loss:-0.893494\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:27\n",
            "loss(total):-0.002669\n",
            "recons_loss:0.005113\n",
            "grad_loss:0.112231\n",
            "dice_loss:-0.890482\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:28\n",
            "loss(total):-0.003142\n",
            "recons_loss:0.004558\n",
            "grad_loss:0.114967\n",
            "dice_loss:-0.884934\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:29\n",
            "loss(total):-0.003900\n",
            "recons_loss:0.004009\n",
            "grad_loss:0.096562\n",
            "dice_loss:-0.887445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:30\n",
            "loss(total):-0.003966\n",
            "recons_loss:0.003920\n",
            "grad_loss:0.107759\n",
            "dice_loss:-0.896344\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:31\n",
            "loss(total):-0.004068\n",
            "recons_loss:0.003881\n",
            "grad_loss:0.094005\n",
            "dice_loss:-0.888846\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:32\n",
            "loss(total):-0.003935\n",
            "recons_loss:0.003841\n",
            "grad_loss:0.098015\n",
            "dice_loss:-0.875605\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:33\n",
            "loss(total):-0.003437\n",
            "recons_loss:0.004674\n",
            "grad_loss:0.088877\n",
            "dice_loss:-0.900014\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:34\n",
            "loss(total):-0.004228\n",
            "recons_loss:0.003988\n",
            "grad_loss:0.073685\n",
            "dice_loss:-0.895344\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:35\n",
            "loss(total):-0.003958\n",
            "recons_loss:0.004088\n",
            "grad_loss:0.084612\n",
            "dice_loss:-0.889221\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:36\n",
            "loss(total):-0.003303\n",
            "recons_loss:0.004506\n",
            "grad_loss:0.113666\n",
            "dice_loss:-0.894559\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:37\n",
            "loss(total):-0.003447\n",
            "recons_loss:0.004567\n",
            "grad_loss:0.095064\n",
            "dice_loss:-0.896495\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:38\n",
            "loss(total):-0.003273\n",
            "recons_loss:0.004424\n",
            "grad_loss:0.117594\n",
            "dice_loss:-0.887321\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:39\n",
            "loss(total):-0.005859\n",
            "recons_loss:0.002561\n",
            "grad_loss:0.073567\n",
            "dice_loss:-0.915570\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:40\n",
            "loss(total):-0.002578\n",
            "recons_loss:0.005075\n",
            "grad_loss:0.121092\n",
            "dice_loss:-0.886410\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:41\n",
            "loss(total):-0.002306\n",
            "recons_loss:0.005357\n",
            "grad_loss:0.121016\n",
            "dice_loss:-0.887338\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:42\n",
            "loss(total):-0.003743\n",
            "recons_loss:0.004363\n",
            "grad_loss:0.082422\n",
            "dice_loss:-0.893026\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:43\n",
            "loss(total):-0.005051\n",
            "recons_loss:0.003035\n",
            "grad_loss:0.081794\n",
            "dice_loss:-0.890426\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:44\n",
            "loss(total):-0.003405\n",
            "recons_loss:0.004435\n",
            "grad_loss:0.107154\n",
            "dice_loss:-0.891096\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:45\n",
            "loss(total):-0.004084\n",
            "recons_loss:0.003946\n",
            "grad_loss:0.082904\n",
            "dice_loss:-0.885906\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:46\n",
            "loss(total):-0.004227\n",
            "recons_loss:0.003775\n",
            "grad_loss:0.087098\n",
            "dice_loss:-0.887246\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:47\n",
            "loss(total):-0.003213\n",
            "recons_loss:0.004731\n",
            "grad_loss:0.092435\n",
            "dice_loss:-0.886823\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:48\n",
            "loss(total):-0.002998\n",
            "recons_loss:0.004619\n",
            "grad_loss:0.121865\n",
            "dice_loss:-0.883574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:49\n",
            "loss(total):-0.003673\n",
            "recons_loss:0.004362\n",
            "grad_loss:0.076893\n",
            "dice_loss:-0.880301\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:50\n",
            "loss(total):-0.004894\n",
            "recons_loss:0.003149\n",
            "grad_loss:0.087712\n",
            "dice_loss:-0.891962\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:51\n",
            "loss(total):-0.003081\n",
            "recons_loss:0.004774\n",
            "grad_loss:0.102342\n",
            "dice_loss:-0.887808\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:52\n",
            "loss(total):-0.002918\n",
            "recons_loss:0.004858\n",
            "grad_loss:0.106749\n",
            "dice_loss:-0.884416\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:53\n",
            "loss(total):-0.004110\n",
            "recons_loss:0.003851\n",
            "grad_loss:0.096688\n",
            "dice_loss:-0.892749\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:54\n",
            "loss(total):-0.003961\n",
            "recons_loss:0.004064\n",
            "grad_loss:0.086483\n",
            "dice_loss:-0.888950\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:55\n",
            "loss(total):-0.003019\n",
            "recons_loss:0.004907\n",
            "grad_loss:0.093397\n",
            "dice_loss:-0.886071\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:56\n",
            "loss(total):-0.003893\n",
            "recons_loss:0.004016\n",
            "grad_loss:0.099113\n",
            "dice_loss:-0.889953\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:57\n",
            "loss(total):-0.003211\n",
            "recons_loss:0.004423\n",
            "grad_loss:0.119328\n",
            "dice_loss:-0.882729\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:58\n",
            "loss(total):-0.003314\n",
            "recons_loss:0.004484\n",
            "grad_loss:0.105292\n",
            "dice_loss:-0.885117\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:59\n",
            "loss(total):-0.004710\n",
            "recons_loss:0.003551\n",
            "grad_loss:0.083321\n",
            "dice_loss:-0.909423\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:60\n",
            "loss(total):-0.004009\n",
            "recons_loss:0.003993\n",
            "grad_loss:0.100545\n",
            "dice_loss:-0.900804\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:61\n",
            "loss(total):-0.003041\n",
            "recons_loss:0.004864\n",
            "grad_loss:0.112833\n",
            "dice_loss:-0.903340\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:62\n",
            "loss(total):-0.003578\n",
            "recons_loss:0.004344\n",
            "grad_loss:0.105946\n",
            "dice_loss:-0.898086\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:63\n",
            "loss(total):-0.001503\n",
            "recons_loss:0.005826\n",
            "grad_loss:0.146029\n",
            "dice_loss:-0.878965\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:64\n",
            "loss(total):-0.004071\n",
            "recons_loss:0.003885\n",
            "grad_loss:0.102553\n",
            "dice_loss:-0.898214\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:65\n",
            "loss(total):-0.004944\n",
            "recons_loss:0.003360\n",
            "grad_loss:0.069367\n",
            "dice_loss:-0.899792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:66\n",
            "loss(total):-0.004950\n",
            "recons_loss:0.003160\n",
            "grad_loss:0.074241\n",
            "dice_loss:-0.885277\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:67\n",
            "loss(total):-0.003959\n",
            "recons_loss:0.003966\n",
            "grad_loss:0.095906\n",
            "dice_loss:-0.888488\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:68\n",
            "loss(total):-0.004843\n",
            "recons_loss:0.003233\n",
            "grad_loss:0.078561\n",
            "dice_loss:-0.886176\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:69\n",
            "loss(total):-0.004896\n",
            "recons_loss:0.003445\n",
            "grad_loss:0.071132\n",
            "dice_loss:-0.905251\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:70\n",
            "loss(total):-0.003204\n",
            "recons_loss:0.004709\n",
            "grad_loss:0.106815\n",
            "dice_loss:-0.898137\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:71\n",
            "loss(total):-0.004247\n",
            "recons_loss:0.003916\n",
            "grad_loss:0.099730\n",
            "dice_loss:-0.915979\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:72\n",
            "loss(total):-0.003570\n",
            "recons_loss:0.004209\n",
            "grad_loss:0.096669\n",
            "dice_loss:-0.874515\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:73\n",
            "loss(total):-0.002193\n",
            "recons_loss:0.005362\n",
            "grad_loss:0.126434\n",
            "dice_loss:-0.881904\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:74\n",
            "loss(total):-0.003978\n",
            "recons_loss:0.003994\n",
            "grad_loss:0.084158\n",
            "dice_loss:-0.881325\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:75\n",
            "loss(total):-0.003115\n",
            "recons_loss:0.004689\n",
            "grad_loss:0.099241\n",
            "dice_loss:-0.879695\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:76\n",
            "loss(total):-0.004286\n",
            "recons_loss:0.003704\n",
            "grad_loss:0.099018\n",
            "dice_loss:-0.898039\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:77\n",
            "loss(total):-0.003648\n",
            "recons_loss:0.004225\n",
            "grad_loss:0.097208\n",
            "dice_loss:-0.884527\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:78\n",
            "loss(total):-0.002667\n",
            "recons_loss:0.004952\n",
            "grad_loss:0.118098\n",
            "dice_loss:-0.879916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:79\n",
            "loss(total):-0.005241\n",
            "recons_loss:0.002846\n",
            "grad_loss:0.069659\n",
            "dice_loss:-0.878356\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:80\n",
            "loss(total):-0.004573\n",
            "recons_loss:0.003584\n",
            "grad_loss:0.078095\n",
            "dice_loss:-0.893800\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:81\n",
            "loss(total):-0.001458\n",
            "recons_loss:0.006064\n",
            "grad_loss:0.120091\n",
            "dice_loss:-0.872299\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:82\n",
            "loss(total):-0.005186\n",
            "recons_loss:0.002979\n",
            "grad_loss:0.086414\n",
            "dice_loss:-0.902860\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:83\n",
            "loss(total):-0.004266\n",
            "recons_loss:0.003657\n",
            "grad_loss:0.097656\n",
            "dice_loss:-0.889971\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:84\n",
            "loss(total):-0.003840\n",
            "recons_loss:0.004213\n",
            "grad_loss:0.099760\n",
            "dice_loss:-0.905000\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:85\n",
            "loss(total):-0.002971\n",
            "recons_loss:0.004938\n",
            "grad_loss:0.100045\n",
            "dice_loss:-0.890926\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:86\n",
            "loss(total):-0.003772\n",
            "recons_loss:0.004236\n",
            "grad_loss:0.095502\n",
            "dice_loss:-0.896284\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:87\n",
            "loss(total):-0.005336\n",
            "recons_loss:0.003074\n",
            "grad_loss:0.074244\n",
            "dice_loss:-0.915209\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:88\n",
            "loss(total):-0.003323\n",
            "recons_loss:0.004409\n",
            "grad_loss:0.109507\n",
            "dice_loss:-0.882739\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:89\n",
            "loss(total):-0.004513\n",
            "recons_loss:0.003492\n",
            "grad_loss:0.080978\n",
            "dice_loss:-0.881462\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:90\n",
            "loss(total):-0.004719\n",
            "recons_loss:0.003268\n",
            "grad_loss:0.082193\n",
            "dice_loss:-0.880879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:91\n",
            "loss(total):-0.004599\n",
            "recons_loss:0.003488\n",
            "grad_loss:0.091009\n",
            "dice_loss:-0.899651\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:92\n",
            "loss(total):-0.003279\n",
            "recons_loss:0.004519\n",
            "grad_loss:0.109473\n",
            "dice_loss:-0.889255\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:93\n",
            "loss(total):-0.002527\n",
            "recons_loss:0.005090\n",
            "grad_loss:0.129480\n",
            "dice_loss:-0.891217\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:94\n",
            "loss(total):-0.004680\n",
            "recons_loss:0.003401\n",
            "grad_loss:0.085746\n",
            "dice_loss:-0.893880\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:95\n",
            "loss(total):-0.004444\n",
            "recons_loss:0.003636\n",
            "grad_loss:0.091664\n",
            "dice_loss:-0.899667\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:96\n",
            "loss(total):-0.003735\n",
            "recons_loss:0.004097\n",
            "grad_loss:0.088242\n",
            "dice_loss:-0.871490\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:97\n",
            "loss(total):-0.003360\n",
            "recons_loss:0.004504\n",
            "grad_loss:0.106725\n",
            "dice_loss:-0.893164\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:98\n",
            "loss(total):-0.003159\n",
            "recons_loss:0.004417\n",
            "grad_loss:0.127676\n",
            "dice_loss:-0.885246\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:99\n",
            "loss(total):-0.003126\n",
            "recons_loss:0.004714\n",
            "grad_loss:0.113288\n",
            "dice_loss:-0.897246\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:100\n",
            "loss(total):-0.002921\n",
            "recons_loss:0.004859\n",
            "grad_loss:0.114315\n",
            "dice_loss:-0.892369\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:101\n",
            "loss(total):-0.003689\n",
            "recons_loss:0.004128\n",
            "grad_loss:0.092382\n",
            "dice_loss:-0.874089\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:102\n",
            "loss(total):-0.003333\n",
            "recons_loss:0.004525\n",
            "grad_loss:0.107660\n",
            "dice_loss:-0.893460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:103\n",
            "loss(total):-0.003367\n",
            "recons_loss:0.004392\n",
            "grad_loss:0.105084\n",
            "dice_loss:-0.881029\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:104\n",
            "loss(total):-0.003616\n",
            "recons_loss:0.004238\n",
            "grad_loss:0.105566\n",
            "dice_loss:-0.890986\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:105\n",
            "loss(total):-0.003133\n",
            "recons_loss:0.004687\n",
            "grad_loss:0.097860\n",
            "dice_loss:-0.879833\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:106\n",
            "loss(total):-0.002380\n",
            "recons_loss:0.005292\n",
            "grad_loss:0.119326\n",
            "dice_loss:-0.886460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:107\n",
            "loss(total):-0.003698\n",
            "recons_loss:0.004280\n",
            "grad_loss:0.096420\n",
            "dice_loss:-0.894283\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:108\n",
            "loss(total):-0.003734\n",
            "recons_loss:0.004228\n",
            "grad_loss:0.097379\n",
            "dice_loss:-0.893552\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:109\n",
            "loss(total):-0.004097\n",
            "recons_loss:0.003930\n",
            "grad_loss:0.095049\n",
            "dice_loss:-0.897686\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:110\n",
            "loss(total):-0.004705\n",
            "recons_loss:0.003304\n",
            "grad_loss:0.088281\n",
            "dice_loss:-0.889132\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:111\n",
            "loss(total):-0.004733\n",
            "recons_loss:0.003324\n",
            "grad_loss:0.099528\n",
            "dice_loss:-0.905265\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:112\n",
            "loss(total):-0.003175\n",
            "recons_loss:0.004464\n",
            "grad_loss:0.118266\n",
            "dice_loss:-0.882190\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:113\n",
            "loss(total):-0.002918\n",
            "recons_loss:0.004765\n",
            "grad_loss:0.122975\n",
            "dice_loss:-0.891210\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:114\n",
            "loss(total):-0.002950\n",
            "recons_loss:0.004892\n",
            "grad_loss:0.103669\n",
            "dice_loss:-0.887850\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:115\n",
            "loss(total):-0.002948\n",
            "recons_loss:0.004742\n",
            "grad_loss:0.122263\n",
            "dice_loss:-0.891212\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:116\n",
            "loss(total):-0.003616\n",
            "recons_loss:0.004355\n",
            "grad_loss:0.089755\n",
            "dice_loss:-0.886856\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:117\n",
            "loss(total):-0.003817\n",
            "recons_loss:0.003984\n",
            "grad_loss:0.115234\n",
            "dice_loss:-0.895338\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:118\n",
            "loss(total):-0.004733\n",
            "recons_loss:0.003680\n",
            "grad_loss:0.061973\n",
            "dice_loss:-0.903296\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:119\n",
            "loss(total):-0.004256\n",
            "recons_loss:0.003827\n",
            "grad_loss:0.103718\n",
            "dice_loss:-0.911955\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:120\n",
            "loss(total):-0.002694\n",
            "recons_loss:0.004899\n",
            "grad_loss:0.128605\n",
            "dice_loss:-0.887842\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:121\n",
            "loss(total):-0.003106\n",
            "recons_loss:0.004637\n",
            "grad_loss:0.129811\n",
            "dice_loss:-0.904183\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:122\n",
            "loss(total):-0.004654\n",
            "recons_loss:0.003414\n",
            "grad_loss:0.088998\n",
            "dice_loss:-0.895819\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:123\n",
            "loss(total):-0.003585\n",
            "recons_loss:0.004204\n",
            "grad_loss:0.105369\n",
            "dice_loss:-0.884237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:124\n",
            "loss(total):-0.003685\n",
            "recons_loss:0.004222\n",
            "grad_loss:0.097091\n",
            "dice_loss:-0.887838\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:125\n",
            "loss(total):-0.003107\n",
            "recons_loss:0.004537\n",
            "grad_loss:0.114058\n",
            "dice_loss:-0.878421\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:126\n",
            "loss(total):-0.002250\n",
            "recons_loss:0.005381\n",
            "grad_loss:0.111830\n",
            "dice_loss:-0.874986\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:127\n",
            "loss(total):-0.003910\n",
            "recons_loss:0.004043\n",
            "grad_loss:0.102170\n",
            "dice_loss:-0.897434\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:128\n",
            "loss(total):-0.004222\n",
            "recons_loss:0.003670\n",
            "grad_loss:0.113867\n",
            "dice_loss:-0.902984\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:129\n",
            "loss(total):-0.004781\n",
            "recons_loss:0.003136\n",
            "grad_loss:0.095211\n",
            "dice_loss:-0.886942\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:130\n",
            "loss(total):-0.004630\n",
            "recons_loss:0.003452\n",
            "grad_loss:0.092050\n",
            "dice_loss:-0.900279\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:131\n",
            "loss(total):-0.004463\n",
            "recons_loss:0.003547\n",
            "grad_loss:0.087709\n",
            "dice_loss:-0.888693\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:132\n",
            "loss(total):-0.003013\n",
            "recons_loss:0.004782\n",
            "grad_loss:0.100026\n",
            "dice_loss:-0.879594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:133\n",
            "loss(total):-0.003824\n",
            "recons_loss:0.004089\n",
            "grad_loss:0.099231\n",
            "dice_loss:-0.890539\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:134\n",
            "loss(total):-0.004471\n",
            "recons_loss:0.003686\n",
            "grad_loss:0.082506\n",
            "dice_loss:-0.898257\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:135\n",
            "loss(total):-0.005787\n",
            "recons_loss:0.002497\n",
            "grad_loss:0.075047\n",
            "dice_loss:-0.903509\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:136\n",
            "loss(total):-0.003319\n",
            "recons_loss:0.004454\n",
            "grad_loss:0.104185\n",
            "dice_loss:-0.881464\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:137\n",
            "loss(total):-0.004506\n",
            "recons_loss:0.003791\n",
            "grad_loss:0.073818\n",
            "dice_loss:-0.903538\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:138\n",
            "loss(total):-0.004180\n",
            "recons_loss:0.003800\n",
            "grad_loss:0.098386\n",
            "dice_loss:-0.896342\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:139\n",
            "loss(total):-0.003325\n",
            "recons_loss:0.004392\n",
            "grad_loss:0.109408\n",
            "dice_loss:-0.881079\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:140\n",
            "loss(total):-0.002617\n",
            "recons_loss:0.004992\n",
            "grad_loss:0.127438\n",
            "dice_loss:-0.888397\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:141\n",
            "loss(total):-0.005442\n",
            "recons_loss:0.002914\n",
            "grad_loss:0.068700\n",
            "dice_loss:-0.904317\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:142\n",
            "loss(total):-0.003378\n",
            "recons_loss:0.004546\n",
            "grad_loss:0.091641\n",
            "dice_loss:-0.884049\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:143\n",
            "loss(total):-0.003560\n",
            "recons_loss:0.004411\n",
            "grad_loss:0.090817\n",
            "dice_loss:-0.887903\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:144\n",
            "loss(total):-0.003210\n",
            "recons_loss:0.004630\n",
            "grad_loss:0.111445\n",
            "dice_loss:-0.895465\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:145\n",
            "loss(total):-0.003699\n",
            "recons_loss:0.004265\n",
            "grad_loss:0.096321\n",
            "dice_loss:-0.892766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:146\n",
            "loss(total):-0.003941\n",
            "recons_loss:0.003922\n",
            "grad_loss:0.105991\n",
            "dice_loss:-0.892287\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:147\n",
            "loss(total):-0.003487\n",
            "recons_loss:0.004390\n",
            "grad_loss:0.086689\n",
            "dice_loss:-0.874398\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:148\n",
            "loss(total):-0.001976\n",
            "recons_loss:0.005459\n",
            "grad_loss:0.145391\n",
            "dice_loss:-0.888910\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:149\n",
            "loss(total):-0.003512\n",
            "recons_loss:0.004405\n",
            "grad_loss:0.101999\n",
            "dice_loss:-0.893707\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:150\n",
            "loss(total):-0.004220\n",
            "recons_loss:0.003875\n",
            "grad_loss:0.091028\n",
            "dice_loss:-0.900441\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:151\n",
            "loss(total):-0.003108\n",
            "recons_loss:0.004559\n",
            "grad_loss:0.120300\n",
            "dice_loss:-0.887010\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:152\n",
            "loss(total):-0.002618\n",
            "recons_loss:0.005126\n",
            "grad_loss:0.125438\n",
            "dice_loss:-0.899888\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:153\n",
            "loss(total):-0.003499\n",
            "recons_loss:0.004302\n",
            "grad_loss:0.109651\n",
            "dice_loss:-0.889766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:154\n",
            "loss(total):-0.004763\n",
            "recons_loss:0.003404\n",
            "grad_loss:0.081903\n",
            "dice_loss:-0.898601\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:155\n",
            "loss(total):-0.005147\n",
            "recons_loss:0.002872\n",
            "grad_loss:0.093286\n",
            "dice_loss:-0.895130\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:156\n",
            "loss(total):-0.003152\n",
            "recons_loss:0.004546\n",
            "grad_loss:0.116137\n",
            "dice_loss:-0.885897\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:157\n",
            "loss(total):-0.003984\n",
            "recons_loss:0.003927\n",
            "grad_loss:0.097944\n",
            "dice_loss:-0.889057\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:158\n",
            "loss(total):-0.004608\n",
            "recons_loss:0.003369\n",
            "grad_loss:0.102733\n",
            "dice_loss:-0.900410\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:159\n",
            "loss(total):-0.003007\n",
            "recons_loss:0.004832\n",
            "grad_loss:0.102932\n",
            "dice_loss:-0.886765\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:160\n",
            "loss(total):-0.003697\n",
            "recons_loss:0.004251\n",
            "grad_loss:0.101707\n",
            "dice_loss:-0.896485\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:161\n",
            "loss(total):-0.003972\n",
            "recons_loss:0.004001\n",
            "grad_loss:0.098065\n",
            "dice_loss:-0.895378\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:162\n",
            "loss(total):-0.004980\n",
            "recons_loss:0.003263\n",
            "grad_loss:0.067044\n",
            "dice_loss:-0.891395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:163\n",
            "loss(total):-0.003914\n",
            "recons_loss:0.004154\n",
            "grad_loss:0.084833\n",
            "dice_loss:-0.891569\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:164\n",
            "loss(total):-0.001416\n",
            "recons_loss:0.006234\n",
            "grad_loss:0.108977\n",
            "dice_loss:-0.873929\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:165\n",
            "loss(total):-0.002839\n",
            "recons_loss:0.004894\n",
            "grad_loss:0.111230\n",
            "dice_loss:-0.884447\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:166\n",
            "loss(total):-0.003606\n",
            "recons_loss:0.004503\n",
            "grad_loss:0.094786\n",
            "dice_loss:-0.905673\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:167\n",
            "loss(total):-0.002401\n",
            "recons_loss:0.005137\n",
            "grad_loss:0.131175\n",
            "dice_loss:-0.885031\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:168\n",
            "loss(total):-0.003896\n",
            "recons_loss:0.004013\n",
            "grad_loss:0.098160\n",
            "dice_loss:-0.889032\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:169\n",
            "loss(total):-0.003140\n",
            "recons_loss:0.004685\n",
            "grad_loss:0.109854\n",
            "dice_loss:-0.892381\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:170\n",
            "loss(total):-0.003149\n",
            "recons_loss:0.004696\n",
            "grad_loss:0.106965\n",
            "dice_loss:-0.891489\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:171\n",
            "loss(total):-0.005473\n",
            "recons_loss:0.002801\n",
            "grad_loss:0.081203\n",
            "dice_loss:-0.908591\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:172\n",
            "loss(total):-0.004035\n",
            "recons_loss:0.004048\n",
            "grad_loss:0.077892\n",
            "dice_loss:-0.886146\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:173\n",
            "loss(total):-0.002960\n",
            "recons_loss:0.004708\n",
            "grad_loss:0.108387\n",
            "dice_loss:-0.875219\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:174\n",
            "loss(total):-0.002907\n",
            "recons_loss:0.004751\n",
            "grad_loss:0.117262\n",
            "dice_loss:-0.883121\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:175\n",
            "loss(total):-0.004720\n",
            "recons_loss:0.003379\n",
            "grad_loss:0.087859\n",
            "dice_loss:-0.897758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:176\n",
            "loss(total):-0.003640\n",
            "recons_loss:0.004409\n",
            "grad_loss:0.098163\n",
            "dice_loss:-0.903081\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:177\n",
            "loss(total):-0.002344\n",
            "recons_loss:0.005621\n",
            "grad_loss:0.108025\n",
            "dice_loss:-0.904591\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:178\n",
            "loss(total):-0.003128\n",
            "recons_loss:0.004517\n",
            "grad_loss:0.119636\n",
            "dice_loss:-0.884204\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:179\n",
            "loss(total):-0.003549\n",
            "recons_loss:0.004235\n",
            "grad_loss:0.106253\n",
            "dice_loss:-0.884667\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:180\n",
            "loss(total):-0.003248\n",
            "recons_loss:0.004447\n",
            "grad_loss:0.125471\n",
            "dice_loss:-0.895009\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:181\n",
            "loss(total):-0.005227\n",
            "recons_loss:0.003044\n",
            "grad_loss:0.073352\n",
            "dice_loss:-0.900455\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:182\n",
            "loss(total):-0.004270\n",
            "recons_loss:0.003739\n",
            "grad_loss:0.090696\n",
            "dice_loss:-0.891594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:183\n",
            "loss(total):-0.005294\n",
            "recons_loss:0.003071\n",
            "grad_loss:0.065049\n",
            "dice_loss:-0.901587\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:184\n",
            "loss(total):-0.003962\n",
            "recons_loss:0.003999\n",
            "grad_loss:0.105573\n",
            "dice_loss:-0.901699\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:185\n",
            "loss(total):-0.004937\n",
            "recons_loss:0.003090\n",
            "grad_loss:0.082402\n",
            "dice_loss:-0.885071\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:186\n",
            "loss(total):-0.002109\n",
            "recons_loss:0.005254\n",
            "grad_loss:0.136627\n",
            "dice_loss:-0.872900\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:187\n",
            "loss(total):-0.002766\n",
            "recons_loss:0.004812\n",
            "grad_loss:0.127452\n",
            "dice_loss:-0.885288\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:188\n",
            "loss(total):-0.002564\n",
            "recons_loss:0.004996\n",
            "grad_loss:0.117943\n",
            "dice_loss:-0.873953\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:189\n",
            "loss(total):-0.003617\n",
            "recons_loss:0.004471\n",
            "grad_loss:0.081283\n",
            "dice_loss:-0.890057\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:190\n",
            "loss(total):-0.005087\n",
            "recons_loss:0.003222\n",
            "grad_loss:0.067390\n",
            "dice_loss:-0.898320\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:191\n",
            "loss(total):-0.005347\n",
            "recons_loss:0.002892\n",
            "grad_loss:0.084098\n",
            "dice_loss:-0.908013\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:192\n",
            "loss(total):-0.004049\n",
            "recons_loss:0.004055\n",
            "grad_loss:0.081526\n",
            "dice_loss:-0.891980\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:193\n",
            "loss(total):-0.001839\n",
            "recons_loss:0.005758\n",
            "grad_loss:0.125184\n",
            "dice_loss:-0.884872\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:194\n",
            "loss(total):-0.002607\n",
            "recons_loss:0.005229\n",
            "grad_loss:0.106294\n",
            "dice_loss:-0.889844\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:195\n",
            "loss(total):-0.003130\n",
            "recons_loss:0.004585\n",
            "grad_loss:0.112246\n",
            "dice_loss:-0.883678\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:196\n",
            "loss(total):-0.003302\n",
            "recons_loss:0.004494\n",
            "grad_loss:0.104680\n",
            "dice_loss:-0.884295\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:197\n",
            "loss(total):-0.003514\n",
            "recons_loss:0.004304\n",
            "grad_loss:0.105004\n",
            "dice_loss:-0.886841\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:198\n",
            "loss(total):-0.004014\n",
            "recons_loss:0.003904\n",
            "grad_loss:0.096769\n",
            "dice_loss:-0.888570\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:199\n",
            "loss(total):-0.003894\n",
            "recons_loss:0.003940\n",
            "grad_loss:0.095563\n",
            "dice_loss:-0.878954\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:200\n",
            "loss(total):-0.003326\n",
            "recons_loss:0.004551\n",
            "grad_loss:0.105997\n",
            "dice_loss:-0.893732\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:201\n",
            "loss(total):-0.003847\n",
            "recons_loss:0.004079\n",
            "grad_loss:0.100758\n",
            "dice_loss:-0.893354\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:202\n",
            "loss(total):-0.003726\n",
            "recons_loss:0.004263\n",
            "grad_loss:0.096841\n",
            "dice_loss:-0.895774\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:203\n",
            "loss(total):-0.002583\n",
            "recons_loss:0.005355\n",
            "grad_loss:0.095350\n",
            "dice_loss:-0.889212\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:204\n",
            "loss(total):-0.003975\n",
            "recons_loss:0.004127\n",
            "grad_loss:0.074726\n",
            "dice_loss:-0.884958\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:205\n",
            "loss(total):-0.004535\n",
            "recons_loss:0.003371\n",
            "grad_loss:0.088388\n",
            "dice_loss:-0.879028\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:206\n",
            "loss(total):-0.003822\n",
            "recons_loss:0.004159\n",
            "grad_loss:0.097688\n",
            "dice_loss:-0.895840\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:207\n",
            "loss(total):-0.004150\n",
            "recons_loss:0.003598\n",
            "grad_loss:0.108312\n",
            "dice_loss:-0.883164\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:208\n",
            "loss(total):-0.003397\n",
            "recons_loss:0.004497\n",
            "grad_loss:0.105825\n",
            "dice_loss:-0.895187\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:209\n",
            "loss(total):-0.002683\n",
            "recons_loss:0.005077\n",
            "grad_loss:0.116309\n",
            "dice_loss:-0.892278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:210\n",
            "loss(total):-0.003673\n",
            "recons_loss:0.004431\n",
            "grad_loss:0.090184\n",
            "dice_loss:-0.900666\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:211\n",
            "loss(total):-0.002916\n",
            "recons_loss:0.004801\n",
            "grad_loss:0.106695\n",
            "dice_loss:-0.878346\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:212\n",
            "loss(total):-0.005335\n",
            "recons_loss:0.002785\n",
            "grad_loss:0.077291\n",
            "dice_loss:-0.889234\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:213\n",
            "loss(total):-0.003099\n",
            "recons_loss:0.004638\n",
            "grad_loss:0.103788\n",
            "dice_loss:-0.877489\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:214\n",
            "loss(total):-0.002992\n",
            "recons_loss:0.004832\n",
            "grad_loss:0.107844\n",
            "dice_loss:-0.890248\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:215\n",
            "loss(total):-0.002834\n",
            "recons_loss:0.004833\n",
            "grad_loss:0.126315\n",
            "dice_loss:-0.893038\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:216\n",
            "loss(total):-0.002530\n",
            "recons_loss:0.005239\n",
            "grad_loss:0.124131\n",
            "dice_loss:-0.901044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:217\n",
            "loss(total):-0.003668\n",
            "recons_loss:0.004338\n",
            "grad_loss:0.096829\n",
            "dice_loss:-0.897378\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:218\n",
            "loss(total):-0.003221\n",
            "recons_loss:0.004601\n",
            "grad_loss:0.100883\n",
            "dice_loss:-0.883073\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:219\n",
            "loss(total):-0.004469\n",
            "recons_loss:0.003509\n",
            "grad_loss:0.080487\n",
            "dice_loss:-0.878316\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:220\n",
            "loss(total):-0.003742\n",
            "recons_loss:0.004171\n",
            "grad_loss:0.088173\n",
            "dice_loss:-0.879495\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:221\n",
            "loss(total):-0.001684\n",
            "recons_loss:0.005844\n",
            "grad_loss:0.134779\n",
            "dice_loss:-0.887513\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:222\n",
            "loss(total):-0.001649\n",
            "recons_loss:0.005755\n",
            "grad_loss:0.141688\n",
            "dice_loss:-0.882157\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:223\n",
            "loss(total):-0.003542\n",
            "recons_loss:0.004407\n",
            "grad_loss:0.096679\n",
            "dice_loss:-0.891568\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:224\n",
            "loss(total):-0.002341\n",
            "recons_loss:0.005220\n",
            "grad_loss:0.133541\n",
            "dice_loss:-0.889598\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:225\n",
            "loss(total):-0.002507\n",
            "recons_loss:0.005093\n",
            "grad_loss:0.119440\n",
            "dice_loss:-0.879404\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:226\n",
            "loss(total):-0.003954\n",
            "recons_loss:0.003988\n",
            "grad_loss:0.091267\n",
            "dice_loss:-0.885528\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:227\n",
            "loss(total):-0.003209\n",
            "recons_loss:0.004592\n",
            "grad_loss:0.097026\n",
            "dice_loss:-0.877216\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:228\n",
            "loss(total):-0.002835\n",
            "recons_loss:0.005052\n",
            "grad_loss:0.103915\n",
            "dice_loss:-0.892586\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:229\n",
            "loss(total):-0.000884\n",
            "recons_loss:0.006540\n",
            "grad_loss:0.146737\n",
            "dice_loss:-0.889096\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:230\n",
            "loss(total):-0.003757\n",
            "recons_loss:0.003970\n",
            "grad_loss:0.110061\n",
            "dice_loss:-0.882807\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:231\n",
            "loss(total):-0.002697\n",
            "recons_loss:0.004972\n",
            "grad_loss:0.109914\n",
            "dice_loss:-0.876754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:232\n",
            "loss(total):-0.003302\n",
            "recons_loss:0.004611\n",
            "grad_loss:0.109285\n",
            "dice_loss:-0.900578\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:233\n",
            "loss(total):-0.003783\n",
            "recons_loss:0.004418\n",
            "grad_loss:0.075131\n",
            "dice_loss:-0.895218\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:234\n",
            "loss(total):-0.002825\n",
            "recons_loss:0.005157\n",
            "grad_loss:0.087641\n",
            "dice_loss:-0.885825\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:235\n",
            "loss(total):-0.003666\n",
            "recons_loss:0.004369\n",
            "grad_loss:0.079938\n",
            "dice_loss:-0.883349\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:236\n",
            "loss(total):-0.003590\n",
            "recons_loss:0.004380\n",
            "grad_loss:0.110656\n",
            "dice_loss:-0.907660\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:237\n",
            "loss(total):-0.002806\n",
            "recons_loss:0.005002\n",
            "grad_loss:0.103811\n",
            "dice_loss:-0.884613\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:238\n",
            "loss(total):-0.003986\n",
            "recons_loss:0.004042\n",
            "grad_loss:0.084293\n",
            "dice_loss:-0.887046\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:239\n",
            "loss(total):-0.004641\n",
            "recons_loss:0.003611\n",
            "grad_loss:0.078944\n",
            "dice_loss:-0.904147\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:240\n",
            "loss(total):-0.002758\n",
            "recons_loss:0.005057\n",
            "grad_loss:0.108359\n",
            "dice_loss:-0.889864\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:241\n",
            "loss(total):-0.004471\n",
            "recons_loss:0.003743\n",
            "grad_loss:0.084057\n",
            "dice_loss:-0.905464\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:242\n",
            "loss(total):-0.004062\n",
            "recons_loss:0.003873\n",
            "grad_loss:0.101854\n",
            "dice_loss:-0.895297\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:243\n",
            "loss(total):-0.004507\n",
            "recons_loss:0.003557\n",
            "grad_loss:0.088696\n",
            "dice_loss:-0.895040\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:244\n",
            "loss(total):-0.002269\n",
            "recons_loss:0.005342\n",
            "grad_loss:0.109179\n",
            "dice_loss:-0.870291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:245\n",
            "loss(total):-0.003236\n",
            "recons_loss:0.004645\n",
            "grad_loss:0.100835\n",
            "dice_loss:-0.888988\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:246\n",
            "loss(total):-0.002962\n",
            "recons_loss:0.004799\n",
            "grad_loss:0.104277\n",
            "dice_loss:-0.880382\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:247\n",
            "loss(total):-0.003491\n",
            "recons_loss:0.004329\n",
            "grad_loss:0.101708\n",
            "dice_loss:-0.883763\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:248\n",
            "loss(total):-0.002555\n",
            "recons_loss:0.005193\n",
            "grad_loss:0.108597\n",
            "dice_loss:-0.883442\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:249\n",
            "loss(total):-0.003818\n",
            "recons_loss:0.004149\n",
            "grad_loss:0.091658\n",
            "dice_loss:-0.888335\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:250\n",
            "loss(total):-0.003531\n",
            "recons_loss:0.004216\n",
            "grad_loss:0.118643\n",
            "dice_loss:-0.893364\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:251\n",
            "loss(total):-0.002160\n",
            "recons_loss:0.005558\n",
            "grad_loss:0.122808\n",
            "dice_loss:-0.894550\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:252\n",
            "loss(total):-0.004239\n",
            "recons_loss:0.003874\n",
            "grad_loss:0.082799\n",
            "dice_loss:-0.894091\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:253\n",
            "loss(total):-0.003693\n",
            "recons_loss:0.004320\n",
            "grad_loss:0.104190\n",
            "dice_loss:-0.905423\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:254\n",
            "loss(total):-0.003835\n",
            "recons_loss:0.004120\n",
            "grad_loss:0.090629\n",
            "dice_loss:-0.886097\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:255\n",
            "loss(total):-0.004013\n",
            "recons_loss:0.004042\n",
            "grad_loss:0.086216\n",
            "dice_loss:-0.891697\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:256\n",
            "loss(total):-0.004726\n",
            "recons_loss:0.003427\n",
            "grad_loss:0.083522\n",
            "dice_loss:-0.898911\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:257\n",
            "loss(total):-0.004552\n",
            "recons_loss:0.003633\n",
            "grad_loss:0.077996\n",
            "dice_loss:-0.896496\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:258\n",
            "loss(total):-0.003427\n",
            "recons_loss:0.004304\n",
            "grad_loss:0.107870\n",
            "dice_loss:-0.880981\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:259\n",
            "loss(total):-0.005228\n",
            "recons_loss:0.003078\n",
            "grad_loss:0.072265\n",
            "dice_loss:-0.902892\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:260\n",
            "loss(total):-0.002674\n",
            "recons_loss:0.005041\n",
            "grad_loss:0.120510\n",
            "dice_loss:-0.891960\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:261\n",
            "loss(total):-0.002539\n",
            "recons_loss:0.005244\n",
            "grad_loss:0.113808\n",
            "dice_loss:-0.892143\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:262\n",
            "loss(total):-0.003704\n",
            "recons_loss:0.004077\n",
            "grad_loss:0.112548\n",
            "dice_loss:-0.890630\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:263\n",
            "loss(total):-0.002382\n",
            "recons_loss:0.005225\n",
            "grad_loss:0.119611\n",
            "dice_loss:-0.880279\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:264\n",
            "loss(total):-0.004022\n",
            "recons_loss:0.003893\n",
            "grad_loss:0.098353\n",
            "dice_loss:-0.889807\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:265\n",
            "loss(total):-0.005836\n",
            "recons_loss:0.002627\n",
            "grad_loss:0.061074\n",
            "dice_loss:-0.907405\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:266\n",
            "loss(total):-0.004101\n",
            "recons_loss:0.003824\n",
            "grad_loss:0.093939\n",
            "dice_loss:-0.886435\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:267\n",
            "loss(total):-0.003606\n",
            "recons_loss:0.004381\n",
            "grad_loss:0.091106\n",
            "dice_loss:-0.889792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:268\n",
            "loss(total):-0.003572\n",
            "recons_loss:0.004218\n",
            "grad_loss:0.107665\n",
            "dice_loss:-0.886642\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:269\n",
            "loss(total):-0.003128\n",
            "recons_loss:0.004729\n",
            "grad_loss:0.111287\n",
            "dice_loss:-0.896959\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:0\n",
            "loss(total):-0.005002\n",
            "recons_loss:0.003175\n",
            "grad_loss:0.077816\n",
            "dice_loss:-0.895517\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:1\n",
            "loss(total):-0.003554\n",
            "recons_loss:0.004294\n",
            "grad_loss:0.105891\n",
            "dice_loss:-0.890667\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:2\n",
            "loss(total):-0.003767\n",
            "recons_loss:0.004124\n",
            "grad_loss:0.102816\n",
            "dice_loss:-0.891936\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:3\n",
            "loss(total):-0.004162\n",
            "recons_loss:0.003754\n",
            "grad_loss:0.100740\n",
            "dice_loss:-0.892343\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:4\n",
            "loss(total):-0.004559\n",
            "recons_loss:0.003425\n",
            "grad_loss:0.084798\n",
            "dice_loss:-0.883131\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:5\n",
            "loss(total):-0.003126\n",
            "recons_loss:0.004535\n",
            "grad_loss:0.121090\n",
            "dice_loss:-0.887203\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:6\n",
            "loss(total):-0.001870\n",
            "recons_loss:0.005606\n",
            "grad_loss:0.141433\n",
            "dice_loss:-0.889042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:7\n",
            "loss(total):-0.002004\n",
            "recons_loss:0.005599\n",
            "grad_loss:0.113494\n",
            "dice_loss:-0.873849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:8\n",
            "loss(total):-0.002564\n",
            "recons_loss:0.005086\n",
            "grad_loss:0.116144\n",
            "dice_loss:-0.881179\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:9\n",
            "loss(total):-0.003696\n",
            "recons_loss:0.004178\n",
            "grad_loss:0.104677\n",
            "dice_loss:-0.892012\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:10\n",
            "loss(total):-0.004251\n",
            "recons_loss:0.003567\n",
            "grad_loss:0.097709\n",
            "dice_loss:-0.879479\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:11\n",
            "loss(total):-0.003367\n",
            "recons_loss:0.004494\n",
            "grad_loss:0.104954\n",
            "dice_loss:-0.891064\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:12\n",
            "loss(total):-0.003568\n",
            "recons_loss:0.004444\n",
            "grad_loss:0.095301\n",
            "dice_loss:-0.896506\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:13\n",
            "loss(total):-0.004507\n",
            "recons_loss:0.003519\n",
            "grad_loss:0.091833\n",
            "dice_loss:-0.894481\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:14\n",
            "loss(total):-0.003623\n",
            "recons_loss:0.004310\n",
            "grad_loss:0.095342\n",
            "dice_loss:-0.888645\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:15\n",
            "loss(total):-0.003843\n",
            "recons_loss:0.004121\n",
            "grad_loss:0.090086\n",
            "dice_loss:-0.886487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:16\n",
            "loss(total):-0.002931\n",
            "recons_loss:0.004750\n",
            "grad_loss:0.118772\n",
            "dice_loss:-0.886823\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:17\n",
            "loss(total):-0.004862\n",
            "recons_loss:0.003479\n",
            "grad_loss:0.071324\n",
            "dice_loss:-0.905388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:18\n",
            "loss(total):-0.003829\n",
            "recons_loss:0.004080\n",
            "grad_loss:0.094981\n",
            "dice_loss:-0.885850\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:19\n",
            "loss(total):-0.003704\n",
            "recons_loss:0.004313\n",
            "grad_loss:0.092426\n",
            "dice_loss:-0.894156\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:20\n",
            "loss(total):-0.005304\n",
            "recons_loss:0.003003\n",
            "grad_loss:0.072700\n",
            "dice_loss:-0.903429\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:21\n",
            "loss(total):-0.004726\n",
            "recons_loss:0.003202\n",
            "grad_loss:0.087575\n",
            "dice_loss:-0.880353\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:22\n",
            "loss(total):-0.004615\n",
            "recons_loss:0.003782\n",
            "grad_loss:0.069316\n",
            "dice_loss:-0.909037\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:23\n",
            "loss(total):-0.004331\n",
            "recons_loss:0.003620\n",
            "grad_loss:0.091248\n",
            "dice_loss:-0.886399\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:24\n",
            "loss(total):-0.003766\n",
            "recons_loss:0.004080\n",
            "grad_loss:0.092510\n",
            "dice_loss:-0.877114\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:25\n",
            "loss(total):-0.004261\n",
            "recons_loss:0.003893\n",
            "grad_loss:0.084567\n",
            "dice_loss:-0.900022\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:26\n",
            "loss(total):-0.003562\n",
            "recons_loss:0.004460\n",
            "grad_loss:0.095739\n",
            "dice_loss:-0.897891\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:27\n",
            "loss(total):-0.004087\n",
            "recons_loss:0.003957\n",
            "grad_loss:0.091500\n",
            "dice_loss:-0.895976\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:28\n",
            "loss(total):-0.003462\n",
            "recons_loss:0.004486\n",
            "grad_loss:0.101732\n",
            "dice_loss:-0.896557\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:29\n",
            "loss(total):-0.004061\n",
            "recons_loss:0.003918\n",
            "grad_loss:0.105798\n",
            "dice_loss:-0.903756\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:30\n",
            "loss(total):-0.002780\n",
            "recons_loss:0.004951\n",
            "grad_loss:0.121030\n",
            "dice_loss:-0.894103\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:31\n",
            "loss(total):-0.003072\n",
            "recons_loss:0.004712\n",
            "grad_loss:0.093711\n",
            "dice_loss:-0.872135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:32\n",
            "loss(total):-0.002726\n",
            "recons_loss:0.005027\n",
            "grad_loss:0.100728\n",
            "dice_loss:-0.876068\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:33\n",
            "loss(total):-0.003253\n",
            "recons_loss:0.004734\n",
            "grad_loss:0.099491\n",
            "dice_loss:-0.898209\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:34\n",
            "loss(total):-0.005150\n",
            "recons_loss:0.003000\n",
            "grad_loss:0.078802\n",
            "dice_loss:-0.893800\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:35\n",
            "loss(total):-0.003747\n",
            "recons_loss:0.004081\n",
            "grad_loss:0.106607\n",
            "dice_loss:-0.889331\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:36\n",
            "loss(total):-0.003531\n",
            "recons_loss:0.004283\n",
            "grad_loss:0.102143\n",
            "dice_loss:-0.883515\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:37\n",
            "loss(total):-0.002977\n",
            "recons_loss:0.004639\n",
            "grad_loss:0.129110\n",
            "dice_loss:-0.890698\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:38\n",
            "loss(total):-0.002953\n",
            "recons_loss:0.004950\n",
            "grad_loss:0.110371\n",
            "dice_loss:-0.900638\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:39\n",
            "loss(total):-0.004225\n",
            "recons_loss:0.004023\n",
            "grad_loss:0.077066\n",
            "dice_loss:-0.901951\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:40\n",
            "loss(total):-0.002659\n",
            "recons_loss:0.004984\n",
            "grad_loss:0.112416\n",
            "dice_loss:-0.876760\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:41\n",
            "loss(total):-0.002847\n",
            "recons_loss:0.005017\n",
            "grad_loss:0.098362\n",
            "dice_loss:-0.884715\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:42\n",
            "loss(total):-0.002945\n",
            "recons_loss:0.004867\n",
            "grad_loss:0.098106\n",
            "dice_loss:-0.879287\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:43\n",
            "loss(total):-0.005173\n",
            "recons_loss:0.003044\n",
            "grad_loss:0.076207\n",
            "dice_loss:-0.897986\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:44\n",
            "loss(total):-0.002786\n",
            "recons_loss:0.005123\n",
            "grad_loss:0.108865\n",
            "dice_loss:-0.899836\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:45\n",
            "loss(total):-0.002813\n",
            "recons_loss:0.004779\n",
            "grad_loss:0.117483\n",
            "dice_loss:-0.876621\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:46\n",
            "loss(total):-0.003845\n",
            "recons_loss:0.004053\n",
            "grad_loss:0.110004\n",
            "dice_loss:-0.899831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:47\n",
            "loss(total):-0.003691\n",
            "recons_loss:0.004198\n",
            "grad_loss:0.101210\n",
            "dice_loss:-0.890072\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:48\n",
            "loss(total):-0.004295\n",
            "recons_loss:0.003696\n",
            "grad_loss:0.090987\n",
            "dice_loss:-0.890122\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:49\n",
            "loss(total):-0.005209\n",
            "recons_loss:0.003071\n",
            "grad_loss:0.070066\n",
            "dice_loss:-0.898085\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:50\n",
            "loss(total):-0.004994\n",
            "recons_loss:0.003087\n",
            "grad_loss:0.080094\n",
            "dice_loss:-0.888140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:51\n",
            "loss(total):-0.004253\n",
            "recons_loss:0.003699\n",
            "grad_loss:0.097436\n",
            "dice_loss:-0.892647\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:52\n",
            "loss(total):-0.003527\n",
            "recons_loss:0.004448\n",
            "grad_loss:0.095040\n",
            "dice_loss:-0.892585\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:53\n",
            "loss(total):-0.003159\n",
            "recons_loss:0.004633\n",
            "grad_loss:0.114074\n",
            "dice_loss:-0.893259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:54\n",
            "loss(total):-0.004378\n",
            "recons_loss:0.003632\n",
            "grad_loss:0.093353\n",
            "dice_loss:-0.894350\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:55\n",
            "loss(total):-0.002268\n",
            "recons_loss:0.005416\n",
            "grad_loss:0.131135\n",
            "dice_loss:-0.899525\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:56\n",
            "loss(total):-0.001007\n",
            "recons_loss:0.006286\n",
            "grad_loss:0.152409\n",
            "dice_loss:-0.881758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:57\n",
            "loss(total):-0.003220\n",
            "recons_loss:0.004518\n",
            "grad_loss:0.113306\n",
            "dice_loss:-0.887111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:58\n",
            "loss(total):-0.003538\n",
            "recons_loss:0.004404\n",
            "grad_loss:0.102576\n",
            "dice_loss:-0.896733\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:59\n",
            "loss(total):-0.004457\n",
            "recons_loss:0.003632\n",
            "grad_loss:0.088772\n",
            "dice_loss:-0.897591\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:60\n",
            "loss(total):-0.004681\n",
            "recons_loss:0.003547\n",
            "grad_loss:0.088200\n",
            "dice_loss:-0.910997\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:61\n",
            "loss(total):-0.003752\n",
            "recons_loss:0.004132\n",
            "grad_loss:0.110267\n",
            "dice_loss:-0.898724\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:62\n",
            "loss(total):-0.003579\n",
            "recons_loss:0.004606\n",
            "grad_loss:0.090059\n",
            "dice_loss:-0.908557\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:63\n",
            "loss(total):-0.003344\n",
            "recons_loss:0.004562\n",
            "grad_loss:0.096866\n",
            "dice_loss:-0.887482\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:64\n",
            "loss(total):-0.002885\n",
            "recons_loss:0.004680\n",
            "grad_loss:0.140471\n",
            "dice_loss:-0.897015\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:65\n",
            "loss(total):-0.004378\n",
            "recons_loss:0.003726\n",
            "grad_loss:0.084496\n",
            "dice_loss:-0.894916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:66\n",
            "loss(total):-0.003829\n",
            "recons_loss:0.003897\n",
            "grad_loss:0.104442\n",
            "dice_loss:-0.877023\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:67\n",
            "loss(total):-0.005232\n",
            "recons_loss:0.003004\n",
            "grad_loss:0.074680\n",
            "dice_loss:-0.898318\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:68\n",
            "loss(total):-0.003159\n",
            "recons_loss:0.004583\n",
            "grad_loss:0.112546\n",
            "dice_loss:-0.886723\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:69\n",
            "loss(total):-0.004411\n",
            "recons_loss:0.003625\n",
            "grad_loss:0.096230\n",
            "dice_loss:-0.899903\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:70\n",
            "loss(total):-0.003802\n",
            "recons_loss:0.004203\n",
            "grad_loss:0.092699\n",
            "dice_loss:-0.893118\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:71\n",
            "loss(total):-0.003196\n",
            "recons_loss:0.004629\n",
            "grad_loss:0.110361\n",
            "dice_loss:-0.892896\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:72\n",
            "loss(total):-0.002501\n",
            "recons_loss:0.005114\n",
            "grad_loss:0.122276\n",
            "dice_loss:-0.883755\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:73\n",
            "loss(total):-0.004307\n",
            "recons_loss:0.003561\n",
            "grad_loss:0.100293\n",
            "dice_loss:-0.887121\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:74\n",
            "loss(total):-0.002105\n",
            "recons_loss:0.005484\n",
            "grad_loss:0.128337\n",
            "dice_loss:-0.887244\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:75\n",
            "loss(total):-0.005239\n",
            "recons_loss:0.002931\n",
            "grad_loss:0.079784\n",
            "dice_loss:-0.896802\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:76\n",
            "loss(total):-0.003843\n",
            "recons_loss:0.004020\n",
            "grad_loss:0.097430\n",
            "dice_loss:-0.883691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:77\n",
            "loss(total):-0.003492\n",
            "recons_loss:0.004228\n",
            "grad_loss:0.124753\n",
            "dice_loss:-0.896718\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:78\n",
            "loss(total):-0.004049\n",
            "recons_loss:0.003719\n",
            "grad_loss:0.116456\n",
            "dice_loss:-0.893244\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:79\n",
            "loss(total):-0.003375\n",
            "recons_loss:0.004295\n",
            "grad_loss:0.107655\n",
            "dice_loss:-0.874716\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:80\n",
            "loss(total):-0.003805\n",
            "recons_loss:0.004329\n",
            "grad_loss:0.086994\n",
            "dice_loss:-0.900400\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:81\n",
            "loss(total):-0.004020\n",
            "recons_loss:0.003952\n",
            "grad_loss:0.094356\n",
            "dice_loss:-0.891555\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:82\n",
            "loss(total):-0.003437\n",
            "recons_loss:0.004523\n",
            "grad_loss:0.100279\n",
            "dice_loss:-0.896333\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:83\n",
            "loss(total):-0.003577\n",
            "recons_loss:0.004099\n",
            "grad_loss:0.107475\n",
            "dice_loss:-0.875127\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:84\n",
            "loss(total):-0.004004\n",
            "recons_loss:0.003902\n",
            "grad_loss:0.102759\n",
            "dice_loss:-0.893414\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:85\n",
            "loss(total):-0.004402\n",
            "recons_loss:0.003688\n",
            "grad_loss:0.088427\n",
            "dice_loss:-0.897391\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:86\n",
            "loss(total):-0.003365\n",
            "recons_loss:0.004422\n",
            "grad_loss:0.109652\n",
            "dice_loss:-0.888367\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:87\n",
            "loss(total):-0.002610\n",
            "recons_loss:0.005127\n",
            "grad_loss:0.121468\n",
            "dice_loss:-0.895087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:88\n",
            "loss(total):-0.004970\n",
            "recons_loss:0.003287\n",
            "grad_loss:0.066876\n",
            "dice_loss:-0.892523\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:89\n",
            "loss(total):-0.003196\n",
            "recons_loss:0.004578\n",
            "grad_loss:0.095117\n",
            "dice_loss:-0.872443\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:90\n",
            "loss(total):-0.004105\n",
            "recons_loss:0.003702\n",
            "grad_loss:0.095995\n",
            "dice_loss:-0.876640\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:91\n",
            "loss(total):-0.004010\n",
            "recons_loss:0.003877\n",
            "grad_loss:0.102654\n",
            "dice_loss:-0.891360\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:92\n",
            "loss(total):-0.003107\n",
            "recons_loss:0.004833\n",
            "grad_loss:0.109467\n",
            "dice_loss:-0.903482\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:93\n",
            "loss(total):-0.001857\n",
            "recons_loss:0.005465\n",
            "grad_loss:0.141017\n",
            "dice_loss:-0.873247\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:94\n",
            "loss(total):-0.002981\n",
            "recons_loss:0.004709\n",
            "grad_loss:0.114533\n",
            "dice_loss:-0.883566\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:95\n",
            "loss(total):-0.004360\n",
            "recons_loss:0.003945\n",
            "grad_loss:0.070590\n",
            "dice_loss:-0.901100\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:96\n",
            "loss(total):-0.003087\n",
            "recons_loss:0.004595\n",
            "grad_loss:0.121463\n",
            "dice_loss:-0.889644\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:97\n",
            "loss(total):-0.002350\n",
            "recons_loss:0.005209\n",
            "grad_loss:0.120471\n",
            "dice_loss:-0.876347\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:98\n",
            "loss(total):-0.002680\n",
            "recons_loss:0.005034\n",
            "grad_loss:0.114784\n",
            "dice_loss:-0.886222\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:99\n",
            "loss(total):-0.003805\n",
            "recons_loss:0.004329\n",
            "grad_loss:0.096494\n",
            "dice_loss:-0.909846\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:100\n",
            "loss(total):-0.001862\n",
            "recons_loss:0.005719\n",
            "grad_loss:0.127281\n",
            "dice_loss:-0.885324\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:101\n",
            "loss(total):-0.003941\n",
            "recons_loss:0.004011\n",
            "grad_loss:0.096633\n",
            "dice_loss:-0.891844\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:102\n",
            "loss(total):-0.004904\n",
            "recons_loss:0.003281\n",
            "grad_loss:0.080596\n",
            "dice_loss:-0.899120\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:103\n",
            "loss(total):-0.004283\n",
            "recons_loss:0.003811\n",
            "grad_loss:0.090106\n",
            "dice_loss:-0.899485\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:104\n",
            "loss(total):-0.004024\n",
            "recons_loss:0.003851\n",
            "grad_loss:0.092494\n",
            "dice_loss:-0.879975\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:105\n",
            "loss(total):-0.004185\n",
            "recons_loss:0.003846\n",
            "grad_loss:0.088711\n",
            "dice_loss:-0.891844\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:106\n",
            "loss(total):-0.004560\n",
            "recons_loss:0.003590\n",
            "grad_loss:0.068665\n",
            "dice_loss:-0.883644\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:107\n",
            "loss(total):-0.003760\n",
            "recons_loss:0.004171\n",
            "grad_loss:0.095789\n",
            "dice_loss:-0.888843\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:108\n",
            "loss(total):-0.003583\n",
            "recons_loss:0.004263\n",
            "grad_loss:0.100307\n",
            "dice_loss:-0.884881\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:109\n",
            "loss(total):-0.003621\n",
            "recons_loss:0.004283\n",
            "grad_loss:0.094798\n",
            "dice_loss:-0.885147\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:110\n",
            "loss(total):-0.004699\n",
            "recons_loss:0.003353\n",
            "grad_loss:0.099431\n",
            "dice_loss:-0.904555\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:111\n",
            "loss(total):-0.003569\n",
            "recons_loss:0.004674\n",
            "grad_loss:0.080884\n",
            "dice_loss:-0.905214\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:112\n",
            "loss(total):-0.002776\n",
            "recons_loss:0.004769\n",
            "grad_loss:0.120827\n",
            "dice_loss:-0.875393\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:113\n",
            "loss(total):-0.003951\n",
            "recons_loss:0.003949\n",
            "grad_loss:0.106558\n",
            "dice_loss:-0.896540\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:114\n",
            "loss(total):-0.003958\n",
            "recons_loss:0.003916\n",
            "grad_loss:0.101822\n",
            "dice_loss:-0.889182\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:115\n",
            "loss(total):-0.004334\n",
            "recons_loss:0.003854\n",
            "grad_loss:0.082946\n",
            "dice_loss:-0.901736\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:116\n",
            "loss(total):-0.003777\n",
            "recons_loss:0.004025\n",
            "grad_loss:0.100013\n",
            "dice_loss:-0.880219\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:117\n",
            "loss(total):-0.004584\n",
            "recons_loss:0.003614\n",
            "grad_loss:0.087106\n",
            "dice_loss:-0.906922\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:118\n",
            "loss(total):-0.003265\n",
            "recons_loss:0.004638\n",
            "grad_loss:0.101601\n",
            "dice_loss:-0.891905\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:119\n",
            "loss(total):-0.004455\n",
            "recons_loss:0.003834\n",
            "grad_loss:0.081331\n",
            "dice_loss:-0.910303\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:120\n",
            "loss(total):-0.003981\n",
            "recons_loss:0.004116\n",
            "grad_loss:0.087652\n",
            "dice_loss:-0.897341\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:121\n",
            "loss(total):-0.003904\n",
            "recons_loss:0.004168\n",
            "grad_loss:0.089422\n",
            "dice_loss:-0.896654\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:122\n",
            "loss(total):-0.003312\n",
            "recons_loss:0.004524\n",
            "grad_loss:0.108556\n",
            "dice_loss:-0.892238\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:123\n",
            "loss(total):-0.003135\n",
            "recons_loss:0.004811\n",
            "grad_loss:0.101926\n",
            "dice_loss:-0.896554\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:124\n",
            "loss(total):-0.004184\n",
            "recons_loss:0.003718\n",
            "grad_loss:0.100642\n",
            "dice_loss:-0.890769\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:125\n",
            "loss(total):-0.004019\n",
            "recons_loss:0.003864\n",
            "grad_loss:0.097348\n",
            "dice_loss:-0.885648\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:126\n",
            "loss(total):-0.001807\n",
            "recons_loss:0.005721\n",
            "grad_loss:0.140007\n",
            "dice_loss:-0.892830\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:127\n",
            "loss(total):-0.002945\n",
            "recons_loss:0.004766\n",
            "grad_loss:0.118967\n",
            "dice_loss:-0.890037\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:128\n",
            "loss(total):-0.003322\n",
            "recons_loss:0.004550\n",
            "grad_loss:0.100598\n",
            "dice_loss:-0.887774\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:129\n",
            "loss(total):-0.005332\n",
            "recons_loss:0.002750\n",
            "grad_loss:0.086185\n",
            "dice_loss:-0.894394\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:130\n",
            "loss(total):-0.003704\n",
            "recons_loss:0.004167\n",
            "grad_loss:0.095009\n",
            "dice_loss:-0.882139\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:131\n",
            "loss(total):-0.003953\n",
            "recons_loss:0.003857\n",
            "grad_loss:0.106009\n",
            "dice_loss:-0.886940\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:132\n",
            "loss(total):-0.004043\n",
            "recons_loss:0.003964\n",
            "grad_loss:0.095580\n",
            "dice_loss:-0.896293\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:133\n",
            "loss(total):-0.004558\n",
            "recons_loss:0.003501\n",
            "grad_loss:0.081333\n",
            "dice_loss:-0.887249\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:134\n",
            "loss(total):-0.003632\n",
            "recons_loss:0.004285\n",
            "grad_loss:0.095983\n",
            "dice_loss:-0.887692\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:135\n",
            "loss(total):-0.004123\n",
            "recons_loss:0.004110\n",
            "grad_loss:0.075635\n",
            "dice_loss:-0.898944\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:136\n",
            "loss(total):-0.002669\n",
            "recons_loss:0.005130\n",
            "grad_loss:0.117358\n",
            "dice_loss:-0.897268\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:137\n",
            "loss(total):-0.003215\n",
            "recons_loss:0.004775\n",
            "grad_loss:0.088801\n",
            "dice_loss:-0.887782\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:138\n",
            "loss(total):-0.003386\n",
            "recons_loss:0.004382\n",
            "grad_loss:0.118327\n",
            "dice_loss:-0.895098\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:139\n",
            "loss(total):-0.002763\n",
            "recons_loss:0.004899\n",
            "grad_loss:0.112545\n",
            "dice_loss:-0.878669\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:140\n",
            "loss(total):-0.002921\n",
            "recons_loss:0.004795\n",
            "grad_loss:0.110435\n",
            "dice_loss:-0.882044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:141\n",
            "loss(total):-0.004304\n",
            "recons_loss:0.003667\n",
            "grad_loss:0.098942\n",
            "dice_loss:-0.896054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:142\n",
            "loss(total):-0.003016\n",
            "recons_loss:0.004767\n",
            "grad_loss:0.109484\n",
            "dice_loss:-0.887759\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:143\n",
            "loss(total):-0.003725\n",
            "recons_loss:0.004130\n",
            "grad_loss:0.103928\n",
            "dice_loss:-0.889425\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:144\n",
            "loss(total):-0.004669\n",
            "recons_loss:0.003444\n",
            "grad_loss:0.073711\n",
            "dice_loss:-0.884990\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:145\n",
            "loss(total):-0.003168\n",
            "recons_loss:0.004627\n",
            "grad_loss:0.104775\n",
            "dice_loss:-0.884309\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:146\n",
            "loss(total):-0.004938\n",
            "recons_loss:0.003289\n",
            "grad_loss:0.079868\n",
            "dice_loss:-0.902576\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:147\n",
            "loss(total):-0.005449\n",
            "recons_loss:0.003012\n",
            "grad_loss:0.060812\n",
            "dice_loss:-0.906917\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:148\n",
            "loss(total):-0.003951\n",
            "recons_loss:0.004189\n",
            "grad_loss:0.084563\n",
            "dice_loss:-0.898619\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:149\n",
            "loss(total):-0.003515\n",
            "recons_loss:0.004359\n",
            "grad_loss:0.096464\n",
            "dice_loss:-0.883845\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:150\n",
            "loss(total):-0.004764\n",
            "recons_loss:0.003289\n",
            "grad_loss:0.084411\n",
            "dice_loss:-0.889754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:151\n",
            "loss(total):-0.004514\n",
            "recons_loss:0.003491\n",
            "grad_loss:0.096596\n",
            "dice_loss:-0.897099\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:152\n",
            "loss(total):-0.003905\n",
            "recons_loss:0.004017\n",
            "grad_loss:0.104049\n",
            "dice_loss:-0.896180\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:153\n",
            "loss(total):-0.003068\n",
            "recons_loss:0.004761\n",
            "grad_loss:0.117226\n",
            "dice_loss:-0.900137\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:154\n",
            "loss(total):-0.004087\n",
            "recons_loss:0.003951\n",
            "grad_loss:0.102331\n",
            "dice_loss:-0.906201\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:155\n",
            "loss(total):-0.002917\n",
            "recons_loss:0.004851\n",
            "grad_loss:0.108798\n",
            "dice_loss:-0.885590\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:156\n",
            "loss(total):-0.003843\n",
            "recons_loss:0.004167\n",
            "grad_loss:0.096244\n",
            "dice_loss:-0.897316\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:157\n",
            "loss(total):-0.003108\n",
            "recons_loss:0.004579\n",
            "grad_loss:0.117220\n",
            "dice_loss:-0.885959\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:158\n",
            "loss(total):-0.004253\n",
            "recons_loss:0.003696\n",
            "grad_loss:0.097797\n",
            "dice_loss:-0.892725\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:159\n",
            "loss(total):-0.004739\n",
            "recons_loss:0.003235\n",
            "grad_loss:0.089971\n",
            "dice_loss:-0.887313\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:160\n",
            "loss(total):-0.004166\n",
            "recons_loss:0.003838\n",
            "grad_loss:0.093539\n",
            "dice_loss:-0.894020\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:161\n",
            "loss(total):-0.002643\n",
            "recons_loss:0.005062\n",
            "grad_loss:0.109483\n",
            "dice_loss:-0.880011\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:162\n",
            "loss(total):-0.002469\n",
            "recons_loss:0.005176\n",
            "grad_loss:0.125482\n",
            "dice_loss:-0.890011\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:163\n",
            "loss(total):-0.004655\n",
            "recons_loss:0.003547\n",
            "grad_loss:0.080106\n",
            "dice_loss:-0.900297\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:164\n",
            "loss(total):-0.002736\n",
            "recons_loss:0.004980\n",
            "grad_loss:0.115258\n",
            "dice_loss:-0.886890\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:165\n",
            "loss(total):-0.004010\n",
            "recons_loss:0.004012\n",
            "grad_loss:0.092695\n",
            "dice_loss:-0.894909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:166\n",
            "loss(total):-0.004046\n",
            "recons_loss:0.003791\n",
            "grad_loss:0.108200\n",
            "dice_loss:-0.891931\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:167\n",
            "loss(total):-0.002728\n",
            "recons_loss:0.005079\n",
            "grad_loss:0.115941\n",
            "dice_loss:-0.896705\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:168\n",
            "loss(total):-0.002912\n",
            "recons_loss:0.004928\n",
            "grad_loss:0.112369\n",
            "dice_loss:-0.896388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:169\n",
            "loss(total):-0.002833\n",
            "recons_loss:0.004926\n",
            "grad_loss:0.118164\n",
            "dice_loss:-0.894007\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:170\n",
            "loss(total):-0.003850\n",
            "recons_loss:0.003977\n",
            "grad_loss:0.109590\n",
            "dice_loss:-0.892302\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:171\n",
            "loss(total):-0.004592\n",
            "recons_loss:0.003274\n",
            "grad_loss:0.088438\n",
            "dice_loss:-0.875027\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:172\n",
            "loss(total):-0.003939\n",
            "recons_loss:0.003826\n",
            "grad_loss:0.098517\n",
            "dice_loss:-0.875015\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:173\n",
            "loss(total):-0.003607\n",
            "recons_loss:0.004225\n",
            "grad_loss:0.106318\n",
            "dice_loss:-0.889560\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:174\n",
            "loss(total):-0.003498\n",
            "recons_loss:0.004382\n",
            "grad_loss:0.103252\n",
            "dice_loss:-0.891281\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:175\n",
            "loss(total):-0.003474\n",
            "recons_loss:0.004320\n",
            "grad_loss:0.097216\n",
            "dice_loss:-0.876694\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:176\n",
            "loss(total):-0.003878\n",
            "recons_loss:0.004145\n",
            "grad_loss:0.097918\n",
            "dice_loss:-0.900171\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:177\n",
            "loss(total):-0.003783\n",
            "recons_loss:0.004335\n",
            "grad_loss:0.087765\n",
            "dice_loss:-0.899574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:178\n",
            "loss(total):-0.005015\n",
            "recons_loss:0.003417\n",
            "grad_loss:0.061726\n",
            "dice_loss:-0.904930\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:179\n",
            "loss(total):-0.003710\n",
            "recons_loss:0.004227\n",
            "grad_loss:0.086077\n",
            "dice_loss:-0.879772\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:180\n",
            "loss(total):-0.005543\n",
            "recons_loss:0.002667\n",
            "grad_loss:0.075822\n",
            "dice_loss:-0.896809\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:181\n",
            "loss(total):-0.003297\n",
            "recons_loss:0.004441\n",
            "grad_loss:0.119572\n",
            "dice_loss:-0.893375\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:182\n",
            "loss(total):-0.002867\n",
            "recons_loss:0.004875\n",
            "grad_loss:0.119464\n",
            "dice_loss:-0.893696\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:183\n",
            "loss(total):-0.003220\n",
            "recons_loss:0.004520\n",
            "grad_loss:0.114113\n",
            "dice_loss:-0.888094\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:184\n",
            "loss(total):-0.003753\n",
            "recons_loss:0.004230\n",
            "grad_loss:0.099852\n",
            "dice_loss:-0.898075\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:185\n",
            "loss(total):-0.003216\n",
            "recons_loss:0.004631\n",
            "grad_loss:0.107505\n",
            "dice_loss:-0.892191\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:186\n",
            "loss(total):-0.003450\n",
            "recons_loss:0.004300\n",
            "grad_loss:0.112488\n",
            "dice_loss:-0.887495\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:187\n",
            "loss(total):-0.003114\n",
            "recons_loss:0.004478\n",
            "grad_loss:0.125002\n",
            "dice_loss:-0.884193\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:188\n",
            "loss(total):-0.004528\n",
            "recons_loss:0.003639\n",
            "grad_loss:0.090508\n",
            "dice_loss:-0.907168\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:189\n",
            "loss(total):-0.004097\n",
            "recons_loss:0.003790\n",
            "grad_loss:0.102941\n",
            "dice_loss:-0.891691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:190\n",
            "loss(total):-0.003180\n",
            "recons_loss:0.004741\n",
            "grad_loss:0.100162\n",
            "dice_loss:-0.892293\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:191\n",
            "loss(total):-0.003763\n",
            "recons_loss:0.004065\n",
            "grad_loss:0.096170\n",
            "dice_loss:-0.879006\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:192\n",
            "loss(total):-0.004319\n",
            "recons_loss:0.003691\n",
            "grad_loss:0.087552\n",
            "dice_loss:-0.888487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:193\n",
            "loss(total):-0.004076\n",
            "recons_loss:0.003756\n",
            "grad_loss:0.099445\n",
            "dice_loss:-0.882627\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:194\n",
            "loss(total):-0.003746\n",
            "recons_loss:0.004005\n",
            "grad_loss:0.117996\n",
            "dice_loss:-0.893170\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:195\n",
            "loss(total):-0.002555\n",
            "recons_loss:0.005296\n",
            "grad_loss:0.110523\n",
            "dice_loss:-0.895565\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:196\n",
            "loss(total):-0.003985\n",
            "recons_loss:0.004257\n",
            "grad_loss:0.073600\n",
            "dice_loss:-0.897873\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:197\n",
            "loss(total):-0.002724\n",
            "recons_loss:0.005106\n",
            "grad_loss:0.101703\n",
            "dice_loss:-0.884704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:198\n",
            "loss(total):-0.003301\n",
            "recons_loss:0.004737\n",
            "grad_loss:0.104573\n",
            "dice_loss:-0.908397\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:199\n",
            "loss(total):-0.003201\n",
            "recons_loss:0.004721\n",
            "grad_loss:0.097112\n",
            "dice_loss:-0.889371\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:200\n",
            "loss(total):-0.003562\n",
            "recons_loss:0.004417\n",
            "grad_loss:0.102544\n",
            "dice_loss:-0.900468\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:201\n",
            "loss(total):-0.003953\n",
            "recons_loss:0.003942\n",
            "grad_loss:0.097103\n",
            "dice_loss:-0.886663\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:202\n",
            "loss(total):-0.003299\n",
            "recons_loss:0.004484\n",
            "grad_loss:0.119094\n",
            "dice_loss:-0.897454\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:203\n",
            "loss(total):-0.004539\n",
            "recons_loss:0.003367\n",
            "grad_loss:0.094009\n",
            "dice_loss:-0.884648\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:204\n",
            "loss(total):-0.003659\n",
            "recons_loss:0.004253\n",
            "grad_loss:0.111920\n",
            "dice_loss:-0.903068\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:205\n",
            "loss(total):-0.002837\n",
            "recons_loss:0.004922\n",
            "grad_loss:0.129856\n",
            "dice_loss:-0.905695\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:206\n",
            "loss(total):-0.003549\n",
            "recons_loss:0.004659\n",
            "grad_loss:0.074839\n",
            "dice_loss:-0.895559\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:207\n",
            "loss(total):-0.004856\n",
            "recons_loss:0.003293\n",
            "grad_loss:0.085170\n",
            "dice_loss:-0.900059\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:208\n",
            "loss(total):-0.003502\n",
            "recons_loss:0.004248\n",
            "grad_loss:0.104720\n",
            "dice_loss:-0.879635\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:209\n",
            "loss(total):-0.003767\n",
            "recons_loss:0.004148\n",
            "grad_loss:0.095861\n",
            "dice_loss:-0.887380\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:210\n",
            "loss(total):-0.003933\n",
            "recons_loss:0.003987\n",
            "grad_loss:0.091028\n",
            "dice_loss:-0.883057\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:211\n",
            "loss(total):-0.003134\n",
            "recons_loss:0.004820\n",
            "grad_loss:0.098684\n",
            "dice_loss:-0.894077\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:212\n",
            "loss(total):-0.004620\n",
            "recons_loss:0.003706\n",
            "grad_loss:0.082670\n",
            "dice_loss:-0.915213\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:213\n",
            "loss(total):-0.003705\n",
            "recons_loss:0.004288\n",
            "grad_loss:0.096150\n",
            "dice_loss:-0.895472\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:214\n",
            "loss(total):-0.005091\n",
            "recons_loss:0.003092\n",
            "grad_loss:0.082804\n",
            "dice_loss:-0.901084\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:215\n",
            "loss(total):-0.004741\n",
            "recons_loss:0.003329\n",
            "grad_loss:0.083022\n",
            "dice_loss:-0.890049\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:216\n",
            "loss(total):-0.002332\n",
            "recons_loss:0.005081\n",
            "grad_loss:0.122949\n",
            "dice_loss:-0.864278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:217\n",
            "loss(total):-0.004242\n",
            "recons_loss:0.003693\n",
            "grad_loss:0.082746\n",
            "dice_loss:-0.876261\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:218\n",
            "loss(total):-0.003725\n",
            "recons_loss:0.004296\n",
            "grad_loss:0.095373\n",
            "dice_loss:-0.897451\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:219\n",
            "loss(total):-0.003149\n",
            "recons_loss:0.004609\n",
            "grad_loss:0.114786\n",
            "dice_loss:-0.890639\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:220\n",
            "loss(total):-0.004741\n",
            "recons_loss:0.003399\n",
            "grad_loss:0.084514\n",
            "dice_loss:-0.898445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:221\n",
            "loss(total):-0.004783\n",
            "recons_loss:0.003279\n",
            "grad_loss:0.086462\n",
            "dice_loss:-0.892657\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:222\n",
            "loss(total):-0.004182\n",
            "recons_loss:0.003946\n",
            "grad_loss:0.081659\n",
            "dice_loss:-0.894395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:223\n",
            "loss(total):-0.002414\n",
            "recons_loss:0.005169\n",
            "grad_loss:0.139199\n",
            "dice_loss:-0.897442\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:224\n",
            "loss(total):-0.002692\n",
            "recons_loss:0.004858\n",
            "grad_loss:0.121373\n",
            "dice_loss:-0.876334\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:225\n",
            "loss(total):-0.003057\n",
            "recons_loss:0.004720\n",
            "grad_loss:0.104014\n",
            "dice_loss:-0.881650\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:226\n",
            "loss(total):-0.003937\n",
            "recons_loss:0.004057\n",
            "grad_loss:0.078682\n",
            "dice_loss:-0.878085\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:227\n",
            "loss(total):-0.003444\n",
            "recons_loss:0.004492\n",
            "grad_loss:0.104308\n",
            "dice_loss:-0.897978\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:228\n",
            "loss(total):-0.004901\n",
            "recons_loss:0.003114\n",
            "grad_loss:0.099946\n",
            "dice_loss:-0.901532\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:229\n",
            "loss(total):-0.003452\n",
            "recons_loss:0.004399\n",
            "grad_loss:0.104839\n",
            "dice_loss:-0.889917\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:230\n",
            "loss(total):-0.003030\n",
            "recons_loss:0.004737\n",
            "grad_loss:0.111821\n",
            "dice_loss:-0.888542\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:231\n",
            "loss(total):-0.004735\n",
            "recons_loss:0.003563\n",
            "grad_loss:0.067790\n",
            "dice_loss:-0.897564\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:232\n",
            "loss(total):-0.002294\n",
            "recons_loss:0.005390\n",
            "grad_loss:0.100424\n",
            "dice_loss:-0.868806\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:233\n",
            "loss(total):-0.004990\n",
            "recons_loss:0.003399\n",
            "grad_loss:0.068983\n",
            "dice_loss:-0.907948\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:234\n",
            "loss(total):-0.002776\n",
            "recons_loss:0.004900\n",
            "grad_loss:0.121845\n",
            "dice_loss:-0.889395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:235\n",
            "loss(total):-0.003206\n",
            "recons_loss:0.004472\n",
            "grad_loss:0.137067\n",
            "dice_loss:-0.904938\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:236\n",
            "loss(total):-0.003664\n",
            "recons_loss:0.004303\n",
            "grad_loss:0.108102\n",
            "dice_loss:-0.904788\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:237\n",
            "loss(total):-0.004062\n",
            "recons_loss:0.003722\n",
            "grad_loss:0.095182\n",
            "dice_loss:-0.873594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:238\n",
            "loss(total):-0.004086\n",
            "recons_loss:0.003826\n",
            "grad_loss:0.096018\n",
            "dice_loss:-0.887244\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:239\n",
            "loss(total):-0.002882\n",
            "recons_loss:0.004881\n",
            "grad_loss:0.102851\n",
            "dice_loss:-0.879224\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:240\n",
            "loss(total):-0.004404\n",
            "recons_loss:0.003679\n",
            "grad_loss:0.076375\n",
            "dice_loss:-0.884712\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:241\n",
            "loss(total):-0.004291\n",
            "recons_loss:0.003681\n",
            "grad_loss:0.090544\n",
            "dice_loss:-0.887741\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:242\n",
            "loss(total):-0.004065\n",
            "recons_loss:0.003847\n",
            "grad_loss:0.105702\n",
            "dice_loss:-0.896869\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:243\n",
            "loss(total):-0.003722\n",
            "recons_loss:0.004223\n",
            "grad_loss:0.095841\n",
            "dice_loss:-0.890299\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:244\n",
            "loss(total):-0.003935\n",
            "recons_loss:0.003861\n",
            "grad_loss:0.102839\n",
            "dice_loss:-0.882384\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:245\n",
            "loss(total):-0.003817\n",
            "recons_loss:0.004144\n",
            "grad_loss:0.103514\n",
            "dice_loss:-0.899536\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:246\n",
            "loss(total):-0.004096\n",
            "recons_loss:0.003727\n",
            "grad_loss:0.107490\n",
            "dice_loss:-0.889848\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:247\n",
            "loss(total):-0.003368\n",
            "recons_loss:0.004460\n",
            "grad_loss:0.102708\n",
            "dice_loss:-0.885467\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:248\n",
            "loss(total):-0.003579\n",
            "recons_loss:0.004490\n",
            "grad_loss:0.102978\n",
            "dice_loss:-0.909887\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:249\n",
            "loss(total):-0.002446\n",
            "recons_loss:0.005162\n",
            "grad_loss:0.118661\n",
            "dice_loss:-0.879452\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:250\n",
            "loss(total):-0.003407\n",
            "recons_loss:0.004444\n",
            "grad_loss:0.108423\n",
            "dice_loss:-0.893480\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:251\n",
            "loss(total):-0.004774\n",
            "recons_loss:0.003233\n",
            "grad_loss:0.090069\n",
            "dice_loss:-0.890807\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:252\n",
            "loss(total):-0.003354\n",
            "recons_loss:0.004417\n",
            "grad_loss:0.118992\n",
            "dice_loss:-0.896045\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:253\n",
            "loss(total):-0.003845\n",
            "recons_loss:0.003975\n",
            "grad_loss:0.108906\n",
            "dice_loss:-0.890916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:254\n",
            "loss(total):-0.001646\n",
            "recons_loss:0.006107\n",
            "grad_loss:0.121651\n",
            "dice_loss:-0.896880\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:255\n",
            "loss(total):-0.003687\n",
            "recons_loss:0.004095\n",
            "grad_loss:0.105237\n",
            "dice_loss:-0.883473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:256\n",
            "loss(total):-0.004746\n",
            "recons_loss:0.003357\n",
            "grad_loss:0.080727\n",
            "dice_loss:-0.891090\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:257\n",
            "loss(total):-0.003784\n",
            "recons_loss:0.004004\n",
            "grad_loss:0.097285\n",
            "dice_loss:-0.876090\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:258\n",
            "loss(total):-0.002959\n",
            "recons_loss:0.004669\n",
            "grad_loss:0.118643\n",
            "dice_loss:-0.881448\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:259\n",
            "loss(total):-0.002914\n",
            "recons_loss:0.004703\n",
            "grad_loss:0.113689\n",
            "dice_loss:-0.875360\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:260\n",
            "loss(total):-0.003305\n",
            "recons_loss:0.004746\n",
            "grad_loss:0.085874\n",
            "dice_loss:-0.890954\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:261\n",
            "loss(total):-0.004390\n",
            "recons_loss:0.003718\n",
            "grad_loss:0.080663\n",
            "dice_loss:-0.891431\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:262\n",
            "loss(total):-0.004646\n",
            "recons_loss:0.003461\n",
            "grad_loss:0.089009\n",
            "dice_loss:-0.899725\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:263\n",
            "loss(total):-0.003830\n",
            "recons_loss:0.003971\n",
            "grad_loss:0.117521\n",
            "dice_loss:-0.897662\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:264\n",
            "loss(total):-0.004675\n",
            "recons_loss:0.003443\n",
            "grad_loss:0.091624\n",
            "dice_loss:-0.903457\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:265\n",
            "loss(total):-0.003752\n",
            "recons_loss:0.004276\n",
            "grad_loss:0.102815\n",
            "dice_loss:-0.905693\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:266\n",
            "loss(total):-0.004027\n",
            "recons_loss:0.003912\n",
            "grad_loss:0.085638\n",
            "dice_loss:-0.879524\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:267\n",
            "loss(total):-0.004464\n",
            "recons_loss:0.003888\n",
            "grad_loss:0.061685\n",
            "dice_loss:-0.896881\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:268\n",
            "loss(total):-0.003865\n",
            "recons_loss:0.004360\n",
            "grad_loss:0.069931\n",
            "dice_loss:-0.892429\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:269\n",
            "loss(total):-0.002748\n",
            "recons_loss:0.005105\n",
            "grad_loss:0.101726\n",
            "dice_loss:-0.887078\n",
            "---------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihSJmSDbyHII",
        "outputId": "5b202e65-9792-4d1e-eb36-1fbf06054f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(losses_1[1:])\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yyg4wQkyOcI",
        "outputId": "9348b855-18bd-4342-8f90-2b0ef09c5115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(validation_1)\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAIECAYAAAAHGhTUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3jU9Z33/9cckpmQIyFnJiHkBApIiIQKeGxrpdailWqx1RarAj3s/lzuXV2vXbr1V+vlfW9v9u69rj+gWraWSmnBtVTrWmu10qqcFFBQIJBkMpADBHI+zeH7+yMkmnLK4Zv5ziTPx3XN5RXmM+Edpkle/Xzen8/HZhiGIQAAgChit7oAAACAoSLAAACAqEOAAQAAUYcAAwAAog4BBgAARB0CDAAAiDpOqwsIB5fLpfT0dKvLAAAAQ3Dy5El1d3ef97lxEWDS09Pl8/msLgMAAAyBx+O54HMsIQEAgKhDgAEAAFGHAAMAAKIOAQYAAEQdAgwAAIg6BBgAABB1CDAAACDqEGAAAEDUIcAAAICoQ4ABAABRhwADAACiDgEGAABEHQIMAACIOgQYAAAQdQgwAAAg6hBgAABA1CHAAACAqEOAAQAAUYcAAwAAog4BZpie+XOlrv/X11VzusPqUgAAGHcIMMPU2uVXVWOHOnqCVpcCAMC4Q4AZJpfTIUnqDhBgAAAINwLMMLljev/pugMhiysBAGD8IcAMU98MTJefGRgAAMKNADNMLufZGRg/MzAAAIQbAWaYXCwhAQBgGQLMMNHECwCAdQgww0QTLwAA1iHADBNNvAAAWIcAM0z9TbzMwAAAEHYEmGHqb+JlFxIAAGFHgBkmN028AABYhgAzTGyjBgDAOgSYYaKJFwAA6xBghokmXgAArEOAGSYCDAAA1iHADJPTYZfTblM3S0gAAIQdAWYEXE47MzAAAFiAADMCrhgHTbwAAFiAADMCzMAAAGANAswIEGAAALAGAWYE3DEOTuIFAMACBJgRcDnt3IUEAIAFTA0wR44c0YIFC1RSUqLy8nIdOHDgvOOeeeYZFRcXq7CwUA888ID8fr8k6Y9//KPmzZunyy+/XDNmzNBDDz2kUOjjgPDiiy9q+vTpKi4u1u23366WlhYzyx8yl5MZGAAArGBqgFmxYoWWL1+uw4cP6+GHH9ayZcvOGVNZWanVq1dr+/btqqioUH19vdavXy9Jmjhxon75y1/q4MGD2rNnj9566y09++yzkqS2tjbdd999euGFF3TkyBHl5OToBz/4gZnlD5krhhkYAACsYFqAaWho0O7du3X33XdLkpYsWaKamhpVVFQMGLdlyxYtXrxYWVlZstlsWrlypTZt2iRJmjNnjgoKCiRJbrdbpaWlqqqqkiS9/PLLmjNnjqZPny5J+va3v93/OqvQxAsAgDVMCzA1NTXKzs6W0+mUJNlsNuXl5cnr9Q4Y5/V6NWXKlP6P8/PzzxkjSXV1ddqyZYtuueWWC76utrZWgUDgnNeuWbNGHo+n/9HW1mbK1/jXXDEO9QRDCoWMUfn8AADg/CKyibelpUVf/OIX9dBDD2nu3LlDfv2qVavk8/n6HwkJCaNQJfchAQBgFdMCTG5u7oAZEcMw5PV6lZeXN2BcXl6eqqur+z+uqqoaMKa1tVWLFi3SrbfeqlWrVl30dZ+c8bGCy+mQJBp5AQAIM9MCTEZGhsrKyrRx40ZJ0tatW+XxeFRUVDRg3JIlS7Rt2zbV1dXJMAytXbtWS5culdTbqLto0SItWrRI//zP/zzgdYsWLdK7776rjz76SJL01FNP9b/OKszAAABgDVOXkNatW6d169appKRETzzxhDZs2CBJuv/++7Vt2zZJUkFBgR599FEtXLhQRUVFSk9P14oVKyRJP/7xj7Vz5049//zzKi0tVWlpqX74wx9KkhITE/X000/rtttuU1FRkXw+n1avXm1m+UPmijkbYNiJBABAWNkMwxjzHagej0c+n8/0z/tvrx7Wj187olf/7loVZyaa/vkBABjPLvb7OyKbeKNF3wxMFzMwAACEFQFmBGjiBQDAGgSYEaCJFwAAaxBgRuDjAMMMDAAA4USAGQF3zNklJHpgAAAIKwLMCPTNwHQxAwMAQFgRYEbAxQwMAACWIMCMAE28AABYgwAzAv09MCwhAQAQVgSYEeifgWEJCQCAsCLAjABNvAAAWIMAMwI08QIAYA0CzAjQxAsAgDUIMCNAEy8AANYgwIxAfw8MS0gAAIQVAWYEnHab7DZmYAAACDcCzAjYbDa5nA56YAAACDMCzAi5YuzsQgIAIMwIMCPkdjpYQgIAIMwIMCPkirHTxAsAQJgRYEbI5bQzAwMAQJgRYEaIJl4AAMKPADNCvTMwBBgAAMKJADNC7hiHuv0sIQEAEE4EmBFyOe3qYgYGAICwIsCMkCvGrp5ASIZhWF0KAADjBgFmhFzOvgsdmYUBACBcCDAj1HehIwEGAIDwIcCMkDumbwaGRl4AAMKFADNC/TMwnMYLAEDYEGBG6OMlJGZgAAAIFwLMCLnOLiFxHxIAAOFDgBkhmngBAAg/AswI9c3AcBovAADhQ4AZIWZgAAAIPwLMCNHECwBA+BFgRoiTeAEACD8CzAi5YzgHBgCAcCPAjFDfDEwXS0gAAIQNAWaEXMzAAAAQdgSYEaKJFwCA8CPAjBBNvAAAhB8BZoT6m3gJMAAAhA0BZoT6m3g5iRcAgLAhwIwQTbwAAIQfAWaEaOIFACD8CDAjFOuwy2ajBwYAgHAiwIyQzWaTy2knwAAAEEYEGBO4nA6aeAEACCMCjAmYgQEAILwIMCZwxdhp4gUAIIwIMCZwOR1sowYAIIwIMCZwx9i5jRoAgDAiwJiAGRgAAMKLAGMCmngBAAgvAowJegMMS0gAAIQLAcYELqdD3YGQDMOwuhQAAMYFAowJ3DF2GYbUE2QZCQCAcCDAmMDldEjiPiQAAMKFAGMCV8zZG6nZiQQAQFgQYEzgcp4NMDTyAgAQFgQYE7CEBABAeBFgTOA+u4TEjdQAAIQHAcYEzMAAABBeBBgT0MQLAEB4EWBMQBMvAADhRYAxgTuGJSQAAMKJAGOCvhkYmngBAAgPAowJaOIFACC8CDAm+LgHhgADAEA4EGBM8PEuJJaQAAAIBwKMCVhCAgAgvAgwJnAzAwMAQFgRYEzADAwAAOFFgDEBTbwAAIQXAcYEH8/AsIQEAEA4EGBM4Oq/jZoZGAAAwoEAYwLuQgIAILxMDTBHjhzRggULVFJSovLych04cOC845555hkVFxersLBQDzzwgPx+vySpqqpK119/vZKTk1VaWjrgNW+88Ybi4uJUWlra/+js7DSz/GGz2WyKddq5jRoAgDAxNcCsWLFCy5cv1+HDh/Xwww9r2bJl54yprKzU6tWrtX37dlVUVKi+vl7r16+XJCUlJemxxx7Tc889d97PP23aNO3du7f/ERcXZ2b5I+Jy2mniBQAgTEwLMA0NDdq9e7fuvvtuSdKSJUtUU1OjioqKAeO2bNmixYsXKysrSzabTStXrtSmTZskSampqbr66qsVHx9vVllh43I6WEICACBMTAswNTU1ys7OltPplNS7rJKXlyev1ztgnNfr1ZQpU/o/zs/PP2fMhRw9elRlZWUqLy/XU089dcFxa9askcfj6X+0tbUN4ysaGneMnSZeAADCxGl1AYNVVlYmn8+n5ORk+Xw+3XzzzUpLS9Odd955zthVq1Zp1apV/R97PJ5Rr693CYkZGAAAwsG0GZjc3FzV1tYqEAhIkgzDkNfrVV5e3oBxeXl5qq6u7v+4qqrqnDHnk5SUpOTkZEm9geSuu+7S9u3bzSp/xHqXkJiBAQAgHEwLMBkZGSorK9PGjRslSVu3bpXH41FRUdGAcUuWLNG2bdtUV1cnwzC0du1aLV269JKfv7a2VqFQb0BobW3Viy++qDlz5phV/oi5YtiFBABAuJi6C2ndunVat26dSkpK9MQTT2jDhg2SpPvvv1/btm2TJBUUFOjRRx/VwoULVVRUpPT0dK1YsUKS1NHRIY/HozvuuEMHDx6Ux+PRI488Iqk3EM2aNUuzZ8/WVVddpRtvvFH33nuvmeWPCEtIAACEj80wDMPqIkabx+ORz+cb1b9j2Yad2nHstD78waJR/XsAABgvLvb7m5N4TdI3AzMO8iAAAJYjwJjE5XQoZEiBEAEGAIDRRoAxycf3IdHICwDAaCPAmKTvRupuP428AACMNgKMSdxOhySpixkYAABGHQHGJMzAAAAQPgQYk7jOzsDQAwMAwOgjwJiEJl4AAMKHAGMSd8zZHhiWkAAAGHUEGJMwAwMAQPgQYExCEy8AAOFDgDEJTbwAAIQPAcYkLCEBABA+BBiT0MQLAED4EGBMwgwMAADhQ4Axycc9MMzAAAAw2ggwJvl4FxIzMAAAjDYCjElYQgIAIHwIMCahiRcAgPAhwJiEGRgAAMKHAGMSmngBAAgfAoxJYpmBAQAgbAgwJnHYbYpx2NiFBABAGBBgTOR2OlhCAgAgDAgwJnLF2JmBAQAgDAgwJnIxAwMAQFgQYEzkctpp4gUAIAwIMCaKddo5yA4AgDAgwJjIHeNgBgYAgDAgwJiIJSQAAMKDAGMiV4xD3SwhAQAw6ggwJmIGBgCA8CDAmMgd41AgZCgQJMQAADCaCDAm4kZqAADCgwBjIgIMAADhQYAxkcvpkCRO4wUAYJQRYEzkijk7A8N9SAAAjCoCjIncZ2dgupiBAQBgVBFgTNQ3A9PFDAwAAKOKAGOi1AmxkqSGli6LKwEAYGwjwJioKDNBknSkoc3iSgAAGNsIMCYqyugNMBUEGAAARhUBxkRJ7hhlJrkIMAAAjDICjMmKMxJV0dCmUMiwuhQAAMYsAozJijIS1OkP6nhTp9WlAAAwZhFgTEYfDAAAo48AY7JiAgwAAKOOAGOy4sxESdKRhlaLKwEAYOwiwJgsNT5Wk+JjOQsGAIBRRIAZBYUZCapoaJNhsBMJAIDRQIAZBcUZCWrtCqihtdvqUgAAGJMIMKOgr5H3SD3LSAAAjAYCzCigkRcAgNFFgBkFnAUDAMDoIsCMgoxElxLdTnYiAQAwSggwo8Bms6n47E4kAABgPgLMKCnKSNDp9h41trETCQAAsxFgRklxRm8jL7MwAACYjwAzSooyz26lJsAAAGA6Aswo4VJHAABGDwFmlOQkxykuxsFZMAAAjAICzCix220qYicSAACjggAzioozElTf0q3mTr/VpQAAMKYQYEZRXyMvszAAAJiLADOKitL7Agx9MAAAmIkAM4r6LnVkBgYAAHMRYEZR7sQ4xTrtnAUDAIDJCDCjyOmwqyAtXkfqCTAAAJiJADPKijISdLypUx09AatLAQBgzCDAjDLuRAIAwHwEmFF2WXZvgNnva7a4EgAAxg4CzCgrz0+VJO2sPG1xJQAAjB0EmFE2MT5WJZkJ2ll5WoZhWF0OAABjAgEmDOZNTVVdS5dqTndaXQoAAGMCASYM5k2dJEnaUdlocSUAAIwNBJgwmEcfDAAApiLAhEFWsltTJk3QzioCDAAAZjA1wBw5ckQLFixQSUmJysvLdeDAgfOOe+aZZ1RcXKzCwkI98MAD8vv9kqSqqipdf/31Sk5OVmlp6aBfFw3m5aequrFDdc1dVpcCAEDUMzXArFixQsuXL9fhw4f18MMPa9myZeeMqays1OrVq7V9+3ZVVFSovr5e69evlyQlJSXpscce03PPPTek10WDeVPPLiMxCwMAwIiZFmAaGhq0e/du3X333ZKkJUuWqKamRhUVFQPGbdmyRYsXL1ZWVpZsNptWrlypTZs2SZJSU1N19dVXKz4+/pzPf7HXRYNPnW3k3UkjLwAAI2ZagKmpqVF2dracTqckyWazKS8vT16vd8A4r9erKVOm9H+cn59/zpjzGcrr1qxZI4/H0/9oa7P+GP/c1DhlJblp5AUAwARjsol31apV8vl8/Y+EhASrS5LNZtO8qak6XN+mM+09VpcDAEBUMy3A5Obmqra2VoFA763LhmHI6/UqLy9vwLi8vDxVV1f3f1xVVXXOmPMZ7usiSV8fzC76YAAAGBHTAkxGRobKysq0ceNGSdLWrVvl8XhUVFQ0YNySJUu0bds21dXVyTAMrV27VkuXLr3k5x/u6yLJp6ZyHgwAAGYwdQlp3bp1WrdunUpKSvTEE09ow4YNkqT7779f27ZtkyQVFBTo0Ucf1cKFC1VUVKT09HStWLFCktTR0SGPx6M77rhDBw8elMfj0SOPPHLJ10WLoowEpcbHshMJAIARshnj4IZBj8cjn89ndRmSpBU/361XD9Zr//dvUoLLaXU5AABErIv9/h6TTbyRbN7USQoZ0p7qM1aXAgBA1CLAhNnHfTCcBwMAwHARYMLssuwkJbicNPICADACBJgwc9htmps/UftqmtXlD1pdDgAAUYkAY4F5U1PVEwzpPW+T1aUAABCVCDAWmJmTLEk6etL6Kw4AAIhGBBgLZCW7JUkNLV0WVwIAQHQiwFggM7E3wNS3dFtcCQAA0YkAY4GkOKfcMXbVMQMDAMCwEGAsYLPZlJnkVj0BBgCAYSHAWCQz0a2GVpaQAAAYDgKMRTKSXDrd3qPuAGfBAAAwVAQYi2Ql9e1EYhYGAIChIsBYJLMvwLTSBwMAwFARYCySkeSSxFZqAACGgwBjkb4ZmLpmZmAAABgqAoxF+npg6llCAgBgyAgwFulbQqKJFwCAoSPAWGRCrFOJbidLSAAADAMBxkJZSW6WkAAAGAYCjIUyk9wsIQEAMAwEGAtlJLnU1h1QW3fA6lIAAIgqBBgL9W2l5lJHAACGhgBjoSwCDAAAw0KAsVAmW6kBABgWAoyFMpiBAQBgWAgwFupbQqojwAAAMCQEGAulJ7KEBADAcBBgLBTjsCstIZYlJAAAhogAY7GMRDdLSAAADBEBxmJZyb2n8RqGYXUpAABEDQKMxTKTXOoJhtTU4be6FAAAogYBxmIZiWe3UnOpIwAAg0aAsVjfdQJ1zQQYAAAGiwBjsaxktlIDADBUBBiL9S8hsRMJAIBBI8BYrP9GanpgAAAYNAKMxSbFx8ppt6mumSUkAAAGiwBjMbvdpoxElxqYgQEAYNAIMBEgI8lNDwwAAENAgIkAmUkunWztViAYsroUAACiAgEmAmQluRUypMb2HqtLAQAgKhBgIkBGElupAQAYCgJMBOjfSs1hdgAADAoBJgJk9V0nwAwMAACDQoCJAJlJfdcJEGAAABgMAkwEoAcGAIChIcBEgCS3U+4Yu+rogQEAYFAIMBHAZrMpK8nNEhIAAINEgIkQnMYLAMDgEWAiRGaSW2c6/OoOBK0uBQCAiEeAiRBZ/TuR6IMBAOBSCDARIpOdSAAADBoBJkJkcBovAACDRoCJEH2n8dY2d1pcCQAAkY8AEyGyk/sCDEtIAABcCgEmQmQlu2WzMQMDAMBgEGAiRIzDroxEl443MQMDAMClEGAiSE5KnE40MQMDAMClEGAiSE5KnE62dnOYHQAAl0CAiSA5Zxt565vZSg0AwMUQYCJITkqcJOk4y0gAAFwUASaC9AUYdiIBAHBxBJgIkpPcG2Bo5AUA4OIIMBEkJ6W3B4at1AAAXBwBJoKkxsfK5bSzhAQAwCUQYCKIzWbjLBgAAAaBABNhclLcOsESEgAAF0WAiTA5yXFq6w6opctvdSkAAEQsAkyEyU5hJxIAAJdCgIkwk8/uRCLAAABwYQSYCJPTPwNDHwwAABdCgIkw2RxmBwDAJRFgIkwOS0gAAFwSASbCTIh1auKEGJ1oZgkJAIALIcBEoOxkDrMDAOBiCDARKCclTnXNXQqGDKtLAQAgIhFgItDkFLcCIUOn2rqtLgUAgIhkaoA5cuSIFixYoJKSEpWXl+vAgQPnHffMM8+ouLhYhYWFeuCBB+T3+y/53BtvvKG4uDiVlpb2Pzo7x+YyS99hdsdZRgIA4LxMDTArVqzQ8uXLdfjwYT388MNatmzZOWMqKyu1evVqbd++XRUVFaqvr9f69esv+ZwkTZs2TXv37u1/xMXFmVl+xMjhNF4AAC7KtADT0NCg3bt36+6775YkLVmyRDU1NaqoqBgwbsuWLVq8eLGysrJks9m0cuVKbdq06ZLPjSd9p/HWcpgdAADnZVqAqampUXZ2tpxOpyTJZrMpLy9PXq93wDiv16spU6b0f5yfn98/5mLPSdLRo0dVVlam8vJyPfXUUxesZc2aNfJ4PP2PtrY2U77GcOk7zI4lJAAAzs9pdQGDVVZWJp/Pp+TkZPl8Pt18881KS0vTnXfeec7YVatWadWqVf0fezyecJY6YhmJLjnsNpaQAAC4ANNmYHJzc1VbW6tAICBJMgxDXq9XeXl5A8bl5eWpurq6/+Oqqqr+MRd7LikpScnJyZJ6A8ldd92l7du3m1V+RHE67MpKcquWw+wAADgv0wJMRkaGysrKtHHjRknS1q1b5fF4VFRUNGDckiVLtG3bNtXV1ckwDK1du1ZLly695HO1tbUKhUKSpNbWVr344ouaM2eOWeVHnJwUNzMwAABcgKm7kNatW6d169appKRETzzxhDZs2CBJuv/++7Vt2zZJUkFBgR599FEtXLhQRUVFSk9P14oVKy753NatWzVr1izNnj1bV111lW688Ubde++9ZpYfUbKT49TY3qMuf9DqUgAAiDg2wzDG/HGvHo9HPp/P6jKG5ImXP9LaPx3V639/vaamxVtdDgAAYXex39+cxBuhJnMrNQAAF0SAiVBspQYA4MIIMBGq7zReDrMDAOBcBJgINZnrBAAAuCACTIRKinNqQqxDJ5oJMAAA/DUCTISy2WzKSYljBgYAgPMgwESw3gDTpXGw0x0AgCEhwESwnGS3Ov1BNXX4rS4FAICIQoCJYH07keiDAQBgIAJMBOsPMGylBgBgAAJMBMtJ7j2N9/iZDosrAQAgshBgIlhxZqLsNmn7kVNWlwIAQEQhwESw9ESXbpiWodcPNaiumWUkAAD6EGAi3FfKcxUypC17aqwuBQCAiEGAiXA3TM9QeqJLm3fXKBTiPBgAACQCTMSLcdh1x5Ue1Zzu1FtHG60uBwCAiECAiQJ3zs2VJP1yl9fiSgAAiAwEmCiQnxav+QWT9PsD9Trd3mN1OQAAWI4AEyWWzstVTzCk59/1WV0KAACWI8BEiZtmZCk5Lkabd9VwuSMAYNwjwEQJd4xDX5ozWUca2vSu94zV5QAAYCkCTBRZOu9sM+9OzoQBAIxvBJgoMj0rSaW5KXpxf61au/xWlwMAgGUIMFFmaXmuOv1Bbdt3wupSAACwDAEmytwyO0fxsQ5t2smZMACA8YsAE2USXE4tLp2sD4636H1fs9XlAABgCQJMFPrqvDxJ0nPMwgAAxikCTBSa5UnWrMnJ2rb3uNq6A1aXAwBA2BFgotRd8/LU3hPUtr008wIAxh8CTJRaXEozLwBg/CLARKm+Zt73jzfTzAsAGHcIMFGMZl4AwHhFgIliNPMCAMYrAkyU62vm/S0n8wIAxhECTJTra+Z9bgfLSACA8YMAE+Vo5gUAjEcEmDGgr5l30y5mYQAA4wMBZgyY5UnW5dlJ+u3eE+rsCVpdDgAAo44AM0bcMdej1u6AXjlQZ3UpAACMOgLMGHFb6WTFOuz69Z4aq0sBAGDUEWDGiInxsfrs5Rn6S0Wjak53WF0OAACjigAzhtxxZa4kaeu7PosrAQBgdBFgxpBritOUmeTSlj0+hUKG1eUAADBqCDBjiNNh1+1lHvnOdOqdY41WlwMAwKghwIwxd1zpkST9eg/LSACAsYsAM8YUpCdo7pSJevmDWrV0+a0uBwCAUUGAGYPumOtRlz+kF/fVWl0KAACjggAzBn3hihzFxTg4EwYAMGYRYMagBJdTn5+Vpfe8TapoaLW6HAAATEeAGaPunNt7JszmXczCAADGHgLMGPWpqakqzkjQL3Z4dbK12+pyAAAwFQFmjLLZbPofn5umjp6gnvzjEavLAQDAVASYMeymGZkqzU3Rczu98jZyPxIAYOwgwIxhNptNDy+aLn/Q0JpXD1ldDgAApiHAjHHzCyfp2pJ0/WbfCR080WJ1OQAAmIIAMw48dNM0GYb0r698ZHUpAACYggAzDsycnKwvzs7R64dOageXPAIAxgACzDjxP24skdNu0//8749kGIbV5QAAMCIEmHEiPy1eS+fl6l1vk/7wYYPV5QAAMCIEmHHkbz9dLHeMXf/xeoXVpQAAMCIEmHEkI8mtRTOytLemSTWnORcGABC9CDDjzBeuyJEkvfR+rcWVAAAwfASYcebakjQlup16cf8Jq0sBAGDYCDDjjMvp0Ocuz9IHx1tUdard6nIAABgWAsw4dMvsbEliFgYAELUIMOPQ1UVpSpkQoxf30wcDAIhOBJhxKMZh16IZWfqorlUVDW1WlwMAwJARYMapL1zBMhIAIHoRYMap+QWTNCk+Vi/ur+VqAQBA1CHAjFNOh12LZmapoqFNh+pbrS4HAIAhIcCMY7f0HWpHMy8AIMoQYMaxeVNTlZ7oYhkJABB1CDDjmMNu080zs1R5ql0HTrRYXQ4AAINGgBnnbpndu4zEmTAAgGhCgBnnrsybqJxkt361u0aNbd1WlwMAwKAQYMY5u92mf7z5Mp1u79H3fnPA6nIAABgUAgz0xSuy9fmZWXrp/Vr9dh8H2wEAIp+pAebIkSNasGCBSkpKVF5ergMHzv//6J955hkVFxersLBQDzzwgPx+/4ifw/DZbDb94LaZSo2P1erffKCG1i6rSwIA4KJMDTArVqzQ8uXLdfjwYT388MNatmzZOWMqKyu1evVqbd++XRUVFaqvr9f69etH9BxGLi3Bpcdum6mmDr/+6b8+YFs1ACCimRZgGhoatHv3bt19992SpCVLlqimpkYVFRUDxm3ZskWLFy9WVlaWbDabVq5cqU2bNo3oOZjj5lnZ+uLsHL16sF6/2ctSEgAgcpkWYGpqapSdnS2n0ympd1kiLy9PXq93wDiv16spU6b0f5yfn98/ZrjP/bU1a9bI4/H0P9rauHF5sP7fxTOUluDSv2w7oPoWlpIAAJFpTDbxrlq1Sj6fr/+RkJBgdaRJlUcAABtlSURBVElRY2J8rB7/0kw1d/r10Jb9CoZYSgIARB7TAkxubq5qa2sVCAQkSYZhyOv1Ki8vb8C4vLw8VVdX939cVVXVP2a4z8Fcn5uRpTvnevSnwyf1w5c+tLocAADOYVqAycjIUFlZmTZu3ChJ2rp1qzwej4qKigaMW7JkibZt26a6ujoZhqG1a9dq6dKlI3oO5vvBbTM1Lz9VP/1LpX72VpXV5QAAMICpS0jr1q3TunXrVFJSoieeeEIbNmyQJN1///3atm2bJKmgoECPPvqoFi5cqKKiIqWnp2vFihUjeg7mczkdWnfPlZqaFq9Hf3tAf/yo3uqSAADoZzPGwX5Zj8cjn89ndRlRqepUu7701F/UHQjpVyvma+bkZKtLAgCMExf7/T0mm3hhnvy0eP3k63MVCBq672e7VNvcaXVJAAAQYHBpc/NT9a93XKH6lm598z93q7WLE5ABANYiwGBQbi2drL//XIk+rG3Rd557T/5gyOqSAADjGAEGg/adG4r0lbm5evPwSa1+gesGAADWcVpdAKKHzWbTY1+aqRPNnfrlrhrlpk7Qd24ouvQLAQAwGTMwGJIYh11Pfa1M07MS9a+vHNJv9h63uiQAwDhEgMGQJbpjtOHecmUlufUPv96vHccarS4JADDOEGAwLNnJcfrpsnLFOu26/2e7tf3ISatLAgCMIwQYDNvlOUn6ydfnSjZp2YZdevbtKqtLAgCMEwQYjMj8wkn6r28vVO7EOH3vNwe0+oUPFGCLNQBglBFgMGJFGQl64TsLNb9gkn7+TrWWbdil5g4OuwMAjB4CDEyRMiFWz943T3fNy9WfK07pS0/9RUdPtlldFgBgjCLAwDQxDrse/9Isfe+Wy1V9ukO3PfkXvfYht1gDAMxHgIGpbDabvnn1VD37zXlyOGy6/9ndevKPRzi1FwBgKgIMRsXCojT99rtXa1pmon70+8P69i/eVXt3wOqyAABjBAEGoyY3dYKe//YCfeGKbL38QZ1uf+otVTe2W10WAGAMIMBgVE2IderJu+booUXTdLihVYuf/MslD71rY6YGAHAJBBiMOpvNpm9fX6SfLitXyDD0jZ/u1E/ePDagL8YwDL1+qEF3rH1LV3z/Ff3u/VoLKwYARDqbMQ66Kz0ej3w+n9VlQNKxk21a/vM9qmho022lOXr89ll68/BJPfl6hT443qIYh00up0M2m/S7v71GuakTrC4ZAGCRi/3+JsAg7Fq7/Pq7zfv0hw/rFRfjUKc/KJfTrrvm5Wn5tQU6XN+qZRt2aU5ein61Yr5iHEwUAsB4dLHf3/xmQNglumO0/p4r9eBni5XgdmrldYX688Of1vcXz1BOSpyun5ahB66Zqve8Tfo/fzhsdbkAgAjEDAwiUk8gpC+vfUvvH2/WL+77lBYUpVldEgAgzJiBQdSJddr1f5fO0YQYhx7cvFeNbd1WlwQAiCAEGESs/LR4PfalmWpo7dbf/3ofp/kCAPoRYBDRvjTHo9vLJuv1Qyd163/8RX84WE+QAQDIaXUBwKU8dttMJbqc2rSrRvc/u1uXZyfpbz9TrM9dnim73WZ1eQAAC9DEi6hR39KldX86pl/sqFZ3IKRpmYmaXzhJ+ZMmaEpavPInxWtySpzauwOqa+lSXXOXapu7dKajR7dcka0pk+Kt/hIAAEPAOTAEmDGlobVLT2+v1C/eqVZ7T3BQr8lIdGnLygXKm8TBeAAQLQgwBJgxKRgyVNfSpepT7ao+3aGqxnb5znQq0eVUVrJbWUluZSW7daKpS//0wvvKnThBW1bOV0aS2+rSAQCDcLHf3/TAIGo57DZNTonT5JQ4LbjEWJtNeuT593XPMzu1ecVVSpkQG5YaAQCjg11IGBfumpenf/z8dB2qb9W9/7lL7dx4DQBRjQCDcWPldYX61vWFes/bpJUb96g7MLj+GQBA5CHAYFx56KZpumtenrYfOaVF/2e7fvLmMZ1u77G6LADAENHEi3EnGDL04z8c1s/fqdaZDr9iHXbdPCtLX7tqiuZOmSibjbNlACASsAuJAIPz6PIH9cqBOv3iHa92Vp2WJHkmxukz0zP06csy9ampqXLHOCyuEgDGLwIMAQaXcKS+VZt21uj3B+vkO9MpSYqLcejq4jRdXZSmsryJmp6dqBgHq64AEC4EGAIMBskwDB1paNNrHzbo9Y8atLv6tEJnv0PcMXZdMTlFc/JSND07UTnJccpJiVNmkluxToINAJiNAEOAwTA1dfToPW+T3vWe0XveJu2taVLbX23BttmktASXLs9O0q2lObppRpbiXYM7YqnLH9SrB+t1srVbd5bnKmGQrwOA8YAAQ4CBSYIhQxUNbTp2sk0nmrtU29Sp2uYuHW/q1IETzfIHDcXFOPS5GZm6bc5kXVOUJudfLTsZhqG9NU3assen3+47oZau3kCUmeTS6lsu1xdmZdNIDAAiwBBgEBZn2nv00vu1euG949pdfUZS72nByXExAx6+Mx06erJdkjQ9K1FfvtKjWKdd//v3h9Xc6dc1xWl6dPEMFaQnyDAMHT3Zrtc/atAfP2qQ93SHvvqpPH1z4VTFxdJgDGBsI8AQYBBm3sYO/Wbvce0/3qzmTr+aO/xq7vSrqbNHE2KdWjw7R1++0qMZOUn9sy2Nbd164uWP9Os9PsU67LppZpb21TTJe7pDUm8PTnJcjOpbupWZ5NKqG0u0pMxzzgwPAIwVBBgCDCKIYRgXXSLaVXVaq1/4QB/VtWpySpw+PT1Dn56eofmFk2S32fTcjmr93z9W6HR7j4ozErTqxhLNnJysSQmxmhBLDw2AsYMAQ4BBlAkEQzrZ1q2sJPd5w05rl1/r3zymp7dXqtP/8ZUIcTEOpSXGKjPRrTvmenR7mYet3wCiFgGGAIMxqqGlS9v2nVB9S5ca23p0qr1HjW3dqm7sUFt3QJNT4vTtGwr15Ss9cjkH3zPTHQjqcF2b3j/erA9ONOtIfavmF6bpOzcUDunzAMBIEGAIMBhnWrv8evbtaj29/ZjOdPiVnezWfVf3Nv76znTq+JlO+c50qK65S0HDkNNul8Nuk9PeO9tTc6ZD/uDHPxrcMXZ1+UMqyUzQ//rybJXmplj1pQEYRwgwBBiMU+3dAW18p1rr3zymxr+6tDItwaWcFLecdpuCIUOBkKHg2Ude6gTNmJysWZOTNXNyktISXFr3p6P68WtHFAwZeuCaAv3djSX9Vy2cbu/RPl+T3vc1a1JCrL4wK1spE2Kt+JL7vXGoQZt2evX/fKZEl+ckWVoLgOEhwBBgMM519AT0xqGTinc55ZkYp8kpccO65+lwfav+4df7tM/XrIK0eM3yJGtvTZOqGzsGjIt12PXZyzN0+xyPrpuWfsk+nO5AUHuqzigQMrSgcNKId1Y9/65P/7Blv4IhQ7FOu/7p5sv09flTOF8HiDIEGAIMYJpAMKRn/lyp//3qYfUEQipIi1dpbopm56boCk+yjp5s19Y9Pr19rFGSNCk+VteWpCt/Urzy0yac/W+8mjp69KfDJ/WnQyf19rFGdfT0NiPnJLt117w8fWVerjIS3UOu7+ntx/TYSx8qJ9mtR26+TD/6/SFVN3bos5dl6l+/fIUmxls7MwRg8AgwBBjAdM0dfklS8oSY8z7vO9Oh3+w9oeff9fUf3Hc+TrtNZVMm6rqSdHUHQtq8y6v6lm457TbdNCNLd5bn6qqC1Es2DxuGof/1yiH9f28cVVFGgn5+3zxlJ8eptcuv1S98oBf2nlBWklv/9pVSzS+cNPwvPEJ0B4IKBI1BX1sBRCMCDAEGsFRrl1/VjR2qbuxQVWO7Kk+1y+W065ridC0omqQk98chyB8M6bUP67XxHa/+XHFKUm8T8VUFk3RtcbquLUlXYXq8bDabegIhdfYE1eEP6N9ePaxf7fZpTl6KfvqN8gEzLYZhaOu7x/W933ygjp6g5hdM0pIrPfr8zHPvrTIMQ9WNHTpc36q5+alKjbAZmyP1rXpup1fPv3tcDrtNz35znmZOTra6LGBUEGAIMEBUOnayTf99oE5vHj6pPdVn+ndGxcc61BMMDdgpJUnXT0vXU18ru+CBfsdOtulHvz+kPxxsUE8wpAmxDi2amaWbZmTJ29ih3dWntaf6jE619TY8u5x23V7m0X1X56soI/GS9YZChipOtmlP9Rl1+4NyxzjOPuxyxzg0LStR2clxQ/536PIH9bv3a7Vpp1e7qnqvqShMj1fNmU65nHb9573zdOWUiUP+vECkI8AQYICo194d0DvHGvXm4ZM6erJd7hiHJsT2PXqbk++ZP2VQB/c1dfTot/trtWWPT/tqmvr/3G6TLstO0twpE5WfFq8X3juufb5mSdJ1Jem6d2G+8lInKBAy5A+GFAga6vQH9cHxZu2oPK3dVad15uzS2oXMyEnSZy7L1Gcvy9DMnGTZ7RduLG7p8uvnb1frp3+uVGN7j2Kddt0yK1t3fSpPc6dM1FtHG3X/z3bLZpOe+Ub5mFgaAz6JAEOAAXABFQ1teuvoKRWkJag0L0UJn1hSMgxDe6rP6Jk/V+qVA3UKXeSnpcNu08ycJJXnp6p8aqqS42LU5Q+qyx9SdyCo9u6gdled1h8PNajpbMjJSHRpQeEkXeFJ0ezcZF2enay4WIdOtXVrw18q9exb1WrtDign2a1vXj1VX77Sc8729N1Vp3Xvhl3qCYa07p4rdf20jFH5dxoNXf6gtuzx6bkdXn32sgz93Y0l7BTDAAQYAgyAEao53aEX3juuTn9QMQ67Yhw2OR12xTjsKs5IUNmUiQPCz4UEgiG9623Sax/W67WPGlTR0Nb/nMNuU1F6gqpPt6vLH1JBery+dV2hbi2drFjnhWeW3vc1656f7lB7d0D/+PnLlOR2qqUroNYuv1o6A5J6bz6/PCdJxZkJF22I7g4EVdvUpeNNnTre1KnWroA+e1mGpkyKH8K/1sU1dfTo529X6z/fqlJje49sNskwpKXlufrhl2bJcZFZKYwvBBgCDIAI1dTRo/ePN2u/r1n7zx4GmJ7o0orrCnXTjKxB/zL/qK5Fdz+9U6faui86zmm3qSgjQVMmTVB3IKSOnqA6e4Jq7wmopTNwwdcvLJqkpeV5+tyMzCFfJ9HS5VdFQ5sq6tu019ekF947ro6eoCanxOm+q6fqi7NztOpXe7X9yCndPCtL//aVUq6sgCQCDAEGwLhQ39KlHZWnleByKMkdo0R3jJLinPIHDH1Y16KDJ1p0sLb3v8ebOuWOsWtCrFNxMQ7FuxxKcDmVndJ70GHfQ5Kef8+nVw/Wyx80lBofq1tLc1SQFq+UCbFKmRCjiRNiFe9y6mRrt443dZy9qqL3UdHQprqWrgF1Ts9K1MrrCvWFK7L7e5Z6AiH93a/26qX9tbqmOE1r777yolvEu/xBvXGoQS+9Xye7TfrsZZm6flq6Et3n39aP6ESAIcAAwACGYQyp3+RUW7e27vHpl7tqVHnqwuf6fNKEWIcK0xNUnJGgoswEFWckqvjs7M/5/u5gyNDq33yg53Z4VZqboh/cOlPxrt6dXHExDsU67dpdfUbb9p7Q7w/UqbU7MOD1MQ6bFhSm6XMzMnVVwaRhnzj9Sf5gSHuqz6jqVLsuz0nSZdlJ5zSKG4Yh7+kO7Th2Wr4zHfrylbnKmzRhWH+X026jD+gTCDAEGAAwhWEYOlzfplNt3Wrq8OtMR4+aO/1q6fIrPcF19qqKCfJMjFPKhJgh/zI2DEM/+v0h/cfrRy86btbkZC2enaNbZmfLbrPp1YP1+v3Ber199NSA7fWT4mOVkxKnnBS3JiW4FOuwy+XsfcQ67Yp3OZWR6FZGkkuZZ//b0dM7u/PHjxr05uGTaun6OCi5nHbNmpys0twUeSbG6b2aJu04dnrALFOsw677r5mqb99QNKi+qIqGNq3901G98N5xJbidmpaZqMuykzQ9K1HTzvYujdclNQIMAQYAosqrB+t1qK5Fnf6gOntC6goE1dUT1JRJ8fri7GwVpCec93UtXX69ceikDp5o0Ymmzv5HfWu3ghfbRnYBV3iS9enpGZqelaiDJ1r0Xk2T9tY0qfUToaYkM0GfmjpJnypIVXysU//zvz/SR3WtSk906aGbpmlJmee82+X3+5r01OtH9crBOhmGNCcvRXabTYfqWtX2idkld4xd5fmpml84SQsK0zQzJ+mi94WFQoZau3ubuOtbuuU709G/pOc70yHD6N0Bl/6Jx/SsJJVkJkTc7A8BhgADAONaIBhSa1dAPcGQuv0h9QSD6g70/llDa7caWrrU0Nqt+pYuGYZ0dXGarp+Wft77uEIhQ8dOtcl3plOzJidrUoJrwPPBkKHNu2r0o98f0un2Hl2WnaT8v1pSOtnard3VvYcSfvayDH3r+kJdOSVVUu8slO9Mpw7VterAiRbtqGzU7uoz6gmEJEmJLqfSEnv/zv64YZO6eoJq6QoMCD9/LS7GIbtNaj9799gnFabH65YrcnTLFdkqzrz4wY1NHT2qauxQ1al21Zzu0Hc/XTQq4YcAQ4ABAIRZc6df//7aEW3cUa3us+GjT4zdrs/PytK3ri/U9KykS36uLn9Q73rP6O2jjdpx7LRaugYemGgYkjvWoSS3U4lupxJdMUp0O5We6JJnYu+SnmdinFLjY2Wz2dTeHdDJ1m6dbOsNbTuOndbLH9T2n0I9LTNRZVMmKhAMqTsQUk8gpJ5gSKfbe1TV2N5/llGfXf/0WaUnDgxyZiDAEGAAALioQDCknZWn9dv9tfrvD2oHnCpts/X29iTFxSh/0se3yvfdMl+SmTioU7CHigBDgAEAYNACwZBaugKKPdvwbNXuqIv9/uYedgAAMIDTYY+4m9j/mvnzPQAAAKOMAAMAAKIOAQYAAEQdAgwAAIg6BBgAABB1CDAAACDqEGAAAEDUIcAAAICoQ4ABAABRhwADAACiDgEGAABEHQIMAACIOgQYAAAQdQgwAAAg6pgSYEKhkP7mb/5GhYWFKioq0pNPPnnBsUeOHNGCBQtUUlKi8vJyHThwYFDP5efna9q0aSotLVVpaak2b95sRukAACAKOc34JBs3btTBgwd1+PBhNTc3a86cObrhhhs0Y8aMc8auWLFCy5cv17Jly7RlyxYtW7ZMu3btuuRzkrR582aVlpaaUTIAAIhipszAbN68WQ888IAcDodSU1P1la98RZs2bTpnXENDg3bv3q27775bkrRkyRLV1NSooqLios8BAAB8kikBxuv1asqUKf0f5+fny+v1njOupqZG2dnZcjp7J35sNpvy8vLk9Xov+lyfr3/965o1a5buu+8+nTx58oL1rFmzRh6Pp//R1tZmxpcJAAAixKACzPz585WWlnbeR01NzWjXKEl68803tX//fr377rtKS0vTN77xjQuOXbVqlXw+X/8jISEhLDUCAIDwGFQPzNtvv33R5/Py8lRdXa358+dLkqqqqpSXl3fOuNzcXNXW1ioQCMjpdMowDHm9XuXl5SkpKemCz/X9HZIUExOjBx98UCUlJYP+Ik+ePCmPxzPo8YPV1tZGOIpAvC+Rh/ck8vCeRCbel4EuttpiShPvHXfcoZ/85Ce644471NzcrM2bN+vFF188Z1xGRobKysq0ceNGLVu2TFu3bpXH41FRUZEkXfC59vZ2+f1+paSkSJI2bdqkOXPmDLq+7u5uM77Mc3g8Hvl8vlH53Bg+3pfIw3sSeXhPIhPvy+CZEmDuuece7dq1S8XFxbLZbFq1apVmzZolSdq2bZu2bdump59+WpK0bt06LVu2TI8//riSkpK0YcOG/s9zoefq6+u1ZMkSBYNBGYahgoICPfvss2aUDgAAopDNMAzD6iKiFUk5MvG+RB7ek8jDexKZeF8Gz/H973//+1YXEc36+n4QWXhfIg/vSeThPYlMvC+DwwwMAACIOtyFBAAAog4BBgAARB0CDAAAiDoEmGG62M3ZGH1dXV267bbbVFJSotmzZ+vGG2/svzeroaFBixYtUnFxsWbOnKk333zT4mrHnw0bNshms+mFF16QxHtite7ubn33u99VcXGxZs2a1X/nHD/HrPO73/1OZWVlKi0t1cyZM/Wzn/1MEt8rQ2JgWG644QZjw4YNhmEYxq9//Wtj7ty51hY0znR2dhovvfSSEQqFDMMwjH//9383rrvuOsMwDOPee+81/uVf/sUwDMPYuXOnMXnyZKOnp8eiSsefyspKY/78+cZVV11l/Nd//ZdhGLwnVnvwwQeN7373u/3fL7W1tYZh8HPMKqFQyJg4caKxb98+wzB6v2dcLpfR0tLC98oQEGCGob6+3khMTDT8fr9hGL3/Y8zMzDSOHDlicWXj165du4wpU6YYhmEY8fHx/T+gDcMwysvLjVdffdWiysaXYDBofOYznzF2795tXHfddf0BhvfEOm1tbUZiYqLR3Nw84M/5OWadUChkpKamGn/6058MwzCMffv2GTk5OUZ3dzffK0PAEtIwDObmbITXj3/8Y916661qbGyU3+9XVlZW/3MXuh0d5luzZo0WLlyoK6+8sv/PeE+sdfToUaWmpurxxx/X3Llzdc011+i1117j55iFbDabNm/erNtvv11TpkzR1VdfrZ/97GdqbW3le2UITLlKALDS448/roqKCr322mvq7Oy0upxx64MPPtDWrVtZs48wgUBA1dXVuvzyy/XEE0/ovffe04033qiXXnrJ6tLGrUAgoMcee0zPP/+8rr32Wu3atUuLFy/W3r17rS4tqjADMwyfvFVb0jk3ZyN8fvSjH+n555/Xyy+/rAkTJmjSpElyOp2qq6vrH3Oh29Fhru3bt6uqqkrFxcXKz8/XO++8o+XLl+tXv/oV74mF8vLyZLfb9bWvfU2SNGfOHE2dOlXV1dX8HLPI3r17deLECV177bWSpPLycnk8Hu3fv5/vlSEgwAzDJ2/VlnTOrdoIjzVr1mjTpk169dVX+28ql3pvR1+7dq0kadeuXTp+/Liuu+46q8ocN771rW+ptrZWVVVVqqqq0lVXXaX169frW9/6Fu+JhdLS0vSZz3xGr7zyiiSpsrJSlZWVWrhwIT/HLNL3f4I//PBDSVJFRYWOHj2qadOm8b0yBFwlMEyHDh3SsmXL1NjY2H9zdt8N3Bh9Pp9Pubm5KigoUGJioiTJ5XJpx44dqq+v1z333KPKykrFxsbqySef1A033GBxxePP9ddfrwcffFC33XYb74nFjh07pvvuu0+nTp2S3W7X9773PS1ZsoSfYxbatGmTHn/8cdntdoVCIT3yyCP66le/yvfKEBBgAABA1GEJCQAARB0CDAAAiDoEGAAAEHUIMAAAIOoQYAAAQNQhwAAAgKhDgAEAAFGHAAMAAKLO/w+Nhke5i0u1zAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0cL0lB7yiOX"
      },
      "source": [
        "import csv\n",
        "with open('validation_1.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QHtHtUKq2zR"
      },
      "source": [
        "for h in range(0,len(validation_0)):\n",
        "  with open('validation_1.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, validation_1[h].numpy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWiod7kOKesf"
      },
      "source": [
        "import csv\n",
        "with open('loss_1.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n",
        "\n",
        "for h in range(0,len(losses_1)):\n",
        "  with open('loss_1.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h, losses_1[h].numpy()])"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "615vI8l4yd5Z"
      },
      "source": [
        "'''Training - hold out fold 2 for validation'''\n",
        "#Training\n",
        "gpu='0'\n",
        "atlas_file='/content/drive/My Drive/2020/Thesis/Data/atlas.npz'\n",
        "lr=1e-4\n",
        "n_iter=5000\n",
        "data_loss='mse'\n",
        "model='vm2'\n",
        "reg_param=0.01\n",
        "batch_size=10\n",
        "n_save_iter=100\n",
        "model_dir='/content/drive/My Drive/2020/Thesis/Data/validation_0/'\n",
        "valid = fold_2\n",
        "train_names = set_2\n",
        "EPOCH=30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBEj5xuByrEf",
        "outputId": "e16f41bf-3c60-45c2-e920-5b4ea682b17a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses_2, validation_2=validate.train(data_dir,\n",
        "          train_names,\n",
        "          atlas_file,\n",
        "          lr,\n",
        "          data_loss,\n",
        "          model,\n",
        "          reg_param, \n",
        "          batch_size,\n",
        "          n_save_iter,\n",
        "          model_dir,Net(),EPOCH, valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch_number:185\n",
            "loss(total):-0.003770\n",
            "recons_loss:0.004202\n",
            "grad_loss:0.090207\n",
            "dice_loss:-0.887428\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:186\n",
            "loss(total):-0.004284\n",
            "recons_loss:0.003661\n",
            "grad_loss:0.105373\n",
            "dice_loss:-0.899784\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:187\n",
            "loss(total):-0.004089\n",
            "recons_loss:0.003883\n",
            "grad_loss:0.085634\n",
            "dice_loss:-0.882828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:188\n",
            "loss(total):-0.002562\n",
            "recons_loss:0.005051\n",
            "grad_loss:0.122747\n",
            "dice_loss:-0.884105\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:189\n",
            "loss(total):-0.004252\n",
            "recons_loss:0.003636\n",
            "grad_loss:0.094261\n",
            "dice_loss:-0.883012\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:190\n",
            "loss(total):-0.004103\n",
            "recons_loss:0.003820\n",
            "grad_loss:0.097279\n",
            "dice_loss:-0.889577\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:191\n",
            "loss(total):-0.003511\n",
            "recons_loss:0.004260\n",
            "grad_loss:0.115837\n",
            "dice_loss:-0.892951\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:192\n",
            "loss(total):-0.003740\n",
            "recons_loss:0.004236\n",
            "grad_loss:0.086543\n",
            "dice_loss:-0.884187\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:193\n",
            "loss(total):-0.001851\n",
            "recons_loss:0.005795\n",
            "grad_loss:0.116142\n",
            "dice_loss:-0.880722\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:194\n",
            "loss(total):-0.003535\n",
            "recons_loss:0.004356\n",
            "grad_loss:0.110410\n",
            "dice_loss:-0.899557\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:195\n",
            "loss(total):-0.003584\n",
            "recons_loss:0.004178\n",
            "grad_loss:0.099758\n",
            "dice_loss:-0.875918\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:196\n",
            "loss(total):-0.003191\n",
            "recons_loss:0.004564\n",
            "grad_loss:0.118228\n",
            "dice_loss:-0.893717\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:197\n",
            "loss(total):-0.003824\n",
            "recons_loss:0.004098\n",
            "grad_loss:0.112615\n",
            "dice_loss:-0.904847\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:198\n",
            "loss(total):-0.002765\n",
            "recons_loss:0.004885\n",
            "grad_loss:0.128085\n",
            "dice_loss:-0.893063\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:199\n",
            "loss(total):-0.004231\n",
            "recons_loss:0.003777\n",
            "grad_loss:0.079281\n",
            "dice_loss:-0.880167\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:200\n",
            "loss(total):-0.003996\n",
            "recons_loss:0.003869\n",
            "grad_loss:0.101094\n",
            "dice_loss:-0.887597\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:201\n",
            "loss(total):-0.003751\n",
            "recons_loss:0.004308\n",
            "grad_loss:0.083781\n",
            "dice_loss:-0.889718\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:202\n",
            "loss(total):-0.003480\n",
            "recons_loss:0.004375\n",
            "grad_loss:0.109519\n",
            "dice_loss:-0.895089\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:203\n",
            "loss(total):-0.004841\n",
            "recons_loss:0.003283\n",
            "grad_loss:0.081998\n",
            "dice_loss:-0.894354\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:204\n",
            "loss(total):-0.004480\n",
            "recons_loss:0.003543\n",
            "grad_loss:0.096604\n",
            "dice_loss:-0.898906\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:205\n",
            "loss(total):-0.003820\n",
            "recons_loss:0.004122\n",
            "grad_loss:0.103753\n",
            "dice_loss:-0.897951\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:206\n",
            "loss(total):-0.002966\n",
            "recons_loss:0.004783\n",
            "grad_loss:0.109811\n",
            "dice_loss:-0.884689\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:207\n",
            "loss(total):-0.003993\n",
            "recons_loss:0.003692\n",
            "grad_loss:0.103923\n",
            "dice_loss:-0.872413\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:208\n",
            "loss(total):-0.004615\n",
            "recons_loss:0.003305\n",
            "grad_loss:0.103295\n",
            "dice_loss:-0.895257\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:209\n",
            "loss(total):-0.003814\n",
            "recons_loss:0.003920\n",
            "grad_loss:0.105892\n",
            "dice_loss:-0.879336\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:210\n",
            "loss(total):-0.003680\n",
            "recons_loss:0.004309\n",
            "grad_loss:0.096105\n",
            "dice_loss:-0.894930\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:211\n",
            "loss(total):-0.001942\n",
            "recons_loss:0.005603\n",
            "grad_loss:0.117038\n",
            "dice_loss:-0.871516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:212\n",
            "loss(total):-0.004417\n",
            "recons_loss:0.003729\n",
            "grad_loss:0.084509\n",
            "dice_loss:-0.899127\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:213\n",
            "loss(total):-0.004388\n",
            "recons_loss:0.003577\n",
            "grad_loss:0.088098\n",
            "dice_loss:-0.884614\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:214\n",
            "loss(total):-0.003750\n",
            "recons_loss:0.004231\n",
            "grad_loss:0.102451\n",
            "dice_loss:-0.900507\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:215\n",
            "loss(total):-0.003818\n",
            "recons_loss:0.004003\n",
            "grad_loss:0.110458\n",
            "dice_loss:-0.892651\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:216\n",
            "loss(total):-0.003676\n",
            "recons_loss:0.004244\n",
            "grad_loss:0.097813\n",
            "dice_loss:-0.889783\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:217\n",
            "loss(total):-0.003499\n",
            "recons_loss:0.004369\n",
            "grad_loss:0.094627\n",
            "dice_loss:-0.881491\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:218\n",
            "loss(total):-0.003942\n",
            "recons_loss:0.004065\n",
            "grad_loss:0.095932\n",
            "dice_loss:-0.896648\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:219\n",
            "loss(total):-0.003889\n",
            "recons_loss:0.004054\n",
            "grad_loss:0.102684\n",
            "dice_loss:-0.897052\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:220\n",
            "loss(total):-0.003511\n",
            "recons_loss:0.004228\n",
            "grad_loss:0.116332\n",
            "dice_loss:-0.890200\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:221\n",
            "loss(total):-0.004726\n",
            "recons_loss:0.003350\n",
            "grad_loss:0.080622\n",
            "dice_loss:-0.888279\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:222\n",
            "loss(total):-0.003896\n",
            "recons_loss:0.004234\n",
            "grad_loss:0.084854\n",
            "dice_loss:-0.897884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:223\n",
            "loss(total):-0.002932\n",
            "recons_loss:0.004738\n",
            "grad_loss:0.095322\n",
            "dice_loss:-0.862249\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:224\n",
            "loss(total):-0.004039\n",
            "recons_loss:0.003858\n",
            "grad_loss:0.114985\n",
            "dice_loss:-0.904726\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:225\n",
            "loss(total):-0.004669\n",
            "recons_loss:0.003514\n",
            "grad_loss:0.084436\n",
            "dice_loss:-0.902691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:226\n",
            "loss(total):-0.004621\n",
            "recons_loss:0.003523\n",
            "grad_loss:0.075682\n",
            "dice_loss:-0.890027\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:227\n",
            "loss(total):-0.004303\n",
            "recons_loss:0.003741\n",
            "grad_loss:0.087562\n",
            "dice_loss:-0.891967\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:228\n",
            "loss(total):-0.004329\n",
            "recons_loss:0.003720\n",
            "grad_loss:0.091670\n",
            "dice_loss:-0.896510\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:229\n",
            "loss(total):-0.004111\n",
            "recons_loss:0.003729\n",
            "grad_loss:0.093299\n",
            "dice_loss:-0.877298\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:230\n",
            "loss(total):-0.003557\n",
            "recons_loss:0.004478\n",
            "grad_loss:0.099909\n",
            "dice_loss:-0.903451\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:231\n",
            "loss(total):-0.002725\n",
            "recons_loss:0.005105\n",
            "grad_loss:0.112439\n",
            "dice_loss:-0.895354\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:232\n",
            "loss(total):-0.004145\n",
            "recons_loss:0.003802\n",
            "grad_loss:0.096437\n",
            "dice_loss:-0.891080\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:233\n",
            "loss(total):-0.002683\n",
            "recons_loss:0.005085\n",
            "grad_loss:0.097326\n",
            "dice_loss:-0.874172\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:234\n",
            "loss(total):-0.003481\n",
            "recons_loss:0.004355\n",
            "grad_loss:0.101703\n",
            "dice_loss:-0.885282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:235\n",
            "loss(total):-0.002953\n",
            "recons_loss:0.004600\n",
            "grad_loss:0.112652\n",
            "dice_loss:-0.867873\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:236\n",
            "loss(total):-0.003839\n",
            "recons_loss:0.004132\n",
            "grad_loss:0.088361\n",
            "dice_loss:-0.885501\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:237\n",
            "loss(total):-0.001867\n",
            "recons_loss:0.005639\n",
            "grad_loss:0.138338\n",
            "dice_loss:-0.888906\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:238\n",
            "loss(total):-0.001023\n",
            "recons_loss:0.006349\n",
            "grad_loss:0.136292\n",
            "dice_loss:-0.873568\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:239\n",
            "loss(total):-0.004147\n",
            "recons_loss:0.003911\n",
            "grad_loss:0.086664\n",
            "dice_loss:-0.892501\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:240\n",
            "loss(total):-0.004008\n",
            "recons_loss:0.003861\n",
            "grad_loss:0.096656\n",
            "dice_loss:-0.883580\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:241\n",
            "loss(total):-0.002517\n",
            "recons_loss:0.004898\n",
            "grad_loss:0.114563\n",
            "dice_loss:-0.856035\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:242\n",
            "loss(total):-0.004493\n",
            "recons_loss:0.003625\n",
            "grad_loss:0.087827\n",
            "dice_loss:-0.899640\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:243\n",
            "loss(total):-0.002676\n",
            "recons_loss:0.005156\n",
            "grad_loss:0.110938\n",
            "dice_loss:-0.894169\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:244\n",
            "loss(total):-0.004141\n",
            "recons_loss:0.004035\n",
            "grad_loss:0.081063\n",
            "dice_loss:-0.898692\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:245\n",
            "loss(total):-0.005896\n",
            "recons_loss:0.002576\n",
            "grad_loss:0.063040\n",
            "dice_loss:-0.910237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:246\n",
            "loss(total):-0.004216\n",
            "recons_loss:0.003825\n",
            "grad_loss:0.094482\n",
            "dice_loss:-0.898595\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:247\n",
            "loss(total):-0.003133\n",
            "recons_loss:0.004686\n",
            "grad_loss:0.110888\n",
            "dice_loss:-0.892740\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:248\n",
            "loss(total):-0.003543\n",
            "recons_loss:0.004408\n",
            "grad_loss:0.096280\n",
            "dice_loss:-0.891469\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:249\n",
            "loss(total):-0.003258\n",
            "recons_loss:0.004467\n",
            "grad_loss:0.116684\n",
            "dice_loss:-0.889251\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:250\n",
            "loss(total):-0.001760\n",
            "recons_loss:0.005684\n",
            "grad_loss:0.141949\n",
            "dice_loss:-0.886370\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:251\n",
            "loss(total):-0.002862\n",
            "recons_loss:0.004989\n",
            "grad_loss:0.106705\n",
            "dice_loss:-0.891831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:252\n",
            "loss(total):-0.003197\n",
            "recons_loss:0.004687\n",
            "grad_loss:0.100925\n",
            "dice_loss:-0.889248\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:253\n",
            "loss(total):-0.004158\n",
            "recons_loss:0.003934\n",
            "grad_loss:0.081489\n",
            "dice_loss:-0.890626\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:254\n",
            "loss(total):-0.003644\n",
            "recons_loss:0.004347\n",
            "grad_loss:0.089362\n",
            "dice_loss:-0.888398\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:255\n",
            "loss(total):-0.002519\n",
            "recons_loss:0.005074\n",
            "grad_loss:0.120798\n",
            "dice_loss:-0.880116\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:256\n",
            "loss(total):-0.003909\n",
            "recons_loss:0.003944\n",
            "grad_loss:0.089197\n",
            "dice_loss:-0.874504\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:257\n",
            "loss(total):-0.002177\n",
            "recons_loss:0.005336\n",
            "grad_loss:0.127968\n",
            "dice_loss:-0.879173\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:258\n",
            "loss(total):-0.002925\n",
            "recons_loss:0.004961\n",
            "grad_loss:0.102883\n",
            "dice_loss:-0.891490\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:259\n",
            "loss(total):-0.004062\n",
            "recons_loss:0.003896\n",
            "grad_loss:0.090308\n",
            "dice_loss:-0.886059\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:260\n",
            "loss(total):-0.003418\n",
            "recons_loss:0.004386\n",
            "grad_loss:0.103175\n",
            "dice_loss:-0.883590\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:261\n",
            "loss(total):-0.003560\n",
            "recons_loss:0.004284\n",
            "grad_loss:0.104052\n",
            "dice_loss:-0.888395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:262\n",
            "loss(total):-0.004565\n",
            "recons_loss:0.003515\n",
            "grad_loss:0.093215\n",
            "dice_loss:-0.901262\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:263\n",
            "loss(total):-0.004116\n",
            "recons_loss:0.004060\n",
            "grad_loss:0.091477\n",
            "dice_loss:-0.909096\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:264\n",
            "loss(total):-0.004150\n",
            "recons_loss:0.004055\n",
            "grad_loss:0.085885\n",
            "dice_loss:-0.906341\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:265\n",
            "loss(total):-0.004430\n",
            "recons_loss:0.003670\n",
            "grad_loss:0.077684\n",
            "dice_loss:-0.887678\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:266\n",
            "loss(total):-0.002884\n",
            "recons_loss:0.004772\n",
            "grad_loss:0.114704\n",
            "dice_loss:-0.880338\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:267\n",
            "loss(total):-0.004373\n",
            "recons_loss:0.003573\n",
            "grad_loss:0.096075\n",
            "dice_loss:-0.890648\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:268\n",
            "loss(total):-0.002480\n",
            "recons_loss:0.005235\n",
            "grad_loss:0.112548\n",
            "dice_loss:-0.884126\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:269\n",
            "loss(total):-0.002539\n",
            "recons_loss:0.005038\n",
            "grad_loss:0.109849\n",
            "dice_loss:-0.867550\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:0\n",
            "loss(total):-0.003190\n",
            "recons_loss:0.004771\n",
            "grad_loss:0.097268\n",
            "dice_loss:-0.893290\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:1\n",
            "loss(total):-0.002873\n",
            "recons_loss:0.004870\n",
            "grad_loss:0.105700\n",
            "dice_loss:-0.879935\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:2\n",
            "loss(total):-0.003795\n",
            "recons_loss:0.004191\n",
            "grad_loss:0.089876\n",
            "dice_loss:-0.888451\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:3\n",
            "loss(total):-0.003586\n",
            "recons_loss:0.004448\n",
            "grad_loss:0.085935\n",
            "dice_loss:-0.889260\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:4\n",
            "loss(total):-0.003978\n",
            "recons_loss:0.004111\n",
            "grad_loss:0.080401\n",
            "dice_loss:-0.889349\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:5\n",
            "loss(total):-0.003836\n",
            "recons_loss:0.004049\n",
            "grad_loss:0.101272\n",
            "dice_loss:-0.889740\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:6\n",
            "loss(total):-0.003561\n",
            "recons_loss:0.004289\n",
            "grad_loss:0.105995\n",
            "dice_loss:-0.890969\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:7\n",
            "loss(total):-0.002146\n",
            "recons_loss:0.005339\n",
            "grad_loss:0.119291\n",
            "dice_loss:-0.867794\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:8\n",
            "loss(total):-0.004433\n",
            "recons_loss:0.003598\n",
            "grad_loss:0.102479\n",
            "dice_loss:-0.905578\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:9\n",
            "loss(total):-0.004104\n",
            "recons_loss:0.003844\n",
            "grad_loss:0.090909\n",
            "dice_loss:-0.885660\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:10\n",
            "loss(total):-0.003897\n",
            "recons_loss:0.004069\n",
            "grad_loss:0.088126\n",
            "dice_loss:-0.884765\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:11\n",
            "loss(total):-0.004157\n",
            "recons_loss:0.003950\n",
            "grad_loss:0.091675\n",
            "dice_loss:-0.902373\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:12\n",
            "loss(total):-0.002384\n",
            "recons_loss:0.005081\n",
            "grad_loss:0.131908\n",
            "dice_loss:-0.878375\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:13\n",
            "loss(total):-0.003206\n",
            "recons_loss:0.004699\n",
            "grad_loss:0.112530\n",
            "dice_loss:-0.903068\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:14\n",
            "loss(total):-0.003210\n",
            "recons_loss:0.004644\n",
            "grad_loss:0.106484\n",
            "dice_loss:-0.891886\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:15\n",
            "loss(total):-0.005280\n",
            "recons_loss:0.003031\n",
            "grad_loss:0.079144\n",
            "dice_loss:-0.910256\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:16\n",
            "loss(total):-0.004056\n",
            "recons_loss:0.003837\n",
            "grad_loss:0.090418\n",
            "dice_loss:-0.879762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:17\n",
            "loss(total):-0.004120\n",
            "recons_loss:0.003989\n",
            "grad_loss:0.080610\n",
            "dice_loss:-0.891515\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:18\n",
            "loss(total):-0.003702\n",
            "recons_loss:0.004153\n",
            "grad_loss:0.107843\n",
            "dice_loss:-0.893304\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:19\n",
            "loss(total):-0.003864\n",
            "recons_loss:0.004064\n",
            "grad_loss:0.097644\n",
            "dice_loss:-0.890363\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:20\n",
            "loss(total):-0.003973\n",
            "recons_loss:0.003911\n",
            "grad_loss:0.102419\n",
            "dice_loss:-0.890808\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:21\n",
            "loss(total):-0.003237\n",
            "recons_loss:0.004490\n",
            "grad_loss:0.124635\n",
            "dice_loss:-0.897336\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:22\n",
            "loss(total):-0.004054\n",
            "recons_loss:0.003907\n",
            "grad_loss:0.105194\n",
            "dice_loss:-0.901314\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:23\n",
            "loss(total):-0.002598\n",
            "recons_loss:0.005003\n",
            "grad_loss:0.128405\n",
            "dice_loss:-0.888496\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:24\n",
            "loss(total):-0.004400\n",
            "recons_loss:0.003853\n",
            "grad_loss:0.069561\n",
            "dice_loss:-0.894846\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:25\n",
            "loss(total):-0.002920\n",
            "recons_loss:0.004725\n",
            "grad_loss:0.110878\n",
            "dice_loss:-0.875305\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:26\n",
            "loss(total):-0.001868\n",
            "recons_loss:0.005624\n",
            "grad_loss:0.115968\n",
            "dice_loss:-0.865175\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:27\n",
            "loss(total):-0.002759\n",
            "recons_loss:0.004735\n",
            "grad_loss:0.131088\n",
            "dice_loss:-0.880473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:28\n",
            "loss(total):-0.003155\n",
            "recons_loss:0.004438\n",
            "grad_loss:0.112386\n",
            "dice_loss:-0.871709\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:29\n",
            "loss(total):-0.002949\n",
            "recons_loss:0.004751\n",
            "grad_loss:0.107584\n",
            "dice_loss:-0.877619\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:30\n",
            "loss(total):-0.003552\n",
            "recons_loss:0.004251\n",
            "grad_loss:0.111326\n",
            "dice_loss:-0.891651\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:31\n",
            "loss(total):-0.004306\n",
            "recons_loss:0.003649\n",
            "grad_loss:0.106559\n",
            "dice_loss:-0.902067\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:32\n",
            "loss(total):-0.003715\n",
            "recons_loss:0.004356\n",
            "grad_loss:0.084493\n",
            "dice_loss:-0.891565\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:33\n",
            "loss(total):-0.004081\n",
            "recons_loss:0.003927\n",
            "grad_loss:0.083388\n",
            "dice_loss:-0.884109\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:34\n",
            "loss(total):-0.003401\n",
            "recons_loss:0.004203\n",
            "grad_loss:0.113985\n",
            "dice_loss:-0.874371\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:35\n",
            "loss(total):-0.004081\n",
            "recons_loss:0.003723\n",
            "grad_loss:0.112491\n",
            "dice_loss:-0.892815\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:36\n",
            "loss(total):-0.003590\n",
            "recons_loss:0.004073\n",
            "grad_loss:0.113740\n",
            "dice_loss:-0.880046\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:37\n",
            "loss(total):-0.005321\n",
            "recons_loss:0.002992\n",
            "grad_loss:0.064737\n",
            "dice_loss:-0.896005\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:38\n",
            "loss(total):-0.002161\n",
            "recons_loss:0.005529\n",
            "grad_loss:0.119665\n",
            "dice_loss:-0.888670\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:39\n",
            "loss(total):-0.004705\n",
            "recons_loss:0.003425\n",
            "grad_loss:0.077325\n",
            "dice_loss:-0.890367\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:40\n",
            "loss(total):-0.002748\n",
            "recons_loss:0.005184\n",
            "grad_loss:0.099608\n",
            "dice_loss:-0.892743\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:41\n",
            "loss(total):-0.002122\n",
            "recons_loss:0.005476\n",
            "grad_loss:0.119966\n",
            "dice_loss:-0.879694\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:42\n",
            "loss(total):-0.003865\n",
            "recons_loss:0.004263\n",
            "grad_loss:0.085680\n",
            "dice_loss:-0.898514\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:43\n",
            "loss(total):-0.003589\n",
            "recons_loss:0.004218\n",
            "grad_loss:0.094188\n",
            "dice_loss:-0.874849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:44\n",
            "loss(total):-0.004147\n",
            "recons_loss:0.003756\n",
            "grad_loss:0.093568\n",
            "dice_loss:-0.883824\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:45\n",
            "loss(total):-0.003044\n",
            "recons_loss:0.004740\n",
            "grad_loss:0.102278\n",
            "dice_loss:-0.880615\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:46\n",
            "loss(total):-0.003857\n",
            "recons_loss:0.004158\n",
            "grad_loss:0.089715\n",
            "dice_loss:-0.891235\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:47\n",
            "loss(total):-0.004732\n",
            "recons_loss:0.003317\n",
            "grad_loss:0.100203\n",
            "dice_loss:-0.905031\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:48\n",
            "loss(total):-0.003341\n",
            "recons_loss:0.004422\n",
            "grad_loss:0.108328\n",
            "dice_loss:-0.884664\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:49\n",
            "loss(total):-0.002995\n",
            "recons_loss:0.004706\n",
            "grad_loss:0.116126\n",
            "dice_loss:-0.886222\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:50\n",
            "loss(total):-0.004262\n",
            "recons_loss:0.003847\n",
            "grad_loss:0.076768\n",
            "dice_loss:-0.887601\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:51\n",
            "loss(total):-0.002762\n",
            "recons_loss:0.005000\n",
            "grad_loss:0.120021\n",
            "dice_loss:-0.896284\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:52\n",
            "loss(total):-0.005140\n",
            "recons_loss:0.002989\n",
            "grad_loss:0.082955\n",
            "dice_loss:-0.895806\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:53\n",
            "loss(total):-0.003827\n",
            "recons_loss:0.004093\n",
            "grad_loss:0.096209\n",
            "dice_loss:-0.888193\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:54\n",
            "loss(total):-0.003604\n",
            "recons_loss:0.004120\n",
            "grad_loss:0.109386\n",
            "dice_loss:-0.881811\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:55\n",
            "loss(total):-0.003267\n",
            "recons_loss:0.004496\n",
            "grad_loss:0.111745\n",
            "dice_loss:-0.887982\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:56\n",
            "loss(total):-0.004081\n",
            "recons_loss:0.003755\n",
            "grad_loss:0.099506\n",
            "dice_loss:-0.883134\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:57\n",
            "loss(total):-0.004004\n",
            "recons_loss:0.003931\n",
            "grad_loss:0.103879\n",
            "dice_loss:-0.897356\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:58\n",
            "loss(total):-0.004950\n",
            "recons_loss:0.003207\n",
            "grad_loss:0.080630\n",
            "dice_loss:-0.896354\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:59\n",
            "loss(total):-0.004969\n",
            "recons_loss:0.003142\n",
            "grad_loss:0.086318\n",
            "dice_loss:-0.897395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:60\n",
            "loss(total):-0.003678\n",
            "recons_loss:0.004290\n",
            "grad_loss:0.091071\n",
            "dice_loss:-0.887869\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:61\n",
            "loss(total):-0.004082\n",
            "recons_loss:0.003890\n",
            "grad_loss:0.090355\n",
            "dice_loss:-0.887548\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:62\n",
            "loss(total):-0.002631\n",
            "recons_loss:0.005180\n",
            "grad_loss:0.099271\n",
            "dice_loss:-0.880353\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:63\n",
            "loss(total):-0.003821\n",
            "recons_loss:0.004088\n",
            "grad_loss:0.098594\n",
            "dice_loss:-0.889421\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:64\n",
            "loss(total):-0.003923\n",
            "recons_loss:0.003938\n",
            "grad_loss:0.093287\n",
            "dice_loss:-0.879390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:65\n",
            "loss(total):-0.002356\n",
            "recons_loss:0.005075\n",
            "grad_loss:0.131980\n",
            "dice_loss:-0.875084\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:66\n",
            "loss(total):-0.003833\n",
            "recons_loss:0.004236\n",
            "grad_loss:0.100503\n",
            "dice_loss:-0.907474\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:67\n",
            "loss(total):-0.004990\n",
            "recons_loss:0.003166\n",
            "grad_loss:0.082617\n",
            "dice_loss:-0.898185\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:68\n",
            "loss(total):-0.003691\n",
            "recons_loss:0.004359\n",
            "grad_loss:0.097822\n",
            "dice_loss:-0.902836\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:69\n",
            "loss(total):-0.003417\n",
            "recons_loss:0.004540\n",
            "grad_loss:0.100115\n",
            "dice_loss:-0.895820\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:70\n",
            "loss(total):-0.003716\n",
            "recons_loss:0.004256\n",
            "grad_loss:0.089157\n",
            "dice_loss:-0.886353\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:71\n",
            "loss(total):-0.003965\n",
            "recons_loss:0.003919\n",
            "grad_loss:0.090483\n",
            "dice_loss:-0.878879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:72\n",
            "loss(total):-0.003364\n",
            "recons_loss:0.004368\n",
            "grad_loss:0.121583\n",
            "dice_loss:-0.894761\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:73\n",
            "loss(total):-0.003630\n",
            "recons_loss:0.004235\n",
            "grad_loss:0.096890\n",
            "dice_loss:-0.883361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:74\n",
            "loss(total):-0.002722\n",
            "recons_loss:0.004909\n",
            "grad_loss:0.118956\n",
            "dice_loss:-0.882083\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:75\n",
            "loss(total):-0.002535\n",
            "recons_loss:0.005022\n",
            "grad_loss:0.138705\n",
            "dice_loss:-0.894348\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:76\n",
            "loss(total):-0.002206\n",
            "recons_loss:0.005483\n",
            "grad_loss:0.114713\n",
            "dice_loss:-0.883672\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:77\n",
            "loss(total):-0.003625\n",
            "recons_loss:0.004347\n",
            "grad_loss:0.105717\n",
            "dice_loss:-0.902976\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:78\n",
            "loss(total):-0.003140\n",
            "recons_loss:0.004447\n",
            "grad_loss:0.107338\n",
            "dice_loss:-0.866043\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:79\n",
            "loss(total):-0.002663\n",
            "recons_loss:0.005069\n",
            "grad_loss:0.115491\n",
            "dice_loss:-0.888651\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:80\n",
            "loss(total):-0.004549\n",
            "recons_loss:0.003403\n",
            "grad_loss:0.104807\n",
            "dice_loss:-0.900013\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:81\n",
            "loss(total):-0.004222\n",
            "recons_loss:0.003820\n",
            "grad_loss:0.096159\n",
            "dice_loss:-0.900310\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:82\n",
            "loss(total):-0.004530\n",
            "recons_loss:0.003415\n",
            "grad_loss:0.090977\n",
            "dice_loss:-0.885461\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:83\n",
            "loss(total):-0.004494\n",
            "recons_loss:0.003572\n",
            "grad_loss:0.097200\n",
            "dice_loss:-0.903823\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:84\n",
            "loss(total):-0.002425\n",
            "recons_loss:0.005146\n",
            "grad_loss:0.102460\n",
            "dice_loss:-0.859487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:85\n",
            "loss(total):-0.002764\n",
            "recons_loss:0.005004\n",
            "grad_loss:0.101053\n",
            "dice_loss:-0.877831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:86\n",
            "loss(total):-0.002179\n",
            "recons_loss:0.005328\n",
            "grad_loss:0.127731\n",
            "dice_loss:-0.878414\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:87\n",
            "loss(total):-0.002490\n",
            "recons_loss:0.005262\n",
            "grad_loss:0.114749\n",
            "dice_loss:-0.889921\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:88\n",
            "loss(total):-0.003603\n",
            "recons_loss:0.004209\n",
            "grad_loss:0.100490\n",
            "dice_loss:-0.881719\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:89\n",
            "loss(total):-0.003137\n",
            "recons_loss:0.004615\n",
            "grad_loss:0.125881\n",
            "dice_loss:-0.901011\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:90\n",
            "loss(total):-0.002734\n",
            "recons_loss:0.004892\n",
            "grad_loss:0.108874\n",
            "dice_loss:-0.871545\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:91\n",
            "loss(total):-0.003960\n",
            "recons_loss:0.003948\n",
            "grad_loss:0.093932\n",
            "dice_loss:-0.884682\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:92\n",
            "loss(total):-0.003440\n",
            "recons_loss:0.004409\n",
            "grad_loss:0.105004\n",
            "dice_loss:-0.889875\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:93\n",
            "loss(total):-0.002695\n",
            "recons_loss:0.005144\n",
            "grad_loss:0.107784\n",
            "dice_loss:-0.891657\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:94\n",
            "loss(total):-0.003528\n",
            "recons_loss:0.004473\n",
            "grad_loss:0.094567\n",
            "dice_loss:-0.894600\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:95\n",
            "loss(total):-0.004036\n",
            "recons_loss:0.003984\n",
            "grad_loss:0.096269\n",
            "dice_loss:-0.898244\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:96\n",
            "loss(total):-0.004791\n",
            "recons_loss:0.003348\n",
            "grad_loss:0.080856\n",
            "dice_loss:-0.894788\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:97\n",
            "loss(total):-0.002474\n",
            "recons_loss:0.005186\n",
            "grad_loss:0.128194\n",
            "dice_loss:-0.894154\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:98\n",
            "loss(total):-0.003499\n",
            "recons_loss:0.004316\n",
            "grad_loss:0.116468\n",
            "dice_loss:-0.898002\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:99\n",
            "loss(total):-0.004921\n",
            "recons_loss:0.003225\n",
            "grad_loss:0.082072\n",
            "dice_loss:-0.896661\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:100\n",
            "loss(total):-0.003617\n",
            "recons_loss:0.004314\n",
            "grad_loss:0.105970\n",
            "dice_loss:-0.899076\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:101\n",
            "loss(total):-0.003967\n",
            "recons_loss:0.003968\n",
            "grad_loss:0.101253\n",
            "dice_loss:-0.894731\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:102\n",
            "loss(total):-0.002468\n",
            "recons_loss:0.005239\n",
            "grad_loss:0.121979\n",
            "dice_loss:-0.892685\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:103\n",
            "loss(total):-0.004591\n",
            "recons_loss:0.003529\n",
            "grad_loss:0.076839\n",
            "dice_loss:-0.888849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:104\n",
            "loss(total):-0.002223\n",
            "recons_loss:0.005364\n",
            "grad_loss:0.115295\n",
            "dice_loss:-0.873931\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:105\n",
            "loss(total):-0.003547\n",
            "recons_loss:0.004232\n",
            "grad_loss:0.108305\n",
            "dice_loss:-0.886212\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:106\n",
            "loss(total):-0.003954\n",
            "recons_loss:0.004137\n",
            "grad_loss:0.078790\n",
            "dice_loss:-0.887880\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:107\n",
            "loss(total):-0.004263\n",
            "recons_loss:0.003890\n",
            "grad_loss:0.075999\n",
            "dice_loss:-0.891279\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:108\n",
            "loss(total):-0.004699\n",
            "recons_loss:0.003362\n",
            "grad_loss:0.093011\n",
            "dice_loss:-0.899134\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:109\n",
            "loss(total):-0.002756\n",
            "recons_loss:0.005041\n",
            "grad_loss:0.107866\n",
            "dice_loss:-0.887630\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:110\n",
            "loss(total):-0.003727\n",
            "recons_loss:0.004154\n",
            "grad_loss:0.089690\n",
            "dice_loss:-0.877797\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:111\n",
            "loss(total):-0.003073\n",
            "recons_loss:0.004741\n",
            "grad_loss:0.110789\n",
            "dice_loss:-0.892232\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:112\n",
            "loss(total):-0.003394\n",
            "recons_loss:0.004324\n",
            "grad_loss:0.102636\n",
            "dice_loss:-0.874474\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:113\n",
            "loss(total):-0.003057\n",
            "recons_loss:0.004646\n",
            "grad_loss:0.112299\n",
            "dice_loss:-0.882672\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:114\n",
            "loss(total):-0.005694\n",
            "recons_loss:0.002849\n",
            "grad_loss:0.052162\n",
            "dice_loss:-0.906392\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:115\n",
            "loss(total):-0.002992\n",
            "recons_loss:0.004763\n",
            "grad_loss:0.113347\n",
            "dice_loss:-0.888822\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:116\n",
            "loss(total):-0.002115\n",
            "recons_loss:0.005258\n",
            "grad_loss:0.140584\n",
            "dice_loss:-0.877875\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:117\n",
            "loss(total):-0.002012\n",
            "recons_loss:0.005653\n",
            "grad_loss:0.114568\n",
            "dice_loss:-0.881051\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:118\n",
            "loss(total):-0.001961\n",
            "recons_loss:0.005578\n",
            "grad_loss:0.141152\n",
            "dice_loss:-0.895057\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:119\n",
            "loss(total):-0.004725\n",
            "recons_loss:0.003326\n",
            "grad_loss:0.087552\n",
            "dice_loss:-0.892612\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:120\n",
            "loss(total):-0.002777\n",
            "recons_loss:0.004840\n",
            "grad_loss:0.127438\n",
            "dice_loss:-0.889201\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:121\n",
            "loss(total):-0.002987\n",
            "recons_loss:0.004688\n",
            "grad_loss:0.111447\n",
            "dice_loss:-0.878883\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:122\n",
            "loss(total):-0.003837\n",
            "recons_loss:0.004062\n",
            "grad_loss:0.097976\n",
            "dice_loss:-0.887835\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:123\n",
            "loss(total):-0.002233\n",
            "recons_loss:0.005322\n",
            "grad_loss:0.127357\n",
            "dice_loss:-0.882899\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:124\n",
            "loss(total):-0.003901\n",
            "recons_loss:0.003955\n",
            "grad_loss:0.089152\n",
            "dice_loss:-0.874778\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:125\n",
            "loss(total):-0.002812\n",
            "recons_loss:0.004957\n",
            "grad_loss:0.103814\n",
            "dice_loss:-0.880771\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:126\n",
            "loss(total):-0.003262\n",
            "recons_loss:0.004499\n",
            "grad_loss:0.106759\n",
            "dice_loss:-0.882844\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:127\n",
            "loss(total):-0.004859\n",
            "recons_loss:0.003124\n",
            "grad_loss:0.102492\n",
            "dice_loss:-0.900751\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:128\n",
            "loss(total):-0.003516\n",
            "recons_loss:0.004350\n",
            "grad_loss:0.097485\n",
            "dice_loss:-0.884134\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:129\n",
            "loss(total):-0.004419\n",
            "recons_loss:0.003582\n",
            "grad_loss:0.083714\n",
            "dice_loss:-0.883832\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:130\n",
            "loss(total):-0.001734\n",
            "recons_loss:0.005765\n",
            "grad_loss:0.126148\n",
            "dice_loss:-0.876031\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:131\n",
            "loss(total):-0.003188\n",
            "recons_loss:0.004645\n",
            "grad_loss:0.102770\n",
            "dice_loss:-0.886036\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:132\n",
            "loss(total):-0.003380\n",
            "recons_loss:0.004371\n",
            "grad_loss:0.099061\n",
            "dice_loss:-0.874172\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:133\n",
            "loss(total):-0.004382\n",
            "recons_loss:0.003892\n",
            "grad_loss:0.073741\n",
            "dice_loss:-0.901152\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:134\n",
            "loss(total):-0.004862\n",
            "recons_loss:0.003238\n",
            "grad_loss:0.078426\n",
            "dice_loss:-0.888460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:135\n",
            "loss(total):-0.003673\n",
            "recons_loss:0.004144\n",
            "grad_loss:0.111663\n",
            "dice_loss:-0.893328\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:136\n",
            "loss(total):-0.002746\n",
            "recons_loss:0.005006\n",
            "grad_loss:0.107309\n",
            "dice_loss:-0.882559\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:137\n",
            "loss(total):-0.003131\n",
            "recons_loss:0.004598\n",
            "grad_loss:0.117716\n",
            "dice_loss:-0.890585\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:138\n",
            "loss(total):-0.003110\n",
            "recons_loss:0.004895\n",
            "grad_loss:0.094718\n",
            "dice_loss:-0.895199\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:139\n",
            "loss(total):-0.004975\n",
            "recons_loss:0.003382\n",
            "grad_loss:0.070233\n",
            "dice_loss:-0.905942\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:140\n",
            "loss(total):-0.003931\n",
            "recons_loss:0.004002\n",
            "grad_loss:0.105727\n",
            "dice_loss:-0.899122\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:141\n",
            "loss(total):-0.004168\n",
            "recons_loss:0.003939\n",
            "grad_loss:0.088082\n",
            "dice_loss:-0.898839\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:142\n",
            "loss(total):-0.004375\n",
            "recons_loss:0.004006\n",
            "grad_loss:0.068742\n",
            "dice_loss:-0.906810\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:143\n",
            "loss(total):-0.004968\n",
            "recons_loss:0.003168\n",
            "grad_loss:0.094457\n",
            "dice_loss:-0.908110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:144\n",
            "loss(total):-0.002627\n",
            "recons_loss:0.005058\n",
            "grad_loss:0.118983\n",
            "dice_loss:-0.887478\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:145\n",
            "loss(total):-0.004239\n",
            "recons_loss:0.003742\n",
            "grad_loss:0.091456\n",
            "dice_loss:-0.889558\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:146\n",
            "loss(total):-0.003957\n",
            "recons_loss:0.004030\n",
            "grad_loss:0.088811\n",
            "dice_loss:-0.887524\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:147\n",
            "loss(total):-0.003581\n",
            "recons_loss:0.004208\n",
            "grad_loss:0.111415\n",
            "dice_loss:-0.890369\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:148\n",
            "loss(total):-0.003132\n",
            "recons_loss:0.004837\n",
            "grad_loss:0.093229\n",
            "dice_loss:-0.890109\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:149\n",
            "loss(total):-0.004191\n",
            "recons_loss:0.003822\n",
            "grad_loss:0.086211\n",
            "dice_loss:-0.887488\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:150\n",
            "loss(total):-0.004294\n",
            "recons_loss:0.003920\n",
            "grad_loss:0.075229\n",
            "dice_loss:-0.896707\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:151\n",
            "loss(total):-0.004429\n",
            "recons_loss:0.003573\n",
            "grad_loss:0.087123\n",
            "dice_loss:-0.887258\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:152\n",
            "loss(total):-0.003085\n",
            "recons_loss:0.004577\n",
            "grad_loss:0.127387\n",
            "dice_loss:-0.893644\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:153\n",
            "loss(total):-0.003008\n",
            "recons_loss:0.004661\n",
            "grad_loss:0.101938\n",
            "dice_loss:-0.868870\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:154\n",
            "loss(total):-0.004534\n",
            "recons_loss:0.003479\n",
            "grad_loss:0.081462\n",
            "dice_loss:-0.882779\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:155\n",
            "loss(total):-0.003967\n",
            "recons_loss:0.004077\n",
            "grad_loss:0.090029\n",
            "dice_loss:-0.894415\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:156\n",
            "loss(total):-0.003564\n",
            "recons_loss:0.004340\n",
            "grad_loss:0.114895\n",
            "dice_loss:-0.905326\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:157\n",
            "loss(total):-0.003266\n",
            "recons_loss:0.004528\n",
            "grad_loss:0.110492\n",
            "dice_loss:-0.889938\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:158\n",
            "loss(total):-0.001298\n",
            "recons_loss:0.005908\n",
            "grad_loss:0.166476\n",
            "dice_loss:-0.887097\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:159\n",
            "loss(total):-0.002171\n",
            "recons_loss:0.005311\n",
            "grad_loss:0.137829\n",
            "dice_loss:-0.886054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:160\n",
            "loss(total):-0.001087\n",
            "recons_loss:0.006377\n",
            "grad_loss:0.126928\n",
            "dice_loss:-0.873280\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:161\n",
            "loss(total):-0.004036\n",
            "recons_loss:0.003942\n",
            "grad_loss:0.090271\n",
            "dice_loss:-0.888086\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:162\n",
            "loss(total):-0.004050\n",
            "recons_loss:0.004235\n",
            "grad_loss:0.068871\n",
            "dice_loss:-0.897372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:163\n",
            "loss(total):-0.003164\n",
            "recons_loss:0.004576\n",
            "grad_loss:0.112649\n",
            "dice_loss:-0.886669\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:164\n",
            "loss(total):-0.003533\n",
            "recons_loss:0.004376\n",
            "grad_loss:0.098736\n",
            "dice_loss:-0.889620\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:165\n",
            "loss(total):-0.002732\n",
            "recons_loss:0.004791\n",
            "grad_loss:0.128973\n",
            "dice_loss:-0.881290\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:166\n",
            "loss(total):-0.004733\n",
            "recons_loss:0.003468\n",
            "grad_loss:0.077859\n",
            "dice_loss:-0.897957\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:167\n",
            "loss(total):-0.002924\n",
            "recons_loss:0.004729\n",
            "grad_loss:0.115198\n",
            "dice_loss:-0.880504\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:168\n",
            "loss(total):-0.004140\n",
            "recons_loss:0.003814\n",
            "grad_loss:0.094079\n",
            "dice_loss:-0.889513\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:169\n",
            "loss(total):-0.004547\n",
            "recons_loss:0.003468\n",
            "grad_loss:0.092142\n",
            "dice_loss:-0.893641\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:170\n",
            "loss(total):-0.002863\n",
            "recons_loss:0.004821\n",
            "grad_loss:0.119573\n",
            "dice_loss:-0.887935\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:171\n",
            "loss(total):-0.004340\n",
            "recons_loss:0.003673\n",
            "grad_loss:0.093011\n",
            "dice_loss:-0.894268\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:172\n",
            "loss(total):-0.004139\n",
            "recons_loss:0.003709\n",
            "grad_loss:0.110880\n",
            "dice_loss:-0.895718\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:173\n",
            "loss(total):-0.003763\n",
            "recons_loss:0.004150\n",
            "grad_loss:0.092919\n",
            "dice_loss:-0.884251\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:174\n",
            "loss(total):-0.002840\n",
            "recons_loss:0.004937\n",
            "grad_loss:0.115683\n",
            "dice_loss:-0.893420\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:175\n",
            "loss(total):-0.004564\n",
            "recons_loss:0.003664\n",
            "grad_loss:0.078158\n",
            "dice_loss:-0.900942\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:176\n",
            "loss(total):-0.003834\n",
            "recons_loss:0.004057\n",
            "grad_loss:0.091657\n",
            "dice_loss:-0.880733\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:177\n",
            "loss(total):-0.003777\n",
            "recons_loss:0.003999\n",
            "grad_loss:0.113732\n",
            "dice_loss:-0.891333\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:178\n",
            "loss(total):-0.003402\n",
            "recons_loss:0.004441\n",
            "grad_loss:0.102760\n",
            "dice_loss:-0.887105\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:179\n",
            "loss(total):-0.003598\n",
            "recons_loss:0.004131\n",
            "grad_loss:0.124464\n",
            "dice_loss:-0.897386\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:180\n",
            "loss(total):-0.003126\n",
            "recons_loss:0.004653\n",
            "grad_loss:0.106461\n",
            "dice_loss:-0.884371\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:181\n",
            "loss(total):-0.002883\n",
            "recons_loss:0.004961\n",
            "grad_loss:0.111980\n",
            "dice_loss:-0.896368\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:182\n",
            "loss(total):-0.003875\n",
            "recons_loss:0.003971\n",
            "grad_loss:0.113739\n",
            "dice_loss:-0.898336\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:183\n",
            "loss(total):-0.003359\n",
            "recons_loss:0.004441\n",
            "grad_loss:0.113541\n",
            "dice_loss:-0.893548\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:184\n",
            "loss(total):-0.003368\n",
            "recons_loss:0.004538\n",
            "grad_loss:0.097155\n",
            "dice_loss:-0.887755\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:185\n",
            "loss(total):-0.001553\n",
            "recons_loss:0.005965\n",
            "grad_loss:0.142722\n",
            "dice_loss:-0.894575\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:186\n",
            "loss(total):-0.003119\n",
            "recons_loss:0.004523\n",
            "grad_loss:0.111700\n",
            "dice_loss:-0.875989\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:187\n",
            "loss(total):-0.003541\n",
            "recons_loss:0.004308\n",
            "grad_loss:0.114071\n",
            "dice_loss:-0.898942\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:188\n",
            "loss(total):-0.004287\n",
            "recons_loss:0.003555\n",
            "grad_loss:0.099429\n",
            "dice_loss:-0.883612\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:189\n",
            "loss(total):-0.003455\n",
            "recons_loss:0.004462\n",
            "grad_loss:0.098781\n",
            "dice_loss:-0.890459\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:190\n",
            "loss(total):-0.002354\n",
            "recons_loss:0.005252\n",
            "grad_loss:0.120089\n",
            "dice_loss:-0.880687\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:191\n",
            "loss(total):-0.004051\n",
            "recons_loss:0.003734\n",
            "grad_loss:0.099189\n",
            "dice_loss:-0.877667\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:192\n",
            "loss(total):-0.004285\n",
            "recons_loss:0.003837\n",
            "grad_loss:0.088671\n",
            "dice_loss:-0.900789\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:193\n",
            "loss(total):-0.003941\n",
            "recons_loss:0.003902\n",
            "grad_loss:0.099507\n",
            "dice_loss:-0.883795\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:194\n",
            "loss(total):-0.003214\n",
            "recons_loss:0.004597\n",
            "grad_loss:0.092452\n",
            "dice_loss:-0.873479\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:195\n",
            "loss(total):-0.003182\n",
            "recons_loss:0.004502\n",
            "grad_loss:0.113141\n",
            "dice_loss:-0.881519\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:196\n",
            "loss(total):-0.005062\n",
            "recons_loss:0.003192\n",
            "grad_loss:0.087134\n",
            "dice_loss:-0.912488\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:197\n",
            "loss(total):-0.005181\n",
            "recons_loss:0.002857\n",
            "grad_loss:0.098176\n",
            "dice_loss:-0.902005\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:198\n",
            "loss(total):-0.002449\n",
            "recons_loss:0.005145\n",
            "grad_loss:0.129438\n",
            "dice_loss:-0.888783\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:199\n",
            "loss(total):-0.002491\n",
            "recons_loss:0.005072\n",
            "grad_loss:0.114576\n",
            "dice_loss:-0.870831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:200\n",
            "loss(total):-0.001606\n",
            "recons_loss:0.005883\n",
            "grad_loss:0.127499\n",
            "dice_loss:-0.876379\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:201\n",
            "loss(total):-0.004442\n",
            "recons_loss:0.003660\n",
            "grad_loss:0.081954\n",
            "dice_loss:-0.892144\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:202\n",
            "loss(total):-0.004904\n",
            "recons_loss:0.003411\n",
            "grad_loss:0.070972\n",
            "dice_loss:-0.902535\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:203\n",
            "loss(total):-0.003555\n",
            "recons_loss:0.004454\n",
            "grad_loss:0.089057\n",
            "dice_loss:-0.889974\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:204\n",
            "loss(total):-0.003364\n",
            "recons_loss:0.004468\n",
            "grad_loss:0.107810\n",
            "dice_loss:-0.890974\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:205\n",
            "loss(total):-0.004745\n",
            "recons_loss:0.003329\n",
            "grad_loss:0.084404\n",
            "dice_loss:-0.891826\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:206\n",
            "loss(total):-0.003536\n",
            "recons_loss:0.004351\n",
            "grad_loss:0.096610\n",
            "dice_loss:-0.885275\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:207\n",
            "loss(total):-0.003802\n",
            "recons_loss:0.004112\n",
            "grad_loss:0.106164\n",
            "dice_loss:-0.897563\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:208\n",
            "loss(total):-0.003962\n",
            "recons_loss:0.004013\n",
            "grad_loss:0.091364\n",
            "dice_loss:-0.888909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:209\n",
            "loss(total):-0.003112\n",
            "recons_loss:0.004601\n",
            "grad_loss:0.117282\n",
            "dice_loss:-0.888508\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:210\n",
            "loss(total):-0.002532\n",
            "recons_loss:0.005042\n",
            "grad_loss:0.124071\n",
            "dice_loss:-0.881477\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:211\n",
            "loss(total):-0.004619\n",
            "recons_loss:0.003381\n",
            "grad_loss:0.091817\n",
            "dice_loss:-0.891861\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:212\n",
            "loss(total):-0.004425\n",
            "recons_loss:0.003604\n",
            "grad_loss:0.091522\n",
            "dice_loss:-0.894452\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:213\n",
            "loss(total):-0.004778\n",
            "recons_loss:0.003361\n",
            "grad_loss:0.092730\n",
            "dice_loss:-0.906614\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:214\n",
            "loss(total):-0.003413\n",
            "recons_loss:0.004469\n",
            "grad_loss:0.089922\n",
            "dice_loss:-0.878188\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:215\n",
            "loss(total):-0.001448\n",
            "recons_loss:0.006066\n",
            "grad_loss:0.119258\n",
            "dice_loss:-0.870586\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:216\n",
            "loss(total):-0.004823\n",
            "recons_loss:0.003194\n",
            "grad_loss:0.084257\n",
            "dice_loss:-0.886034\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:217\n",
            "loss(total):-0.003238\n",
            "recons_loss:0.004525\n",
            "grad_loss:0.116014\n",
            "dice_loss:-0.892325\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:218\n",
            "loss(total):-0.002927\n",
            "recons_loss:0.004737\n",
            "grad_loss:0.129584\n",
            "dice_loss:-0.895976\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:219\n",
            "loss(total):-0.003585\n",
            "recons_loss:0.004101\n",
            "grad_loss:0.118249\n",
            "dice_loss:-0.886813\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:220\n",
            "loss(total):-0.003587\n",
            "recons_loss:0.004068\n",
            "grad_loss:0.123682\n",
            "dice_loss:-0.889186\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:221\n",
            "loss(total):-0.004604\n",
            "recons_loss:0.003553\n",
            "grad_loss:0.083122\n",
            "dice_loss:-0.898776\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:222\n",
            "loss(total):-0.005077\n",
            "recons_loss:0.002991\n",
            "grad_loss:0.089887\n",
            "dice_loss:-0.896638\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:223\n",
            "loss(total):-0.004075\n",
            "recons_loss:0.003975\n",
            "grad_loss:0.094031\n",
            "dice_loss:-0.899038\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:224\n",
            "loss(total):-0.003920\n",
            "recons_loss:0.004059\n",
            "grad_loss:0.110363\n",
            "dice_loss:-0.908268\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:225\n",
            "loss(total):-0.005280\n",
            "recons_loss:0.002856\n",
            "grad_loss:0.079726\n",
            "dice_loss:-0.893329\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:226\n",
            "loss(total):-0.004801\n",
            "recons_loss:0.003213\n",
            "grad_loss:0.078934\n",
            "dice_loss:-0.880339\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:227\n",
            "loss(total):-0.003994\n",
            "recons_loss:0.003900\n",
            "grad_loss:0.093822\n",
            "dice_loss:-0.883205\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:228\n",
            "loss(total):-0.004748\n",
            "recons_loss:0.003376\n",
            "grad_loss:0.084725\n",
            "dice_loss:-0.897169\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:229\n",
            "loss(total):-0.003800\n",
            "recons_loss:0.004190\n",
            "grad_loss:0.093655\n",
            "dice_loss:-0.892671\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:230\n",
            "loss(total):-0.002871\n",
            "recons_loss:0.004992\n",
            "grad_loss:0.113876\n",
            "dice_loss:-0.900133\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:231\n",
            "loss(total):-0.002673\n",
            "recons_loss:0.005192\n",
            "grad_loss:0.107069\n",
            "dice_loss:-0.893570\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:232\n",
            "loss(total):-0.003389\n",
            "recons_loss:0.004364\n",
            "grad_loss:0.111563\n",
            "dice_loss:-0.886862\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:233\n",
            "loss(total):-0.003425\n",
            "recons_loss:0.004320\n",
            "grad_loss:0.113220\n",
            "dice_loss:-0.887757\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:234\n",
            "loss(total):-0.004717\n",
            "recons_loss:0.003432\n",
            "grad_loss:0.094405\n",
            "dice_loss:-0.909275\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:235\n",
            "loss(total):-0.003562\n",
            "recons_loss:0.004250\n",
            "grad_loss:0.105880\n",
            "dice_loss:-0.887045\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:236\n",
            "loss(total):-0.004431\n",
            "recons_loss:0.003726\n",
            "grad_loss:0.085739\n",
            "dice_loss:-0.901467\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:237\n",
            "loss(total):-0.004052\n",
            "recons_loss:0.003893\n",
            "grad_loss:0.099840\n",
            "dice_loss:-0.894322\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:238\n",
            "loss(total):-0.005318\n",
            "recons_loss:0.002939\n",
            "grad_loss:0.083789\n",
            "dice_loss:-0.909429\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:239\n",
            "loss(total):-0.002887\n",
            "recons_loss:0.004761\n",
            "grad_loss:0.125000\n",
            "dice_loss:-0.889760\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:240\n",
            "loss(total):-0.003194\n",
            "recons_loss:0.004717\n",
            "grad_loss:0.101694\n",
            "dice_loss:-0.892736\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:241\n",
            "loss(total):-0.004285\n",
            "recons_loss:0.003802\n",
            "grad_loss:0.085426\n",
            "dice_loss:-0.894109\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:242\n",
            "loss(total):-0.003771\n",
            "recons_loss:0.004266\n",
            "grad_loss:0.087549\n",
            "dice_loss:-0.891240\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:243\n",
            "loss(total):-0.003213\n",
            "recons_loss:0.004732\n",
            "grad_loss:0.088932\n",
            "dice_loss:-0.883350\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:244\n",
            "loss(total):-0.002396\n",
            "recons_loss:0.005246\n",
            "grad_loss:0.117261\n",
            "dice_loss:-0.881450\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:245\n",
            "loss(total):-0.004200\n",
            "recons_loss:0.003703\n",
            "grad_loss:0.098262\n",
            "dice_loss:-0.888550\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:246\n",
            "loss(total):-0.004062\n",
            "recons_loss:0.004008\n",
            "grad_loss:0.090207\n",
            "dice_loss:-0.897184\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:247\n",
            "loss(total):-0.003904\n",
            "recons_loss:0.004123\n",
            "grad_loss:0.097121\n",
            "dice_loss:-0.899851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:248\n",
            "loss(total):-0.004937\n",
            "recons_loss:0.003180\n",
            "grad_loss:0.073069\n",
            "dice_loss:-0.884757\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:249\n",
            "loss(total):-0.003808\n",
            "recons_loss:0.004093\n",
            "grad_loss:0.091819\n",
            "dice_loss:-0.881998\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:250\n",
            "loss(total):-0.004816\n",
            "recons_loss:0.003208\n",
            "grad_loss:0.081800\n",
            "dice_loss:-0.884256\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:251\n",
            "loss(total):-0.003166\n",
            "recons_loss:0.004722\n",
            "grad_loss:0.108159\n",
            "dice_loss:-0.896886\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:252\n",
            "loss(total):-0.003343\n",
            "recons_loss:0.004496\n",
            "grad_loss:0.111733\n",
            "dice_loss:-0.895585\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:253\n",
            "loss(total):-0.002906\n",
            "recons_loss:0.004786\n",
            "grad_loss:0.120933\n",
            "dice_loss:-0.890136\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:254\n",
            "loss(total):-0.003944\n",
            "recons_loss:0.004110\n",
            "grad_loss:0.092018\n",
            "dice_loss:-0.897444\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:255\n",
            "loss(total):-0.004340\n",
            "recons_loss:0.003621\n",
            "grad_loss:0.087600\n",
            "dice_loss:-0.883704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:256\n",
            "loss(total):-0.003433\n",
            "recons_loss:0.004442\n",
            "grad_loss:0.096405\n",
            "dice_loss:-0.883891\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:257\n",
            "loss(total):-0.002742\n",
            "recons_loss:0.005189\n",
            "grad_loss:0.102821\n",
            "dice_loss:-0.895928\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:258\n",
            "loss(total):-0.002315\n",
            "recons_loss:0.005292\n",
            "grad_loss:0.126129\n",
            "dice_loss:-0.886803\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:259\n",
            "loss(total):-0.004566\n",
            "recons_loss:0.003368\n",
            "grad_loss:0.094824\n",
            "dice_loss:-0.888275\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:260\n",
            "loss(total):-0.003443\n",
            "recons_loss:0.004399\n",
            "grad_loss:0.104187\n",
            "dice_loss:-0.888412\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:261\n",
            "loss(total):-0.004039\n",
            "recons_loss:0.003985\n",
            "grad_loss:0.092155\n",
            "dice_loss:-0.894571\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:262\n",
            "loss(total):-0.003790\n",
            "recons_loss:0.004107\n",
            "grad_loss:0.110268\n",
            "dice_loss:-0.900014\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:263\n",
            "loss(total):-0.003591\n",
            "recons_loss:0.004304\n",
            "grad_loss:0.091791\n",
            "dice_loss:-0.881225\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:264\n",
            "loss(total):-0.004493\n",
            "recons_loss:0.003690\n",
            "grad_loss:0.079332\n",
            "dice_loss:-0.897623\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:265\n",
            "loss(total):-0.002356\n",
            "recons_loss:0.005369\n",
            "grad_loss:0.111006\n",
            "dice_loss:-0.883497\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:266\n",
            "loss(total):-0.004689\n",
            "recons_loss:0.003439\n",
            "grad_loss:0.076670\n",
            "dice_loss:-0.889416\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:267\n",
            "loss(total):-0.004075\n",
            "recons_loss:0.003853\n",
            "grad_loss:0.082095\n",
            "dice_loss:-0.874916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:268\n",
            "loss(total):-0.004344\n",
            "recons_loss:0.003599\n",
            "grad_loss:0.096198\n",
            "dice_loss:-0.890492\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:269\n",
            "loss(total):-0.003972\n",
            "recons_loss:0.003775\n",
            "grad_loss:0.113063\n",
            "dice_loss:-0.887696\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:0\n",
            "loss(total):-0.002690\n",
            "recons_loss:0.004915\n",
            "grad_loss:0.124449\n",
            "dice_loss:-0.884971\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:1\n",
            "loss(total):-0.004212\n",
            "recons_loss:0.003925\n",
            "grad_loss:0.081250\n",
            "dice_loss:-0.894908\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:2\n",
            "loss(total):-0.003077\n",
            "recons_loss:0.004694\n",
            "grad_loss:0.100423\n",
            "dice_loss:-0.877521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:3\n",
            "loss(total):-0.004425\n",
            "recons_loss:0.003563\n",
            "grad_loss:0.085104\n",
            "dice_loss:-0.883947\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:4\n",
            "loss(total):-0.002703\n",
            "recons_loss:0.005057\n",
            "grad_loss:0.106472\n",
            "dice_loss:-0.882505\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:5\n",
            "loss(total):-0.003041\n",
            "recons_loss:0.004747\n",
            "grad_loss:0.114401\n",
            "dice_loss:-0.893228\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:6\n",
            "loss(total):-0.003584\n",
            "recons_loss:0.004206\n",
            "grad_loss:0.118247\n",
            "dice_loss:-0.897229\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:7\n",
            "loss(total):-0.004641\n",
            "recons_loss:0.003446\n",
            "grad_loss:0.094547\n",
            "dice_loss:-0.903240\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:8\n",
            "loss(total):-0.003687\n",
            "recons_loss:0.004174\n",
            "grad_loss:0.109530\n",
            "dice_loss:-0.895720\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:9\n",
            "loss(total):-0.002726\n",
            "recons_loss:0.004937\n",
            "grad_loss:0.116076\n",
            "dice_loss:-0.882341\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:10\n",
            "loss(total):-0.003703\n",
            "recons_loss:0.004211\n",
            "grad_loss:0.095850\n",
            "dice_loss:-0.887281\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:11\n",
            "loss(total):-0.002781\n",
            "recons_loss:0.004999\n",
            "grad_loss:0.108379\n",
            "dice_loss:-0.886425\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:12\n",
            "loss(total):-0.003804\n",
            "recons_loss:0.004011\n",
            "grad_loss:0.106871\n",
            "dice_loss:-0.888394\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:13\n",
            "loss(total):-0.005001\n",
            "recons_loss:0.003055\n",
            "grad_loss:0.074497\n",
            "dice_loss:-0.880060\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:14\n",
            "loss(total):-0.003222\n",
            "recons_loss:0.004565\n",
            "grad_loss:0.102080\n",
            "dice_loss:-0.880780\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:15\n",
            "loss(total):-0.003426\n",
            "recons_loss:0.004231\n",
            "grad_loss:0.114481\n",
            "dice_loss:-0.880163\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:16\n",
            "loss(total):-0.003907\n",
            "recons_loss:0.003970\n",
            "grad_loss:0.094066\n",
            "dice_loss:-0.881757\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:17\n",
            "loss(total):-0.003311\n",
            "recons_loss:0.004328\n",
            "grad_loss:0.124024\n",
            "dice_loss:-0.887963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:18\n",
            "loss(total):-0.002761\n",
            "recons_loss:0.004959\n",
            "grad_loss:0.106481\n",
            "dice_loss:-0.878422\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:19\n",
            "loss(total):-0.004037\n",
            "recons_loss:0.004050\n",
            "grad_loss:0.081271\n",
            "dice_loss:-0.889964\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:20\n",
            "loss(total):-0.004688\n",
            "recons_loss:0.003356\n",
            "grad_loss:0.088766\n",
            "dice_loss:-0.893142\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:21\n",
            "loss(total):-0.004329\n",
            "recons_loss:0.003675\n",
            "grad_loss:0.080896\n",
            "dice_loss:-0.881260\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:22\n",
            "loss(total):-0.004280\n",
            "recons_loss:0.003670\n",
            "grad_loss:0.096632\n",
            "dice_loss:-0.891676\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:23\n",
            "loss(total):-0.002063\n",
            "recons_loss:0.005516\n",
            "grad_loss:0.128628\n",
            "dice_loss:-0.886469\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:24\n",
            "loss(total):-0.004648\n",
            "recons_loss:0.003527\n",
            "grad_loss:0.075258\n",
            "dice_loss:-0.892737\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:25\n",
            "loss(total):-0.002561\n",
            "recons_loss:0.005110\n",
            "grad_loss:0.116439\n",
            "dice_loss:-0.883526\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:26\n",
            "loss(total):-0.003628\n",
            "recons_loss:0.004407\n",
            "grad_loss:0.084652\n",
            "dice_loss:-0.888199\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:27\n",
            "loss(total):-0.002349\n",
            "recons_loss:0.005116\n",
            "grad_loss:0.137751\n",
            "dice_loss:-0.884245\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:28\n",
            "loss(total):-0.004685\n",
            "recons_loss:0.003351\n",
            "grad_loss:0.093803\n",
            "dice_loss:-0.897348\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:29\n",
            "loss(total):-0.003877\n",
            "recons_loss:0.004027\n",
            "grad_loss:0.107432\n",
            "dice_loss:-0.897806\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:30\n",
            "loss(total):-0.004045\n",
            "recons_loss:0.003919\n",
            "grad_loss:0.098555\n",
            "dice_loss:-0.895043\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:31\n",
            "loss(total):-0.004691\n",
            "recons_loss:0.003568\n",
            "grad_loss:0.076429\n",
            "dice_loss:-0.902253\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:32\n",
            "loss(total):-0.004981\n",
            "recons_loss:0.003215\n",
            "grad_loss:0.083502\n",
            "dice_loss:-0.903130\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:33\n",
            "loss(total):-0.003173\n",
            "recons_loss:0.004619\n",
            "grad_loss:0.110002\n",
            "dice_loss:-0.889219\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:34\n",
            "loss(total):-0.004509\n",
            "recons_loss:0.003572\n",
            "grad_loss:0.081026\n",
            "dice_loss:-0.889102\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:35\n",
            "loss(total):-0.003848\n",
            "recons_loss:0.004154\n",
            "grad_loss:0.088140\n",
            "dice_loss:-0.888276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:36\n",
            "loss(total):-0.004624\n",
            "recons_loss:0.003533\n",
            "grad_loss:0.083825\n",
            "dice_loss:-0.899481\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:37\n",
            "loss(total):-0.004242\n",
            "recons_loss:0.003796\n",
            "grad_loss:0.095380\n",
            "dice_loss:-0.899241\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:38\n",
            "loss(total):-0.004988\n",
            "recons_loss:0.003302\n",
            "grad_loss:0.080030\n",
            "dice_loss:-0.909002\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:39\n",
            "loss(total):-0.003844\n",
            "recons_loss:0.004081\n",
            "grad_loss:0.098253\n",
            "dice_loss:-0.890680\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:40\n",
            "loss(total):-0.004466\n",
            "recons_loss:0.003638\n",
            "grad_loss:0.084661\n",
            "dice_loss:-0.895061\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:41\n",
            "loss(total):-0.003971\n",
            "recons_loss:0.003858\n",
            "grad_loss:0.097600\n",
            "dice_loss:-0.880480\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:42\n",
            "loss(total):-0.001841\n",
            "recons_loss:0.005633\n",
            "grad_loss:0.126757\n",
            "dice_loss:-0.874157\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:43\n",
            "loss(total):-0.003997\n",
            "recons_loss:0.003828\n",
            "grad_loss:0.112490\n",
            "dice_loss:-0.894894\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:44\n",
            "loss(total):-0.003545\n",
            "recons_loss:0.004338\n",
            "grad_loss:0.106712\n",
            "dice_loss:-0.894980\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:45\n",
            "loss(total):-0.003128\n",
            "recons_loss:0.004631\n",
            "grad_loss:0.110071\n",
            "dice_loss:-0.885998\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:46\n",
            "loss(total):-0.004949\n",
            "recons_loss:0.003281\n",
            "grad_loss:0.095200\n",
            "dice_loss:-0.918224\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:47\n",
            "loss(total):-0.003970\n",
            "recons_loss:0.004036\n",
            "grad_loss:0.096763\n",
            "dice_loss:-0.897325\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:48\n",
            "loss(total):-0.003970\n",
            "recons_loss:0.004039\n",
            "grad_loss:0.090578\n",
            "dice_loss:-0.891500\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:49\n",
            "loss(total):-0.002648\n",
            "recons_loss:0.005021\n",
            "grad_loss:0.122891\n",
            "dice_loss:-0.889833\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:50\n",
            "loss(total):-0.004731\n",
            "recons_loss:0.003292\n",
            "grad_loss:0.098028\n",
            "dice_loss:-0.900363\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:51\n",
            "loss(total):-0.004632\n",
            "recons_loss:0.003508\n",
            "grad_loss:0.078752\n",
            "dice_loss:-0.892810\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:52\n",
            "loss(total):-0.004506\n",
            "recons_loss:0.003572\n",
            "grad_loss:0.080762\n",
            "dice_loss:-0.888539\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:53\n",
            "loss(total):-0.003839\n",
            "recons_loss:0.004132\n",
            "grad_loss:0.085592\n",
            "dice_loss:-0.882695\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:54\n",
            "loss(total):-0.003370\n",
            "recons_loss:0.004629\n",
            "grad_loss:0.090942\n",
            "dice_loss:-0.890896\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:55\n",
            "loss(total):-0.002840\n",
            "recons_loss:0.004878\n",
            "grad_loss:0.118161\n",
            "dice_loss:-0.890027\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:56\n",
            "loss(total):-0.004036\n",
            "recons_loss:0.003927\n",
            "grad_loss:0.097896\n",
            "dice_loss:-0.894227\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:57\n",
            "loss(total):-0.003416\n",
            "recons_loss:0.004373\n",
            "grad_loss:0.108312\n",
            "dice_loss:-0.887209\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:58\n",
            "loss(total):-0.002619\n",
            "recons_loss:0.005166\n",
            "grad_loss:0.126798\n",
            "dice_loss:-0.905254\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:59\n",
            "loss(total):-0.003037\n",
            "recons_loss:0.004748\n",
            "grad_loss:0.125258\n",
            "dice_loss:-0.903839\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:60\n",
            "loss(total):-0.004398\n",
            "recons_loss:0.003658\n",
            "grad_loss:0.087708\n",
            "dice_loss:-0.893234\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:61\n",
            "loss(total):-0.004192\n",
            "recons_loss:0.003797\n",
            "grad_loss:0.092925\n",
            "dice_loss:-0.891822\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:62\n",
            "loss(total):-0.001594\n",
            "recons_loss:0.005863\n",
            "grad_loss:0.124362\n",
            "dice_loss:-0.870022\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:63\n",
            "loss(total):-0.003899\n",
            "recons_loss:0.004112\n",
            "grad_loss:0.090060\n",
            "dice_loss:-0.891164\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:64\n",
            "loss(total):-0.004122\n",
            "recons_loss:0.003773\n",
            "grad_loss:0.090454\n",
            "dice_loss:-0.880015\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:65\n",
            "loss(total):-0.002967\n",
            "recons_loss:0.004821\n",
            "grad_loss:0.105996\n",
            "dice_loss:-0.884769\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:66\n",
            "loss(total):-0.004282\n",
            "recons_loss:0.003633\n",
            "grad_loss:0.093439\n",
            "dice_loss:-0.884961\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:67\n",
            "loss(total):-0.004033\n",
            "recons_loss:0.003841\n",
            "grad_loss:0.108833\n",
            "dice_loss:-0.896292\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:68\n",
            "loss(total):-0.003810\n",
            "recons_loss:0.003942\n",
            "grad_loss:0.113095\n",
            "dice_loss:-0.888302\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:69\n",
            "loss(total):-0.002793\n",
            "recons_loss:0.004845\n",
            "grad_loss:0.121364\n",
            "dice_loss:-0.885125\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:70\n",
            "loss(total):-0.002643\n",
            "recons_loss:0.005023\n",
            "grad_loss:0.119667\n",
            "dice_loss:-0.886266\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:71\n",
            "loss(total):-0.004224\n",
            "recons_loss:0.003730\n",
            "grad_loss:0.087079\n",
            "dice_loss:-0.882410\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:72\n",
            "loss(total):-0.002980\n",
            "recons_loss:0.004842\n",
            "grad_loss:0.108929\n",
            "dice_loss:-0.891107\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:73\n",
            "loss(total):-0.005300\n",
            "recons_loss:0.003028\n",
            "grad_loss:0.071237\n",
            "dice_loss:-0.904091\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:74\n",
            "loss(total):-0.003630\n",
            "recons_loss:0.004261\n",
            "grad_loss:0.093301\n",
            "dice_loss:-0.882348\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:75\n",
            "loss(total):-0.002674\n",
            "recons_loss:0.004893\n",
            "grad_loss:0.126566\n",
            "dice_loss:-0.883291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:76\n",
            "loss(total):-0.003621\n",
            "recons_loss:0.004249\n",
            "grad_loss:0.105753\n",
            "dice_loss:-0.892777\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:77\n",
            "loss(total):-0.004335\n",
            "recons_loss:0.003769\n",
            "grad_loss:0.090596\n",
            "dice_loss:-0.901025\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:78\n",
            "loss(total):-0.003973\n",
            "recons_loss:0.003877\n",
            "grad_loss:0.102536\n",
            "dice_loss:-0.887481\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:79\n",
            "loss(total):-0.004757\n",
            "recons_loss:0.003297\n",
            "grad_loss:0.095220\n",
            "dice_loss:-0.900568\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:80\n",
            "loss(total):-0.004549\n",
            "recons_loss:0.003530\n",
            "grad_loss:0.085964\n",
            "dice_loss:-0.893907\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:81\n",
            "loss(total):-0.004798\n",
            "recons_loss:0.003398\n",
            "grad_loss:0.072309\n",
            "dice_loss:-0.891910\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:82\n",
            "loss(total):-0.003167\n",
            "recons_loss:0.004559\n",
            "grad_loss:0.099468\n",
            "dice_loss:-0.872065\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:83\n",
            "loss(total):-0.004139\n",
            "recons_loss:0.003883\n",
            "grad_loss:0.085760\n",
            "dice_loss:-0.887909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:84\n",
            "loss(total):-0.003705\n",
            "recons_loss:0.004184\n",
            "grad_loss:0.106004\n",
            "dice_loss:-0.894908\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:85\n",
            "loss(total):-0.004027\n",
            "recons_loss:0.003759\n",
            "grad_loss:0.102403\n",
            "dice_loss:-0.880995\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:86\n",
            "loss(total):-0.004708\n",
            "recons_loss:0.003256\n",
            "grad_loss:0.098857\n",
            "dice_loss:-0.895196\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:87\n",
            "loss(total):-0.004361\n",
            "recons_loss:0.003678\n",
            "grad_loss:0.088219\n",
            "dice_loss:-0.892179\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:88\n",
            "loss(total):-0.003042\n",
            "recons_loss:0.004714\n",
            "grad_loss:0.109011\n",
            "dice_loss:-0.884643\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:89\n",
            "loss(total):-0.003418\n",
            "recons_loss:0.004413\n",
            "grad_loss:0.103614\n",
            "dice_loss:-0.886710\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:90\n",
            "loss(total):-0.003759\n",
            "recons_loss:0.004039\n",
            "grad_loss:0.104581\n",
            "dice_loss:-0.884392\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:91\n",
            "loss(total):-0.002927\n",
            "recons_loss:0.005049\n",
            "grad_loss:0.102071\n",
            "dice_loss:-0.899719\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:92\n",
            "loss(total):-0.004321\n",
            "recons_loss:0.003933\n",
            "grad_loss:0.078193\n",
            "dice_loss:-0.903604\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:93\n",
            "loss(total):-0.004084\n",
            "recons_loss:0.003796\n",
            "grad_loss:0.108925\n",
            "dice_loss:-0.896931\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:94\n",
            "loss(total):-0.002459\n",
            "recons_loss:0.005000\n",
            "grad_loss:0.124896\n",
            "dice_loss:-0.870748\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:95\n",
            "loss(total):-0.004623\n",
            "recons_loss:0.003602\n",
            "grad_loss:0.079107\n",
            "dice_loss:-0.901522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:96\n",
            "loss(total):-0.004050\n",
            "recons_loss:0.003969\n",
            "grad_loss:0.088833\n",
            "dice_loss:-0.890727\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:97\n",
            "loss(total):-0.002151\n",
            "recons_loss:0.005469\n",
            "grad_loss:0.126696\n",
            "dice_loss:-0.888673\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:98\n",
            "loss(total):-0.003741\n",
            "recons_loss:0.004192\n",
            "grad_loss:0.094262\n",
            "dice_loss:-0.887598\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:99\n",
            "loss(total):-0.003667\n",
            "recons_loss:0.004269\n",
            "grad_loss:0.104321\n",
            "dice_loss:-0.897935\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:100\n",
            "loss(total):-0.004349\n",
            "recons_loss:0.003713\n",
            "grad_loss:0.087277\n",
            "dice_loss:-0.893487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:101\n",
            "loss(total):-0.004017\n",
            "recons_loss:0.003881\n",
            "grad_loss:0.096089\n",
            "dice_loss:-0.885854\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:102\n",
            "loss(total):-0.003238\n",
            "recons_loss:0.004576\n",
            "grad_loss:0.115352\n",
            "dice_loss:-0.896664\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:103\n",
            "loss(total):-0.002435\n",
            "recons_loss:0.005152\n",
            "grad_loss:0.117966\n",
            "dice_loss:-0.876664\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:104\n",
            "loss(total):-0.004702\n",
            "recons_loss:0.003389\n",
            "grad_loss:0.082054\n",
            "dice_loss:-0.891127\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:105\n",
            "loss(total):-0.003360\n",
            "recons_loss:0.004387\n",
            "grad_loss:0.109776\n",
            "dice_loss:-0.884478\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:106\n",
            "loss(total):-0.003216\n",
            "recons_loss:0.004644\n",
            "grad_loss:0.110573\n",
            "dice_loss:-0.896562\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:107\n",
            "loss(total):-0.003229\n",
            "recons_loss:0.004505\n",
            "grad_loss:0.098275\n",
            "dice_loss:-0.871645\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:108\n",
            "loss(total):-0.003562\n",
            "recons_loss:0.004383\n",
            "grad_loss:0.084805\n",
            "dice_loss:-0.879375\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:109\n",
            "loss(total):-0.003611\n",
            "recons_loss:0.004382\n",
            "grad_loss:0.081901\n",
            "dice_loss:-0.881234\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:110\n",
            "loss(total):-0.003352\n",
            "recons_loss:0.004541\n",
            "grad_loss:0.105482\n",
            "dice_loss:-0.894816\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:111\n",
            "loss(total):-0.004222\n",
            "recons_loss:0.003617\n",
            "grad_loss:0.103712\n",
            "dice_loss:-0.887608\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:112\n",
            "loss(total):-0.003250\n",
            "recons_loss:0.004344\n",
            "grad_loss:0.124756\n",
            "dice_loss:-0.884122\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:113\n",
            "loss(total):-0.003050\n",
            "recons_loss:0.004619\n",
            "grad_loss:0.111182\n",
            "dice_loss:-0.878114\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:114\n",
            "loss(total):-0.002298\n",
            "recons_loss:0.005497\n",
            "grad_loss:0.114973\n",
            "dice_loss:-0.894505\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:115\n",
            "loss(total):-0.003120\n",
            "recons_loss:0.004729\n",
            "grad_loss:0.106168\n",
            "dice_loss:-0.891124\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:116\n",
            "loss(total):-0.002437\n",
            "recons_loss:0.005265\n",
            "grad_loss:0.114358\n",
            "dice_loss:-0.884527\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:117\n",
            "loss(total):-0.002346\n",
            "recons_loss:0.005365\n",
            "grad_loss:0.119284\n",
            "dice_loss:-0.890433\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:118\n",
            "loss(total):-0.003912\n",
            "recons_loss:0.004216\n",
            "grad_loss:0.090650\n",
            "dice_loss:-0.903473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:119\n",
            "loss(total):-0.004348\n",
            "recons_loss:0.003678\n",
            "grad_loss:0.091738\n",
            "dice_loss:-0.894394\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:120\n",
            "loss(total):-0.003027\n",
            "recons_loss:0.004762\n",
            "grad_loss:0.102678\n",
            "dice_loss:-0.881634\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:121\n",
            "loss(total):-0.002991\n",
            "recons_loss:0.004792\n",
            "grad_loss:0.109861\n",
            "dice_loss:-0.888176\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:122\n",
            "loss(total):-0.003706\n",
            "recons_loss:0.004440\n",
            "grad_loss:0.071449\n",
            "dice_loss:-0.885980\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:123\n",
            "loss(total):-0.004133\n",
            "recons_loss:0.004016\n",
            "grad_loss:0.084604\n",
            "dice_loss:-0.899473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:124\n",
            "loss(total):-0.004174\n",
            "recons_loss:0.003924\n",
            "grad_loss:0.090293\n",
            "dice_loss:-0.900042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:125\n",
            "loss(total):-0.004255\n",
            "recons_loss:0.003897\n",
            "grad_loss:0.094401\n",
            "dice_loss:-0.909664\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:126\n",
            "loss(total):-0.003249\n",
            "recons_loss:0.004443\n",
            "grad_loss:0.120640\n",
            "dice_loss:-0.889851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:127\n",
            "loss(total):-0.002424\n",
            "recons_loss:0.005192\n",
            "grad_loss:0.111900\n",
            "dice_loss:-0.873531\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:128\n",
            "loss(total):-0.003716\n",
            "recons_loss:0.004243\n",
            "grad_loss:0.101400\n",
            "dice_loss:-0.897349\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:129\n",
            "loss(total):-0.003424\n",
            "recons_loss:0.004385\n",
            "grad_loss:0.116992\n",
            "dice_loss:-0.897865\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:130\n",
            "loss(total):-0.001978\n",
            "recons_loss:0.005809\n",
            "grad_loss:0.116815\n",
            "dice_loss:-0.895524\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:131\n",
            "loss(total):-0.002904\n",
            "recons_loss:0.004936\n",
            "grad_loss:0.107720\n",
            "dice_loss:-0.891676\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:132\n",
            "loss(total):-0.004168\n",
            "recons_loss:0.003883\n",
            "grad_loss:0.095841\n",
            "dice_loss:-0.900978\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:133\n",
            "loss(total):-0.002211\n",
            "recons_loss:0.005328\n",
            "grad_loss:0.131032\n",
            "dice_loss:-0.884953\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:134\n",
            "loss(total):-0.003180\n",
            "recons_loss:0.004611\n",
            "grad_loss:0.113684\n",
            "dice_loss:-0.892828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:135\n",
            "loss(total):-0.003891\n",
            "recons_loss:0.004166\n",
            "grad_loss:0.096423\n",
            "dice_loss:-0.902197\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:136\n",
            "loss(total):-0.003693\n",
            "recons_loss:0.004147\n",
            "grad_loss:0.100645\n",
            "dice_loss:-0.884694\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:137\n",
            "loss(total):-0.003752\n",
            "recons_loss:0.004171\n",
            "grad_loss:0.101306\n",
            "dice_loss:-0.893624\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:138\n",
            "loss(total):-0.003181\n",
            "recons_loss:0.004465\n",
            "grad_loss:0.114583\n",
            "dice_loss:-0.879176\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:139\n",
            "loss(total):-0.003145\n",
            "recons_loss:0.004662\n",
            "grad_loss:0.105539\n",
            "dice_loss:-0.886236\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:140\n",
            "loss(total):-0.003275\n",
            "recons_loss:0.004517\n",
            "grad_loss:0.098440\n",
            "dice_loss:-0.877625\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:141\n",
            "loss(total):-0.003578\n",
            "recons_loss:0.004274\n",
            "grad_loss:0.098090\n",
            "dice_loss:-0.883301\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:142\n",
            "loss(total):-0.004020\n",
            "recons_loss:0.003821\n",
            "grad_loss:0.113607\n",
            "dice_loss:-0.897785\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:143\n",
            "loss(total):-0.004116\n",
            "recons_loss:0.003898\n",
            "grad_loss:0.087017\n",
            "dice_loss:-0.888372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:144\n",
            "loss(total):-0.004927\n",
            "recons_loss:0.003269\n",
            "grad_loss:0.072340\n",
            "dice_loss:-0.891889\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:145\n",
            "loss(total):-0.005124\n",
            "recons_loss:0.003109\n",
            "grad_loss:0.078154\n",
            "dice_loss:-0.901522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:146\n",
            "loss(total):-0.003438\n",
            "recons_loss:0.004320\n",
            "grad_loss:0.096698\n",
            "dice_loss:-0.872543\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:147\n",
            "loss(total):-0.003834\n",
            "recons_loss:0.004137\n",
            "grad_loss:0.088595\n",
            "dice_loss:-0.885673\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:148\n",
            "loss(total):-0.003235\n",
            "recons_loss:0.004674\n",
            "grad_loss:0.114537\n",
            "dice_loss:-0.905423\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:149\n",
            "loss(total):-0.004440\n",
            "recons_loss:0.003632\n",
            "grad_loss:0.077842\n",
            "dice_loss:-0.885006\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:150\n",
            "loss(total):-0.002299\n",
            "recons_loss:0.005255\n",
            "grad_loss:0.123471\n",
            "dice_loss:-0.878827\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:151\n",
            "loss(total):-0.005075\n",
            "recons_loss:0.003114\n",
            "grad_loss:0.081642\n",
            "dice_loss:-0.900491\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:152\n",
            "loss(total):-0.001408\n",
            "recons_loss:0.005891\n",
            "grad_loss:0.159151\n",
            "dice_loss:-0.889119\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:153\n",
            "loss(total):-0.004324\n",
            "recons_loss:0.003584\n",
            "grad_loss:0.103883\n",
            "dice_loss:-0.894683\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:154\n",
            "loss(total):-0.001911\n",
            "recons_loss:0.005774\n",
            "grad_loss:0.119875\n",
            "dice_loss:-0.888365\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:155\n",
            "loss(total):-0.002381\n",
            "recons_loss:0.005464\n",
            "grad_loss:0.100372\n",
            "dice_loss:-0.884915\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:156\n",
            "loss(total):-0.002692\n",
            "recons_loss:0.005178\n",
            "grad_loss:0.098292\n",
            "dice_loss:-0.885373\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:157\n",
            "loss(total):-0.004032\n",
            "recons_loss:0.003856\n",
            "grad_loss:0.098527\n",
            "dice_loss:-0.887289\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:158\n",
            "loss(total):-0.002495\n",
            "recons_loss:0.005144\n",
            "grad_loss:0.119209\n",
            "dice_loss:-0.883067\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:159\n",
            "loss(total):-0.003168\n",
            "recons_loss:0.004722\n",
            "grad_loss:0.096884\n",
            "dice_loss:-0.885897\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:160\n",
            "loss(total):-0.002739\n",
            "recons_loss:0.004967\n",
            "grad_loss:0.120419\n",
            "dice_loss:-0.890971\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:161\n",
            "loss(total):-0.004078\n",
            "recons_loss:0.003799\n",
            "grad_loss:0.104591\n",
            "dice_loss:-0.892225\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:162\n",
            "loss(total):-0.003402\n",
            "recons_loss:0.004343\n",
            "grad_loss:0.114760\n",
            "dice_loss:-0.889302\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:163\n",
            "loss(total):-0.003776\n",
            "recons_loss:0.004250\n",
            "grad_loss:0.086507\n",
            "dice_loss:-0.889097\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:164\n",
            "loss(total):-0.002281\n",
            "recons_loss:0.005279\n",
            "grad_loss:0.120020\n",
            "dice_loss:-0.876057\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:165\n",
            "loss(total):-0.003514\n",
            "recons_loss:0.004239\n",
            "grad_loss:0.120314\n",
            "dice_loss:-0.895606\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:166\n",
            "loss(total):-0.003982\n",
            "recons_loss:0.004048\n",
            "grad_loss:0.089843\n",
            "dice_loss:-0.892852\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:167\n",
            "loss(total):-0.004405\n",
            "recons_loss:0.003576\n",
            "grad_loss:0.091766\n",
            "dice_loss:-0.889858\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:168\n",
            "loss(total):-0.003528\n",
            "recons_loss:0.004371\n",
            "grad_loss:0.108818\n",
            "dice_loss:-0.898766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:169\n",
            "loss(total):-0.003189\n",
            "recons_loss:0.004570\n",
            "grad_loss:0.101314\n",
            "dice_loss:-0.877288\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:170\n",
            "loss(total):-0.004174\n",
            "recons_loss:0.003723\n",
            "grad_loss:0.094152\n",
            "dice_loss:-0.883866\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:171\n",
            "loss(total):-0.002935\n",
            "recons_loss:0.004737\n",
            "grad_loss:0.111025\n",
            "dice_loss:-0.878237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:172\n",
            "loss(total):-0.002516\n",
            "recons_loss:0.005268\n",
            "grad_loss:0.113152\n",
            "dice_loss:-0.891629\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:173\n",
            "loss(total):-0.004116\n",
            "recons_loss:0.003945\n",
            "grad_loss:0.083725\n",
            "dice_loss:-0.889855\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:174\n",
            "loss(total):-0.003778\n",
            "recons_loss:0.004098\n",
            "grad_loss:0.093746\n",
            "dice_loss:-0.881390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:175\n",
            "loss(total):-0.004109\n",
            "recons_loss:0.003776\n",
            "grad_loss:0.091128\n",
            "dice_loss:-0.879631\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:176\n",
            "loss(total):-0.001967\n",
            "recons_loss:0.005385\n",
            "grad_loss:0.140761\n",
            "dice_loss:-0.875968\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:177\n",
            "loss(total):-0.003943\n",
            "recons_loss:0.004086\n",
            "grad_loss:0.093914\n",
            "dice_loss:-0.896884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:178\n",
            "loss(total):-0.002663\n",
            "recons_loss:0.004944\n",
            "grad_loss:0.103468\n",
            "dice_loss:-0.864104\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:179\n",
            "loss(total):-0.003371\n",
            "recons_loss:0.004370\n",
            "grad_loss:0.092417\n",
            "dice_loss:-0.866562\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:180\n",
            "loss(total):-0.004432\n",
            "recons_loss:0.003543\n",
            "grad_loss:0.098948\n",
            "dice_loss:-0.896453\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:181\n",
            "loss(total):-0.002870\n",
            "recons_loss:0.004864\n",
            "grad_loss:0.116505\n",
            "dice_loss:-0.889906\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:182\n",
            "loss(total):-0.004157\n",
            "recons_loss:0.003784\n",
            "grad_loss:0.092513\n",
            "dice_loss:-0.886541\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:183\n",
            "loss(total):-0.005462\n",
            "recons_loss:0.002848\n",
            "grad_loss:0.076385\n",
            "dice_loss:-0.907358\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:184\n",
            "loss(total):-0.004559\n",
            "recons_loss:0.003587\n",
            "grad_loss:0.089076\n",
            "dice_loss:-0.903720\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:185\n",
            "loss(total):-0.003804\n",
            "recons_loss:0.004115\n",
            "grad_loss:0.097463\n",
            "dice_loss:-0.889393\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:186\n",
            "loss(total):-0.003092\n",
            "recons_loss:0.004730\n",
            "grad_loss:0.094356\n",
            "dice_loss:-0.876572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:187\n",
            "loss(total):-0.003503\n",
            "recons_loss:0.004386\n",
            "grad_loss:0.106355\n",
            "dice_loss:-0.895286\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:188\n",
            "loss(total):-0.003426\n",
            "recons_loss:0.004303\n",
            "grad_loss:0.100923\n",
            "dice_loss:-0.873839\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:189\n",
            "loss(total):-0.003864\n",
            "recons_loss:0.004085\n",
            "grad_loss:0.085664\n",
            "dice_loss:-0.880590\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:190\n",
            "loss(total):-0.005011\n",
            "recons_loss:0.003085\n",
            "grad_loss:0.101822\n",
            "dice_loss:-0.911376\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:191\n",
            "loss(total):-0.004526\n",
            "recons_loss:0.003598\n",
            "grad_loss:0.096187\n",
            "dice_loss:-0.908617\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:192\n",
            "loss(total):-0.003890\n",
            "recons_loss:0.004014\n",
            "grad_loss:0.105904\n",
            "dice_loss:-0.896329\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:193\n",
            "loss(total):-0.003161\n",
            "recons_loss:0.004613\n",
            "grad_loss:0.117967\n",
            "dice_loss:-0.895377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:194\n",
            "loss(total):-0.003789\n",
            "recons_loss:0.004161\n",
            "grad_loss:0.108957\n",
            "dice_loss:-0.903902\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:195\n",
            "loss(total):-0.002281\n",
            "recons_loss:0.005399\n",
            "grad_loss:0.106313\n",
            "dice_loss:-0.874296\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:196\n",
            "loss(total):-0.004498\n",
            "recons_loss:0.003660\n",
            "grad_loss:0.078820\n",
            "dice_loss:-0.894631\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:197\n",
            "loss(total):-0.004669\n",
            "recons_loss:0.003251\n",
            "grad_loss:0.097119\n",
            "dice_loss:-0.889083\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:198\n",
            "loss(total):-0.003240\n",
            "recons_loss:0.004304\n",
            "grad_loss:0.118766\n",
            "dice_loss:-0.873135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:199\n",
            "loss(total):-0.004104\n",
            "recons_loss:0.003803\n",
            "grad_loss:0.114612\n",
            "dice_loss:-0.905296\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:200\n",
            "loss(total):-0.003486\n",
            "recons_loss:0.004351\n",
            "grad_loss:0.103903\n",
            "dice_loss:-0.887618\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:201\n",
            "loss(total):-0.002172\n",
            "recons_loss:0.005552\n",
            "grad_loss:0.106839\n",
            "dice_loss:-0.879254\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:202\n",
            "loss(total):-0.004345\n",
            "recons_loss:0.003644\n",
            "grad_loss:0.096291\n",
            "dice_loss:-0.895147\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:203\n",
            "loss(total):-0.003610\n",
            "recons_loss:0.004310\n",
            "grad_loss:0.095761\n",
            "dice_loss:-0.887784\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:204\n",
            "loss(total):-0.003760\n",
            "recons_loss:0.004234\n",
            "grad_loss:0.086706\n",
            "dice_loss:-0.886130\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:205\n",
            "loss(total):-0.004193\n",
            "recons_loss:0.003816\n",
            "grad_loss:0.095171\n",
            "dice_loss:-0.896157\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:206\n",
            "loss(total):-0.004441\n",
            "recons_loss:0.003414\n",
            "grad_loss:0.112005\n",
            "dice_loss:-0.897432\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:207\n",
            "loss(total):-0.002574\n",
            "recons_loss:0.005135\n",
            "grad_loss:0.115139\n",
            "dice_loss:-0.886063\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:208\n",
            "loss(total):-0.003766\n",
            "recons_loss:0.004079\n",
            "grad_loss:0.110938\n",
            "dice_loss:-0.895370\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:209\n",
            "loss(total):-0.004101\n",
            "recons_loss:0.003918\n",
            "grad_loss:0.100158\n",
            "dice_loss:-0.902019\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:210\n",
            "loss(total):-0.001154\n",
            "recons_loss:0.006264\n",
            "grad_loss:0.144581\n",
            "dice_loss:-0.886341\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:211\n",
            "loss(total):-0.003831\n",
            "recons_loss:0.003963\n",
            "grad_loss:0.101582\n",
            "dice_loss:-0.880939\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:212\n",
            "loss(total):-0.002243\n",
            "recons_loss:0.005318\n",
            "grad_loss:0.133400\n",
            "dice_loss:-0.889488\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:213\n",
            "loss(total):-0.003950\n",
            "recons_loss:0.003960\n",
            "grad_loss:0.105079\n",
            "dice_loss:-0.896035\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:214\n",
            "loss(total):-0.002594\n",
            "recons_loss:0.004971\n",
            "grad_loss:0.127155\n",
            "dice_loss:-0.883647\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:215\n",
            "loss(total):-0.003839\n",
            "recons_loss:0.004313\n",
            "grad_loss:0.087136\n",
            "dice_loss:-0.902391\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:216\n",
            "loss(total):-0.003721\n",
            "recons_loss:0.004273\n",
            "grad_loss:0.095510\n",
            "dice_loss:-0.894978\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:217\n",
            "loss(total):-0.003291\n",
            "recons_loss:0.004785\n",
            "grad_loss:0.084267\n",
            "dice_loss:-0.891943\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:218\n",
            "loss(total):-0.002755\n",
            "recons_loss:0.004888\n",
            "grad_loss:0.116050\n",
            "dice_loss:-0.880287\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:219\n",
            "loss(total):-0.003577\n",
            "recons_loss:0.004378\n",
            "grad_loss:0.096291\n",
            "dice_loss:-0.891758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:220\n",
            "loss(total):-0.004536\n",
            "recons_loss:0.003505\n",
            "grad_loss:0.082673\n",
            "dice_loss:-0.886723\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:221\n",
            "loss(total):-0.003291\n",
            "recons_loss:0.004354\n",
            "grad_loss:0.121545\n",
            "dice_loss:-0.886091\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:222\n",
            "loss(total):-0.002596\n",
            "recons_loss:0.005107\n",
            "grad_loss:0.117732\n",
            "dice_loss:-0.888087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:223\n",
            "loss(total):-0.002779\n",
            "recons_loss:0.004999\n",
            "grad_loss:0.102597\n",
            "dice_loss:-0.880439\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:224\n",
            "loss(total):-0.003603\n",
            "recons_loss:0.004273\n",
            "grad_loss:0.097824\n",
            "dice_loss:-0.885346\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:225\n",
            "loss(total):-0.003314\n",
            "recons_loss:0.004434\n",
            "grad_loss:0.104999\n",
            "dice_loss:-0.879776\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:226\n",
            "loss(total):-0.004132\n",
            "recons_loss:0.003930\n",
            "grad_loss:0.082595\n",
            "dice_loss:-0.888855\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:227\n",
            "loss(total):-0.004250\n",
            "recons_loss:0.003646\n",
            "grad_loss:0.089187\n",
            "dice_loss:-0.878759\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:228\n",
            "loss(total):-0.004805\n",
            "recons_loss:0.003155\n",
            "grad_loss:0.085120\n",
            "dice_loss:-0.881114\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:229\n",
            "loss(total):-0.003181\n",
            "recons_loss:0.004548\n",
            "grad_loss:0.103008\n",
            "dice_loss:-0.875923\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:230\n",
            "loss(total):-0.005022\n",
            "recons_loss:0.003256\n",
            "grad_loss:0.070377\n",
            "dice_loss:-0.898188\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:231\n",
            "loss(total):-0.003232\n",
            "recons_loss:0.004691\n",
            "grad_loss:0.100545\n",
            "dice_loss:-0.892819\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:232\n",
            "loss(total):-0.003207\n",
            "recons_loss:0.004647\n",
            "grad_loss:0.111085\n",
            "dice_loss:-0.896517\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:233\n",
            "loss(total):-0.003735\n",
            "recons_loss:0.004155\n",
            "grad_loss:0.102281\n",
            "dice_loss:-0.891324\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:234\n",
            "loss(total):-0.004018\n",
            "recons_loss:0.003952\n",
            "grad_loss:0.100249\n",
            "dice_loss:-0.897249\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:235\n",
            "loss(total):-0.003263\n",
            "recons_loss:0.004475\n",
            "grad_loss:0.106282\n",
            "dice_loss:-0.880063\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:236\n",
            "loss(total):-0.003607\n",
            "recons_loss:0.004028\n",
            "grad_loss:0.117910\n",
            "dice_loss:-0.881412\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:237\n",
            "loss(total):-0.004473\n",
            "recons_loss:0.003624\n",
            "grad_loss:0.094123\n",
            "dice_loss:-0.903863\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:238\n",
            "loss(total):-0.003637\n",
            "recons_loss:0.004252\n",
            "grad_loss:0.113544\n",
            "dice_loss:-0.902451\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:239\n",
            "loss(total):-0.004924\n",
            "recons_loss:0.003143\n",
            "grad_loss:0.079247\n",
            "dice_loss:-0.885870\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:240\n",
            "loss(total):-0.002314\n",
            "recons_loss:0.005299\n",
            "grad_loss:0.130047\n",
            "dice_loss:-0.891329\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:241\n",
            "loss(total):-0.003439\n",
            "recons_loss:0.004472\n",
            "grad_loss:0.107493\n",
            "dice_loss:-0.898580\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:242\n",
            "loss(total):-0.002938\n",
            "recons_loss:0.004841\n",
            "grad_loss:0.110534\n",
            "dice_loss:-0.888496\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:243\n",
            "loss(total):-0.004521\n",
            "recons_loss:0.003473\n",
            "grad_loss:0.091700\n",
            "dice_loss:-0.891131\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:244\n",
            "loss(total):-0.003489\n",
            "recons_loss:0.004306\n",
            "grad_loss:0.117066\n",
            "dice_loss:-0.896512\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:245\n",
            "loss(total):-0.003680\n",
            "recons_loss:0.004245\n",
            "grad_loss:0.102037\n",
            "dice_loss:-0.894538\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:246\n",
            "loss(total):-0.003212\n",
            "recons_loss:0.004680\n",
            "grad_loss:0.092097\n",
            "dice_loss:-0.881252\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:247\n",
            "loss(total):-0.004033\n",
            "recons_loss:0.003888\n",
            "grad_loss:0.085818\n",
            "dice_loss:-0.877912\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:248\n",
            "loss(total):-0.005208\n",
            "recons_loss:0.003220\n",
            "grad_loss:0.064467\n",
            "dice_loss:-0.907246\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:249\n",
            "loss(total):-0.004012\n",
            "recons_loss:0.003953\n",
            "grad_loss:0.103957\n",
            "dice_loss:-0.900403\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:250\n",
            "loss(total):-0.004297\n",
            "recons_loss:0.003789\n",
            "grad_loss:0.077504\n",
            "dice_loss:-0.886125\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:251\n",
            "loss(total):-0.002650\n",
            "recons_loss:0.004794\n",
            "grad_loss:0.138786\n",
            "dice_loss:-0.883186\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:252\n",
            "loss(total):-0.004000\n",
            "recons_loss:0.004008\n",
            "grad_loss:0.094248\n",
            "dice_loss:-0.894991\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:253\n",
            "loss(total):-0.003099\n",
            "recons_loss:0.004762\n",
            "grad_loss:0.108081\n",
            "dice_loss:-0.894226\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:254\n",
            "loss(total):-0.005712\n",
            "recons_loss:0.002614\n",
            "grad_loss:0.075822\n",
            "dice_loss:-0.908463\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:255\n",
            "loss(total):-0.004102\n",
            "recons_loss:0.003826\n",
            "grad_loss:0.099426\n",
            "dice_loss:-0.892204\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:256\n",
            "loss(total):-0.002198\n",
            "recons_loss:0.005318\n",
            "grad_loss:0.123003\n",
            "dice_loss:-0.874590\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:257\n",
            "loss(total):-0.006161\n",
            "recons_loss:0.002276\n",
            "grad_loss:0.063561\n",
            "dice_loss:-0.907268\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:258\n",
            "loss(total):-0.003909\n",
            "recons_loss:0.004103\n",
            "grad_loss:0.088617\n",
            "dice_loss:-0.889876\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:259\n",
            "loss(total):-0.002701\n",
            "recons_loss:0.004884\n",
            "grad_loss:0.112236\n",
            "dice_loss:-0.870725\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:260\n",
            "loss(total):-0.002874\n",
            "recons_loss:0.004637\n",
            "grad_loss:0.114337\n",
            "dice_loss:-0.865487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:261\n",
            "loss(total):-0.002378\n",
            "recons_loss:0.005293\n",
            "grad_loss:0.115562\n",
            "dice_loss:-0.882749\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:262\n",
            "loss(total):-0.003361\n",
            "recons_loss:0.004376\n",
            "grad_loss:0.106112\n",
            "dice_loss:-0.879816\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:263\n",
            "loss(total):-0.002786\n",
            "recons_loss:0.004966\n",
            "grad_loss:0.119302\n",
            "dice_loss:-0.894518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:264\n",
            "loss(total):-0.004622\n",
            "recons_loss:0.003468\n",
            "grad_loss:0.097532\n",
            "dice_loss:-0.906514\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:265\n",
            "loss(total):-0.003349\n",
            "recons_loss:0.004486\n",
            "grad_loss:0.110142\n",
            "dice_loss:-0.893685\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:266\n",
            "loss(total):-0.004120\n",
            "recons_loss:0.004150\n",
            "grad_loss:0.075701\n",
            "dice_loss:-0.902724\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:267\n",
            "loss(total):-0.003858\n",
            "recons_loss:0.004260\n",
            "grad_loss:0.082824\n",
            "dice_loss:-0.894661\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:268\n",
            "loss(total):-0.001795\n",
            "recons_loss:0.005500\n",
            "grad_loss:0.148713\n",
            "dice_loss:-0.878236\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:269\n",
            "loss(total):-0.003223\n",
            "recons_loss:0.004588\n",
            "grad_loss:0.114416\n",
            "dice_loss:-0.895534\n",
            "---------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE_D-rZS2YjS",
        "outputId": "e432c7c2-6d2a-41e6-e9ca-f40e60a25be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(losses_2[1:])\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAIECAYAAAAgtJU8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3zU9eHH8fclYYche4QQRsISCFNmwYFFceNARcWWodWqpVa0gqNFpQ5+1bYWqIirohbQogwXMioooGzEECAkAcLeI/P7+yO548b3VnL3vST3ej4eeTxy9/3e9/v55pJ83/eZNsMwDAEAAFgoJtIFAAAA0YcAAgAALEcAAQAAliOAAAAAyxFAAACA5QggAADAcnGRLkAgqlWrpkaNGkW6GAAAIAiHDh1Sbm6u6bYKEUAaNWqk7OzsSBcDAAAEISEhwes2mmAAAIDlCCAAAMByBBAAAGA5AggAALAcAQQAAFiOAAIAACxHAAEAAJYjgAAAAMsRQAAAgOUIIAAAwHIEEAAAYDkCCAAAsBwBBAAAWI4AAgAALEcAAQAAliOAAAAAyxFAAACA5QggAADAcgQQAABguagPIO9+t0cTPtoQ6WIAABBVoj6ATP5ki+b/uDfSxQAAIKpEfQABAADWI4AAAADLEUAAAIDlCCAAAMByBBAAAGA5AggAALAcAQQAAFiOAAIAACxHAAEAAJYjgAAAAMsRQAAAgOUIIAAAwHIEEAAAYDkCCAAAsBwBBAAAWI4AAgAALEcAAQAAliOAAAAAyxFAAACA5QggAADAcgQQAABgOQIIAACwHAEEAABYjgACAAAsRwABAACWI4AAAADLEUAAAIDlCCAAAMByBBAAAGA5AggAALAcAQQAAFiOAAIAACxHAAEAAJYjgAAAAMsRQAAAgOUIIAAAwHIEEAAAYDkCCAAAsBwBBAAAWC6qA8iJs/mRLgIAAFEpqgNIkWFEuggAAESlqA4gAAAgMgggAADAcgQQAABgOQIIAACwHAEEAABYjgACAAAsF9UBhEG4AABERlQHEAAAEBkEEAAAYLmoDiC2SBcAAIAoFdUBBAAARAYBBAAAWI4AAgAALEcAAQAAliOAlFiwcZ/+sy4r0sUAACAqxEW6AJHkPBHZQ3PWS5Ju6dUyMoUBACCKUAMCAAAsRwABAACWi+oAwkRkAABERlQHEAAAEBkEEAAAYLmAA8iOHTvUv39/paSkqHfv3tq6davpfrNmzVJycrLatm2rsWPHKj8/X5K0evVqpaamKjU1VZ07d9b48eOVm5sbmqsAAAAVSsABZPz48Ro3bpzS0tI0ceJEjR492mOf3bt3a/LkyVq5cqXS09N14MABzZw5U5LUrVs3rV27Vhs2bNDmzZt18OBBvf766yG7EAAAUHEEFEAOHjyodevWadSoUZKkESNGKCsrS+np6S77zZ07V9ddd52aNm0qm82m++67T3PmzJEk1axZU1WqVJEk5eXl6dy5c7LZ6AYKAEA0CiiAZGVlqVmzZoqLK563zGazKTExUZmZmS77ZWZmqlWrVo7HSUlJLvtkZGSoW7duatiwoerWravf/OY3puebNm2aEhISHF+nT58O+sICYfjfBQAAhIGlnVCTkpK0ceNG5eTkKDc3V/Pnzzfdb8KECcrOznZ8xcfHW1lMAAAQZgEFkJYtW2r//v0qKCiQJBmGoczMTCUmJrrsl5iYqD179jgeZ2RkeOwjSfHx8Ro5cqT+/e9/l6XsAACgggoogDRu3Fg9evTQe++9J0maN2+eEhIS1K5dO5f9RowYoQULFignJ0eGYWj69OkaOXKkJCk9Pd0xIiYvL08ff/yxunbtGsprAQAAFUTATTAzZszQjBkzlJKSoqlTp2r27NmSpDFjxmjBggWSpDZt2ujZZ5/VgAED1K5dOzVq1Ejjx4+XJC1dulTdu3dXt27d1L17dzVp0kSTJ08OwyUFji6wAABEhs0wjHLfFzMhIUHZ2dkhP+6xM3nq/ucvXZ7LmDo85OcBACAa+bp/MxMqAACwHAEEAABYjgACAAAsF9UBpNx3fgEAoJKK6gACAAAiI2oDyMas4+o/9etIFwMAgKgUtQHkhcU/6Xx+UaSLAQBAVIraAAIAACInagOIjXlQAQCImKgNIAAAIHKiNoDYqAABACBiCCAAAMByURtAAABA5BBAAACA5aI2gHgbBZNx+IzFJQEAIPpEbQDx5uEP1ke6CAAAVHpRG0C8dUI9m1dobUEAAIhCURtAAABA5BBAAACA5QggboxIFwAAgChAAAEAAJaL2gBiYypUAAAiJnoDSKQLAABAFIvaAOINwQQAgPCL2gDirQWGTqgAAIRf1AYQAAAQOVEbQGhqAQAgcqI2gAAAgMghgAAAAMtFbQBhHhAAACInagPI0u0HI10EAACiVtQGEAAAEDkEEAAAYDkCCAAAsBwBxI1hMBcqAADhRgABAACWI4AAAADLEUAAAIDlCCAAAMByBBAAAGA5AggAALAcAQQAAFiOAAIAACxHAHHDNGQAAIQfAQQAAFiOAOLGFukCAAAQBQggAADAcgQQAABgOQKIGzqhAgAQfgQQAABgOQIIAACwHAEEAABYjgACAAAsRwABAACWI4AAAADLEUAAAIDlCCAAAMByBBB3zEQGAEDYEUAAAIDlCCAAAMByBBB3tkgXAACAyo8AAgAALEcAcUcnVAAAwo4AAgAALEcAAQAAliOAAAAAyxFAAACA5QggAADAcgQQAABgOQIIAACwHAEEAABYjgDihnnIAAAIPwIIAACwHAEEAABYjgACAAAsRwBxY4t0AQAAiAIEEDd0QgUAIPwIIAAAwHIEEAAAYDkCCAAAsBwBBAAAWI4A4sYw6IYKAEC4EUAAAIDlCCBubDZmAgEAINwIIAAAwHIEEAAAYDkCiBs6oQIAEH4EEAAAYDkCCAAAsBwBBAAAWI4A4ibjyNlIFwEAgEqPAAIAACxHAAEAAJYjgAAAAMsFHEB27Nih/v37KyUlRb1799bWrVtN95s1a5aSk5PVtm1bjR07Vvn5+ZKkpUuXqk+fPurUqZM6d+6sxx57TEVFRaG5CgAAUKEEHEDGjx+vcePGKS0tTRMnTtTo0aM99tm9e7cmT56slStXKj09XQcOHNDMmTMlSRdddJE++OADbdu2TT/88INWrVqld955J2QXAgAAKo6AAsjBgwe1bt06jRo1SpI0YsQIZWVlKT093WW/uXPn6rrrrlPTpk1ls9l03333ac6cOZKk7t27q02bNpKk6tWrKzU1VRkZGSG8FAAAUFEEFECysrLUrFkzxcXFSSpeMTYxMVGZmZku+2VmZqpVq1aOx0lJSR77SFJOTo7mzp2ra665xvR806ZNU0JCguPr9OnTAV8QAAAo/yzvhHry5Elde+21euyxx9SrVy/TfSZMmKDs7GzHV3x8vMWlBAAA4RRQAGnZsqX279+vgoICScULtmVmZioxMdFlv8TERO3Zs8fxOCMjw2WfU6dOadiwYbr++us1YcKEUJQfAABUQAEFkMaNG6tHjx567733JEnz5s1TQkKC2rVr57LfiBEjtGDBAuXk5MgwDE2fPl0jR46UJJ0+fVrDhg3TsGHDNGnSpBBfBgAAqEgCboKZMWOGZsyYoZSUFE2dOlWzZ8+WJI0ZM0YLFiyQJLVp00bPPvusBgwYoHbt2qlRo0YaP368JOnVV1/VmjVrNH/+fKWmpio1NVXPPfdcGC4JAACUdzbDMIxIF8KfhIQEZWdnh/SYSY8v9LotY+rwkJ4LAIBo5Ov+zUyoAADAcgQQAABgOQIIAACwHAEEAABYjgACAAAsRwABAACWI4AAAADLEUB8OH42TxVgmhQAACocAogXP+ecUuqfvtQLi7dHuigAAFQ6BBAvNmYflyS9u3qPnz0BAECwCCAAAMByBBAAAGA5Aog39D0FACBsCCB+2GyRLgEAAJUPAQQAAFiOAAIAACxHAAEAAJYjgAAAAMsRQAAAgOUIIF4YjMMFACBsCCB+MAoXAIDQI4AAAADLEUC8sFH3AQBA2BBAvKAPCAAA4UMAAQAAliOAAAAAyxFAvDBogQEAIGwIICZ2Hjrt+N7GcrgAAIQcAcTEFdOWy547DKpCAAAIOQKICTIHAADhRQDxwh5CaIIBACD0CCAAAMByBBAAAGA5AogXR87kRboIAABUWgQQL176/GdJrIYLAEA4EED8YEAMAAChRwABAACWI4D4QRMMAAChRwABAACWI4AAAADLEUAAAIDlCCD+0AkEAICQI4D4wzhcAABCjgACAAAsRwDxhyYYAABCjgDix6nzBTqbVxDpYgAAUKkQQAJw9asrI10EAAAqFQJIADKOnI10EQAAqFQIIAAAwHJRG0A+fXCgrujYJNLFAAAgKkVtAOmSUFd3XNIy0sUAACAqRW0AAQAAkUMAAQAAliOAAAAAyxFAAvTcwm1auv1ApIsBAEClQAAJ0L9W7tav3loX6WIAAFApEECCZBiGZn+7Wz/sORrpogAAUGHFRboAFc3WfSf17KfbJEkZU4dHuDQAAFRM1IAEKb+wKNJFAACgwiOABGnNbppeAAAoKwJIkF5YvD3SRQAAoMIjgAAAAMtFdQCpHhdbptefOJsfopIAABBdojqA9G3ToEyvzy0oDFFJAACILlEdQGJibJEuAgAAUSmqA0hZFRqGx3OHT+dq0ItLtXLHoQiUCACAioEAUgYr0jxDxmcb9ynr6DlN+GhjBEoEAEDFQAApg3N59AEBAKA0CCBl8EzJlOwAACA4BJAyyi0o1Lfph1VU5NofxKR7CAAAKEEAKaOXP/9Zd77xveb+mB3pogAAUGEQQMpo3Z5jkqS0nFMRLgkAABUHAaSM7E0tp84XaNu+k47nbUwxAgCAVwSQEmMHtS7T6z9cl6WrX1upE+cKJNEHBAAAXwggJZ4c3ikkxzmdy/owAAD4QwApow1Zx10e22h7AQDALwJIiBklbS/n8goiXBIAAMovAkiYnGGWVAAAvCKAhNi/Vu6OdBEAACj3CCAAAMByBBAAAGA5AggAALAcAQQAAFiOAAIAACxHAAEAAJYjgIRRXkGRY2IyAABwQVykCxBp3//xchUWhSckpExarOu6Nddrt3cPy/EBAKioor4GpEmd6mper0bYjr9g476wHRsAgIoq6gMIAACwHgEEAABYjgACAAAsRwABAACWI4AAAADLEUAAAIDlAg4gO3bsUP/+/ZWSkqLevXtr69atpvvNmjVLycnJatu2rcaOHav8/HxJUkZGhoYMGaK6desqNTU1NKUHAAAVUsABZPz48Ro3bpzS0tI0ceJEjR492mOf3bt3a/LkyVq5cqXS09N14MABzZw5U5JUp04dTZkyRe+//37ICl9RnDqfH+kiAABQrgQUQA4ePKh169Zp1KhRkqQRI0YoKytL6enpLvvNnTtX1113nZo2bSqbzab77rtPc+bMkSTVr19fAwcOVK1atUJ8CeXf1MXbI10EAADKlYACSFZWlpo1a6a4uOKZ2202mxITE5WZmemyX2Zmplq1auV4nJSU5LFPIKZNm6aEhATH1+nTp4M+Rnmy/8T5SBcBAIBypVx2Qp0wYYKys7MdX/Hx8ZEuUpkcPEUAAQDAWUABpGXLltq/f78KCgokSYZhKDMzU4mJiS77JSYmas+ePY7HGRkZHvtEoy17T2pF2qFIFwMAgHIjoADSuHFj9ejRQ++9954kad68eUpISFC7du1c9hsxYoQWLFignJwcGYah6dOna+TIkaEvdQV095trIl0EAADKjYCbYGbMmKEZM2YoJSVFU6dO1ezZsyVJY8aM0YIFCyRJbdq00bPPPqsBAwaoXbt2atSokcaPHy9JOnv2rBISEnTLLbdo27ZtSkhI0BNPPBGGSyq9HycPVc2qsZEuBgAAlZ7NMAwj0oXwJyEhQdnZ2Zaca+i05dpxMDydXjOmDg/LcQEAKI983b/LZSfUSLLZIl0CAAAqPwIIAACwHAEEAABYjgDiJpw9Yl5csl2FReW+yw0AAGFHALHQ68t26outOZEuBgAAEUcAcRPuTqhn8grDewIAACoAAoib8j8oGQCAio8AYrEnP94c6SIAABBxBBA34W6CyS0oCu8JAACoAAggbmiCAQAg/AggAADAcgQQN0zFDgBA+BFA3NAEAwBA+BFAypG8giIdPHU+0sUAACDsCCDlyC3TV6nPc1/rfD6TlQEAKjcCSDmyMfuEJOnd1Xu0NuNohEsDAED4EEAiYOeh0z63P7foJ90yfbVFpQEAwHoEEDddE+qF/RxDpy2XJJ3JLdA51oYBAEQhAoibP9/QOeznKDKks3kF6vz05+r41JKwnw8AgPKGAOKmZtU4S85zzWv/s+Q8AACURwSQCNl1+EykiwAAQMQQQILw4KXtwnLcqYu3m/YFYTguAKCyIoD4Me3Wbo7vH/1l+7CcY/rynXpndYbH8zsO+B4tAwBARUUA8aNZ3RqWnOfU+QJLzgMAQHlAACkniliEBgAQRQgg5Rgr8wIAKisCSDnx+rKdkS4CAACWIYCY+O8DAyJdBAAAKjUCiIn2TWs7vjfku2/GFR0bh7s4AABUOgQQE8H0B72he4vwFQQAgEqKAGLCV63HZ78dqD5J9R2PY+kpCgBA0AggJqrFxUqS7rgk0WPbxS3qauqILlYXCQCASoUAYiI2xqbdL1yt5280DxptGsU7vneuK1n6+8Fq06hWmEsHAEDFRwDxwlaKppVqVWJ1cfO6ISxDyA4FAEC5QgApI+eM0KBWVcUQGgAA8IsAEkLVq8QqJoTVFr/594/6aG1WyI4HAEB5QQAppX5tGkiSmtatrkUPDdKyR4eE/Bx7jpzVY/M2hfy4AABEWlykC1DetW9SPCnZ/UPaujw/8+6e2ph1Qt0TL4pEsQAAqNAIIH40iK+m9OeuUlysa2VR7epVNDC5oecL6AMCAIBfNMEEwD18WC23oFB//SpN23NORrQcAACECgEkxGxhqAJpP2mJ/vrVDl396kpJkmEYyi8skiT9sOeYtu47EfJzAgAQTgSQCqSoZNazW6avVvKTiyVJI/65SsNf+18ESwUAQPAIICGW0iTe/05ltG7PsbCfAwCAcCKAhNiYQW0iXQQAAMo9AkiIxcbYNPOunpEuBgAA5RoBJAya1Kke6SIAAFCuEUDCoFvLenrr3t6RLgYAAOUWASRMhrRvHJbjPs7U7ACASoAAUsF8UIrF6aZ98bOWbMkJQ2kAACgdpmKPAq8tTZckZUwdHuGSAABQjBqQMBrepVmkiwAAQLlEAAmjf9zZI9JFAACgXCKAhNkfftnekvMcPHVec9ZkyjCMMh/LMAydzy8MQakAADBHAAmzBy5tZ8l5xr7zg56Yv1nL0g753XfPkTM6fjbP6/aHPtigDpOX6FweIQQAEB50Qq0kftp/UpJ07Eyetu07qUa1q+mzTft01iREDH5pmarGxijtuatMj/Xpxn3FxzqbpxpVa0iSTp3PV3y1ONlsoV/tFwAQfQggFdiqnYdNn7/6tZV+X5tXWOR3H3tjTtbRsxr04jca3T9Jz1zXOZgiAgBgiiaYCuyOf30f9Gv+t8M8tPhir115a1VG0K8FAMAMAaSSyCvwX6MhSRuyjoW5JAAA+EcAqWQWbfY94yl9OAAA5QEBpJL56qcDkS4CAAB+EUAsMPe+fpEugl8bs46rw+TF2pR93PFcKOYUAQDADAHEAr2S6ke6CJKk0bPXeO0r8s9lO3U+v0gzVuzy2EYMAQCEGsNwo8iynw/p9PkC020GMQMAYCFqQKKMvz6oZpvptgoACDVqQKLM2gzXYbgHT53X26sydC7f+zBe6kYAAKFGAIlyI2d8p12Hz5huow8qACBcaIKJYifO5XsNH87cm2A+XJupH/a41qQUFZFWAACBI4BEsbtmBTaVu3u0mDhvs0b8c5Xj8cfrs9Xmj4u0bd/JEJYOAFCZEUCi2KbsEx7PlWam1Ne/2SlJ+nyr71lYAQCwI4DAL0bBAABCjQACv+jdAQAINQIIXBQU+l5Vl2YWAEAoEEDgYvEWz4Dh3AQz/t0fvL52+vKdYSgRAKAyIoDAK/s8ICt2HPK5n73fam5Bkc7mFWhj1nFd9epK5Zw4H+YS+lfI8GAAKJcIIBE2tFOTSBfBr/e+ywx43xibTRPnbdJP+0/q3e8ywleoADzw7x/V9o+LIloGAIA5AkgEDUpuqDsvSYx0MSqthZv3R7oIAAAvmIo9wkoz74ZV/v7NDnVNqOd3P5tTL5Hb//Wd6fORZBhGuf45A0A0ogYkgu7ulxTpIvj00bpsTfpkS1CvWZ95PCTnPpNbYPr8sTN5GvLSN/rm54MhOQ8AIDIIIBEwaXhHfTVhsIZ2alJO6ghKr6CwSOcLCk23GaWcQWTmip3q/PTnWp95zGPbF9tylHHkrO5/7wevIcWjHPRDBYByhwBikcUPD9K13ZpLkq7r1lztGsdHuEShMfilZdpz5Kzptn98s1Nf/3Qg6GO++90eSdKqnUe87nM+v0idn/48oOORPwCg/CGAWKRjszr62+3dlTblKjWuU93xfEXumvDh2kztPX7O5z7/WrnL5fGJc/l669vd+m6X93BhV5F/NgAA3+iEarGqca6Zr7x01CyNifM2B/2ax+Zu1Odbi2tFNj51perWrOKxT6ibTAzDECvaAED5Qg1IhNWsFhvpIlhq676Tju/P5pv34bAHkIoczgAAvhFAIqx7S//DXCuLvIIiVYm98CtXZEiPfLBeq7309dhx4FSpznPg5Hl9uPbC5Gn0AQGA8ocAEmGVfX6K73Yd1frMYzqXV6iUSYu1+/AZx7b3vtujTzbsc5k7xNn89Xt19EyeVqUf1itf/CwpsFqRu2Z9X6rmIQCAdQggCLsbX1+lBRv3ejz/rxWuHVS355zUfze47nf0TJ7ueON7/W1pus7meTbZTJy7yeO5tAOnXR479yn5bNM+LWMOEQCIOAIILGFWI1Ho1tt02F9X6uEPNii/sOjCPn4Wk/twXZbfczvPR/Lg++s1evZaSVJROV6orjyXDQBCgQBSDrVpVCvSRSiT7TmB9d3wNtrF+WnnMOLLmdwCv0OCne0+fEZt/rhI767OCPg1UnE/lkCczSvQg+//qJ/2n/S/s5vsY2fV5o+L9IbbEGYAqEwIIOXQCzd2iXQRLHfkdG6ZXj/k5WUaMHWp6bYzuZ4zta7ccUiS9H9f7Qj4HIdO5Spl0mL9+bNtfved9+NefbZpv3791tqAj2+3ZvdRSdKLS34O+rVllVtQqMNlfC8AIBAEkHIoGivf12ZcmHbda82Il+d7/vlLHTrl/ab5kY9mGiOISUd2HCyu2Zn1v91+9y0oqbnJC7AGJxwKSnHuq19dqV5TvgpDaQDAFQEE5YJzXw/nUODcYdRbVDhyJi/gYwdryZb9Wptx1HcBfLJulNOBk+e1rWSelYMnz6vdk4s17YvAalFOnM3XK1/8rJ2HzvjfGQBCgABSAdw7IEm1q1XuSWsfeP9Hx/fOnVNf/iLN8b1hGKW6n5vVcsxZ47/zqiTd996PumX6aknFw4IDP2fAu4bMJc9/ratfWylJ2rLvhCTptaXpAb126pLt+luA+wJAKBBAKoCnr+2sdk0qx+J1gfDW0fP42Xy/r801WZm3wKQGJNjOoVv2ntDcH7KDeo3kuZ5N2oFTHkONvSntasKlUdY+OAAQLAJIOTd2UGtJcplBtLI7m+cZIiRp0Ivf+H3tV9s85/j461c7lPT4QmV6WbU3ECfOuYafJz8uHlb8vx2H1faPi5R+MLCRP1f+3wo9/MEGnc83v0Yp/IvwpR04pY6Tlzg6u4ZLfmGR6dwtACAFEUB27Nih/v37KyUlRb1799bWrVtN95s1a5aSk5PVtm1bjR07Vvn5+QFti2bxPppXnhzeSZL0+FUdrCpOufaYycRjzgqKvHe8/MPcjX6Pfy6vUMfPFvcp8dV35N/fF0/1/tLn21VYZOjDtVk6l1eoXlO+1L+/3+P3PEVObTTuYSRczTfrMo7q/e8z9faqDJ3LL9S0L733Dwmmc643Q15apk5PfV7m45TV1n0nAh7ODcA6AQeQ8ePHa9y4cUpLS9PEiRM1evRoj312796tyZMna+XKlUpPT9eBAwc0c+ZMv9ui3donr9B3T1zuc5/E+jUd34/okRDuIlVKgYxI6TXlS6X+6UtN+GiD2v5xkeN5b/fjjdknHN9vzzmpw6fz9OTHWxyNJ4dO5erkee9Be8pn29Rh8hLlnDgf0DWUxc3TV+uPH29WbExxFUu45zoLZl6WcFm6/YCGv/Y//elT/0Ony6v0g6d91pgBFVVAAeTgwYNat26dRo0aJUkaMWKEsrKylJ7u2mlt7ty5uu6669S0aVPZbDbdd999mjNnjt9t0a5G1VjVM1mW3lnD+GqacsPF+vyRX1hUqsrHrGXj2Nl89X3+a/19afF8IGdKmn/m/+jaT6PIT42AzWbz2kdlwofea17eKBnS+7PTwnvBNsFkHD6jLXsvBKF1GUd9rpkTU3KCUNRyBKKoyIjIzK7n8gr1q7fWSZKWbq+Y0+9nHT2rK6Yt19h31kW6KEDIBTS0IisrS82aNVNcXPHuNptNiYmJyszMVLt27Rz7ZWZmqlWrVo7HSUlJyszM9LvN3bRp0zRt2jTH49OnT5vuF21G9S3++VnZObGi8bayriT9mHnc9Pmck+f18hdp6tS8jtfXBvITn758p+nzX/10wOM594Dg/CjQXLDv+Dk9+fFmffPzIZfnb56+Wm+O7uX39b6amAwjdH1R2j25SEWGlDF1eGgOGKAjZyp+x9rsY8W1SCt3HI5wSYDQK5c9GydMmKDs7GzHV3x89IwACQj5w6sP1gY2vNaM/dOymUBqC4LpZxCKm/uLS7Z7hI9A2GtzQlkp4WuKevt59hxhjhEAFwQUQFq2bKn9+/eroKC4R7thGMrMzFRiYqLLfomJidqz50IHvIyMDMc+vrYhOMlNake6CFHH37165opdLiNlgm3e+F/6Ya3aWfwp1z2cfL/riJIeX6i3V2Vo9+ELN/FCH6cocNv4xdYcx/f+mpOCdfDkeaVMWqypi7c7nnMfNSRJp0hutuYAACAASURBVM5XnBExWUfPatqXaaWaTVYqfv+nffGztu474X9nC2UeOau/LNlOp1yUCwEFkMaNG6tHjx567733JEnz5s1TQkKCS/OLVNw3ZMGCBcrJyZFhGJo+fbpGjhzpdxuk6lViNWFoit4fe4nffW/q0cKCEsGFyT37qNsMrM6ziPpqCpKk8e/+oIOnLnQ8nblil+741/em+87+NkOS9PSCrbr05WWO531VojhPKjZx7iaNe/cHj32cL8k99AQTUezT6Ds3QV311xVBHCEw23NO6tH/bDSd6yXU7n1rrV77eocWb8nxv7OJbftP6rWl6Rr+2v/KVI5QN7eOfmuN/rlspxZt3q+/L92h5xf9FNLjh1LagVM6cDL8nbMROQE3wcyYMUMzZsxQSkqKpk6dqtmzZ0uSxowZowULFkiS2rRpo2effVYDBgxQu3bt1KhRI40fP97vNhR76PJk9W/b0O9+1k3uDTuzG8G9Phaa27TX9yff5WmH9FeThfB2OHVGzfdVxeHHZqfzf+i2Fk4wFSA5J847anO255zU4/M2eTS3/HbOjx6v22cyqqesFS+j3lijuT9ka9Hm/WU7UIlv0w97hEi7/SUjeEo7j0lugKsm+xXi5tZDJ4v7xZzNK9TLX6Rp5grzFZet6qDsy5X/t0KXPP91pIsRdgs27lPbPy7SwSgMWwHP792+fXutXr3a4/k33njD5fHYsWM1duxY02P42oYLLqpZVZKU1KCm+Q4kEMtNX+b5j3pjlnmnVimwf+Dvf+/ZCfvON753qY14IUKfUA3D0Nc/HdSv316nJ67qoPGD2+r2md/p2Nl8DUxuqGu6Nnfsa9UAlzO5xWEgv6DsJ8w6elZ3vvG92jSspaWPDvG6X2nvw95et3LHIdWoEqteSfUDOs6pXN8BaM3uo/p6+wE9PqyDbCHqNXziXL66PfuFHrkiWY9ckRKSY8K7J+ZtUmGRoWVph3Rrr5aRLo6lymUn1GjXvmltTR/VUx/d1890e6P4ahrZu6UGJfuvLbFb+NDAUBUvKq3JCG7WUPcRJuszj6nL0/4n5Tp4KlcHTl4YvTFjxS6PPhv29vsy32+cjvvFNs+ROvZmpPdKJlaz9+Fw7j/wpdvrfM2uWtbmBPv12o/zyfq9Xqvo/QVAe83HrsPmHWPtN/NQZ6u7Zq3RzdM9P8h5M96k6czZrTNWa8byXdpvWuNkaMmW/ab9cXyx18KZ1dCFy4SPNqj/C+a1HbkFhRrz9lp9t8t3syYqHgJIOTXs4qZqXLu66TabzaapI7rq3V/77y9i1zC+WqiKhgAcc5sT5MbXV/n9NOuNezjY4qd5J1DON1df9+uso+eU8uRilzV1zuYV6LWvd3jMT7H7sO8h874mZfPHOW9tzj6hRz7coNtmeN7Mz+cXqvUTizTls9LXHpXnSsaso2f16H826oTT75hZx+JlPx/Sfe/9qIc/WO94ztvbXFBYpL8s2e7SydlK83/ca9psJ0kr0w7rq58OauTM7ywuFcKNABIl4mJsjnVlULGdyS3UpmzvzT/+BPKpftSs77Xj4IUw4TyLrGFILyzarmlfppm91KsNWcfV9Zkv9MT8zZq6eLvPobtmHLUShnT8XHENRobJ+j6HThXXIC1xGvljrxGZ/e1uvbhku8drQi+4upPCIkMbso4HNGHbxHmbNPeHbM1ceaHTr1nzy74Txf1YNpg0Fbrv/dVPB/XPZTs16g3zjtBAOBBAKolpt3bT8K7N9JshbU23V42LUfum3ifaQsUxatb3uu7v3zomqQqH73Yd1fI08zlGFm/J0Y4AF99zZm/SmbMmU9OX79TH6wNfXfib7Qd1uqQGKe3AaZ8zvfry7Kfb9Poy8wnjImn68p264R/fas5a88kZndln6z2ffyHAzfk+U59t2hfw+dxjjn2qd3t4C0ZRkaFt+06qqMiQYRh6fN4mx5DycFm8eb+SHl+oj8ow7483uw6ddhmhhvAhgFQSN/VI0D/u6KEHL2unKzs1cTz/6shUvXBTF9Wu7nuqd1Q8pblZOCttB8svtx3Qd7uCX0nXvZ/Cmdzim97h07n61VtrlfT4QiU9vtC0/4bziKM3v93tsu10KZu27M7mFeh79/4F9v4mIeyE6ly74b4ys73vjK+OzZe/skz/3bDXNHr9/Zt0Pfj+epMtF6zLOOr1ZxVo/5zsY2e1Kt01XLz57W5d/dpKzVy5SzsPndEHa7O8Dil3V1hk6IXFwTeV3f/v4pFXj81zXZzyTG6BlqcdkmEYpR7Jc9kry9XnOf+jb3YeOq0nP94cunV6DGlF2qEy/z5XJASQSqZm1TjNvPvCNNydmtXR7X18T/j2t9u7h7tYCIOydkI1ZGhz9glLFsKTPJsC7OWfuWKXy1otvqaIt3OeZn3yJ1v03w17NeGjDTp5Pj/on8tDczbotpnfaW2QHY2D8cyCrWrjtLjhL176Juhj7Dx0Rg9/sMHx2LmJzF1eQZFHc85HTsOxn5i/2fH9ki37dS4vsOawgX/5Rne88b1jgra8giJNWVgcIIonogvupr90+0HNWG4+FLg0fv/RRt3z5hr9ZcnPav3EIr/vqWEYWrBxn0t/mkCNeXud/v19pj5Zv9f/zgFYveuI7n5zjR6e4ztIViYBD8NF+TT1pi7KKeP48Wu7Nddvo+iXPtrZh/9u2XtS1/69bBNluZs4b7NWpAVX/e6tJqewyNBflmzXzT09V392vhF/vH6vPi65CbSqX0s39wputegVJU1NWUfPqnb1OE34cGNQs7aeyS1QtbgYxcVe+Dznfht+a1VGQMfKLSjSwk37NbRTE1WN8/35cIVJE1l+YZFe+3qHy0R0dt6are5778cLi2EGGN7s15cyabHHWdwtTzukjk1rq3Edz071gdQeeFtjyV3W0bOOfj/217z33R719jHk+fOtB/TQnPUa0r6R3rq3T0DnsbOPLgpklW1f7D/LrKPFtWLRNNqHGpAKbmSfxIDH6g9p3yjMpYGVyutIjYUBThT27KfbNPmTLY7wYLdt/0lJ0qqdhzVzxS6N+OeqgM+dV2h+QzuTV+i1Xb+wpKp+wkcbNeyvKx3nD1Tnpz/XL0s58+uhU7n606fbHKOD/rthnx54/0fN+t9ur9PA+6rhuefNNabhwx9vKznvP2Hez8hbEdzLdvDked3z5hpd/drKoMtkt27PMcf3vmrHBr0YfK1STsn1mY0sW595TPfOXqO9x8/p4/XZHk064ZqszddRV6QdUtLjC10mLHT3+rJ0rc+88DM7dCpXN73+rcs1vvm/3Xrqv1tCUdwyIYBUcs7/EBrGV1PG1OH67onLI1cghIzZCJCK5t3v9ng8d93fv5Uk5ZZ0sgymNsImm0cfBan406q3dn2fqwI73Q7yC4u0dPsBJT2+UAs3uYYs52n4A7Vq52H9+bNtevPb3VrvtlLzos379b2POVW8HzO0n577vbBUUvGNz7nZxhv3YGIfen749IUZZ0u7vo4k9ZzyZalfu+zngzpxLl8/Zh4LaDr/G19fpW9+PqQBU5fqdx9u1Dc/HzTdL1QfBAJpOnz5i58luTanOTt2Jk8vLvlZN76+SnuPn1PS4wt14+vf6sfM43r0Pxsd+/3ps216Z7Xn357VCCBRqGndC1WhNavG+t2/VtVYXdetud/9gFD5ymRitEDsPHRaf5i7ye9+gXbgNYziTrKSdPWrKx0rJj/w/o+mN9IFG/fpifmbAppP445/fa9jZ82ngt+894Tuf898ErJgb3j5Jv1BvPF27LvfXKM5a1xH6JjVAFz7N99Nej/tP6l2Ty7Wv783v/kVFhl697s9OnLa/P0xq6k5n1+oBRvNRwD9d0Px8z/sOarRs9eq27Nf6KbXV+mpT7bqhz1H9fIXxUPJA1n2IOeEeZkOnsrVwL8sNQ2+ZrwtBGhfU6ksnOfZsferso+W255zqlR9XcKJAFJJ3XlJccfTpnVr+Nzvrn6t/B4rqWGtkCwfDwRqzDvr9Nevg5tnRFLAi8c5T87ly7Qv09RrylfF1d5unT5vfN2zaeihOes1Z02WHgsgBEnSyh3eb1onvdT8OM+UG4gzeYUa+n/Lg3qNP4aKh4ObncsXey2Ct46nn27cp8mfbPE7osdZh8lL9JCfPmz7jrs2vy1PO6QR/1ztGHFy4ly+iooMr01OkvdVpN9ZvUfZx87psXmbdDavQG99u1vpJh2ET+cWKOnxhUp+crHXGgxfnAPfv1bu1qRPLtRIHTqVK8MwNPilZY7nJn/i2cTyoMm6TZFEAKmknruxi3Y8d5Xiq/nuZ1za+RSAcNuyN7i+GMHwd6O087ZYneS64J/kfwXkUNl7PPj5XwJtIgr0g0aRYejbdN/Xe+p8vtf/Lt6G/T7yYXHn4vRDvmfUDcaa3Uf11U/+a9QKigxHk5MZbwHE3hk1+9g53T1rjZ75dJuumLZcaU79NP65rHieF7upi7cHNXz32/TDav3EIm3KvvA79953xTVSl7+yTL2f+yqg+W3MJqWLJAJIJVYl1v/bG8g/HGo/AP9u/5f5VOFmn4YjIZC/Y+fJzXxZsMH/pGddnvnCZfp+6cIHnqyjvkNUKP/l3DpjtaMpxs4sAPmbC2X1ziMa8/Zanc8v1G/nrPdYbkFy7TC748CF9/0vS7a7/B4cPZPn6FwdyLXO/jbD6zZ7uHzp858DOJLUtxytMMww3Cjnr4bEbsLQFGUcPqPEBrX0qZf2ViDamK1F4+7ON8rHGiYfBDhrqPunZLO+Hmk+RmE4m+02aVxh0YWAc8rHukBWrbDs7Fs/fTjszXtvrcoI6H+gPdCYrXotSVv3mdfwBTO45oc9wXVUPnW+wKVT97m8QtUIoB9guFADEuXuHZDk8vinPw0z3a9Vg1r674MD1aZhLQtKBVQMgYxUCbbPRqTZJxYLhTlrLoSe5WmHXNbn6fLMF1q8xduQbe934ZU7zJcICIbZTd7ewdif4gnXAudvyYGyZK0R/wx8ZWUz+UVlm8OkrAggUa5m1eIakLaNaqlqXIxpGnbuJ+L+x/LCTV3CWTwAEWY20ZZzU0Og7nlzjUe/nkA7DTu7a9aaoF8TCWdLlhrw1c9uzppMj0UZCw3DY3bi07nla/RKqNAEA0nSl78b7LWTlYswTb4DoHxqP2mJx3Pu85aUlrd/J87zhlRUj83bpOpVY3128jCbWyWvoEh9X/hawzo31ai+rdSsXvVSrb0UiLnrsrUs7ZDevre36YrK4UYNSJQa/4s2Sqxf0/E4JsbmMpW0M+ffS+f/F3+9LdXxfe0A+5IAQKRZ9THqoTnrS92hdsnWHI2a9b3plPuh8qfPtmlF2iGdPBeZBfAIIFHqias7asVjlwa074geF9bWsH9i6disjm7o3iIcRQOASqOsFQtvB7iOUEVEAIFPm565Uvf0T3I8Tm4SL0m6pLXnAk+7nr/aqmIBQKkFOhNuKJR1htPKsOSCNwQQeHjx5q6O7+tUr+Ky7dquzfXBuL564uoOHq+LiWHCEABw5mutofJie074Jv3zhQACD7f2aul1W0yMTX3bNFC1OP9jxwclN1SVWJsWPjQwlMUDAITQA0FMfR9K9ByEqU3PXOkxPCxY7/76EhUVGYqJsemG1Ob6JIDZEwEA1gpoBGQYUAMCU3WqV1HD+GplPo69Web/bktlpAwAwIEAAkvYbDbHJGcdm9VRwkWuq/TWrk44AYBoQgBBSDnPDeLu9j6JkqSpN3XxqF25vEPjsJYLAGDObL0fK/CxEyF1Q/cWuqRNfY+phCXpkSuSde+AJNWrWdXx3BUdm6hqnE2PXJESUB+Rv93eXb//z8Yy908BABSL1DgdakBQJvVqFA/TTXJapK5Z3RrqnniRx742m80lfEhSYv2aev3Oni6v96VujSp6yWmYMACgbCK1wgYBBGVyZeemmjS8o964p1dQrxuc0kiSlJpYz/Hcdd2a65LW9fXBuL6mE53ZXZ/aQluf/aXG/6JN6QoNAHCI1CgYmmBQJrExNo0ZFHwQeOjyZA27uKk6NK3teO6127s7vk9NrKfvdx9Vg1pVdeSM58JUtarFaVByI81YscvneR4b1l4vLvk56PIBQNSgBgTRJDbGpo7N6nhdgXHC0BS9dW9v3XFJosvzzrv3bu3ZzOMuxs9CDHPG9lWLehdG5DxwaVu/xwSAyuRULovRAQ7V4mI1pH1jjwDRvkltl338iXeae+TFEZ59R1KaxOvbxy9zPO7bpoHqhGlI8As3dVGVWKarBwCJAIIKpnGd6gHtN7xLM00c1kGDkhs6nuuZ5FljYlZDsubJK0yP2bFZnQBLae72Pom6fzA1LAAgEUBQybSsX9ycklC/hu4f0tZvE0yVONc/AZtsql7lQs1KoBOkBbrkdlmbWkc7rUx8aftGAb/uLyO6lPHMABBaBBCUa/5u2L8e2Nrl8cs3d1PD+Kq6o0+il1e4ql4SQOxBo0ZV1z+J/0280DxjzxhjB7meU5JeuNGaG7xzoPrt5ckBvea127vrtt6B/TwAwCoEEFQYZmvJTL6mk3a/cLXj8SVtGmjdpKFq1cD/vCIr/nCp4mKL/wQ+eWCAHr0yRT3c5i+pW6OKRvVNVGrLerq9T/EqwZd3bOJxrA7N6rg094RLjM35+wsPnENR/7YNXF5T323uFQAoDxiGiwqhce1qWvHYpabbvI2k8SexQU3H920bxevBy1xrFFqVbJ9yw4XajRE9E1SzapyqxsV4zMb6jzt7qOszX0iSurWsp41ZxyUVh4PhXZtLki4qCQPJjeO14+DpgMvapUVdbd57Qu0ax5tuf3J4J/VsVV+1qsUq58R5rdp5JOBjh8Obo3vpV2+ti2gZAJRv1ICgfCuZIKdujSoufTPc/e6KFA3r3NTjeeds4jzXzp2X+G6S2PDUUH35u8Eez9esWpzZ103y7Khap3oVjRno2Tzz5PBOSm1ZPOHaHZck6tErU/T+2L4+z+/uqWs7adY9vXRLr5Ze9xl2cVMNSm6kW3q11NZnf+nzeMseHRLU+YMVGxP4v5Znru3kdduLEZ71dvMzV0b0/L50d5rED6iICCCoEPxVcjx8RbKm39Uz4OM956fPRr2aVVU1zvufR53qVfSf+/o5Hpst5lSrqmdgql4lVg9elqxGtS8sxud+nsT6Nd1fpp6JF+nyjk0U69QG476isMu5nZqrjJKeNCN7F4eXhvHlq0nG/Sd374Akx/e39mqpD8YFFtb+PeYS0+edJ7sLVu3qVYLa332RRUm6sXuLUp/fF38drIFANasb2OjCUCOAIGqE+v9176T6mnLDxapfq6o6NPUcovvD5KE+P0HXr1UcBJ64qoPjuT9e3UEf/6a/kpyahy7v0FgxMZ6FN7vZ+WK//vZB3JAfG9be5fHvrkjxuu/Lt3RzfO8cyJybjf7wS9fjFe/r+rh/W9e+NH3buPZpMdO6YS0NaHfhdb8aUFwTFV8tTm0aBbbOkF31Kq7/Fn0tC+BulsmSBDWrxqpbQt2gyhCImiYBFyiNe5xG11mJAIKoERuGT4yj+rbSj5OHqoaX2g5fn6DtN2l7R1hJuq1XohrEV9Og5AtDbId0aOzyutn39taihwYFXdZglntoXvKJKC7Gprd/1UeSNOOunnr4imTd0jPBdCTQzT0TTI/1sNNonTEmrzMkLXkk+Otx5v7WPnVtJ300vp9WPXGZmte9UFMUSO3Ps9d1liRVLXlfRni5LjNdWngGjRibTfeZzP8STM2McxCMjbFpZO+WqlMjuNqZYE0c1sHRDwqVW5zJBxwrEEBQrpV13gznDqqtGtTU/UPa6r8PDCjjUUPDfm0uf/olD+4f0lYdmtbW/UPa6vberv0+Lm3fWJ2aBz8pmr3mo0uLegH/XG2yaXBKI2VMHa5flvSxeemWbnpy+IV+G9v/PExrTSZvs9+M+zjVIDjPXmsfVZTSJF7JjS/cjM2as9w9c20nrXnycr1SUuvS0aQGqk/r+qpTvYp+N/RCrU3VWO//8uw1CjbZ9MOkK7T+qaF+y2E/j51ZxrXZPDtK73z+an04vp/nziqeRM/drwa01hUdi4PoP+7orqkms/qWxWe/HejxXFyMTcv/YN7xuyK4IbV5WI5bw0dftIoqNkIBhFEwqBBsKt0fSHWn/hU2m00Th3Xwsbe17PfZGJtNH4zrq1U7j6huyafa5vVqaMkjvwjp+e7q20pJDWupf9sGOp9XPIKnV6uLtG7PMZf9PvvtQI17J/ARLNWrxJp2EJ4zrq/2HDmjJm6z1y58aKBqVY1T83o1dOclrXRxi7oqKgouao4uaWK5oXsLxcbYdFnHxl73de4P423EVIemtbXnyFnH4wZOzVtXmAy7tnv31300KLmRkh5fqFYNapoeP8Zmc2nW6dC0tmJjbF6bBG/ulaDeSRepZrU4PTZ3k+MY025L1Yq0Q44g6KsPkLOrLm6qxVtyJBWHpTW7j7psH90/SReb1NzYy/f6nT30wuKflHX0nNdz1K1RRSfO5fstyxUdG+urnw4GVO6ySmoYXNNbIDo0ra1pt6bq6tdWhvzYoWb2t+0NNSCAieSStV8CWXjOTIP4anrp5q76akJob+ahYF8CO8ZW3M9hwlDv/StCIS42Rpe2b6xqcbGqW7OKVj1+mcdonBb1apjejMz894EBLisYOzNU3P+ic/PiY827v5+++F3xe9C5eV0lNaylqnExjnM534zttTtmzTzuYmNsuqF7C9UpaeqafW9v/f0O8zJJ3mtXYmNsjs667lm3fq2qmjO2r+nIIXtTWdqUq7T090NKnnPtw3JP/yQNSm6kXw9srZu6t9A7v+7j97pGD2itW51GPNlsxR2fr+na3BFyHr48WfcP8T+1/z/u6OGopakWF+Ox1tEzJU1O3lzdpZm6JriOuHnosnYuj+39mSTvfZPaNqoljx9uKXV16lOTMXW4Zpp0QA8005qNtPq9yd/iv+7upX+PucSl9jFc60Z5s/T3niPzvKlWJfDbu1kfMysQQFCuXdOlmd4fe4kmDfc+VNOfW3q1VLvGpR8JES4DSjpbJoapnf3pkuGtXVuYD9dsXq+G15E+gfzv7taynq7rFlg1d89W9ZXSxPt74FxzkHBRTW370y9dmnkCdWn7xrqmq/cyOZ/nj1e71obZQ0w1k59Jv7YNfH6irhoX46jGdr4ZS8UdZGNjbJp8TSdNuy1VjWtX93oeb8xGvNSsGufSv8auVYOa+v3QFD16ZYomDe+omBibWgcwMV8wnH9vurSoq6suvjAE/r7BbfRRSfNSjSqxjlq90QNa6+ouxfv9akBrTbnhYr/n6eylqdE9R17pNAQ/pUl8yT7+f4vH/6KNS9CzM7shD+3UxKVmTCrueD373t6Ox+N+0cbvOcuiTSPzeYDMxAUxFD7Y0V6hQhMMyrWYGJvHqIjyzL62TCA3l2m3ddPdma3Cdn33Dmitewf4r0VoUKuqjpzJC0sZgmXv/GqfbyVcuifWU782F37ud/drpe6JF2n2txm66mLPPhjBcL7v+Rr9Ui0uVqsev0w2m9TvhaWO51uZDMP29gHVPZdMGt5RN3Zv4XGjLCv3T/rOQe6e/km6qXsLDWnfWMt+PqhRfVupamyMHri0ra5PbaFbZ6x27HtTjwRd1qGx6pVMyDfpky2SikPa7sNnHPv9IqWR3hrdW4/P36St+056lKfIR7iwhzVf+9g9cXVH0+cDCS92l7a/0Pz364GtNXPFLknSxqeuVI2qsfpiW44efH99wMeze3Vkqh7+YIPH878fmqJXvkzz+/qG8dX04bi+OnY2T9WrxOqVL9K0ee8J030HtYvM/1hqQIAQGv+LNro+tbleCmACrZpV49Q/Qn/4zj4c389rJ7RgBw49XjKkuGuAzTjOVj1+mb4Kooq5rJyv+bbeiUppUlsv3NTF5/wvzq/9xx09TLcF05uleb0aala3hubd308z7+qpOWP7mn7K9dZ3xblmJP25qzRmUBvT8GE4lWrGXZ5Dhf35wy87aHT/JPUomfysWd3qqhJrKylD8QeFPq3r67FhHVS9SqxiYmz6wy87KKVJbY0dVFwr0CepuBmontPSAG/c3UspTeI1+RrXINC6QU3FxNj06JXtdXWXph7vSZHhfRSRfcXs+Gql/1Tf3qRTsxn7+/LzlGH6YdIVLv2dalcvnjHZW43cqyNTTZ+vW6OKhrRvZNoZWfKcN8jM8C7NNGl4R13SpoGGXdxMQ9o31qe/Hai0KVd5/K3/4ZftdVGtyMwNRAABQqhezap6dWT3gNaiCYXb+7R0NLWUVrvG8abzc5TGfYPbavcLV5fqE3jzejW81nx8MK6v3g2g70SgDEPq2Ky2RvdP0rz7+wf8ulYNaqpD09ra+fzVGt7V/Abh8uk5wATXs1V9Xdm5qfq19T/niTPno8f5GOHjrF/bBhqcEvhKylJxs9Iz13XWm6N768URXXV9auCTqz1waTtt//Mw0/lnrujURF/8brBHE4D9xt64TnW9fmdPR82YnWEYWvTQIO147iqPY758c1f9Zkhbl5WjA51Rd8zA1vr4N/11RcfGHmsq+VItLtbjd975rf/4N/0dc9NI0kU1q3j9GV7ZqYneurePx/v519vMA4uZx6/qYBoqqsbFeMwfc3e/VgEfN9QIIEAF9sJNXQNqZrFSadfm8aVvmwYalNxIjWtXC6rvhDt70QwVl/OZ6zqrZ6vAOzgve3SIFj8c+JwlwUxiZublW7p5nV9FKv1sqO6TrTk/17hkll6z97Fezaq6tXdLxcbY9NuStZPcF3A0P5/voav+rsK9LAPbNVRMjE1VTEJX4zrV9diwDi5z87RrHK+W9b2PGlr6+8G6qXsLTbyqg7onXiSbzeZ1Zl1/7DUMzmXunniRnrq2k/50vXmH30Amyxvgo7a0a0JdLXhwgOP3u7avzrFuVXSR6v8h0QcEQAWy+onLA2rb96Z5JNieMQAACxZJREFU3RrKPnZObUs5RDOQcJVUUvvVO+kiPXpl2WqWbu6Z4DOABJo/7J+m7Tfsp67trG37T+pP11/oCLrhqStVWGRoyMvLAjrmQ5cna/zgNi5zu4SLe5+MiVcFN5zeJun9MX016MVvTLe3aRSvaW41DM7vdTDT6a9+/DLtP3Hed3lKjj2iR4LSDpzSp78dqNnf7tazn25T/3bmNS++3uv/3NdP1eJitfHpK5V55KxLM5e7QSkNtWhzjv8LsQABBICj42R5X14kNsam2DIM5byzb6Ju6N5C13QrW0dTXx68rJ1aNaipa7s1D6i9viwCrW165IpkHT+bpyeuKu5r0aJeDa187DKXfey1FHf1baVpX6Y5+mz4Eqrw4d58MaS99yaiQckNTWs+fImLiQl43hQz7sOdkxrUVMaRs44RPs4a16nu6Ifizj5s+3dXFNcevXLrheULRvdP0uUdmvisqZHMa5Ps70Od6lX8DqN/5ZZU3d3vuOrWqKLTuQU+9w03AggAhzJULlQIVWJjdMcl4Vkczq56lVifqxaH2j/v7OF3eGbj2sV9KQLx0OXJGj0gyTEs2QqtG9bSu7/uo87N6yo2xuZxY2/dsJYynCaKM/PUNZ30bfphl+fm3tdPH6/f6xjOe31qcw1KbqRH/7OxTOWdM66vvtl+SL2TgpufqHXDWtr1/NWmw3xtNltAQ/Jv7dVSTy/YGtR5ndWoGhvQ+kpWoA8IAA9tS25owS54V95VxoB1VZdmQS0wGAgrw4fdoORGql+rqmmtgvNCh95qfX41sLVmje7t8lyvpPp67sYuiomxyWaz6dWR3X02aXnjfsZmdWvojksSS9XfqbSTftnfkxpVY/Xj5KHa+uwvS3Wc8oQaEAAO9v+nr45M1aLN+3VtgBONAeHUIL6abu6ZoLk/ZIdkLtWnr+0U8Iy/kXTvgCS1qFdDvx7Y2iXsuM48G5khtKFAAAHgqKK+vGTl3Qbx1XRXv6QIlghwFcraq0BHjsVXi9Pp3ALVrBaZW+XT1/qeJn+9l5W4KwoCCAANSm6oxQ8PUrvGgU/1DFR2ix8epPVZx9WiXuk7sIZTpCYQCxX6gACQzWZTx2Z1gh5dUFH8/Y7uahhfTQPLwcyzqDha1q8Z8HpHCB41IAAqvWu6Nve5SB3KP/t08uV9qDgCVzk/7gAAKhX71OW3WTjEGeFlM4JZ9i9CEhISlJ2dHeliAAAiKK+gKOyTuyG0fN2/eScBABUC4aNy4d0EAACWI4AAAADLEUAAAIDlCCAAAMByBBAAAGA5AggAALAcAQQAAFiOAAIAACxHAAEAAJYjgAAAAMsRQAAAgOUIIAAAwHIEEAAAYDkCCAAAsBwBBAAAWI4AAgAALEcAAQAAliOAAAAAyxFAAACA5WyGYRiRLoQ/1apVU6NGjUJ+3NOnTys+Pj7kxy0vKvP1VeZrk7i+iqwyX5vE9VVkkbi2Q4cOKTc313RbhQgg4ZKQkKDs7OxIFyNsKvP1VeZrk7i+iqwyX5vE9VVk5e3aaIIBAACWI4AAAADLxT7zzDPPRLoQkdSvX79IFyGsKvP1VeZrk7i+iqwyX5vE9VVk5enaoroPCAAAiAyaYAAAgOUIIAAAwHIEEAAAYLmoDCA7duxQ//79lZKSot69e2vr1q2RLpJfDz30kJKSkmSz2bRhwwbH876upbTbrHb+/HndcMMNSklJUbdu3TR06FClp6dLkg4ePKhhw4YpOTlZF198sVasWOF4XWm3RcKVV16prl27KjU1VYMGDdL69eslVY73z2727Nmy2Wz65JNPJFWe9y4pKUnt27dXamqqUlNT9eGHH0qqPO9dbm6uHnzwQSUnJ6tLly4aNWqU33JWlOs7cuSI431LTU1VSkqK4uLidPTo0Urx+7lo0SL16NFDqampuvjii/X222/7LWO5ujYjCl166aXG7NmzDcMwjP/85z9Gr169IlugACxfvtzIysoyWrVqZaxfv97xvK9rKe02q507d85YuHChUVRUZBiGYfztb38zBg8ebBiGYdx7773G008/bRiGYaxZs8Zo0aKFkZeXV6ZtkXDs2DHH9/Pnzze6du1qGEbleP8MwzB2795t9OvXz+jbt6/x8ccfG4ZRed479785u8ry3j3yyCPGgw8+6Pj7279/v2EYlef6nL300kvGNddcYxhGxf/9LCoqMi666CJj48aNhmEU/w1Wq1bNOHnyZIW5tqgLIAcOHDBq165t5OfnG4ZR/CY2adLE2LFjR4RLFhjnf4a+rqW028qDtWvXGq1atTIMwzBq1arl+IdoGIbRu3dv48svvyzTtkibPXu20a1bt0rz/hUWFhqXX365sW7dOmPw4MGOAFJZ3juzAFJZ3rvTp08btWvXNk6cOOHyfGW5PncdOnSoNL+fRUVFRv369Y3ly5cbhmEYGzduNJo3b27k5uZWmGuLC2/9SvmTlZWlZs2aKS6u+NJtNpsSExOVmZmpdu3aRbh0wfF1LXXr1i3VtvLwM3j11Vd1/fXX68iRI8rPz1fTpk0d25KSkpSZmVnqbZF0991365tvvpFUXHVaWd6/adOmacCAAerZs6fjucr43hmGoT59+mjq1KmV5r3buXOn6tevr+eff15fffWVatSooWeeeUb16tWrFNfnbNWqVTp27JiuueaaSvH7abPZ9OGHH+qmm25SrVq1dOzYMc2fP1+nTp2qMNcWlX1AUH49//zzSk9P1wsvvBDpooTcO++8o6ysLE2ZMkUTJ06MdHFCYsuWLZo3b54mTZoU6aKEzYoVK7Rp0yb9+OOPatiwoe65555IFylkCgoKtGfPHnXq1Enr1q3Ta6+9pttuu00FBQWRLlrIzZo1S3fffbcjHFV0BQUFmjJliubPn689e/bo66+/1l133VWh3ruoCyAtW7bU/v37HW+SYRjKzMxUYmJihEsWPF/XUtptkfTyyy9r/vz5Wrx4sWrWrKkGDRooLi5OOTk5jn0yMjKUmJhY6m3lwT333KNvvvlGCQkJFf79W7lypTIyMpScnKykpCR99913GjdunD766KNK897Zz12lShU98sgjWrlyZaX520tMTFRMTIzuvPNOSVL37t3VunVr7dmzp1Jcn93p06f10Ucf6Ve/+pUkVYr/LRs2bNC+ffv0i1/8QpLUu3dvJSQkaNOmTRXn2sLWuFOODR482KWTVM+ePSNboCC4t0f7upbSbouEV155xejRo4dx9OhRl+fvuecel05RzZs3d3SKKu02qx07dszYu3ev4/HHH39stGjRwigqKqo075+dcx+QyvDenT592qUD8SuvvGIMGjTIMIzK87c3dOhQY+HChYZhGMauXbuMBg0aGNnZ2ZXm+gzDMN544w1jwIABLs9V9N/PnJwcIz4+3ti2bZthGIaxY8cO46KLLjL27NlTYa4tKgPI9u3bjb59+xrJyclGz549jU2bNkW6SH6NGzfOaNGihREbG2s0btzYaNu2rWEYvq+ltNuslpX1/+3dMYqEQBBGYc8iRlLaJgpmgph6RDONPIM3aRT2IP8GAzITCRPU7jjvCxWhm2rhBYI/SpJEaZoqhKAQgpqmkfR4yYZhUJZlyvNc27adz717z9txHKrrWmamsizV9/0ZkXeY37PnALnD7GKMqqpKRVHIzDSOo/Z9l3Sf2cUY1XXdeT7Xdb1c5yftT5LattU0TS/X7nA+l2U552Zmmuf5co3/aW/8CwYAALj7um9AAADA3yNAAACAOwIEAAC4I0AAAIA7AgQAALgjQAAAgDsCBAAAuCNAAACAu1+v+SgmtITqCgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-gRk5NX2dZx",
        "outputId": "8b8ee10a-f7dc-40b5-8d77-b048609615dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(validation_2)\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MNTDJKW2jDp"
      },
      "source": [
        "import csv\n",
        "with open('validation_2.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgdB1omuuJfc"
      },
      "source": [
        "for h in range(0,len(validation_0)):\n",
        "  with open('validation_2.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, validation_2[h].numpy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFEIxxUZKwNa"
      },
      "source": [
        "import csv\n",
        "with open('loss_2.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n",
        "\n",
        "for h in range(0,len(losses_2)):\n",
        "  with open('loss_2.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h, losses_2[h].numpy()])"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWrRJ6KG2sZL"
      },
      "source": [
        "'''Training - hold out fold 3 for validation'''\n",
        "#Training\n",
        "gpu='0'\n",
        "atlas_file='/content/drive/My Drive/2020/Thesis/Data/atlas.npz'\n",
        "lr=1e-4\n",
        "n_iter=5000\n",
        "data_loss='mse'\n",
        "model='vm2'\n",
        "reg_param=0.01\n",
        "batch_size=10\n",
        "n_save_iter=100\n",
        "model_dir='/content/drive/My Drive/2020/Thesis/Data/validation_0/'\n",
        "valid = fold_3\n",
        "train_names = set_3\n",
        "EPOCH=30"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrdxT2Hv2xXD",
        "outputId": "59e2f2c2-68b3-4942-d6a2-1a1115ded15b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses_3, validation_3=validate.train(data_dir,\n",
        "          train_names,\n",
        "          atlas_file,\n",
        "          lr,\n",
        "          data_loss,\n",
        "          model,\n",
        "          reg_param, \n",
        "          batch_size,\n",
        "          n_save_iter,\n",
        "          model_dir,Net(),EPOCH, valid)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch_number:185\n",
            "loss(total):-0.002917\n",
            "recons_loss:0.004924\n",
            "grad_loss:0.104801\n",
            "dice_loss:-0.888907\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:186\n",
            "loss(total):-0.003888\n",
            "recons_loss:0.004133\n",
            "grad_loss:0.093532\n",
            "dice_loss:-0.895630\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:187\n",
            "loss(total):-0.003181\n",
            "recons_loss:0.004599\n",
            "grad_loss:0.115260\n",
            "dice_loss:-0.893198\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:188\n",
            "loss(total):-0.003464\n",
            "recons_loss:0.004290\n",
            "grad_loss:0.100895\n",
            "dice_loss:-0.876276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:189\n",
            "loss(total):-0.004741\n",
            "recons_loss:0.003350\n",
            "grad_loss:0.082944\n",
            "dice_loss:-0.892087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:190\n",
            "loss(total):-0.003129\n",
            "recons_loss:0.004571\n",
            "grad_loss:0.096688\n",
            "dice_loss:-0.866665\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:191\n",
            "loss(total):-0.004993\n",
            "recons_loss:0.003182\n",
            "grad_loss:0.082676\n",
            "dice_loss:-0.900106\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:192\n",
            "loss(total):-0.004310\n",
            "recons_loss:0.003561\n",
            "grad_loss:0.095685\n",
            "dice_loss:-0.882731\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:193\n",
            "loss(total):-0.002103\n",
            "recons_loss:0.005729\n",
            "grad_loss:0.104406\n",
            "dice_loss:-0.887574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:194\n",
            "loss(total):-0.003858\n",
            "recons_loss:0.004033\n",
            "grad_loss:0.103069\n",
            "dice_loss:-0.892179\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:195\n",
            "loss(total):-0.004460\n",
            "recons_loss:0.003600\n",
            "grad_loss:0.084868\n",
            "dice_loss:-0.890795\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:196\n",
            "loss(total):-0.004821\n",
            "recons_loss:0.003095\n",
            "grad_loss:0.083554\n",
            "dice_loss:-0.875182\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:197\n",
            "loss(total):-0.003589\n",
            "recons_loss:0.004286\n",
            "grad_loss:0.107753\n",
            "dice_loss:-0.895309\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:198\n",
            "loss(total):-0.004944\n",
            "recons_loss:0.003106\n",
            "grad_loss:0.079461\n",
            "dice_loss:-0.884544\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:199\n",
            "loss(total):-0.004911\n",
            "recons_loss:0.003247\n",
            "grad_loss:0.077721\n",
            "dice_loss:-0.893559\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:200\n",
            "loss(total):-0.004465\n",
            "recons_loss:0.003478\n",
            "grad_loss:0.091311\n",
            "dice_loss:-0.885614\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:201\n",
            "loss(total):-0.004105\n",
            "recons_loss:0.003871\n",
            "grad_loss:0.085147\n",
            "dice_loss:-0.882737\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:202\n",
            "loss(total):-0.004122\n",
            "recons_loss:0.003746\n",
            "grad_loss:0.099744\n",
            "dice_loss:-0.886516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:203\n",
            "loss(total):-0.002724\n",
            "recons_loss:0.004954\n",
            "grad_loss:0.112116\n",
            "dice_loss:-0.879820\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:204\n",
            "loss(total):-0.005320\n",
            "recons_loss:0.002927\n",
            "grad_loss:0.075096\n",
            "dice_loss:-0.899796\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:205\n",
            "loss(total):-0.003162\n",
            "recons_loss:0.004435\n",
            "grad_loss:0.118259\n",
            "dice_loss:-0.878025\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:206\n",
            "loss(total):-0.003019\n",
            "recons_loss:0.004811\n",
            "grad_loss:0.108890\n",
            "dice_loss:-0.891852\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:207\n",
            "loss(total):-0.004252\n",
            "recons_loss:0.003827\n",
            "grad_loss:0.082422\n",
            "dice_loss:-0.890286\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:208\n",
            "loss(total):-0.003224\n",
            "recons_loss:0.004554\n",
            "grad_loss:0.104864\n",
            "dice_loss:-0.882673\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:209\n",
            "loss(total):-0.003651\n",
            "recons_loss:0.004142\n",
            "grad_loss:0.094343\n",
            "dice_loss:-0.873646\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:210\n",
            "loss(total):-0.003934\n",
            "recons_loss:0.004118\n",
            "grad_loss:0.088931\n",
            "dice_loss:-0.894126\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:211\n",
            "loss(total):-0.004041\n",
            "recons_loss:0.004002\n",
            "grad_loss:0.095789\n",
            "dice_loss:-0.900103\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:212\n",
            "loss(total):-0.004912\n",
            "recons_loss:0.003148\n",
            "grad_loss:0.077634\n",
            "dice_loss:-0.883602\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:213\n",
            "loss(total):-0.003591\n",
            "recons_loss:0.004159\n",
            "grad_loss:0.100163\n",
            "dice_loss:-0.875216\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:214\n",
            "loss(total):-0.003827\n",
            "recons_loss:0.003920\n",
            "grad_loss:0.108845\n",
            "dice_loss:-0.883583\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:215\n",
            "loss(total):-0.002967\n",
            "recons_loss:0.004646\n",
            "grad_loss:0.116563\n",
            "dice_loss:-0.877826\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:216\n",
            "loss(total):-0.002767\n",
            "recons_loss:0.004795\n",
            "grad_loss:0.124046\n",
            "dice_loss:-0.880244\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:217\n",
            "loss(total):-0.003632\n",
            "recons_loss:0.004432\n",
            "grad_loss:0.083086\n",
            "dice_loss:-0.889528\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:218\n",
            "loss(total):-0.004327\n",
            "recons_loss:0.003654\n",
            "grad_loss:0.087936\n",
            "dice_loss:-0.885975\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:219\n",
            "loss(total):-0.002287\n",
            "recons_loss:0.005544\n",
            "grad_loss:0.101882\n",
            "dice_loss:-0.884949\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:220\n",
            "loss(total):-0.003051\n",
            "recons_loss:0.004693\n",
            "grad_loss:0.118839\n",
            "dice_loss:-0.893287\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:221\n",
            "loss(total):-0.002327\n",
            "recons_loss:0.005234\n",
            "grad_loss:0.113973\n",
            "dice_loss:-0.870041\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:222\n",
            "loss(total):-0.003180\n",
            "recons_loss:0.004696\n",
            "grad_loss:0.109460\n",
            "dice_loss:-0.897111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:223\n",
            "loss(total):-0.002901\n",
            "recons_loss:0.004831\n",
            "grad_loss:0.096691\n",
            "dice_loss:-0.869975\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:224\n",
            "loss(total):-0.003262\n",
            "recons_loss:0.004582\n",
            "grad_loss:0.100598\n",
            "dice_loss:-0.885004\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:225\n",
            "loss(total):-0.002519\n",
            "recons_loss:0.005427\n",
            "grad_loss:0.092214\n",
            "dice_loss:-0.886790\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:226\n",
            "loss(total):-0.005045\n",
            "recons_loss:0.003222\n",
            "grad_loss:0.076494\n",
            "dice_loss:-0.903183\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:227\n",
            "loss(total):-0.003721\n",
            "recons_loss:0.003988\n",
            "grad_loss:0.105202\n",
            "dice_loss:-0.876109\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:228\n",
            "loss(total):-0.003204\n",
            "recons_loss:0.004456\n",
            "grad_loss:0.109522\n",
            "dice_loss:-0.875514\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:229\n",
            "loss(total):-0.003307\n",
            "recons_loss:0.004402\n",
            "grad_loss:0.104498\n",
            "dice_loss:-0.875401\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:230\n",
            "loss(total):-0.005259\n",
            "recons_loss:0.003027\n",
            "grad_loss:0.075839\n",
            "dice_loss:-0.904394\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:231\n",
            "loss(total):-0.002714\n",
            "recons_loss:0.005066\n",
            "grad_loss:0.109787\n",
            "dice_loss:-0.887834\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:232\n",
            "loss(total):-0.003153\n",
            "recons_loss:0.004553\n",
            "grad_loss:0.122386\n",
            "dice_loss:-0.893008\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:233\n",
            "loss(total):-0.002889\n",
            "recons_loss:0.005065\n",
            "grad_loss:0.098605\n",
            "dice_loss:-0.893980\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:234\n",
            "loss(total):-0.003077\n",
            "recons_loss:0.004702\n",
            "grad_loss:0.109531\n",
            "dice_loss:-0.887409\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:235\n",
            "loss(total):-0.002311\n",
            "recons_loss:0.005454\n",
            "grad_loss:0.099974\n",
            "dice_loss:-0.876535\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:236\n",
            "loss(total):-0.004618\n",
            "recons_loss:0.003479\n",
            "grad_loss:0.085060\n",
            "dice_loss:-0.894762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:237\n",
            "loss(total):-0.002716\n",
            "recons_loss:0.004779\n",
            "grad_loss:0.121593\n",
            "dice_loss:-0.871071\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:238\n",
            "loss(total):-0.004813\n",
            "recons_loss:0.003249\n",
            "grad_loss:0.078208\n",
            "dice_loss:-0.884419\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:239\n",
            "loss(total):-0.004116\n",
            "recons_loss:0.003808\n",
            "grad_loss:0.088779\n",
            "dice_loss:-0.881201\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:240\n",
            "loss(total):-0.004128\n",
            "recons_loss:0.003899\n",
            "grad_loss:0.092841\n",
            "dice_loss:-0.895567\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:241\n",
            "loss(total):-0.004241\n",
            "recons_loss:0.003718\n",
            "grad_loss:0.099217\n",
            "dice_loss:-0.895075\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:242\n",
            "loss(total):-0.003299\n",
            "recons_loss:0.004487\n",
            "grad_loss:0.105449\n",
            "dice_loss:-0.884031\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:243\n",
            "loss(total):-0.004381\n",
            "recons_loss:0.003695\n",
            "grad_loss:0.088725\n",
            "dice_loss:-0.896334\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:244\n",
            "loss(total):-0.003065\n",
            "recons_loss:0.004574\n",
            "grad_loss:0.119296\n",
            "dice_loss:-0.883229\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:245\n",
            "loss(total):-0.004112\n",
            "recons_loss:0.003976\n",
            "grad_loss:0.091711\n",
            "dice_loss:-0.900587\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:246\n",
            "loss(total):-0.003565\n",
            "recons_loss:0.004418\n",
            "grad_loss:0.095948\n",
            "dice_loss:-0.894271\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:247\n",
            "loss(total):-0.002463\n",
            "recons_loss:0.005272\n",
            "grad_loss:0.110999\n",
            "dice_loss:-0.884574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:248\n",
            "loss(total):-0.003728\n",
            "recons_loss:0.004055\n",
            "grad_loss:0.104352\n",
            "dice_loss:-0.882707\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:249\n",
            "loss(total):-0.005113\n",
            "recons_loss:0.003170\n",
            "grad_loss:0.076037\n",
            "dice_loss:-0.904246\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:250\n",
            "loss(total):-0.003057\n",
            "recons_loss:0.004898\n",
            "grad_loss:0.086621\n",
            "dice_loss:-0.882141\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:251\n",
            "loss(total):-0.002752\n",
            "recons_loss:0.005016\n",
            "grad_loss:0.110474\n",
            "dice_loss:-0.887244\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:252\n",
            "loss(total):-0.004166\n",
            "recons_loss:0.003902\n",
            "grad_loss:0.093965\n",
            "dice_loss:-0.900749\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:253\n",
            "loss(total):-0.002263\n",
            "recons_loss:0.005451\n",
            "grad_loss:0.114963\n",
            "dice_loss:-0.886372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:254\n",
            "loss(total):-0.003616\n",
            "recons_loss:0.004302\n",
            "grad_loss:0.093373\n",
            "dice_loss:-0.885237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:255\n",
            "loss(total):-0.003406\n",
            "recons_loss:0.004404\n",
            "grad_loss:0.109526\n",
            "dice_loss:-0.890487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:256\n",
            "loss(total):-0.003425\n",
            "recons_loss:0.004313\n",
            "grad_loss:0.109242\n",
            "dice_loss:-0.883051\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:257\n",
            "loss(total):-0.003562\n",
            "recons_loss:0.004402\n",
            "grad_loss:0.091778\n",
            "dice_loss:-0.888200\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:258\n",
            "loss(total):-0.002514\n",
            "recons_loss:0.005369\n",
            "grad_loss:0.103967\n",
            "dice_loss:-0.892268\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:259\n",
            "loss(total):-0.003535\n",
            "recons_loss:0.004336\n",
            "grad_loss:0.107468\n",
            "dice_loss:-0.894611\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:260\n",
            "loss(total):-0.002757\n",
            "recons_loss:0.005031\n",
            "grad_loss:0.105831\n",
            "dice_loss:-0.884632\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:261\n",
            "loss(total):-0.001744\n",
            "recons_loss:0.005927\n",
            "grad_loss:0.107528\n",
            "dice_loss:-0.874627\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:262\n",
            "loss(total):-0.003468\n",
            "recons_loss:0.004347\n",
            "grad_loss:0.113082\n",
            "dice_loss:-0.894540\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:263\n",
            "loss(total):-0.002663\n",
            "recons_loss:0.005152\n",
            "grad_loss:0.102674\n",
            "dice_loss:-0.884164\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:264\n",
            "loss(total):-0.004563\n",
            "recons_loss:0.003212\n",
            "grad_loss:0.093684\n",
            "dice_loss:-0.871184\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:265\n",
            "loss(total):-0.002853\n",
            "recons_loss:0.004909\n",
            "grad_loss:0.098626\n",
            "dice_loss:-0.874823\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:266\n",
            "loss(total):-0.002150\n",
            "recons_loss:0.005397\n",
            "grad_loss:0.126476\n",
            "dice_loss:-0.881113\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:267\n",
            "loss(total):-0.003849\n",
            "recons_loss:0.004112\n",
            "grad_loss:0.082547\n",
            "dice_loss:-0.878633\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:268\n",
            "loss(total):-0.004084\n",
            "recons_loss:0.003961\n",
            "grad_loss:0.102123\n",
            "dice_loss:-0.906601\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:269\n",
            "loss(total):-0.002752\n",
            "recons_loss:0.005019\n",
            "grad_loss:0.107292\n",
            "dice_loss:-0.884326\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:0\n",
            "loss(total):-0.004271\n",
            "recons_loss:0.003601\n",
            "grad_loss:0.094596\n",
            "dice_loss:-0.881850\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:1\n",
            "loss(total):-0.004392\n",
            "recons_loss:0.003660\n",
            "grad_loss:0.081581\n",
            "dice_loss:-0.886758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:2\n",
            "loss(total):-0.005058\n",
            "recons_loss:0.003162\n",
            "grad_loss:0.074197\n",
            "dice_loss:-0.896241\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:3\n",
            "loss(total):-0.004526\n",
            "recons_loss:0.003512\n",
            "grad_loss:0.082486\n",
            "dice_loss:-0.886341\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:4\n",
            "loss(total):-0.003872\n",
            "recons_loss:0.004063\n",
            "grad_loss:0.094383\n",
            "dice_loss:-0.887849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:5\n",
            "loss(total):-0.002290\n",
            "recons_loss:0.005555\n",
            "grad_loss:0.101612\n",
            "dice_loss:-0.886123\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:6\n",
            "loss(total):-0.004727\n",
            "recons_loss:0.003474\n",
            "grad_loss:0.083578\n",
            "dice_loss:-0.903722\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:7\n",
            "loss(total):-0.003451\n",
            "recons_loss:0.004465\n",
            "grad_loss:0.092925\n",
            "dice_loss:-0.884473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:8\n",
            "loss(total):-0.004082\n",
            "recons_loss:0.004007\n",
            "grad_loss:0.093075\n",
            "dice_loss:-0.902029\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:9\n",
            "loss(total):-0.003318\n",
            "recons_loss:0.004542\n",
            "grad_loss:0.102272\n",
            "dice_loss:-0.888346\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:10\n",
            "loss(total):-0.003017\n",
            "recons_loss:0.004542\n",
            "grad_loss:0.121037\n",
            "dice_loss:-0.876903\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:11\n",
            "loss(total):-0.003211\n",
            "recons_loss:0.004666\n",
            "grad_loss:0.094295\n",
            "dice_loss:-0.882042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:12\n",
            "loss(total):-0.002815\n",
            "recons_loss:0.004982\n",
            "grad_loss:0.099325\n",
            "dice_loss:-0.879053\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:13\n",
            "loss(total):-0.003945\n",
            "recons_loss:0.003908\n",
            "grad_loss:0.096890\n",
            "dice_loss:-0.882155\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:14\n",
            "loss(total):-0.003675\n",
            "recons_loss:0.004254\n",
            "grad_loss:0.106461\n",
            "dice_loss:-0.899432\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:15\n",
            "loss(total):-0.005641\n",
            "recons_loss:0.002700\n",
            "grad_loss:0.068989\n",
            "dice_loss:-0.903111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:16\n",
            "loss(total):-0.004043\n",
            "recons_loss:0.004033\n",
            "grad_loss:0.089604\n",
            "dice_loss:-0.897154\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:17\n",
            "loss(total):-0.003607\n",
            "recons_loss:0.004308\n",
            "grad_loss:0.089579\n",
            "dice_loss:-0.881090\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:18\n",
            "loss(total):-0.004096\n",
            "recons_loss:0.004039\n",
            "grad_loss:0.079776\n",
            "dice_loss:-0.893196\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:19\n",
            "loss(total):-0.004240\n",
            "recons_loss:0.003853\n",
            "grad_loss:0.090480\n",
            "dice_loss:-0.899859\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:20\n",
            "loss(total):-0.004116\n",
            "recons_loss:0.003953\n",
            "grad_loss:0.089201\n",
            "dice_loss:-0.896148\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:21\n",
            "loss(total):-0.003024\n",
            "recons_loss:0.004914\n",
            "grad_loss:0.081008\n",
            "dice_loss:-0.874780\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:22\n",
            "loss(total):-0.003474\n",
            "recons_loss:0.004621\n",
            "grad_loss:0.087809\n",
            "dice_loss:-0.897279\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:23\n",
            "loss(total):-0.003106\n",
            "recons_loss:0.004698\n",
            "grad_loss:0.115098\n",
            "dice_loss:-0.895533\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:24\n",
            "loss(total):-0.003011\n",
            "recons_loss:0.004823\n",
            "grad_loss:0.112207\n",
            "dice_loss:-0.895691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:25\n",
            "loss(total):-0.002553\n",
            "recons_loss:0.005235\n",
            "grad_loss:0.110430\n",
            "dice_loss:-0.889302\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:26\n",
            "loss(total):-0.001623\n",
            "recons_loss:0.005623\n",
            "grad_loss:0.137090\n",
            "dice_loss:-0.861613\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:27\n",
            "loss(total):-0.002892\n",
            "recons_loss:0.004893\n",
            "grad_loss:0.112193\n",
            "dice_loss:-0.890728\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:28\n",
            "loss(total):-0.002412\n",
            "recons_loss:0.005402\n",
            "grad_loss:0.099300\n",
            "dice_loss:-0.880726\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:29\n",
            "loss(total):-0.002948\n",
            "recons_loss:0.004935\n",
            "grad_loss:0.108639\n",
            "dice_loss:-0.896897\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:30\n",
            "loss(total):-0.002820\n",
            "recons_loss:0.004943\n",
            "grad_loss:0.115544\n",
            "dice_loss:-0.891909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:31\n",
            "loss(total):-0.003633\n",
            "recons_loss:0.004423\n",
            "grad_loss:0.089225\n",
            "dice_loss:-0.894803\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:32\n",
            "loss(total):-0.001715\n",
            "recons_loss:0.005747\n",
            "grad_loss:0.135127\n",
            "dice_loss:-0.881311\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:33\n",
            "loss(total):-0.003058\n",
            "recons_loss:0.004668\n",
            "grad_loss:0.119954\n",
            "dice_loss:-0.892544\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:34\n",
            "loss(total):-0.002941\n",
            "recons_loss:0.004947\n",
            "grad_loss:0.086483\n",
            "dice_loss:-0.875276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:35\n",
            "loss(total):-0.002811\n",
            "recons_loss:0.004906\n",
            "grad_loss:0.122096\n",
            "dice_loss:-0.893722\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:36\n",
            "loss(total):-0.003482\n",
            "recons_loss:0.004397\n",
            "grad_loss:0.107249\n",
            "dice_loss:-0.895156\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:37\n",
            "loss(total):-0.003387\n",
            "recons_loss:0.004300\n",
            "grad_loss:0.113724\n",
            "dice_loss:-0.882386\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:38\n",
            "loss(total):-0.002829\n",
            "recons_loss:0.004730\n",
            "grad_loss:0.127549\n",
            "dice_loss:-0.883445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:39\n",
            "loss(total):-0.003538\n",
            "recons_loss:0.004311\n",
            "grad_loss:0.102943\n",
            "dice_loss:-0.887776\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:40\n",
            "loss(total):-0.003694\n",
            "recons_loss:0.004046\n",
            "grad_loss:0.099224\n",
            "dice_loss:-0.873226\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:41\n",
            "loss(total):-0.002299\n",
            "recons_loss:0.005302\n",
            "grad_loss:0.115832\n",
            "dice_loss:-0.875864\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:42\n",
            "loss(total):-0.004788\n",
            "recons_loss:0.003374\n",
            "grad_loss:0.077227\n",
            "dice_loss:-0.893506\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:43\n",
            "loss(total):-0.002753\n",
            "recons_loss:0.004814\n",
            "grad_loss:0.119435\n",
            "dice_loss:-0.876147\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:44\n",
            "loss(total):-0.003405\n",
            "recons_loss:0.004648\n",
            "grad_loss:0.089530\n",
            "dice_loss:-0.894819\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:45\n",
            "loss(total):-0.003336\n",
            "recons_loss:0.004356\n",
            "grad_loss:0.109190\n",
            "dice_loss:-0.878456\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:46\n",
            "loss(total):-0.004375\n",
            "recons_loss:0.003738\n",
            "grad_loss:0.087089\n",
            "dice_loss:-0.898340\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:47\n",
            "loss(total):-0.003694\n",
            "recons_loss:0.004171\n",
            "grad_loss:0.098173\n",
            "dice_loss:-0.884621\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:48\n",
            "loss(total):-0.004675\n",
            "recons_loss:0.003247\n",
            "grad_loss:0.094003\n",
            "dice_loss:-0.886211\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:49\n",
            "loss(total):-0.003781\n",
            "recons_loss:0.004162\n",
            "grad_loss:0.093033\n",
            "dice_loss:-0.887381\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:50\n",
            "loss(total):-0.003806\n",
            "recons_loss:0.004073\n",
            "grad_loss:0.094782\n",
            "dice_loss:-0.882707\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:51\n",
            "loss(total):-0.003699\n",
            "recons_loss:0.004178\n",
            "grad_loss:0.103523\n",
            "dice_loss:-0.891219\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:52\n",
            "loss(total):-0.003894\n",
            "recons_loss:0.004057\n",
            "grad_loss:0.101479\n",
            "dice_loss:-0.896566\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:53\n",
            "loss(total):-0.003336\n",
            "recons_loss:0.004455\n",
            "grad_loss:0.100497\n",
            "dice_loss:-0.879633\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:54\n",
            "loss(total):-0.003407\n",
            "recons_loss:0.004412\n",
            "grad_loss:0.097265\n",
            "dice_loss:-0.879139\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:55\n",
            "loss(total):-0.003515\n",
            "recons_loss:0.004226\n",
            "grad_loss:0.108624\n",
            "dice_loss:-0.882706\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:56\n",
            "loss(total):-0.004423\n",
            "recons_loss:0.003614\n",
            "grad_loss:0.081605\n",
            "dice_loss:-0.885318\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:57\n",
            "loss(total):-0.003801\n",
            "recons_loss:0.004133\n",
            "grad_loss:0.095624\n",
            "dice_loss:-0.889012\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:58\n",
            "loss(total):-0.004226\n",
            "recons_loss:0.003818\n",
            "grad_loss:0.087964\n",
            "dice_loss:-0.892354\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:59\n",
            "loss(total):-0.004316\n",
            "recons_loss:0.003755\n",
            "grad_loss:0.081650\n",
            "dice_loss:-0.888749\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:60\n",
            "loss(total):-0.003646\n",
            "recons_loss:0.004408\n",
            "grad_loss:0.089076\n",
            "dice_loss:-0.894482\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:61\n",
            "loss(total):-0.003823\n",
            "recons_loss:0.003966\n",
            "grad_loss:0.101253\n",
            "dice_loss:-0.880188\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:62\n",
            "loss(total):-0.003601\n",
            "recons_loss:0.004437\n",
            "grad_loss:0.083112\n",
            "dice_loss:-0.886953\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:63\n",
            "loss(total):-0.003394\n",
            "recons_loss:0.004438\n",
            "grad_loss:0.107538\n",
            "dice_loss:-0.890672\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:64\n",
            "loss(total):-0.004144\n",
            "recons_loss:0.003900\n",
            "grad_loss:0.083815\n",
            "dice_loss:-0.888149\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:65\n",
            "loss(total):-0.004928\n",
            "recons_loss:0.003273\n",
            "grad_loss:0.075580\n",
            "dice_loss:-0.895652\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:66\n",
            "loss(total):-0.003988\n",
            "recons_loss:0.004104\n",
            "grad_loss:0.092637\n",
            "dice_loss:-0.901830\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:67\n",
            "loss(total):-0.003841\n",
            "recons_loss:0.004100\n",
            "grad_loss:0.097064\n",
            "dice_loss:-0.891187\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:68\n",
            "loss(total):-0.002663\n",
            "recons_loss:0.004938\n",
            "grad_loss:0.119862\n",
            "dice_loss:-0.879926\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:69\n",
            "loss(total):-0.004317\n",
            "recons_loss:0.003511\n",
            "grad_loss:0.098153\n",
            "dice_loss:-0.880924\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:70\n",
            "loss(total):-0.004606\n",
            "recons_loss:0.003431\n",
            "grad_loss:0.081381\n",
            "dice_loss:-0.885118\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:71\n",
            "loss(total):-0.002950\n",
            "recons_loss:0.004704\n",
            "grad_loss:0.112666\n",
            "dice_loss:-0.878064\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:72\n",
            "loss(total):-0.003632\n",
            "recons_loss:0.004351\n",
            "grad_loss:0.086451\n",
            "dice_loss:-0.884790\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:73\n",
            "loss(total):-0.003875\n",
            "recons_loss:0.004123\n",
            "grad_loss:0.089269\n",
            "dice_loss:-0.889091\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:74\n",
            "loss(total):-0.003430\n",
            "recons_loss:0.004477\n",
            "grad_loss:0.096822\n",
            "dice_loss:-0.887490\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:75\n",
            "loss(total):-0.003879\n",
            "recons_loss:0.003912\n",
            "grad_loss:0.112855\n",
            "dice_loss:-0.892027\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:76\n",
            "loss(total):-0.003450\n",
            "recons_loss:0.004265\n",
            "grad_loss:0.109887\n",
            "dice_loss:-0.881375\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:77\n",
            "loss(total):-0.004367\n",
            "recons_loss:0.003900\n",
            "grad_loss:0.070883\n",
            "dice_loss:-0.897574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:78\n",
            "loss(total):-0.003366\n",
            "recons_loss:0.004548\n",
            "grad_loss:0.099090\n",
            "dice_loss:-0.890501\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:79\n",
            "loss(total):-0.002007\n",
            "recons_loss:0.005543\n",
            "grad_loss:0.122625\n",
            "dice_loss:-0.877632\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:80\n",
            "loss(total):-0.002613\n",
            "recons_loss:0.004886\n",
            "grad_loss:0.134906\n",
            "dice_loss:-0.884764\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:81\n",
            "loss(total):-0.002075\n",
            "recons_loss:0.005456\n",
            "grad_loss:0.113219\n",
            "dice_loss:-0.866377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:82\n",
            "loss(total):-0.002723\n",
            "recons_loss:0.004936\n",
            "grad_loss:0.122376\n",
            "dice_loss:-0.888278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:83\n",
            "loss(total):-0.003626\n",
            "recons_loss:0.004118\n",
            "grad_loss:0.109637\n",
            "dice_loss:-0.884042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:84\n",
            "loss(total):-0.002432\n",
            "recons_loss:0.005113\n",
            "grad_loss:0.129278\n",
            "dice_loss:-0.883798\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:85\n",
            "loss(total):-0.002888\n",
            "recons_loss:0.004725\n",
            "grad_loss:0.123514\n",
            "dice_loss:-0.884879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:86\n",
            "loss(total):-0.003680\n",
            "recons_loss:0.004396\n",
            "grad_loss:0.084668\n",
            "dice_loss:-0.892308\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:87\n",
            "loss(total):-0.004078\n",
            "recons_loss:0.003895\n",
            "grad_loss:0.084108\n",
            "dice_loss:-0.881368\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:88\n",
            "loss(total):-0.004316\n",
            "recons_loss:0.003833\n",
            "grad_loss:0.088457\n",
            "dice_loss:-0.903348\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:89\n",
            "loss(total):-0.002848\n",
            "recons_loss:0.005077\n",
            "grad_loss:0.091597\n",
            "dice_loss:-0.884119\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:90\n",
            "loss(total):-0.003973\n",
            "recons_loss:0.003981\n",
            "grad_loss:0.092391\n",
            "dice_loss:-0.887806\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:91\n",
            "loss(total):-0.004797\n",
            "recons_loss:0.003400\n",
            "grad_loss:0.077891\n",
            "dice_loss:-0.897639\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:92\n",
            "loss(total):-0.002966\n",
            "recons_loss:0.004825\n",
            "grad_loss:0.093197\n",
            "dice_loss:-0.872322\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:93\n",
            "loss(total):-0.004157\n",
            "recons_loss:0.003691\n",
            "grad_loss:0.098649\n",
            "dice_loss:-0.883477\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:94\n",
            "loss(total):-0.003912\n",
            "recons_loss:0.003927\n",
            "grad_loss:0.096400\n",
            "dice_loss:-0.880295\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:95\n",
            "loss(total):-0.004727\n",
            "recons_loss:0.003350\n",
            "grad_loss:0.085712\n",
            "dice_loss:-0.893419\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:96\n",
            "loss(total):-0.003739\n",
            "recons_loss:0.004264\n",
            "grad_loss:0.094710\n",
            "dice_loss:-0.895092\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:97\n",
            "loss(total):-0.005028\n",
            "recons_loss:0.003296\n",
            "grad_loss:0.064218\n",
            "dice_loss:-0.896640\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:98\n",
            "loss(total):-0.004542\n",
            "recons_loss:0.003437\n",
            "grad_loss:0.087400\n",
            "dice_loss:-0.885259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:99\n",
            "loss(total):-0.004812\n",
            "recons_loss:0.003168\n",
            "grad_loss:0.099652\n",
            "dice_loss:-0.897651\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:100\n",
            "loss(total):-0.004297\n",
            "recons_loss:0.003648\n",
            "grad_loss:0.101254\n",
            "dice_loss:-0.895742\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:101\n",
            "loss(total):-0.004247\n",
            "recons_loss:0.003721\n",
            "grad_loss:0.091455\n",
            "dice_loss:-0.888306\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:102\n",
            "loss(total):-0.002435\n",
            "recons_loss:0.005289\n",
            "grad_loss:0.113616\n",
            "dice_loss:-0.886045\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:103\n",
            "loss(total):-0.003831\n",
            "recons_loss:0.004002\n",
            "grad_loss:0.101237\n",
            "dice_loss:-0.884488\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:104\n",
            "loss(total):-0.003737\n",
            "recons_loss:0.004171\n",
            "grad_loss:0.089081\n",
            "dice_loss:-0.879893\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:105\n",
            "loss(total):-0.003815\n",
            "recons_loss:0.004274\n",
            "grad_loss:0.083782\n",
            "dice_loss:-0.892683\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:106\n",
            "loss(total):-0.004055\n",
            "recons_loss:0.004010\n",
            "grad_loss:0.087653\n",
            "dice_loss:-0.894175\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:107\n",
            "loss(total):-0.004102\n",
            "recons_loss:0.003860\n",
            "grad_loss:0.096551\n",
            "dice_loss:-0.892785\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:108\n",
            "loss(total):-0.001717\n",
            "recons_loss:0.005845\n",
            "grad_loss:0.122475\n",
            "dice_loss:-0.878707\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:109\n",
            "loss(total):-0.003237\n",
            "recons_loss:0.004540\n",
            "grad_loss:0.105901\n",
            "dice_loss:-0.883621\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:110\n",
            "loss(total):-0.002847\n",
            "recons_loss:0.004767\n",
            "grad_loss:0.117218\n",
            "dice_loss:-0.878694\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:111\n",
            "loss(total):-0.004956\n",
            "recons_loss:0.003342\n",
            "grad_loss:0.068936\n",
            "dice_loss:-0.898751\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:112\n",
            "loss(total):-0.002784\n",
            "recons_loss:0.005121\n",
            "grad_loss:0.092944\n",
            "dice_loss:-0.883378\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:113\n",
            "loss(total):-0.003567\n",
            "recons_loss:0.004422\n",
            "grad_loss:0.100996\n",
            "dice_loss:-0.899863\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:114\n",
            "loss(total):-0.003536\n",
            "recons_loss:0.004421\n",
            "grad_loss:0.101412\n",
            "dice_loss:-0.897095\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:115\n",
            "loss(total):-0.003604\n",
            "recons_loss:0.004223\n",
            "grad_loss:0.096647\n",
            "dice_loss:-0.879344\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:116\n",
            "loss(total):-0.004187\n",
            "recons_loss:0.003711\n",
            "grad_loss:0.099596\n",
            "dice_loss:-0.889377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:117\n",
            "loss(total):-0.002192\n",
            "recons_loss:0.005414\n",
            "grad_loss:0.114185\n",
            "dice_loss:-0.874766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:118\n",
            "loss(total):-0.003431\n",
            "recons_loss:0.004418\n",
            "grad_loss:0.097502\n",
            "dice_loss:-0.882425\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:119\n",
            "loss(total):-0.004880\n",
            "recons_loss:0.003464\n",
            "grad_loss:0.077518\n",
            "dice_loss:-0.911875\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:120\n",
            "loss(total):-0.004722\n",
            "recons_loss:0.003355\n",
            "grad_loss:0.084989\n",
            "dice_loss:-0.892600\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:121\n",
            "loss(total):-0.004125\n",
            "recons_loss:0.004042\n",
            "grad_loss:0.078910\n",
            "dice_loss:-0.895640\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:122\n",
            "loss(total):-0.003213\n",
            "recons_loss:0.004572\n",
            "grad_loss:0.112829\n",
            "dice_loss:-0.891309\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:123\n",
            "loss(total):-0.003218\n",
            "recons_loss:0.004543\n",
            "grad_loss:0.107217\n",
            "dice_loss:-0.883249\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:124\n",
            "loss(total):-0.004734\n",
            "recons_loss:0.003369\n",
            "grad_loss:0.080657\n",
            "dice_loss:-0.891022\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:125\n",
            "loss(total):-0.003494\n",
            "recons_loss:0.004368\n",
            "grad_loss:0.101531\n",
            "dice_loss:-0.887702\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:126\n",
            "loss(total):-0.003262\n",
            "recons_loss:0.004599\n",
            "grad_loss:0.097109\n",
            "dice_loss:-0.883184\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:127\n",
            "loss(total):-0.002279\n",
            "recons_loss:0.005489\n",
            "grad_loss:0.127024\n",
            "dice_loss:-0.903904\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:128\n",
            "loss(total):-0.003647\n",
            "recons_loss:0.004049\n",
            "grad_loss:0.099447\n",
            "dice_loss:-0.869006\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:129\n",
            "loss(total):-0.003289\n",
            "recons_loss:0.004282\n",
            "grad_loss:0.114632\n",
            "dice_loss:-0.871791\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:130\n",
            "loss(total):-0.003090\n",
            "recons_loss:0.004882\n",
            "grad_loss:0.101215\n",
            "dice_loss:-0.898425\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:131\n",
            "loss(total):-0.004571\n",
            "recons_loss:0.003579\n",
            "grad_loss:0.076790\n",
            "dice_loss:-0.891744\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:132\n",
            "loss(total):-0.003738\n",
            "recons_loss:0.004282\n",
            "grad_loss:0.097121\n",
            "dice_loss:-0.899141\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:133\n",
            "loss(total):-0.004214\n",
            "recons_loss:0.003846\n",
            "grad_loss:0.092618\n",
            "dice_loss:-0.898624\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:134\n",
            "loss(total):-0.004011\n",
            "recons_loss:0.003746\n",
            "grad_loss:0.100751\n",
            "dice_loss:-0.876494\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:135\n",
            "loss(total):-0.003909\n",
            "recons_loss:0.003957\n",
            "grad_loss:0.102012\n",
            "dice_loss:-0.888558\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:136\n",
            "loss(total):-0.002598\n",
            "recons_loss:0.005027\n",
            "grad_loss:0.118538\n",
            "dice_loss:-0.881056\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:137\n",
            "loss(total):-0.004332\n",
            "recons_loss:0.003766\n",
            "grad_loss:0.072393\n",
            "dice_loss:-0.882189\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:138\n",
            "loss(total):-0.004393\n",
            "recons_loss:0.003747\n",
            "grad_loss:0.072673\n",
            "dice_loss:-0.886724\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:139\n",
            "loss(total):-0.004198\n",
            "recons_loss:0.003794\n",
            "grad_loss:0.091671\n",
            "dice_loss:-0.890916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:140\n",
            "loss(total):-0.002445\n",
            "recons_loss:0.005203\n",
            "grad_loss:0.107867\n",
            "dice_loss:-0.872656\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:141\n",
            "loss(total):-0.002489\n",
            "recons_loss:0.005292\n",
            "grad_loss:0.114548\n",
            "dice_loss:-0.892674\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:142\n",
            "loss(total):-0.003995\n",
            "recons_loss:0.004068\n",
            "grad_loss:0.084898\n",
            "dice_loss:-0.891223\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:143\n",
            "loss(total):-0.003613\n",
            "recons_loss:0.004320\n",
            "grad_loss:0.088818\n",
            "dice_loss:-0.882052\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:144\n",
            "loss(total):-0.004516\n",
            "recons_loss:0.003484\n",
            "grad_loss:0.092781\n",
            "dice_loss:-0.892774\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:145\n",
            "loss(total):-0.004769\n",
            "recons_loss:0.003361\n",
            "grad_loss:0.077557\n",
            "dice_loss:-0.890595\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:146\n",
            "loss(total):-0.004597\n",
            "recons_loss:0.003307\n",
            "grad_loss:0.090833\n",
            "dice_loss:-0.881214\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:147\n",
            "loss(total):-0.003033\n",
            "recons_loss:0.004657\n",
            "grad_loss:0.115419\n",
            "dice_loss:-0.884377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:148\n",
            "loss(total):-0.003665\n",
            "recons_loss:0.004113\n",
            "grad_loss:0.109428\n",
            "dice_loss:-0.887204\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:149\n",
            "loss(total):-0.003701\n",
            "recons_loss:0.004199\n",
            "grad_loss:0.091210\n",
            "dice_loss:-0.881174\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:150\n",
            "loss(total):-0.004842\n",
            "recons_loss:0.003048\n",
            "grad_loss:0.085353\n",
            "dice_loss:-0.874357\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:151\n",
            "loss(total):-0.003994\n",
            "recons_loss:0.003743\n",
            "grad_loss:0.095598\n",
            "dice_loss:-0.869317\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:152\n",
            "loss(total):-0.002167\n",
            "recons_loss:0.005472\n",
            "grad_loss:0.123873\n",
            "dice_loss:-0.887749\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:153\n",
            "loss(total):-0.003307\n",
            "recons_loss:0.004692\n",
            "grad_loss:0.093551\n",
            "dice_loss:-0.893505\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:154\n",
            "loss(total):-0.003458\n",
            "recons_loss:0.004485\n",
            "grad_loss:0.090393\n",
            "dice_loss:-0.884682\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:155\n",
            "loss(total):-0.002479\n",
            "recons_loss:0.005242\n",
            "grad_loss:0.115716\n",
            "dice_loss:-0.887741\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:156\n",
            "loss(total):-0.004928\n",
            "recons_loss:0.003066\n",
            "grad_loss:0.074484\n",
            "dice_loss:-0.873870\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:157\n",
            "loss(total):-0.002789\n",
            "recons_loss:0.004962\n",
            "grad_loss:0.115461\n",
            "dice_loss:-0.890530\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:158\n",
            "loss(total):-0.004725\n",
            "recons_loss:0.003355\n",
            "grad_loss:0.068824\n",
            "dice_loss:-0.876846\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:159\n",
            "loss(total):-0.003134\n",
            "recons_loss:0.004537\n",
            "grad_loss:0.111998\n",
            "dice_loss:-0.879089\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:160\n",
            "loss(total):-0.003372\n",
            "recons_loss:0.004602\n",
            "grad_loss:0.101376\n",
            "dice_loss:-0.898791\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:161\n",
            "loss(total):-0.004196\n",
            "recons_loss:0.003701\n",
            "grad_loss:0.090685\n",
            "dice_loss:-0.880365\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:162\n",
            "loss(total):-0.004508\n",
            "recons_loss:0.003681\n",
            "grad_loss:0.087186\n",
            "dice_loss:-0.906151\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:163\n",
            "loss(total):-0.000176\n",
            "recons_loss:0.006972\n",
            "grad_loss:0.159561\n",
            "dice_loss:-0.874294\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:164\n",
            "loss(total):-0.002878\n",
            "recons_loss:0.004884\n",
            "grad_loss:0.094554\n",
            "dice_loss:-0.870741\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:165\n",
            "loss(total):-0.004051\n",
            "recons_loss:0.003922\n",
            "grad_loss:0.094585\n",
            "dice_loss:-0.891916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:166\n",
            "loss(total):-0.002153\n",
            "recons_loss:0.005390\n",
            "grad_loss:0.123088\n",
            "dice_loss:-0.877364\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:167\n",
            "loss(total):-0.002941\n",
            "recons_loss:0.004738\n",
            "grad_loss:0.110227\n",
            "dice_loss:-0.878159\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:168\n",
            "loss(total):-0.003767\n",
            "recons_loss:0.004070\n",
            "grad_loss:0.102194\n",
            "dice_loss:-0.885920\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:169\n",
            "loss(total):-0.002118\n",
            "recons_loss:0.005759\n",
            "grad_loss:0.113128\n",
            "dice_loss:-0.900892\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:170\n",
            "loss(total):-0.003027\n",
            "recons_loss:0.004691\n",
            "grad_loss:0.113446\n",
            "dice_loss:-0.885277\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:171\n",
            "loss(total):-0.003110\n",
            "recons_loss:0.004756\n",
            "grad_loss:0.090436\n",
            "dice_loss:-0.877065\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:172\n",
            "loss(total):-0.002063\n",
            "recons_loss:0.005641\n",
            "grad_loss:0.121625\n",
            "dice_loss:-0.892044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:173\n",
            "loss(total):-0.004405\n",
            "recons_loss:0.003593\n",
            "grad_loss:0.093290\n",
            "dice_loss:-0.893125\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:174\n",
            "loss(total):-0.003137\n",
            "recons_loss:0.004504\n",
            "grad_loss:0.119645\n",
            "dice_loss:-0.883797\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:175\n",
            "loss(total):-0.002640\n",
            "recons_loss:0.005153\n",
            "grad_loss:0.111857\n",
            "dice_loss:-0.891151\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:176\n",
            "loss(total):-0.004830\n",
            "recons_loss:0.003400\n",
            "grad_loss:0.080742\n",
            "dice_loss:-0.903702\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:177\n",
            "loss(total):-0.004177\n",
            "recons_loss:0.003823\n",
            "grad_loss:0.091296\n",
            "dice_loss:-0.891282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:178\n",
            "loss(total):-0.003046\n",
            "recons_loss:0.004661\n",
            "grad_loss:0.108179\n",
            "dice_loss:-0.878892\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:179\n",
            "loss(total):-0.003646\n",
            "recons_loss:0.004297\n",
            "grad_loss:0.094821\n",
            "dice_loss:-0.889117\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:180\n",
            "loss(total):-0.003825\n",
            "recons_loss:0.004149\n",
            "grad_loss:0.111560\n",
            "dice_loss:-0.908997\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:181\n",
            "loss(total):-0.003623\n",
            "recons_loss:0.004283\n",
            "grad_loss:0.090101\n",
            "dice_loss:-0.880649\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:182\n",
            "loss(total):-0.003132\n",
            "recons_loss:0.004881\n",
            "grad_loss:0.086603\n",
            "dice_loss:-0.887955\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:183\n",
            "loss(total):-0.003904\n",
            "recons_loss:0.004102\n",
            "grad_loss:0.092759\n",
            "dice_loss:-0.893359\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:184\n",
            "loss(total):-0.003051\n",
            "recons_loss:0.004736\n",
            "grad_loss:0.101569\n",
            "dice_loss:-0.880323\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:185\n",
            "loss(total):-0.003690\n",
            "recons_loss:0.004167\n",
            "grad_loss:0.105485\n",
            "dice_loss:-0.891128\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:186\n",
            "loss(total):-0.004138\n",
            "recons_loss:0.003752\n",
            "grad_loss:0.105408\n",
            "dice_loss:-0.894433\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:187\n",
            "loss(total):-0.002072\n",
            "recons_loss:0.005519\n",
            "grad_loss:0.113198\n",
            "dice_loss:-0.872285\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:188\n",
            "loss(total):-0.001377\n",
            "recons_loss:0.006096\n",
            "grad_loss:0.115246\n",
            "dice_loss:-0.862497\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:189\n",
            "loss(total):-0.004047\n",
            "recons_loss:0.003993\n",
            "grad_loss:0.088197\n",
            "dice_loss:-0.892219\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:190\n",
            "loss(total):-0.002342\n",
            "recons_loss:0.005188\n",
            "grad_loss:0.130129\n",
            "dice_loss:-0.883137\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:191\n",
            "loss(total):-0.002607\n",
            "recons_loss:0.004919\n",
            "grad_loss:0.124512\n",
            "dice_loss:-0.877109\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:192\n",
            "loss(total):-0.003531\n",
            "recons_loss:0.004325\n",
            "grad_loss:0.102132\n",
            "dice_loss:-0.887742\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:193\n",
            "loss(total):-0.003993\n",
            "recons_loss:0.004015\n",
            "grad_loss:0.090773\n",
            "dice_loss:-0.891626\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:194\n",
            "loss(total):-0.004259\n",
            "recons_loss:0.003693\n",
            "grad_loss:0.086272\n",
            "dice_loss:-0.881460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:195\n",
            "loss(total):-0.003036\n",
            "recons_loss:0.004676\n",
            "grad_loss:0.106292\n",
            "dice_loss:-0.877515\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:196\n",
            "loss(total):-0.004788\n",
            "recons_loss:0.003327\n",
            "grad_loss:0.085877\n",
            "dice_loss:-0.897415\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:197\n",
            "loss(total):-0.003852\n",
            "recons_loss:0.004237\n",
            "grad_loss:0.093747\n",
            "dice_loss:-0.902617\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:198\n",
            "loss(total):-0.004144\n",
            "recons_loss:0.003723\n",
            "grad_loss:0.096041\n",
            "dice_loss:-0.882702\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:199\n",
            "loss(total):-0.004594\n",
            "recons_loss:0.003607\n",
            "grad_loss:0.083915\n",
            "dice_loss:-0.904015\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:200\n",
            "loss(total):-0.004388\n",
            "recons_loss:0.003475\n",
            "grad_loss:0.100828\n",
            "dice_loss:-0.887192\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:201\n",
            "loss(total):-0.003302\n",
            "recons_loss:0.004417\n",
            "grad_loss:0.106916\n",
            "dice_loss:-0.878761\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:202\n",
            "loss(total):-0.003061\n",
            "recons_loss:0.004660\n",
            "grad_loss:0.097667\n",
            "dice_loss:-0.869759\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:203\n",
            "loss(total):-0.005632\n",
            "recons_loss:0.002676\n",
            "grad_loss:0.061631\n",
            "dice_loss:-0.892447\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:204\n",
            "loss(total):-0.002787\n",
            "recons_loss:0.004974\n",
            "grad_loss:0.100246\n",
            "dice_loss:-0.876344\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:205\n",
            "loss(total):-0.002894\n",
            "recons_loss:0.004959\n",
            "grad_loss:0.103887\n",
            "dice_loss:-0.889169\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:206\n",
            "loss(total):-0.003310\n",
            "recons_loss:0.004665\n",
            "grad_loss:0.101417\n",
            "dice_loss:-0.898920\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:207\n",
            "loss(total):-0.004490\n",
            "recons_loss:0.003552\n",
            "grad_loss:0.083462\n",
            "dice_loss:-0.887755\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:208\n",
            "loss(total):-0.002850\n",
            "recons_loss:0.004705\n",
            "grad_loss:0.124866\n",
            "dice_loss:-0.880445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:209\n",
            "loss(total):-0.004867\n",
            "recons_loss:0.003291\n",
            "grad_loss:0.082832\n",
            "dice_loss:-0.898604\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:210\n",
            "loss(total):-0.003533\n",
            "recons_loss:0.004421\n",
            "grad_loss:0.106799\n",
            "dice_loss:-0.902196\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:211\n",
            "loss(total):-0.003530\n",
            "recons_loss:0.004528\n",
            "grad_loss:0.085924\n",
            "dice_loss:-0.891695\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:212\n",
            "loss(total):-0.002625\n",
            "recons_loss:0.005179\n",
            "grad_loss:0.113384\n",
            "dice_loss:-0.893787\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:213\n",
            "loss(total):-0.003749\n",
            "recons_loss:0.004200\n",
            "grad_loss:0.094377\n",
            "dice_loss:-0.889317\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:214\n",
            "loss(total):-0.002229\n",
            "recons_loss:0.005437\n",
            "grad_loss:0.117219\n",
            "dice_loss:-0.883827\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:215\n",
            "loss(total):-0.003933\n",
            "recons_loss:0.003971\n",
            "grad_loss:0.097179\n",
            "dice_loss:-0.887639\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:216\n",
            "loss(total):-0.003080\n",
            "recons_loss:0.004843\n",
            "grad_loss:0.097215\n",
            "dice_loss:-0.889535\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:217\n",
            "loss(total):-0.003434\n",
            "recons_loss:0.004457\n",
            "grad_loss:0.094421\n",
            "dice_loss:-0.883561\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:218\n",
            "loss(total):-0.003633\n",
            "recons_loss:0.004177\n",
            "grad_loss:0.092244\n",
            "dice_loss:-0.873252\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:219\n",
            "loss(total):-0.002070\n",
            "recons_loss:0.005514\n",
            "grad_loss:0.114069\n",
            "dice_loss:-0.872381\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:220\n",
            "loss(total):-0.003053\n",
            "recons_loss:0.004679\n",
            "grad_loss:0.114253\n",
            "dice_loss:-0.887377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:221\n",
            "loss(total):-0.003885\n",
            "recons_loss:0.004254\n",
            "grad_loss:0.085441\n",
            "dice_loss:-0.899257\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:222\n",
            "loss(total):-0.003724\n",
            "recons_loss:0.004233\n",
            "grad_loss:0.106179\n",
            "dice_loss:-0.901866\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:223\n",
            "loss(total):-0.002081\n",
            "recons_loss:0.005643\n",
            "grad_loss:0.113605\n",
            "dice_loss:-0.886032\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:224\n",
            "loss(total):-0.004474\n",
            "recons_loss:0.003427\n",
            "grad_loss:0.093066\n",
            "dice_loss:-0.883205\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:225\n",
            "loss(total):-0.001500\n",
            "recons_loss:0.006026\n",
            "grad_loss:0.135784\n",
            "dice_loss:-0.888390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:226\n",
            "loss(total):-0.002350\n",
            "recons_loss:0.005286\n",
            "grad_loss:0.118034\n",
            "dice_loss:-0.881628\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:227\n",
            "loss(total):-0.003495\n",
            "recons_loss:0.004434\n",
            "grad_loss:0.097897\n",
            "dice_loss:-0.890748\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:228\n",
            "loss(total):-0.003658\n",
            "recons_loss:0.004048\n",
            "grad_loss:0.102192\n",
            "dice_loss:-0.872759\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:229\n",
            "loss(total):-0.002889\n",
            "recons_loss:0.004659\n",
            "grad_loss:0.131712\n",
            "dice_loss:-0.886598\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:230\n",
            "loss(total):-0.002987\n",
            "recons_loss:0.004922\n",
            "grad_loss:0.094051\n",
            "dice_loss:-0.884910\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:231\n",
            "loss(total):-0.002975\n",
            "recons_loss:0.004761\n",
            "grad_loss:0.104645\n",
            "dice_loss:-0.878322\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:232\n",
            "loss(total):-0.002827\n",
            "recons_loss:0.004906\n",
            "grad_loss:0.110243\n",
            "dice_loss:-0.883578\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:233\n",
            "loss(total):-0.002895\n",
            "recons_loss:0.004814\n",
            "grad_loss:0.116827\n",
            "dice_loss:-0.887658\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:234\n",
            "loss(total):-0.003556\n",
            "recons_loss:0.004278\n",
            "grad_loss:0.101828\n",
            "dice_loss:-0.885220\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:235\n",
            "loss(total):-0.002682\n",
            "recons_loss:0.004843\n",
            "grad_loss:0.113798\n",
            "dice_loss:-0.866305\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:236\n",
            "loss(total):-0.004214\n",
            "recons_loss:0.003637\n",
            "grad_loss:0.097035\n",
            "dice_loss:-0.882060\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:237\n",
            "loss(total):-0.003871\n",
            "recons_loss:0.004050\n",
            "grad_loss:0.098682\n",
            "dice_loss:-0.890722\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:238\n",
            "loss(total):-0.002818\n",
            "recons_loss:0.005096\n",
            "grad_loss:0.092768\n",
            "dice_loss:-0.884131\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:239\n",
            "loss(total):-0.002894\n",
            "recons_loss:0.004744\n",
            "grad_loss:0.124522\n",
            "dice_loss:-0.888377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:240\n",
            "loss(total):-0.004403\n",
            "recons_loss:0.003799\n",
            "grad_loss:0.078818\n",
            "dice_loss:-0.899038\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:241\n",
            "loss(total):-0.004272\n",
            "recons_loss:0.003831\n",
            "grad_loss:0.090894\n",
            "dice_loss:-0.901175\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:242\n",
            "loss(total):-0.003667\n",
            "recons_loss:0.004405\n",
            "grad_loss:0.084303\n",
            "dice_loss:-0.891432\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:243\n",
            "loss(total):-0.004615\n",
            "recons_loss:0.003479\n",
            "grad_loss:0.084375\n",
            "dice_loss:-0.893854\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:244\n",
            "loss(total):-0.004124\n",
            "recons_loss:0.003991\n",
            "grad_loss:0.081811\n",
            "dice_loss:-0.893361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:245\n",
            "loss(total):-0.003221\n",
            "recons_loss:0.004666\n",
            "grad_loss:0.105544\n",
            "dice_loss:-0.894275\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:246\n",
            "loss(total):-0.003946\n",
            "recons_loss:0.004197\n",
            "grad_loss:0.085949\n",
            "dice_loss:-0.900237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:247\n",
            "loss(total):-0.004293\n",
            "recons_loss:0.003761\n",
            "grad_loss:0.087161\n",
            "dice_loss:-0.892571\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:248\n",
            "loss(total):-0.004007\n",
            "recons_loss:0.003950\n",
            "grad_loss:0.103389\n",
            "dice_loss:-0.899103\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:249\n",
            "loss(total):-0.004375\n",
            "recons_loss:0.003710\n",
            "grad_loss:0.082826\n",
            "dice_loss:-0.891340\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:250\n",
            "loss(total):-0.003773\n",
            "recons_loss:0.003950\n",
            "grad_loss:0.097731\n",
            "dice_loss:-0.870047\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:251\n",
            "loss(total):-0.004895\n",
            "recons_loss:0.003285\n",
            "grad_loss:0.079632\n",
            "dice_loss:-0.897619\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:252\n",
            "loss(total):-0.003833\n",
            "recons_loss:0.004142\n",
            "grad_loss:0.102549\n",
            "dice_loss:-0.900099\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:253\n",
            "loss(total):-0.001691\n",
            "recons_loss:0.005602\n",
            "grad_loss:0.146527\n",
            "dice_loss:-0.875857\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:254\n",
            "loss(total):-0.003725\n",
            "recons_loss:0.004260\n",
            "grad_loss:0.092959\n",
            "dice_loss:-0.891421\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:255\n",
            "loss(total):-0.002497\n",
            "recons_loss:0.005221\n",
            "grad_loss:0.129663\n",
            "dice_loss:-0.901445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:256\n",
            "loss(total):-0.004237\n",
            "recons_loss:0.003746\n",
            "grad_loss:0.085984\n",
            "dice_loss:-0.884247\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:257\n",
            "loss(total):-0.004187\n",
            "recons_loss:0.003926\n",
            "grad_loss:0.099269\n",
            "dice_loss:-0.910620\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:258\n",
            "loss(total):-0.004483\n",
            "recons_loss:0.003417\n",
            "grad_loss:0.084150\n",
            "dice_loss:-0.874170\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:259\n",
            "loss(total):-0.002406\n",
            "recons_loss:0.005190\n",
            "grad_loss:0.119212\n",
            "dice_loss:-0.878878\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:260\n",
            "loss(total):-0.002057\n",
            "recons_loss:0.005498\n",
            "grad_loss:0.114641\n",
            "dice_loss:-0.870135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:261\n",
            "loss(total):-0.003604\n",
            "recons_loss:0.004338\n",
            "grad_loss:0.094385\n",
            "dice_loss:-0.888589\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:262\n",
            "loss(total):-0.003499\n",
            "recons_loss:0.004248\n",
            "grad_loss:0.107495\n",
            "dice_loss:-0.882189\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:263\n",
            "loss(total):-0.003742\n",
            "recons_loss:0.004165\n",
            "grad_loss:0.100827\n",
            "dice_loss:-0.891476\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:264\n",
            "loss(total):-0.004360\n",
            "recons_loss:0.003601\n",
            "grad_loss:0.101409\n",
            "dice_loss:-0.897539\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:265\n",
            "loss(total):-0.002310\n",
            "recons_loss:0.005456\n",
            "grad_loss:0.106526\n",
            "dice_loss:-0.883112\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:266\n",
            "loss(total):-0.002870\n",
            "recons_loss:0.004845\n",
            "grad_loss:0.111685\n",
            "dice_loss:-0.883174\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:267\n",
            "loss(total):-0.003937\n",
            "recons_loss:0.003907\n",
            "grad_loss:0.092180\n",
            "dice_loss:-0.876578\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:268\n",
            "loss(total):-0.002567\n",
            "recons_loss:0.005154\n",
            "grad_loss:0.101449\n",
            "dice_loss:-0.873502\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:269\n",
            "loss(total):-0.004105\n",
            "recons_loss:0.003970\n",
            "grad_loss:0.091125\n",
            "dice_loss:-0.898533\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:0\n",
            "loss(total):-0.002940\n",
            "recons_loss:0.004606\n",
            "grad_loss:0.116075\n",
            "dice_loss:-0.870647\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:1\n",
            "loss(total):-0.002778\n",
            "recons_loss:0.004988\n",
            "grad_loss:0.114423\n",
            "dice_loss:-0.891102\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:2\n",
            "loss(total):-0.004438\n",
            "recons_loss:0.003589\n",
            "grad_loss:0.082146\n",
            "dice_loss:-0.884786\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:3\n",
            "loss(total):-0.002310\n",
            "recons_loss:0.005372\n",
            "grad_loss:0.117619\n",
            "dice_loss:-0.885808\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:4\n",
            "loss(total):-0.004364\n",
            "recons_loss:0.003718\n",
            "grad_loss:0.096432\n",
            "dice_loss:-0.904641\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:5\n",
            "loss(total):-0.004569\n",
            "recons_loss:0.003353\n",
            "grad_loss:0.088062\n",
            "dice_loss:-0.880300\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:6\n",
            "loss(total):-0.003181\n",
            "recons_loss:0.004515\n",
            "grad_loss:0.122190\n",
            "dice_loss:-0.891725\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:7\n",
            "loss(total):-0.003642\n",
            "recons_loss:0.004421\n",
            "grad_loss:0.094231\n",
            "dice_loss:-0.900472\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:8\n",
            "loss(total):-0.004195\n",
            "recons_loss:0.003804\n",
            "grad_loss:0.079351\n",
            "dice_loss:-0.879178\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:9\n",
            "loss(total):-0.003690\n",
            "recons_loss:0.004180\n",
            "grad_loss:0.094251\n",
            "dice_loss:-0.881282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:10\n",
            "loss(total):-0.004344\n",
            "recons_loss:0.003769\n",
            "grad_loss:0.095020\n",
            "dice_loss:-0.906301\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:11\n",
            "loss(total):-0.003206\n",
            "recons_loss:0.004487\n",
            "grad_loss:0.121000\n",
            "dice_loss:-0.890278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:12\n",
            "loss(total):-0.003154\n",
            "recons_loss:0.004468\n",
            "grad_loss:0.119510\n",
            "dice_loss:-0.881683\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:13\n",
            "loss(total):-0.004163\n",
            "recons_loss:0.003802\n",
            "grad_loss:0.091115\n",
            "dice_loss:-0.887577\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:14\n",
            "loss(total):-0.003998\n",
            "recons_loss:0.004024\n",
            "grad_loss:0.090561\n",
            "dice_loss:-0.892784\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:15\n",
            "loss(total):-0.004095\n",
            "recons_loss:0.004106\n",
            "grad_loss:0.084335\n",
            "dice_loss:-0.904435\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:16\n",
            "loss(total):-0.003110\n",
            "recons_loss:0.004778\n",
            "grad_loss:0.089686\n",
            "dice_loss:-0.878535\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:17\n",
            "loss(total):-0.004330\n",
            "recons_loss:0.003644\n",
            "grad_loss:0.088053\n",
            "dice_loss:-0.885423\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:18\n",
            "loss(total):-0.003342\n",
            "recons_loss:0.004475\n",
            "grad_loss:0.104217\n",
            "dice_loss:-0.885928\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:19\n",
            "loss(total):-0.004553\n",
            "recons_loss:0.003503\n",
            "grad_loss:0.079611\n",
            "dice_loss:-0.885223\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:20\n",
            "loss(total):-0.002635\n",
            "recons_loss:0.004945\n",
            "grad_loss:0.121209\n",
            "dice_loss:-0.879214\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:21\n",
            "loss(total):-0.003406\n",
            "recons_loss:0.004648\n",
            "grad_loss:0.079506\n",
            "dice_loss:-0.884899\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:22\n",
            "loss(total):-0.004578\n",
            "recons_loss:0.003583\n",
            "grad_loss:0.074115\n",
            "dice_loss:-0.890237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:23\n",
            "loss(total):-0.002220\n",
            "recons_loss:0.005159\n",
            "grad_loss:0.127983\n",
            "dice_loss:-0.865823\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:24\n",
            "loss(total):-0.004282\n",
            "recons_loss:0.003728\n",
            "grad_loss:0.103426\n",
            "dice_loss:-0.904398\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:25\n",
            "loss(total):-0.002323\n",
            "recons_loss:0.005263\n",
            "grad_loss:0.118225\n",
            "dice_loss:-0.876783\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:26\n",
            "loss(total):-0.003581\n",
            "recons_loss:0.004433\n",
            "grad_loss:0.094283\n",
            "dice_loss:-0.895608\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:27\n",
            "loss(total):-0.003642\n",
            "recons_loss:0.004100\n",
            "grad_loss:0.095092\n",
            "dice_loss:-0.869292\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:28\n",
            "loss(total):-0.003782\n",
            "recons_loss:0.004039\n",
            "grad_loss:0.097099\n",
            "dice_loss:-0.879232\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:29\n",
            "loss(total):-0.003673\n",
            "recons_loss:0.004268\n",
            "grad_loss:0.096440\n",
            "dice_loss:-0.890609\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:30\n",
            "loss(total):-0.003337\n",
            "recons_loss:0.004414\n",
            "grad_loss:0.108176\n",
            "dice_loss:-0.883278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:31\n",
            "loss(total):-0.003333\n",
            "recons_loss:0.004558\n",
            "grad_loss:0.106773\n",
            "dice_loss:-0.895840\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:32\n",
            "loss(total):-0.003658\n",
            "recons_loss:0.004126\n",
            "grad_loss:0.098676\n",
            "dice_loss:-0.877072\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:33\n",
            "loss(total):-0.004851\n",
            "recons_loss:0.003162\n",
            "grad_loss:0.096868\n",
            "dice_loss:-0.898200\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:34\n",
            "loss(total):-0.003552\n",
            "recons_loss:0.004582\n",
            "grad_loss:0.088733\n",
            "dice_loss:-0.902086\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:35\n",
            "loss(total):-0.003138\n",
            "recons_loss:0.004674\n",
            "grad_loss:0.105357\n",
            "dice_loss:-0.886638\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:36\n",
            "loss(total):-0.003804\n",
            "recons_loss:0.004257\n",
            "grad_loss:0.098268\n",
            "dice_loss:-0.904308\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:37\n",
            "loss(total):-0.003680\n",
            "recons_loss:0.004350\n",
            "grad_loss:0.095464\n",
            "dice_loss:-0.898518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:38\n",
            "loss(total):-0.003924\n",
            "recons_loss:0.003967\n",
            "grad_loss:0.091552\n",
            "dice_loss:-0.880725\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:39\n",
            "loss(total):-0.003103\n",
            "recons_loss:0.004734\n",
            "grad_loss:0.107141\n",
            "dice_loss:-0.890832\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:40\n",
            "loss(total):-0.000900\n",
            "recons_loss:0.006555\n",
            "grad_loss:0.128159\n",
            "dice_loss:-0.873633\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:41\n",
            "loss(total):-0.003456\n",
            "recons_loss:0.004404\n",
            "grad_loss:0.100301\n",
            "dice_loss:-0.886322\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:42\n",
            "loss(total):-0.004436\n",
            "recons_loss:0.003699\n",
            "grad_loss:0.082355\n",
            "dice_loss:-0.895823\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:43\n",
            "loss(total):-0.002995\n",
            "recons_loss:0.004684\n",
            "grad_loss:0.111446\n",
            "dice_loss:-0.879349\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:44\n",
            "loss(total):-0.003589\n",
            "recons_loss:0.004330\n",
            "grad_loss:0.094110\n",
            "dice_loss:-0.885941\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:45\n",
            "loss(total):-0.003374\n",
            "recons_loss:0.004268\n",
            "grad_loss:0.109658\n",
            "dice_loss:-0.873883\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:46\n",
            "loss(total):-0.003536\n",
            "recons_loss:0.004307\n",
            "grad_loss:0.107926\n",
            "dice_loss:-0.892284\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:47\n",
            "loss(total):-0.003292\n",
            "recons_loss:0.004561\n",
            "grad_loss:0.111445\n",
            "dice_loss:-0.896771\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:48\n",
            "loss(total):-0.003912\n",
            "recons_loss:0.003971\n",
            "grad_loss:0.090654\n",
            "dice_loss:-0.878937\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:49\n",
            "loss(total):-0.001880\n",
            "recons_loss:0.005716\n",
            "grad_loss:0.119580\n",
            "dice_loss:-0.879213\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:50\n",
            "loss(total):-0.003255\n",
            "recons_loss:0.004492\n",
            "grad_loss:0.115536\n",
            "dice_loss:-0.890238\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:51\n",
            "loss(total):-0.003422\n",
            "recons_loss:0.004425\n",
            "grad_loss:0.105276\n",
            "dice_loss:-0.889966\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:52\n",
            "loss(total):-0.002895\n",
            "recons_loss:0.004665\n",
            "grad_loss:0.111637\n",
            "dice_loss:-0.867642\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:53\n",
            "loss(total):-0.004139\n",
            "recons_loss:0.003842\n",
            "grad_loss:0.086959\n",
            "dice_loss:-0.885130\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:54\n",
            "loss(total):-0.002827\n",
            "recons_loss:0.005034\n",
            "grad_loss:0.101455\n",
            "dice_loss:-0.887600\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:55\n",
            "loss(total):-0.003810\n",
            "recons_loss:0.004096\n",
            "grad_loss:0.094427\n",
            "dice_loss:-0.884979\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:56\n",
            "loss(total):-0.002889\n",
            "recons_loss:0.004982\n",
            "grad_loss:0.100968\n",
            "dice_loss:-0.888119\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:57\n",
            "loss(total):-0.004435\n",
            "recons_loss:0.003587\n",
            "grad_loss:0.079969\n",
            "dice_loss:-0.882239\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:58\n",
            "loss(total):-0.004548\n",
            "recons_loss:0.003572\n",
            "grad_loss:0.075577\n",
            "dice_loss:-0.887579\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:59\n",
            "loss(total):-0.003393\n",
            "recons_loss:0.004609\n",
            "grad_loss:0.092572\n",
            "dice_loss:-0.892813\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:60\n",
            "loss(total):-0.004548\n",
            "recons_loss:0.003587\n",
            "grad_loss:0.085736\n",
            "dice_loss:-0.899240\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:61\n",
            "loss(total):-0.001893\n",
            "recons_loss:0.005732\n",
            "grad_loss:0.127101\n",
            "dice_loss:-0.889576\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:62\n",
            "loss(total):-0.003670\n",
            "recons_loss:0.004153\n",
            "grad_loss:0.107168\n",
            "dice_loss:-0.889496\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:63\n",
            "loss(total):-0.003986\n",
            "recons_loss:0.003976\n",
            "grad_loss:0.091921\n",
            "dice_loss:-0.888116\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:64\n",
            "loss(total):-0.003143\n",
            "recons_loss:0.004535\n",
            "grad_loss:0.113237\n",
            "dice_loss:-0.881054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:65\n",
            "loss(total):-0.002653\n",
            "recons_loss:0.004997\n",
            "grad_loss:0.104284\n",
            "dice_loss:-0.869313\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:66\n",
            "loss(total):-0.004250\n",
            "recons_loss:0.003703\n",
            "grad_loss:0.094793\n",
            "dice_loss:-0.890104\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:67\n",
            "loss(total):-0.003350\n",
            "recons_loss:0.004485\n",
            "grad_loss:0.098634\n",
            "dice_loss:-0.882182\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:68\n",
            "loss(total):-0.004469\n",
            "recons_loss:0.003611\n",
            "grad_loss:0.084280\n",
            "dice_loss:-0.892237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:69\n",
            "loss(total):-0.002188\n",
            "recons_loss:0.005441\n",
            "grad_loss:0.120954\n",
            "dice_loss:-0.883791\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:70\n",
            "loss(total):-0.003686\n",
            "recons_loss:0.004243\n",
            "grad_loss:0.101424\n",
            "dice_loss:-0.894331\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:71\n",
            "loss(total):-0.002635\n",
            "recons_loss:0.005039\n",
            "grad_loss:0.122909\n",
            "dice_loss:-0.890285\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:72\n",
            "loss(total):-0.002832\n",
            "recons_loss:0.004902\n",
            "grad_loss:0.113285\n",
            "dice_loss:-0.886687\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:73\n",
            "loss(total):-0.003364\n",
            "recons_loss:0.004419\n",
            "grad_loss:0.109827\n",
            "dice_loss:-0.888163\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:74\n",
            "loss(total):-0.002279\n",
            "recons_loss:0.005236\n",
            "grad_loss:0.126561\n",
            "dice_loss:-0.878089\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:75\n",
            "loss(total):-0.002815\n",
            "recons_loss:0.004834\n",
            "grad_loss:0.108874\n",
            "dice_loss:-0.873763\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:76\n",
            "loss(total):-0.003888\n",
            "recons_loss:0.004154\n",
            "grad_loss:0.093892\n",
            "dice_loss:-0.898135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:77\n",
            "loss(total):-0.002609\n",
            "recons_loss:0.005150\n",
            "grad_loss:0.110370\n",
            "dice_loss:-0.886287\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:78\n",
            "loss(total):-0.003821\n",
            "recons_loss:0.004151\n",
            "grad_loss:0.102641\n",
            "dice_loss:-0.899827\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:79\n",
            "loss(total):-0.003572\n",
            "recons_loss:0.004299\n",
            "grad_loss:0.097030\n",
            "dice_loss:-0.884153\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:80\n",
            "loss(total):-0.004160\n",
            "recons_loss:0.003954\n",
            "grad_loss:0.077796\n",
            "dice_loss:-0.889115\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:81\n",
            "loss(total):-0.003459\n",
            "recons_loss:0.004342\n",
            "grad_loss:0.092636\n",
            "dice_loss:-0.872693\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:82\n",
            "loss(total):-0.003435\n",
            "recons_loss:0.004606\n",
            "grad_loss:0.090534\n",
            "dice_loss:-0.894636\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:83\n",
            "loss(total):-0.004789\n",
            "recons_loss:0.003524\n",
            "grad_loss:0.067686\n",
            "dice_loss:-0.898980\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:84\n",
            "loss(total):-0.002907\n",
            "recons_loss:0.004660\n",
            "grad_loss:0.125099\n",
            "dice_loss:-0.881757\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:85\n",
            "loss(total):-0.003692\n",
            "recons_loss:0.004141\n",
            "grad_loss:0.107267\n",
            "dice_loss:-0.890607\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:86\n",
            "loss(total):-0.002397\n",
            "recons_loss:0.005234\n",
            "grad_loss:0.117829\n",
            "dice_loss:-0.880898\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:87\n",
            "loss(total):-0.003982\n",
            "recons_loss:0.003974\n",
            "grad_loss:0.100937\n",
            "dice_loss:-0.896540\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:88\n",
            "loss(total):-0.003313\n",
            "recons_loss:0.004452\n",
            "grad_loss:0.114486\n",
            "dice_loss:-0.890953\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:89\n",
            "loss(total):-0.001905\n",
            "recons_loss:0.005472\n",
            "grad_loss:0.144999\n",
            "dice_loss:-0.882659\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:90\n",
            "loss(total):-0.003340\n",
            "recons_loss:0.004478\n",
            "grad_loss:0.116436\n",
            "dice_loss:-0.898204\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:91\n",
            "loss(total):-0.003438\n",
            "recons_loss:0.004484\n",
            "grad_loss:0.096016\n",
            "dice_loss:-0.888213\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:92\n",
            "loss(total):-0.005056\n",
            "recons_loss:0.003299\n",
            "grad_loss:0.071150\n",
            "dice_loss:-0.906656\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:93\n",
            "loss(total):-0.003784\n",
            "recons_loss:0.004265\n",
            "grad_loss:0.084535\n",
            "dice_loss:-0.889439\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:94\n",
            "loss(total):-0.005134\n",
            "recons_loss:0.003063\n",
            "grad_loss:0.075158\n",
            "dice_loss:-0.894857\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:95\n",
            "loss(total):-0.005213\n",
            "recons_loss:0.002996\n",
            "grad_loss:0.080558\n",
            "dice_loss:-0.901502\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:96\n",
            "loss(total):-0.002465\n",
            "recons_loss:0.005281\n",
            "grad_loss:0.116931\n",
            "dice_loss:-0.891485\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:97\n",
            "loss(total):-0.003066\n",
            "recons_loss:0.004628\n",
            "grad_loss:0.114873\n",
            "dice_loss:-0.884232\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:98\n",
            "loss(total):-0.002773\n",
            "recons_loss:0.004944\n",
            "grad_loss:0.112780\n",
            "dice_loss:-0.884417\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:99\n",
            "loss(total):-0.003188\n",
            "recons_loss:0.004789\n",
            "grad_loss:0.094443\n",
            "dice_loss:-0.892117\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:100\n",
            "loss(total):-0.003851\n",
            "recons_loss:0.004225\n",
            "grad_loss:0.085661\n",
            "dice_loss:-0.893249\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:101\n",
            "loss(total):-0.003154\n",
            "recons_loss:0.004490\n",
            "grad_loss:0.102071\n",
            "dice_loss:-0.866484\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:102\n",
            "loss(total):-0.002985\n",
            "recons_loss:0.004686\n",
            "grad_loss:0.117725\n",
            "dice_loss:-0.884772\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:103\n",
            "loss(total):-0.003533\n",
            "recons_loss:0.004147\n",
            "grad_loss:0.117667\n",
            "dice_loss:-0.885664\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:104\n",
            "loss(total):-0.002074\n",
            "recons_loss:0.005326\n",
            "grad_loss:0.114157\n",
            "dice_loss:-0.854108\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:105\n",
            "loss(total):-0.004642\n",
            "recons_loss:0.003590\n",
            "grad_loss:0.076696\n",
            "dice_loss:-0.899962\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:106\n",
            "loss(total):-0.002252\n",
            "recons_loss:0.005316\n",
            "grad_loss:0.122042\n",
            "dice_loss:-0.878773\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:107\n",
            "loss(total):-0.003724\n",
            "recons_loss:0.004120\n",
            "grad_loss:0.093369\n",
            "dice_loss:-0.877782\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:108\n",
            "loss(total):-0.003219\n",
            "recons_loss:0.004727\n",
            "grad_loss:0.093836\n",
            "dice_loss:-0.888389\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:109\n",
            "loss(total):-0.003596\n",
            "recons_loss:0.004356\n",
            "grad_loss:0.085321\n",
            "dice_loss:-0.880513\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:110\n",
            "loss(total):-0.003989\n",
            "recons_loss:0.004039\n",
            "grad_loss:0.078925\n",
            "dice_loss:-0.881767\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:111\n",
            "loss(total):-0.003900\n",
            "recons_loss:0.004150\n",
            "grad_loss:0.083330\n",
            "dice_loss:-0.888345\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:112\n",
            "loss(total):-0.004206\n",
            "recons_loss:0.004006\n",
            "grad_loss:0.084322\n",
            "dice_loss:-0.905476\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:113\n",
            "loss(total):-0.002601\n",
            "recons_loss:0.005086\n",
            "grad_loss:0.115748\n",
            "dice_loss:-0.884382\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:114\n",
            "loss(total):-0.003009\n",
            "recons_loss:0.004784\n",
            "grad_loss:0.110351\n",
            "dice_loss:-0.889570\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:115\n",
            "loss(total):-0.004649\n",
            "recons_loss:0.003305\n",
            "grad_loss:0.082601\n",
            "dice_loss:-0.878075\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:116\n",
            "loss(total):-0.003350\n",
            "recons_loss:0.004308\n",
            "grad_loss:0.131293\n",
            "dice_loss:-0.897091\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:117\n",
            "loss(total):-0.003778\n",
            "recons_loss:0.004273\n",
            "grad_loss:0.087719\n",
            "dice_loss:-0.892884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:118\n",
            "loss(total):-0.004163\n",
            "recons_loss:0.003957\n",
            "grad_loss:0.081944\n",
            "dice_loss:-0.893909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:119\n",
            "loss(total):-0.004005\n",
            "recons_loss:0.004129\n",
            "grad_loss:0.080750\n",
            "dice_loss:-0.894125\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:120\n",
            "loss(total):-0.003319\n",
            "recons_loss:0.004476\n",
            "grad_loss:0.111093\n",
            "dice_loss:-0.890613\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:121\n",
            "loss(total):-0.002760\n",
            "recons_loss:0.004972\n",
            "grad_loss:0.115412\n",
            "dice_loss:-0.888572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:122\n",
            "loss(total):-0.003006\n",
            "recons_loss:0.004719\n",
            "grad_loss:0.114032\n",
            "dice_loss:-0.886446\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:123\n",
            "loss(total):-0.003717\n",
            "recons_loss:0.004012\n",
            "grad_loss:0.107859\n",
            "dice_loss:-0.880723\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:124\n",
            "loss(total):-0.005699\n",
            "recons_loss:0.002556\n",
            "grad_loss:0.079233\n",
            "dice_loss:-0.904761\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:125\n",
            "loss(total):-0.003367\n",
            "recons_loss:0.004595\n",
            "grad_loss:0.098776\n",
            "dice_loss:-0.894963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:126\n",
            "loss(total):-0.003676\n",
            "recons_loss:0.004133\n",
            "grad_loss:0.093506\n",
            "dice_loss:-0.874419\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:127\n",
            "loss(total):-0.003746\n",
            "recons_loss:0.004046\n",
            "grad_loss:0.096376\n",
            "dice_loss:-0.875578\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:128\n",
            "loss(total):-0.003889\n",
            "recons_loss:0.004066\n",
            "grad_loss:0.094543\n",
            "dice_loss:-0.890101\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:129\n",
            "loss(total):-0.001777\n",
            "recons_loss:0.005738\n",
            "grad_loss:0.130550\n",
            "dice_loss:-0.882062\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:130\n",
            "loss(total):-0.004223\n",
            "recons_loss:0.003737\n",
            "grad_loss:0.087478\n",
            "dice_loss:-0.883444\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:131\n",
            "loss(total):-0.003853\n",
            "recons_loss:0.004179\n",
            "grad_loss:0.090277\n",
            "dice_loss:-0.893507\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:132\n",
            "loss(total):-0.003687\n",
            "recons_loss:0.004321\n",
            "grad_loss:0.084151\n",
            "dice_loss:-0.884987\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:133\n",
            "loss(total):-0.003499\n",
            "recons_loss:0.004384\n",
            "grad_loss:0.096949\n",
            "dice_loss:-0.885202\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:134\n",
            "loss(total):-0.003732\n",
            "recons_loss:0.004187\n",
            "grad_loss:0.095953\n",
            "dice_loss:-0.887842\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:135\n",
            "loss(total):-0.003927\n",
            "recons_loss:0.003931\n",
            "grad_loss:0.112244\n",
            "dice_loss:-0.898007\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:136\n",
            "loss(total):-0.003569\n",
            "recons_loss:0.004278\n",
            "grad_loss:0.105823\n",
            "dice_loss:-0.890529\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:137\n",
            "loss(total):-0.003640\n",
            "recons_loss:0.004484\n",
            "grad_loss:0.076659\n",
            "dice_loss:-0.888988\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:138\n",
            "loss(total):-0.003826\n",
            "recons_loss:0.004023\n",
            "grad_loss:0.105436\n",
            "dice_loss:-0.890311\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:139\n",
            "loss(total):-0.004053\n",
            "recons_loss:0.003922\n",
            "grad_loss:0.088468\n",
            "dice_loss:-0.886010\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:140\n",
            "loss(total):-0.001941\n",
            "recons_loss:0.005676\n",
            "grad_loss:0.130084\n",
            "dice_loss:-0.891753\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:141\n",
            "loss(total):-0.004688\n",
            "recons_loss:0.003408\n",
            "grad_loss:0.091753\n",
            "dice_loss:-0.901393\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:142\n",
            "loss(total):-0.003069\n",
            "recons_loss:0.004783\n",
            "grad_loss:0.124996\n",
            "dice_loss:-0.910240\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:143\n",
            "loss(total):-0.003494\n",
            "recons_loss:0.004236\n",
            "grad_loss:0.111564\n",
            "dice_loss:-0.884552\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:144\n",
            "loss(total):-0.003304\n",
            "recons_loss:0.004583\n",
            "grad_loss:0.095776\n",
            "dice_loss:-0.884516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:145\n",
            "loss(total):-0.001832\n",
            "recons_loss:0.005757\n",
            "grad_loss:0.114666\n",
            "dice_loss:-0.873554\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:146\n",
            "loss(total):-0.003634\n",
            "recons_loss:0.004035\n",
            "grad_loss:0.097786\n",
            "dice_loss:-0.864668\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:147\n",
            "loss(total):-0.004454\n",
            "recons_loss:0.003543\n",
            "grad_loss:0.080510\n",
            "dice_loss:-0.880163\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:148\n",
            "loss(total):-0.002977\n",
            "recons_loss:0.004621\n",
            "grad_loss:0.128372\n",
            "dice_loss:-0.888247\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:149\n",
            "loss(total):-0.004687\n",
            "recons_loss:0.003429\n",
            "grad_loss:0.081256\n",
            "dice_loss:-0.892828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:150\n",
            "loss(total):-0.005053\n",
            "recons_loss:0.003097\n",
            "grad_loss:0.080772\n",
            "dice_loss:-0.895771\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:151\n",
            "loss(total):-0.003826\n",
            "recons_loss:0.003942\n",
            "grad_loss:0.098586\n",
            "dice_loss:-0.875380\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:152\n",
            "loss(total):-0.002563\n",
            "recons_loss:0.005052\n",
            "grad_loss:0.097952\n",
            "dice_loss:-0.859522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:153\n",
            "loss(total):-0.003103\n",
            "recons_loss:0.004757\n",
            "grad_loss:0.101452\n",
            "dice_loss:-0.887436\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:154\n",
            "loss(total):-0.003889\n",
            "recons_loss:0.004251\n",
            "grad_loss:0.080418\n",
            "dice_loss:-0.894444\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:155\n",
            "loss(total):-0.002695\n",
            "recons_loss:0.005147\n",
            "grad_loss:0.093634\n",
            "dice_loss:-0.877759\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:156\n",
            "loss(total):-0.003401\n",
            "recons_loss:0.004400\n",
            "grad_loss:0.103319\n",
            "dice_loss:-0.883454\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:157\n",
            "loss(total):-0.004304\n",
            "recons_loss:0.003585\n",
            "grad_loss:0.087070\n",
            "dice_loss:-0.875923\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:158\n",
            "loss(total):-0.004432\n",
            "recons_loss:0.003632\n",
            "grad_loss:0.096494\n",
            "dice_loss:-0.902908\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:159\n",
            "loss(total):-0.003392\n",
            "recons_loss:0.004500\n",
            "grad_loss:0.104782\n",
            "dice_loss:-0.893922\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:160\n",
            "loss(total):-0.005145\n",
            "recons_loss:0.003203\n",
            "grad_loss:0.079133\n",
            "dice_loss:-0.913949\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:161\n",
            "loss(total):-0.004524\n",
            "recons_loss:0.003793\n",
            "grad_loss:0.069393\n",
            "dice_loss:-0.901025\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:162\n",
            "loss(total):-0.003914\n",
            "recons_loss:0.003961\n",
            "grad_loss:0.089525\n",
            "dice_loss:-0.877051\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:163\n",
            "loss(total):-0.003576\n",
            "recons_loss:0.004413\n",
            "grad_loss:0.106021\n",
            "dice_loss:-0.904929\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:164\n",
            "loss(total):-0.002912\n",
            "recons_loss:0.004977\n",
            "grad_loss:0.089749\n",
            "dice_loss:-0.878646\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:165\n",
            "loss(total):-0.004219\n",
            "recons_loss:0.003817\n",
            "grad_loss:0.086195\n",
            "dice_loss:-0.889770\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:166\n",
            "loss(total):-0.003474\n",
            "recons_loss:0.004154\n",
            "grad_loss:0.114883\n",
            "dice_loss:-0.877700\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:167\n",
            "loss(total):-0.004020\n",
            "recons_loss:0.003866\n",
            "grad_loss:0.102411\n",
            "dice_loss:-0.891062\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:168\n",
            "loss(total):-0.004580\n",
            "recons_loss:0.003571\n",
            "grad_loss:0.072049\n",
            "dice_loss:-0.887080\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:169\n",
            "loss(total):-0.004079\n",
            "recons_loss:0.004090\n",
            "grad_loss:0.085855\n",
            "dice_loss:-0.902753\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:170\n",
            "loss(total):-0.003847\n",
            "recons_loss:0.004165\n",
            "grad_loss:0.089528\n",
            "dice_loss:-0.890674\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:171\n",
            "loss(total):-0.003679\n",
            "recons_loss:0.004009\n",
            "grad_loss:0.099218\n",
            "dice_loss:-0.868089\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:172\n",
            "loss(total):-0.001878\n",
            "recons_loss:0.005719\n",
            "grad_loss:0.124343\n",
            "dice_loss:-0.883978\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:173\n",
            "loss(total):-0.002307\n",
            "recons_loss:0.005255\n",
            "grad_loss:0.108999\n",
            "dice_loss:-0.865230\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:174\n",
            "loss(total):-0.003060\n",
            "recons_loss:0.004648\n",
            "grad_loss:0.122938\n",
            "dice_loss:-0.893718\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:175\n",
            "loss(total):-0.003726\n",
            "recons_loss:0.004138\n",
            "grad_loss:0.086636\n",
            "dice_loss:-0.873031\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:176\n",
            "loss(total):-0.004133\n",
            "recons_loss:0.003774\n",
            "grad_loss:0.092345\n",
            "dice_loss:-0.883044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:177\n",
            "loss(total):-0.003503\n",
            "recons_loss:0.004437\n",
            "grad_loss:0.098825\n",
            "dice_loss:-0.892823\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:178\n",
            "loss(total):-0.003077\n",
            "recons_loss:0.004791\n",
            "grad_loss:0.107548\n",
            "dice_loss:-0.894368\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:179\n",
            "loss(total):-0.003758\n",
            "recons_loss:0.004144\n",
            "grad_loss:0.097505\n",
            "dice_loss:-0.887728\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:180\n",
            "loss(total):-0.002157\n",
            "recons_loss:0.005383\n",
            "grad_loss:0.129324\n",
            "dice_loss:-0.883318\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:181\n",
            "loss(total):-0.004193\n",
            "recons_loss:0.003823\n",
            "grad_loss:0.084438\n",
            "dice_loss:-0.886044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:182\n",
            "loss(total):-0.004227\n",
            "recons_loss:0.003818\n",
            "grad_loss:0.081339\n",
            "dice_loss:-0.885848\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:183\n",
            "loss(total):-0.004749\n",
            "recons_loss:0.003480\n",
            "grad_loss:0.074193\n",
            "dice_loss:-0.897118\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:184\n",
            "loss(total):-0.004197\n",
            "recons_loss:0.003730\n",
            "grad_loss:0.088397\n",
            "dice_loss:-0.881091\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:185\n",
            "loss(total):-0.003901\n",
            "recons_loss:0.004294\n",
            "grad_loss:0.080442\n",
            "dice_loss:-0.899982\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:186\n",
            "loss(total):-0.003272\n",
            "recons_loss:0.004567\n",
            "grad_loss:0.101819\n",
            "dice_loss:-0.885734\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:187\n",
            "loss(total):-0.003496\n",
            "recons_loss:0.004392\n",
            "grad_loss:0.117287\n",
            "dice_loss:-0.906068\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:188\n",
            "loss(total):-0.002968\n",
            "recons_loss:0.004636\n",
            "grad_loss:0.131486\n",
            "dice_loss:-0.891851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:189\n",
            "loss(total):-0.003851\n",
            "recons_loss:0.003837\n",
            "grad_loss:0.101939\n",
            "dice_loss:-0.870715\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:190\n",
            "loss(total):-0.003227\n",
            "recons_loss:0.004401\n",
            "grad_loss:0.104608\n",
            "dice_loss:-0.867448\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:191\n",
            "loss(total):-0.003990\n",
            "recons_loss:0.004045\n",
            "grad_loss:0.090386\n",
            "dice_loss:-0.893887\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:192\n",
            "loss(total):-0.004324\n",
            "recons_loss:0.003814\n",
            "grad_loss:0.082489\n",
            "dice_loss:-0.896264\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:193\n",
            "loss(total):-0.005068\n",
            "recons_loss:0.003065\n",
            "grad_loss:0.088915\n",
            "dice_loss:-0.902215\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:194\n",
            "loss(total):-0.003542\n",
            "recons_loss:0.004243\n",
            "grad_loss:0.092358\n",
            "dice_loss:-0.870938\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:195\n",
            "loss(total):-0.003587\n",
            "recons_loss:0.004498\n",
            "grad_loss:0.097331\n",
            "dice_loss:-0.905904\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:196\n",
            "loss(total):-0.003195\n",
            "recons_loss:0.004615\n",
            "grad_loss:0.117976\n",
            "dice_loss:-0.898982\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:197\n",
            "loss(total):-0.003817\n",
            "recons_loss:0.004129\n",
            "grad_loss:0.095410\n",
            "dice_loss:-0.890064\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:198\n",
            "loss(total):-0.004269\n",
            "recons_loss:0.003807\n",
            "grad_loss:0.087595\n",
            "dice_loss:-0.895248\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:199\n",
            "loss(total):-0.003925\n",
            "recons_loss:0.003966\n",
            "grad_loss:0.093754\n",
            "dice_loss:-0.882839\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:200\n",
            "loss(total):-0.003480\n",
            "recons_loss:0.004378\n",
            "grad_loss:0.103556\n",
            "dice_loss:-0.889270\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:201\n",
            "loss(total):-0.003591\n",
            "recons_loss:0.004183\n",
            "grad_loss:0.103952\n",
            "dice_loss:-0.881393\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:202\n",
            "loss(total):-0.003221\n",
            "recons_loss:0.004811\n",
            "grad_loss:0.095930\n",
            "dice_loss:-0.899181\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:203\n",
            "loss(total):-0.003942\n",
            "recons_loss:0.004207\n",
            "grad_loss:0.080934\n",
            "dice_loss:-0.895830\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:204\n",
            "loss(total):-0.003719\n",
            "recons_loss:0.004100\n",
            "grad_loss:0.104073\n",
            "dice_loss:-0.885969\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:205\n",
            "loss(total):-0.004013\n",
            "recons_loss:0.003918\n",
            "grad_loss:0.092369\n",
            "dice_loss:-0.885457\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:206\n",
            "loss(total):-0.005351\n",
            "recons_loss:0.002898\n",
            "grad_loss:0.078185\n",
            "dice_loss:-0.903069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:207\n",
            "loss(total):-0.003874\n",
            "recons_loss:0.004046\n",
            "grad_loss:0.091683\n",
            "dice_loss:-0.883663\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:208\n",
            "loss(total):-0.004471\n",
            "recons_loss:0.003630\n",
            "grad_loss:0.080842\n",
            "dice_loss:-0.890913\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:209\n",
            "loss(total):-0.003582\n",
            "recons_loss:0.004295\n",
            "grad_loss:0.102639\n",
            "dice_loss:-0.890349\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:210\n",
            "loss(total):-0.003203\n",
            "recons_loss:0.004532\n",
            "grad_loss:0.115414\n",
            "dice_loss:-0.888900\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:211\n",
            "loss(total):-0.002474\n",
            "recons_loss:0.005164\n",
            "grad_loss:0.113905\n",
            "dice_loss:-0.877692\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:212\n",
            "loss(total):-0.004454\n",
            "recons_loss:0.003527\n",
            "grad_loss:0.095148\n",
            "dice_loss:-0.893233\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:213\n",
            "loss(total):-0.002598\n",
            "recons_loss:0.004952\n",
            "grad_loss:0.122627\n",
            "dice_loss:-0.877670\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:214\n",
            "loss(total):-0.003844\n",
            "recons_loss:0.004186\n",
            "grad_loss:0.084563\n",
            "dice_loss:-0.887593\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:215\n",
            "loss(total):-0.001995\n",
            "recons_loss:0.005355\n",
            "grad_loss:0.143069\n",
            "dice_loss:-0.878049\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:216\n",
            "loss(total):-0.004109\n",
            "recons_loss:0.003833\n",
            "grad_loss:0.096886\n",
            "dice_loss:-0.891079\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:217\n",
            "loss(total):-0.005640\n",
            "recons_loss:0.002548\n",
            "grad_loss:0.075873\n",
            "dice_loss:-0.894665\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:218\n",
            "loss(total):-0.004043\n",
            "recons_loss:0.004047\n",
            "grad_loss:0.087056\n",
            "dice_loss:-0.896033\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:219\n",
            "loss(total):-0.003676\n",
            "recons_loss:0.004195\n",
            "grad_loss:0.094034\n",
            "dice_loss:-0.881100\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:220\n",
            "loss(total):-0.004514\n",
            "recons_loss:0.003708\n",
            "grad_loss:0.074038\n",
            "dice_loss:-0.896273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:221\n",
            "loss(total):-0.003446\n",
            "recons_loss:0.004391\n",
            "grad_loss:0.107777\n",
            "dice_loss:-0.891485\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:222\n",
            "loss(total):-0.001901\n",
            "recons_loss:0.005521\n",
            "grad_loss:0.134581\n",
            "dice_loss:-0.876850\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:223\n",
            "loss(total):-0.004329\n",
            "recons_loss:0.003746\n",
            "grad_loss:0.084799\n",
            "dice_loss:-0.892338\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:224\n",
            "loss(total):-0.003838\n",
            "recons_loss:0.004065\n",
            "grad_loss:0.093696\n",
            "dice_loss:-0.883974\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:225\n",
            "loss(total):-0.003032\n",
            "recons_loss:0.004635\n",
            "grad_loss:0.125732\n",
            "dice_loss:-0.892489\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:226\n",
            "loss(total):-0.003260\n",
            "recons_loss:0.004387\n",
            "grad_loss:0.132377\n",
            "dice_loss:-0.897101\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:227\n",
            "loss(total):-0.004365\n",
            "recons_loss:0.003696\n",
            "grad_loss:0.090808\n",
            "dice_loss:-0.896964\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:228\n",
            "loss(total):-0.003139\n",
            "recons_loss:0.004648\n",
            "grad_loss:0.114676\n",
            "dice_loss:-0.893342\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:229\n",
            "loss(total):-0.004297\n",
            "recons_loss:0.003777\n",
            "grad_loss:0.085460\n",
            "dice_loss:-0.892886\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:230\n",
            "loss(total):-0.003929\n",
            "recons_loss:0.003914\n",
            "grad_loss:0.097345\n",
            "dice_loss:-0.881649\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:231\n",
            "loss(total):-0.003889\n",
            "recons_loss:0.004131\n",
            "grad_loss:0.089663\n",
            "dice_loss:-0.891660\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:232\n",
            "loss(total):-0.004041\n",
            "recons_loss:0.004003\n",
            "grad_loss:0.084981\n",
            "dice_loss:-0.889417\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:233\n",
            "loss(total):-0.004054\n",
            "recons_loss:0.003914\n",
            "grad_loss:0.103624\n",
            "dice_loss:-0.900443\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:234\n",
            "loss(total):-0.004764\n",
            "recons_loss:0.003333\n",
            "grad_loss:0.080268\n",
            "dice_loss:-0.889976\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:235\n",
            "loss(total):-0.003064\n",
            "recons_loss:0.004661\n",
            "grad_loss:0.113194\n",
            "dice_loss:-0.885670\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:236\n",
            "loss(total):-0.003878\n",
            "recons_loss:0.004278\n",
            "grad_loss:0.078399\n",
            "dice_loss:-0.893943\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:237\n",
            "loss(total):-0.004471\n",
            "recons_loss:0.003617\n",
            "grad_loss:0.092148\n",
            "dice_loss:-0.900992\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:238\n",
            "loss(total):-0.004508\n",
            "recons_loss:0.003629\n",
            "grad_loss:0.076382\n",
            "dice_loss:-0.889984\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:239\n",
            "loss(total):-0.003525\n",
            "recons_loss:0.004360\n",
            "grad_loss:0.097928\n",
            "dice_loss:-0.886366\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:240\n",
            "loss(total):-0.003665\n",
            "recons_loss:0.003984\n",
            "grad_loss:0.117973\n",
            "dice_loss:-0.882864\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:241\n",
            "loss(total):-0.004911\n",
            "recons_loss:0.003278\n",
            "grad_loss:0.075532\n",
            "dice_loss:-0.894398\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:242\n",
            "loss(total):-0.002658\n",
            "recons_loss:0.004898\n",
            "grad_loss:0.122264\n",
            "dice_loss:-0.877889\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:243\n",
            "loss(total):-0.001311\n",
            "recons_loss:0.005971\n",
            "grad_loss:0.146182\n",
            "dice_loss:-0.874293\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:244\n",
            "loss(total):-0.001657\n",
            "recons_loss:0.006042\n",
            "grad_loss:0.123404\n",
            "dice_loss:-0.893259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:245\n",
            "loss(total):-0.003229\n",
            "recons_loss:0.004674\n",
            "grad_loss:0.092652\n",
            "dice_loss:-0.882958\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:246\n",
            "loss(total):-0.003484\n",
            "recons_loss:0.004553\n",
            "grad_loss:0.082025\n",
            "dice_loss:-0.885768\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:247\n",
            "loss(total):-0.004524\n",
            "recons_loss:0.003641\n",
            "grad_loss:0.083110\n",
            "dice_loss:-0.899579\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:248\n",
            "loss(total):-0.003742\n",
            "recons_loss:0.004140\n",
            "grad_loss:0.091026\n",
            "dice_loss:-0.879212\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:249\n",
            "loss(total):-0.004107\n",
            "recons_loss:0.004014\n",
            "grad_loss:0.080379\n",
            "dice_loss:-0.892389\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:250\n",
            "loss(total):-0.002297\n",
            "recons_loss:0.005286\n",
            "grad_loss:0.121252\n",
            "dice_loss:-0.879569\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:251\n",
            "loss(total):-0.003849\n",
            "recons_loss:0.003989\n",
            "grad_loss:0.107451\n",
            "dice_loss:-0.891218\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:252\n",
            "loss(total):-0.004059\n",
            "recons_loss:0.003873\n",
            "grad_loss:0.097927\n",
            "dice_loss:-0.891160\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:253\n",
            "loss(total):-0.004263\n",
            "recons_loss:0.003896\n",
            "grad_loss:0.082502\n",
            "dice_loss:-0.898428\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:254\n",
            "loss(total):-0.003141\n",
            "recons_loss:0.004746\n",
            "grad_loss:0.111933\n",
            "dice_loss:-0.900633\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:255\n",
            "loss(total):-0.001637\n",
            "recons_loss:0.005753\n",
            "grad_loss:0.137263\n",
            "dice_loss:-0.876277\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:256\n",
            "loss(total):-0.001766\n",
            "recons_loss:0.005628\n",
            "grad_loss:0.139200\n",
            "dice_loss:-0.878596\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:257\n",
            "loss(total):-0.004463\n",
            "recons_loss:0.003532\n",
            "grad_loss:0.090454\n",
            "dice_loss:-0.889968\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:258\n",
            "loss(total):-0.003756\n",
            "recons_loss:0.004171\n",
            "grad_loss:0.100601\n",
            "dice_loss:-0.893339\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:259\n",
            "loss(total):-0.004147\n",
            "recons_loss:0.003908\n",
            "grad_loss:0.091553\n",
            "dice_loss:-0.897000\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:260\n",
            "loss(total):-0.003500\n",
            "recons_loss:0.004430\n",
            "grad_loss:0.090021\n",
            "dice_loss:-0.883068\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:261\n",
            "loss(total):-0.004226\n",
            "recons_loss:0.003669\n",
            "grad_loss:0.103677\n",
            "dice_loss:-0.893233\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:262\n",
            "loss(total):-0.003596\n",
            "recons_loss:0.004144\n",
            "grad_loss:0.103431\n",
            "dice_loss:-0.877499\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:263\n",
            "loss(total):-0.003044\n",
            "recons_loss:0.004748\n",
            "grad_loss:0.095173\n",
            "dice_loss:-0.874352\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:264\n",
            "loss(total):-0.002494\n",
            "recons_loss:0.005224\n",
            "grad_loss:0.111154\n",
            "dice_loss:-0.882924\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:265\n",
            "loss(total):-0.004302\n",
            "recons_loss:0.003945\n",
            "grad_loss:0.073237\n",
            "dice_loss:-0.897879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:266\n",
            "loss(total):-0.003866\n",
            "recons_loss:0.003980\n",
            "grad_loss:0.100848\n",
            "dice_loss:-0.885432\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:267\n",
            "loss(total):-0.005961\n",
            "recons_loss:0.002494\n",
            "grad_loss:0.058139\n",
            "dice_loss:-0.903681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:268\n",
            "loss(total):-0.002425\n",
            "recons_loss:0.005210\n",
            "grad_loss:0.123013\n",
            "dice_loss:-0.886548\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:269\n",
            "loss(total):-0.001852\n",
            "recons_loss:0.005685\n",
            "grad_loss:0.136006\n",
            "dice_loss:-0.889647\n",
            "---------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__3RH1oq6dM7",
        "outputId": "351cffc9-0808-458f-9a06-289dec52674b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(losses_3[1:])\n",
        "plt.show"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnxwfWUV6hM5",
        "outputId": "f569306b-0e64-4d4b-afdc-a2cec33a7e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(validation_3)\n",
        "plt.show"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3BmANAP6sjq"
      },
      "source": [
        "import csv\n",
        "with open('validation_3.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAOBBjzhz9wS"
      },
      "source": [
        "for h in range(0,len(validation_0)):\n",
        "  with open('validation_3.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, validation_3[h].numpy()])"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6_bhgJkK0qx"
      },
      "source": [
        "import csv\n",
        "with open('loss_3.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n",
        "\n",
        "for h in range(0,len(losses_3)):\n",
        "  with open('loss_3.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h, losses_3[h].numpy()])"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pZVhduB6r0X"
      },
      "source": [
        "'''Training - hold out fold 4 for validation'''\n",
        "#Training\n",
        "gpu='0'\n",
        "atlas_file='/content/drive/My Drive/2020/Thesis/Data/atlas.npz'\n",
        "lr=1e-4\n",
        "n_iter=5000\n",
        "data_loss='mse'\n",
        "model='vm2'\n",
        "reg_param=0.01\n",
        "batch_size=10\n",
        "n_save_iter=100\n",
        "model_dir='/content/drive/My Drive/2020/Thesis/Data/validation_0/'\n",
        "valid = fold_4\n",
        "train_names = set_4\n",
        "EPOCH=30"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49J-mGtQ62cs",
        "outputId": "c204b8db-20b7-466c-9fbd-83bc3e0cc1e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses_4, validation_4=validate.train(data_dir,\n",
        "          train_names,\n",
        "          atlas_file,\n",
        "          lr,\n",
        "          data_loss,\n",
        "          model,\n",
        "          reg_param, \n",
        "          batch_size,\n",
        "          n_save_iter,\n",
        "          model_dir,Net(),EPOCH, valid)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch_number:185\n",
            "loss(total):-0.004319\n",
            "recons_loss:0.003478\n",
            "grad_loss:0.104997\n",
            "dice_loss:-0.884658\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:186\n",
            "loss(total):-0.002878\n",
            "recons_loss:0.004900\n",
            "grad_loss:0.103396\n",
            "dice_loss:-0.881262\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:187\n",
            "loss(total):-0.004564\n",
            "recons_loss:0.003548\n",
            "grad_loss:0.079176\n",
            "dice_loss:-0.890334\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:188\n",
            "loss(total):-0.002901\n",
            "recons_loss:0.004937\n",
            "grad_loss:0.098686\n",
            "dice_loss:-0.882466\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:189\n",
            "loss(total):-0.003784\n",
            "recons_loss:0.004131\n",
            "grad_loss:0.092360\n",
            "dice_loss:-0.883864\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:190\n",
            "loss(total):-0.002927\n",
            "recons_loss:0.004697\n",
            "grad_loss:0.093830\n",
            "dice_loss:-0.856158\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:191\n",
            "loss(total):-0.002681\n",
            "recons_loss:0.004957\n",
            "grad_loss:0.120783\n",
            "dice_loss:-0.884584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:192\n",
            "loss(total):-0.003462\n",
            "recons_loss:0.004505\n",
            "grad_loss:0.088933\n",
            "dice_loss:-0.885691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:193\n",
            "loss(total):-0.002130\n",
            "recons_loss:0.005582\n",
            "grad_loss:0.113968\n",
            "dice_loss:-0.885101\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:194\n",
            "loss(total):-0.001274\n",
            "recons_loss:0.006183\n",
            "grad_loss:0.113508\n",
            "dice_loss:-0.859195\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:195\n",
            "loss(total):-0.002911\n",
            "recons_loss:0.005013\n",
            "grad_loss:0.097191\n",
            "dice_loss:-0.889563\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:196\n",
            "loss(total):-0.004349\n",
            "recons_loss:0.003763\n",
            "grad_loss:0.084078\n",
            "dice_loss:-0.895299\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:197\n",
            "loss(total):-0.003837\n",
            "recons_loss:0.003998\n",
            "grad_loss:0.104473\n",
            "dice_loss:-0.887962\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:198\n",
            "loss(total):-0.002946\n",
            "recons_loss:0.004620\n",
            "grad_loss:0.132457\n",
            "dice_loss:-0.889023\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:199\n",
            "loss(total):-0.003392\n",
            "recons_loss:0.004456\n",
            "grad_loss:0.107372\n",
            "dice_loss:-0.892131\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:200\n",
            "loss(total):-0.004178\n",
            "recons_loss:0.003755\n",
            "grad_loss:0.093205\n",
            "dice_loss:-0.886483\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:201\n",
            "loss(total):-0.002984\n",
            "recons_loss:0.005046\n",
            "grad_loss:0.102441\n",
            "dice_loss:-0.905459\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:202\n",
            "loss(total):-0.004122\n",
            "recons_loss:0.003972\n",
            "grad_loss:0.090360\n",
            "dice_loss:-0.899756\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:203\n",
            "loss(total):-0.002512\n",
            "recons_loss:0.005079\n",
            "grad_loss:0.111566\n",
            "dice_loss:-0.870633\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:204\n",
            "loss(total):-0.003979\n",
            "recons_loss:0.004039\n",
            "grad_loss:0.084195\n",
            "dice_loss:-0.885919\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:205\n",
            "loss(total):-0.002727\n",
            "recons_loss:0.005030\n",
            "grad_loss:0.106412\n",
            "dice_loss:-0.882024\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:206\n",
            "loss(total):-0.004261\n",
            "recons_loss:0.003861\n",
            "grad_loss:0.079057\n",
            "dice_loss:-0.891216\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:207\n",
            "loss(total):-0.001953\n",
            "recons_loss:0.005707\n",
            "grad_loss:0.110369\n",
            "dice_loss:-0.876330\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:208\n",
            "loss(total):-0.003352\n",
            "recons_loss:0.004438\n",
            "grad_loss:0.101816\n",
            "dice_loss:-0.880856\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:209\n",
            "loss(total):-0.003969\n",
            "recons_loss:0.004018\n",
            "grad_loss:0.075206\n",
            "dice_loss:-0.873966\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:210\n",
            "loss(total):-0.002861\n",
            "recons_loss:0.004859\n",
            "grad_loss:0.102850\n",
            "dice_loss:-0.874869\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:211\n",
            "loss(total):-0.002902\n",
            "recons_loss:0.004707\n",
            "grad_loss:0.117727\n",
            "dice_loss:-0.878587\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:212\n",
            "loss(total):-0.002792\n",
            "recons_loss:0.005112\n",
            "grad_loss:0.095961\n",
            "dice_loss:-0.886313\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:213\n",
            "loss(total):-0.002928\n",
            "recons_loss:0.004913\n",
            "grad_loss:0.108553\n",
            "dice_loss:-0.892672\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:214\n",
            "loss(total):-0.002670\n",
            "recons_loss:0.005056\n",
            "grad_loss:0.113612\n",
            "dice_loss:-0.886129\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:215\n",
            "loss(total):-0.004388\n",
            "recons_loss:0.003540\n",
            "grad_loss:0.091137\n",
            "dice_loss:-0.883931\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:216\n",
            "loss(total):-0.004104\n",
            "recons_loss:0.003851\n",
            "grad_loss:0.098670\n",
            "dice_loss:-0.894224\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:217\n",
            "loss(total):-0.004497\n",
            "recons_loss:0.003461\n",
            "grad_loss:0.093933\n",
            "dice_loss:-0.889735\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:218\n",
            "loss(total):-0.002402\n",
            "recons_loss:0.005261\n",
            "grad_loss:0.117686\n",
            "dice_loss:-0.883949\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:219\n",
            "loss(total):-0.001399\n",
            "recons_loss:0.006214\n",
            "grad_loss:0.118573\n",
            "dice_loss:-0.879868\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:220\n",
            "loss(total):-0.003536\n",
            "recons_loss:0.004511\n",
            "grad_loss:0.090427\n",
            "dice_loss:-0.895084\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:221\n",
            "loss(total):-0.003759\n",
            "recons_loss:0.004146\n",
            "grad_loss:0.102661\n",
            "dice_loss:-0.893140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:222\n",
            "loss(total):-0.004940\n",
            "recons_loss:0.003202\n",
            "grad_loss:0.086002\n",
            "dice_loss:-0.900234\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:223\n",
            "loss(total):-0.001952\n",
            "recons_loss:0.005532\n",
            "grad_loss:0.137439\n",
            "dice_loss:-0.885835\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:224\n",
            "loss(total):-0.004800\n",
            "recons_loss:0.003355\n",
            "grad_loss:0.091409\n",
            "dice_loss:-0.906897\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:225\n",
            "loss(total):-0.004045\n",
            "recons_loss:0.003805\n",
            "grad_loss:0.104633\n",
            "dice_loss:-0.889643\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:226\n",
            "loss(total):-0.003027\n",
            "recons_loss:0.004828\n",
            "grad_loss:0.106042\n",
            "dice_loss:-0.891555\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:227\n",
            "loss(total):-0.003037\n",
            "recons_loss:0.004651\n",
            "grad_loss:0.114512\n",
            "dice_loss:-0.883278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:228\n",
            "loss(total):-0.003737\n",
            "recons_loss:0.004279\n",
            "grad_loss:0.102185\n",
            "dice_loss:-0.903777\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:229\n",
            "loss(total):-0.003753\n",
            "recons_loss:0.003968\n",
            "grad_loss:0.103164\n",
            "dice_loss:-0.875241\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:230\n",
            "loss(total):-0.002011\n",
            "recons_loss:0.005637\n",
            "grad_loss:0.109923\n",
            "dice_loss:-0.874719\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:231\n",
            "loss(total):-0.002835\n",
            "recons_loss:0.004970\n",
            "grad_loss:0.111576\n",
            "dice_loss:-0.892080\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:232\n",
            "loss(total):-0.004716\n",
            "recons_loss:0.003343\n",
            "grad_loss:0.079758\n",
            "dice_loss:-0.885604\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:233\n",
            "loss(total):-0.003436\n",
            "recons_loss:0.004716\n",
            "grad_loss:0.072617\n",
            "dice_loss:-0.887793\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:234\n",
            "loss(total):-0.001279\n",
            "recons_loss:0.006136\n",
            "grad_loss:0.121848\n",
            "dice_loss:-0.863320\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:235\n",
            "loss(total):-0.003725\n",
            "recons_loss:0.004098\n",
            "grad_loss:0.102858\n",
            "dice_loss:-0.885139\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:236\n",
            "loss(total):-0.003384\n",
            "recons_loss:0.004320\n",
            "grad_loss:0.104292\n",
            "dice_loss:-0.874770\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:237\n",
            "loss(total):-0.001916\n",
            "recons_loss:0.005649\n",
            "grad_loss:0.114147\n",
            "dice_loss:-0.870636\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:238\n",
            "loss(total):-0.003391\n",
            "recons_loss:0.004461\n",
            "grad_loss:0.098118\n",
            "dice_loss:-0.883273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:239\n",
            "loss(total):-0.004238\n",
            "recons_loss:0.003848\n",
            "grad_loss:0.088587\n",
            "dice_loss:-0.897116\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:240\n",
            "loss(total):-0.002553\n",
            "recons_loss:0.005209\n",
            "grad_loss:0.098507\n",
            "dice_loss:-0.874659\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:241\n",
            "loss(total):-0.004333\n",
            "recons_loss:0.003768\n",
            "grad_loss:0.085166\n",
            "dice_loss:-0.895240\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:242\n",
            "loss(total):-0.003123\n",
            "recons_loss:0.004930\n",
            "grad_loss:0.084777\n",
            "dice_loss:-0.890139\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:243\n",
            "loss(total):-0.003680\n",
            "recons_loss:0.004124\n",
            "grad_loss:0.097209\n",
            "dice_loss:-0.877668\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:244\n",
            "loss(total):-0.001311\n",
            "recons_loss:0.006043\n",
            "grad_loss:0.143191\n",
            "dice_loss:-0.878653\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:245\n",
            "loss(total):-0.003503\n",
            "recons_loss:0.004216\n",
            "grad_loss:0.099829\n",
            "dice_loss:-0.871699\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:246\n",
            "loss(total):-0.002565\n",
            "recons_loss:0.005007\n",
            "grad_loss:0.106511\n",
            "dice_loss:-0.863753\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:247\n",
            "loss(total):-0.005092\n",
            "recons_loss:0.003121\n",
            "grad_loss:0.081246\n",
            "dice_loss:-0.902456\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:248\n",
            "loss(total):-0.004333\n",
            "recons_loss:0.003673\n",
            "grad_loss:0.088505\n",
            "dice_loss:-0.889086\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:249\n",
            "loss(total):-0.003039\n",
            "recons_loss:0.004633\n",
            "grad_loss:0.110507\n",
            "dice_loss:-0.877699\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:250\n",
            "loss(total):-0.004019\n",
            "recons_loss:0.003948\n",
            "grad_loss:0.099930\n",
            "dice_loss:-0.896624\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:251\n",
            "loss(total):-0.003094\n",
            "recons_loss:0.004778\n",
            "grad_loss:0.104238\n",
            "dice_loss:-0.891393\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:252\n",
            "loss(total):-0.003763\n",
            "recons_loss:0.004062\n",
            "grad_loss:0.117761\n",
            "dice_loss:-0.900259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:253\n",
            "loss(total):-0.003439\n",
            "recons_loss:0.004325\n",
            "grad_loss:0.119693\n",
            "dice_loss:-0.896008\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:254\n",
            "loss(total):-0.004363\n",
            "recons_loss:0.003570\n",
            "grad_loss:0.091216\n",
            "dice_loss:-0.884594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:255\n",
            "loss(total):-0.004261\n",
            "recons_loss:0.003760\n",
            "grad_loss:0.093228\n",
            "dice_loss:-0.895282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:256\n",
            "loss(total):-0.002716\n",
            "recons_loss:0.005153\n",
            "grad_loss:0.107691\n",
            "dice_loss:-0.894573\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:257\n",
            "loss(total):-0.003241\n",
            "recons_loss:0.004418\n",
            "grad_loss:0.106984\n",
            "dice_loss:-0.872886\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:258\n",
            "loss(total):-0.003979\n",
            "recons_loss:0.004045\n",
            "grad_loss:0.083094\n",
            "dice_loss:-0.885542\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:259\n",
            "loss(total):-0.003589\n",
            "recons_loss:0.004189\n",
            "grad_loss:0.099601\n",
            "dice_loss:-0.877388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:260\n",
            "loss(total):-0.003242\n",
            "recons_loss:0.004591\n",
            "grad_loss:0.098157\n",
            "dice_loss:-0.881437\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:261\n",
            "loss(total):-0.001629\n",
            "recons_loss:0.005995\n",
            "grad_loss:0.127472\n",
            "dice_loss:-0.889813\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:262\n",
            "loss(total):-0.003428\n",
            "recons_loss:0.004325\n",
            "grad_loss:0.098718\n",
            "dice_loss:-0.874045\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:263\n",
            "loss(total):-0.005020\n",
            "recons_loss:0.003256\n",
            "grad_loss:0.073354\n",
            "dice_loss:-0.900903\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:264\n",
            "loss(total):-0.002381\n",
            "recons_loss:0.005046\n",
            "grad_loss:0.137073\n",
            "dice_loss:-0.879778\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:265\n",
            "loss(total):-0.003164\n",
            "recons_loss:0.004508\n",
            "grad_loss:0.113491\n",
            "dice_loss:-0.880701\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:266\n",
            "loss(total):-0.004521\n",
            "recons_loss:0.003523\n",
            "grad_loss:0.077360\n",
            "dice_loss:-0.881763\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:267\n",
            "loss(total):-0.002935\n",
            "recons_loss:0.004730\n",
            "grad_loss:0.109060\n",
            "dice_loss:-0.875556\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:268\n",
            "loss(total):-0.003303\n",
            "recons_loss:0.004495\n",
            "grad_loss:0.106559\n",
            "dice_loss:-0.886346\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:269\n",
            "loss(total):-0.003234\n",
            "recons_loss:0.004571\n",
            "grad_loss:0.110837\n",
            "dice_loss:-0.891358\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:0\n",
            "loss(total):-0.004717\n",
            "recons_loss:0.003464\n",
            "grad_loss:0.074545\n",
            "dice_loss:-0.892584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:1\n",
            "loss(total):-0.002726\n",
            "recons_loss:0.005074\n",
            "grad_loss:0.108810\n",
            "dice_loss:-0.888801\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:2\n",
            "loss(total):-0.003840\n",
            "recons_loss:0.004166\n",
            "grad_loss:0.091238\n",
            "dice_loss:-0.891893\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:3\n",
            "loss(total):-0.003722\n",
            "recons_loss:0.004347\n",
            "grad_loss:0.084689\n",
            "dice_loss:-0.891549\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:4\n",
            "loss(total):-0.000990\n",
            "recons_loss:0.006393\n",
            "grad_loss:0.129741\n",
            "dice_loss:-0.868049\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:5\n",
            "loss(total):-0.003447\n",
            "recons_loss:0.004571\n",
            "grad_loss:0.088501\n",
            "dice_loss:-0.890290\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:6\n",
            "loss(total):-0.002433\n",
            "recons_loss:0.005238\n",
            "grad_loss:0.123221\n",
            "dice_loss:-0.890270\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:7\n",
            "loss(total):-0.002887\n",
            "recons_loss:0.004758\n",
            "grad_loss:0.122337\n",
            "dice_loss:-0.886862\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:8\n",
            "loss(total):-0.003585\n",
            "recons_loss:0.004210\n",
            "grad_loss:0.093632\n",
            "dice_loss:-0.873134\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:9\n",
            "loss(total):-0.004900\n",
            "recons_loss:0.003348\n",
            "grad_loss:0.079951\n",
            "dice_loss:-0.904809\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:10\n",
            "loss(total):-0.003271\n",
            "recons_loss:0.004506\n",
            "grad_loss:0.097843\n",
            "dice_loss:-0.875504\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:11\n",
            "loss(total):-0.003241\n",
            "recons_loss:0.004779\n",
            "grad_loss:0.093765\n",
            "dice_loss:-0.895782\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:12\n",
            "loss(total):-0.002302\n",
            "recons_loss:0.005440\n",
            "grad_loss:0.101549\n",
            "dice_loss:-0.875693\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:13\n",
            "loss(total):-0.002330\n",
            "recons_loss:0.005236\n",
            "grad_loss:0.114593\n",
            "dice_loss:-0.871220\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:14\n",
            "loss(total):-0.003670\n",
            "recons_loss:0.004227\n",
            "grad_loss:0.094867\n",
            "dice_loss:-0.884530\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:15\n",
            "loss(total):-0.002595\n",
            "recons_loss:0.005131\n",
            "grad_loss:0.106878\n",
            "dice_loss:-0.879521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:16\n",
            "loss(total):-0.004170\n",
            "recons_loss:0.003806\n",
            "grad_loss:0.090236\n",
            "dice_loss:-0.887880\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:17\n",
            "loss(total):-0.002623\n",
            "recons_loss:0.005067\n",
            "grad_loss:0.097185\n",
            "dice_loss:-0.866115\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:18\n",
            "loss(total):-0.003825\n",
            "recons_loss:0.004170\n",
            "grad_loss:0.096592\n",
            "dice_loss:-0.896074\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:19\n",
            "loss(total):-0.004016\n",
            "recons_loss:0.003854\n",
            "grad_loss:0.097090\n",
            "dice_loss:-0.884055\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:20\n",
            "loss(total):-0.004126\n",
            "recons_loss:0.003873\n",
            "grad_loss:0.087789\n",
            "dice_loss:-0.887684\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:21\n",
            "loss(total):-0.003472\n",
            "recons_loss:0.004404\n",
            "grad_loss:0.107686\n",
            "dice_loss:-0.895262\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:22\n",
            "loss(total):-0.004789\n",
            "recons_loss:0.003208\n",
            "grad_loss:0.082280\n",
            "dice_loss:-0.882067\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:23\n",
            "loss(total):-0.003582\n",
            "recons_loss:0.004373\n",
            "grad_loss:0.094971\n",
            "dice_loss:-0.890540\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:24\n",
            "loss(total):-0.002779\n",
            "recons_loss:0.004953\n",
            "grad_loss:0.112682\n",
            "dice_loss:-0.885888\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:25\n",
            "loss(total):-0.002367\n",
            "recons_loss:0.005138\n",
            "grad_loss:0.125007\n",
            "dice_loss:-0.875460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:26\n",
            "loss(total):-0.003422\n",
            "recons_loss:0.004274\n",
            "grad_loss:0.124714\n",
            "dice_loss:-0.894263\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:27\n",
            "loss(total):-0.004687\n",
            "recons_loss:0.003437\n",
            "grad_loss:0.084360\n",
            "dice_loss:-0.896840\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:28\n",
            "loss(total):-0.002756\n",
            "recons_loss:0.004910\n",
            "grad_loss:0.108281\n",
            "dice_loss:-0.874849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:29\n",
            "loss(total):-0.003823\n",
            "recons_loss:0.004090\n",
            "grad_loss:0.100241\n",
            "dice_loss:-0.891521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:30\n",
            "loss(total):-0.003126\n",
            "recons_loss:0.004841\n",
            "grad_loss:0.081892\n",
            "dice_loss:-0.878557\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:31\n",
            "loss(total):-0.003195\n",
            "recons_loss:0.004474\n",
            "grad_loss:0.103258\n",
            "dice_loss:-0.870205\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:32\n",
            "loss(total):-0.003651\n",
            "recons_loss:0.004244\n",
            "grad_loss:0.097704\n",
            "dice_loss:-0.887224\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:33\n",
            "loss(total):-0.002863\n",
            "recons_loss:0.005127\n",
            "grad_loss:0.096047\n",
            "dice_loss:-0.895045\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:34\n",
            "loss(total):-0.003797\n",
            "recons_loss:0.003934\n",
            "grad_loss:0.103258\n",
            "dice_loss:-0.876347\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:35\n",
            "loss(total):-0.003982\n",
            "recons_loss:0.004129\n",
            "grad_loss:0.083730\n",
            "dice_loss:-0.894907\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:36\n",
            "loss(total):-0.005146\n",
            "recons_loss:0.003129\n",
            "grad_loss:0.069981\n",
            "dice_loss:-0.897523\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:37\n",
            "loss(total):-0.002830\n",
            "recons_loss:0.004543\n",
            "grad_loss:0.116784\n",
            "dice_loss:-0.854067\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:38\n",
            "loss(total):-0.003647\n",
            "recons_loss:0.004257\n",
            "grad_loss:0.107016\n",
            "dice_loss:-0.897406\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:39\n",
            "loss(total):-0.004485\n",
            "recons_loss:0.003484\n",
            "grad_loss:0.097844\n",
            "dice_loss:-0.894713\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:40\n",
            "loss(total):-0.002661\n",
            "recons_loss:0.005071\n",
            "grad_loss:0.110393\n",
            "dice_loss:-0.883562\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:41\n",
            "loss(total):-0.004662\n",
            "recons_loss:0.003487\n",
            "grad_loss:0.075172\n",
            "dice_loss:-0.889991\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:42\n",
            "loss(total):-0.003960\n",
            "recons_loss:0.003866\n",
            "grad_loss:0.087498\n",
            "dice_loss:-0.870082\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:43\n",
            "loss(total):-0.002457\n",
            "recons_loss:0.005161\n",
            "grad_loss:0.125538\n",
            "dice_loss:-0.887327\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:44\n",
            "loss(total):-0.003383\n",
            "recons_loss:0.004322\n",
            "grad_loss:0.098589\n",
            "dice_loss:-0.869165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:45\n",
            "loss(total):-0.004038\n",
            "recons_loss:0.004006\n",
            "grad_loss:0.095215\n",
            "dice_loss:-0.899626\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:46\n",
            "loss(total):-0.002701\n",
            "recons_loss:0.005123\n",
            "grad_loss:0.109611\n",
            "dice_loss:-0.892094\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:47\n",
            "loss(total):-0.003467\n",
            "recons_loss:0.004473\n",
            "grad_loss:0.097624\n",
            "dice_loss:-0.891564\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:48\n",
            "loss(total):-0.003698\n",
            "recons_loss:0.004153\n",
            "grad_loss:0.089714\n",
            "dice_loss:-0.874850\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:49\n",
            "loss(total):-0.003100\n",
            "recons_loss:0.004443\n",
            "grad_loss:0.105952\n",
            "dice_loss:-0.860222\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:50\n",
            "loss(total):-0.002112\n",
            "recons_loss:0.005570\n",
            "grad_loss:0.096125\n",
            "dice_loss:-0.864290\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:51\n",
            "loss(total):-0.002386\n",
            "recons_loss:0.005437\n",
            "grad_loss:0.102919\n",
            "dice_loss:-0.885270\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:52\n",
            "loss(total):-0.002747\n",
            "recons_loss:0.005063\n",
            "grad_loss:0.102285\n",
            "dice_loss:-0.883299\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:53\n",
            "loss(total):-0.001101\n",
            "recons_loss:0.006349\n",
            "grad_loss:0.131437\n",
            "dice_loss:-0.876382\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:54\n",
            "loss(total):-0.003189\n",
            "recons_loss:0.004554\n",
            "grad_loss:0.127360\n",
            "dice_loss:-0.901606\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:55\n",
            "loss(total):-0.003411\n",
            "recons_loss:0.004299\n",
            "grad_loss:0.109395\n",
            "dice_loss:-0.880469\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:56\n",
            "loss(total):-0.002654\n",
            "recons_loss:0.005032\n",
            "grad_loss:0.115762\n",
            "dice_loss:-0.884400\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:57\n",
            "loss(total):-0.003672\n",
            "recons_loss:0.004116\n",
            "grad_loss:0.095282\n",
            "dice_loss:-0.874090\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:58\n",
            "loss(total):-0.003208\n",
            "recons_loss:0.004376\n",
            "grad_loss:0.098355\n",
            "dice_loss:-0.856748\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:59\n",
            "loss(total):-0.003560\n",
            "recons_loss:0.004272\n",
            "grad_loss:0.107047\n",
            "dice_loss:-0.890322\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:60\n",
            "loss(total):-0.001410\n",
            "recons_loss:0.006105\n",
            "grad_loss:0.131402\n",
            "dice_loss:-0.882957\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:61\n",
            "loss(total):-0.003101\n",
            "recons_loss:0.004724\n",
            "grad_loss:0.103829\n",
            "dice_loss:-0.886408\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:62\n",
            "loss(total):-0.002588\n",
            "recons_loss:0.005319\n",
            "grad_loss:0.089005\n",
            "dice_loss:-0.879690\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:63\n",
            "loss(total):-0.003340\n",
            "recons_loss:0.004500\n",
            "grad_loss:0.114329\n",
            "dice_loss:-0.898327\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:64\n",
            "loss(total):-0.002786\n",
            "recons_loss:0.004882\n",
            "grad_loss:0.116883\n",
            "dice_loss:-0.883772\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:65\n",
            "loss(total):-0.004516\n",
            "recons_loss:0.003554\n",
            "grad_loss:0.087300\n",
            "dice_loss:-0.894310\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:66\n",
            "loss(total):-0.001912\n",
            "recons_loss:0.005483\n",
            "grad_loss:0.130662\n",
            "dice_loss:-0.870177\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:67\n",
            "loss(total):-0.001427\n",
            "recons_loss:0.006172\n",
            "grad_loss:0.125473\n",
            "dice_loss:-0.885404\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:68\n",
            "loss(total):-0.002440\n",
            "recons_loss:0.005374\n",
            "grad_loss:0.110568\n",
            "dice_loss:-0.891955\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:69\n",
            "loss(total):-0.002689\n",
            "recons_loss:0.005024\n",
            "grad_loss:0.117559\n",
            "dice_loss:-0.888915\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:70\n",
            "loss(total):-0.003960\n",
            "recons_loss:0.003906\n",
            "grad_loss:0.101208\n",
            "dice_loss:-0.887743\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:71\n",
            "loss(total):-0.003470\n",
            "recons_loss:0.004439\n",
            "grad_loss:0.093632\n",
            "dice_loss:-0.884510\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:72\n",
            "loss(total):-0.002538\n",
            "recons_loss:0.005194\n",
            "grad_loss:0.112784\n",
            "dice_loss:-0.885968\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:73\n",
            "loss(total):-0.003034\n",
            "recons_loss:0.004863\n",
            "grad_loss:0.102087\n",
            "dice_loss:-0.891779\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:74\n",
            "loss(total):-0.002576\n",
            "recons_loss:0.005054\n",
            "grad_loss:0.109241\n",
            "dice_loss:-0.872269\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:75\n",
            "loss(total):-0.004625\n",
            "recons_loss:0.003463\n",
            "grad_loss:0.086296\n",
            "dice_loss:-0.895083\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:76\n",
            "loss(total):-0.003171\n",
            "recons_loss:0.004664\n",
            "grad_loss:0.101729\n",
            "dice_loss:-0.885209\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:77\n",
            "loss(total):-0.003815\n",
            "recons_loss:0.004104\n",
            "grad_loss:0.097538\n",
            "dice_loss:-0.889394\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:78\n",
            "loss(total):-0.002181\n",
            "recons_loss:0.005247\n",
            "grad_loss:0.141716\n",
            "dice_loss:-0.884583\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:79\n",
            "loss(total):-0.003310\n",
            "recons_loss:0.004487\n",
            "grad_loss:0.103191\n",
            "dice_loss:-0.882842\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:80\n",
            "loss(total):-0.002158\n",
            "recons_loss:0.005365\n",
            "grad_loss:0.120591\n",
            "dice_loss:-0.872871\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:81\n",
            "loss(total):-0.004416\n",
            "recons_loss:0.003489\n",
            "grad_loss:0.091671\n",
            "dice_loss:-0.882165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:82\n",
            "loss(total):-0.004700\n",
            "recons_loss:0.003276\n",
            "grad_loss:0.089245\n",
            "dice_loss:-0.886782\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:83\n",
            "loss(total):-0.003497\n",
            "recons_loss:0.004473\n",
            "grad_loss:0.084485\n",
            "dice_loss:-0.881473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:84\n",
            "loss(total):-0.003463\n",
            "recons_loss:0.004621\n",
            "grad_loss:0.093257\n",
            "dice_loss:-0.901592\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:85\n",
            "loss(total):-0.003172\n",
            "recons_loss:0.004737\n",
            "grad_loss:0.104617\n",
            "dice_loss:-0.895460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:86\n",
            "loss(total):-0.003664\n",
            "recons_loss:0.004292\n",
            "grad_loss:0.082798\n",
            "dice_loss:-0.878311\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:87\n",
            "loss(total):-0.004398\n",
            "recons_loss:0.003545\n",
            "grad_loss:0.094922\n",
            "dice_loss:-0.889154\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:88\n",
            "loss(total):-0.002550\n",
            "recons_loss:0.005396\n",
            "grad_loss:0.089549\n",
            "dice_loss:-0.884154\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:89\n",
            "loss(total):-0.003509\n",
            "recons_loss:0.004624\n",
            "grad_loss:0.079881\n",
            "dice_loss:-0.893213\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:90\n",
            "loss(total):-0.002757\n",
            "recons_loss:0.005023\n",
            "grad_loss:0.092940\n",
            "dice_loss:-0.870914\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:91\n",
            "loss(total):-0.003402\n",
            "recons_loss:0.004577\n",
            "grad_loss:0.091009\n",
            "dice_loss:-0.888947\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:92\n",
            "loss(total):-0.001779\n",
            "recons_loss:0.005591\n",
            "grad_loss:0.123801\n",
            "dice_loss:-0.860720\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:93\n",
            "loss(total):-0.003233\n",
            "recons_loss:0.004734\n",
            "grad_loss:0.104015\n",
            "dice_loss:-0.900699\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:94\n",
            "loss(total):-0.002988\n",
            "recons_loss:0.004874\n",
            "grad_loss:0.108277\n",
            "dice_loss:-0.894476\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:95\n",
            "loss(total):-0.004324\n",
            "recons_loss:0.003824\n",
            "grad_loss:0.085985\n",
            "dice_loss:-0.900828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:96\n",
            "loss(total):-0.003833\n",
            "recons_loss:0.004189\n",
            "grad_loss:0.093548\n",
            "dice_loss:-0.895691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:97\n",
            "loss(total):-0.002021\n",
            "recons_loss:0.005592\n",
            "grad_loss:0.113514\n",
            "dice_loss:-0.874890\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:98\n",
            "loss(total):-0.003729\n",
            "recons_loss:0.004076\n",
            "grad_loss:0.098517\n",
            "dice_loss:-0.878963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:99\n",
            "loss(total):-0.003544\n",
            "recons_loss:0.004137\n",
            "grad_loss:0.103098\n",
            "dice_loss:-0.871174\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:100\n",
            "loss(total):-0.004328\n",
            "recons_loss:0.003563\n",
            "grad_loss:0.085445\n",
            "dice_loss:-0.874555\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:101\n",
            "loss(total):-0.002891\n",
            "recons_loss:0.004981\n",
            "grad_loss:0.096215\n",
            "dice_loss:-0.883447\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:102\n",
            "loss(total):-0.004029\n",
            "recons_loss:0.003976\n",
            "grad_loss:0.095554\n",
            "dice_loss:-0.896050\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:103\n",
            "loss(total):-0.003250\n",
            "recons_loss:0.004583\n",
            "grad_loss:0.094956\n",
            "dice_loss:-0.878225\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:104\n",
            "loss(total):-0.003053\n",
            "recons_loss:0.004725\n",
            "grad_loss:0.111167\n",
            "dice_loss:-0.888925\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:105\n",
            "loss(total):-0.004539\n",
            "recons_loss:0.003612\n",
            "grad_loss:0.079182\n",
            "dice_loss:-0.894267\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:106\n",
            "loss(total):-0.004864\n",
            "recons_loss:0.003283\n",
            "grad_loss:0.083802\n",
            "dice_loss:-0.898441\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:107\n",
            "loss(total):-0.004015\n",
            "recons_loss:0.004004\n",
            "grad_loss:0.084897\n",
            "dice_loss:-0.886718\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:108\n",
            "loss(total):-0.003460\n",
            "recons_loss:0.004415\n",
            "grad_loss:0.105931\n",
            "dice_loss:-0.893438\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:109\n",
            "loss(total):-0.004161\n",
            "recons_loss:0.003811\n",
            "grad_loss:0.099727\n",
            "dice_loss:-0.896928\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:110\n",
            "loss(total):-0.003914\n",
            "recons_loss:0.003967\n",
            "grad_loss:0.101390\n",
            "dice_loss:-0.889423\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:111\n",
            "loss(total):-0.001739\n",
            "recons_loss:0.005844\n",
            "grad_loss:0.127512\n",
            "dice_loss:-0.885776\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:112\n",
            "loss(total):-0.001696\n",
            "recons_loss:0.005533\n",
            "grad_loss:0.135725\n",
            "dice_loss:-0.858617\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:113\n",
            "loss(total):-0.003582\n",
            "recons_loss:0.004215\n",
            "grad_loss:0.098699\n",
            "dice_loss:-0.878451\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:114\n",
            "loss(total):-0.003967\n",
            "recons_loss:0.003841\n",
            "grad_loss:0.101604\n",
            "dice_loss:-0.882313\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:115\n",
            "loss(total):-0.004279\n",
            "recons_loss:0.003700\n",
            "grad_loss:0.085440\n",
            "dice_loss:-0.883339\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:116\n",
            "loss(total):-0.003919\n",
            "recons_loss:0.003991\n",
            "grad_loss:0.095108\n",
            "dice_loss:-0.886150\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:117\n",
            "loss(total):-0.005172\n",
            "recons_loss:0.002878\n",
            "grad_loss:0.075934\n",
            "dice_loss:-0.880914\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:118\n",
            "loss(total):-0.002253\n",
            "recons_loss:0.005465\n",
            "grad_loss:0.121752\n",
            "dice_loss:-0.893587\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:119\n",
            "loss(total):-0.002993\n",
            "recons_loss:0.004617\n",
            "grad_loss:0.108700\n",
            "dice_loss:-0.869726\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:120\n",
            "loss(total):-0.003933\n",
            "recons_loss:0.004051\n",
            "grad_loss:0.094200\n",
            "dice_loss:-0.892605\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:121\n",
            "loss(total):-0.003678\n",
            "recons_loss:0.004250\n",
            "grad_loss:0.091244\n",
            "dice_loss:-0.884071\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:122\n",
            "loss(total):-0.002696\n",
            "recons_loss:0.005181\n",
            "grad_loss:0.103090\n",
            "dice_loss:-0.890851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:123\n",
            "loss(total):-0.004115\n",
            "recons_loss:0.003806\n",
            "grad_loss:0.096327\n",
            "dice_loss:-0.888413\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:124\n",
            "loss(total):-0.004353\n",
            "recons_loss:0.003640\n",
            "grad_loss:0.088127\n",
            "dice_loss:-0.887458\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:125\n",
            "loss(total):-0.005087\n",
            "recons_loss:0.003190\n",
            "grad_loss:0.074731\n",
            "dice_loss:-0.902394\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:126\n",
            "loss(total):-0.004296\n",
            "recons_loss:0.003570\n",
            "grad_loss:0.096536\n",
            "dice_loss:-0.883155\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:127\n",
            "loss(total):-0.004522\n",
            "recons_loss:0.003616\n",
            "grad_loss:0.077281\n",
            "dice_loss:-0.891056\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:128\n",
            "loss(total):-0.003713\n",
            "recons_loss:0.004277\n",
            "grad_loss:0.093602\n",
            "dice_loss:-0.892614\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:129\n",
            "loss(total):-0.003934\n",
            "recons_loss:0.003964\n",
            "grad_loss:0.097649\n",
            "dice_loss:-0.887407\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:130\n",
            "loss(total):-0.003018\n",
            "recons_loss:0.004904\n",
            "grad_loss:0.093482\n",
            "dice_loss:-0.885758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:131\n",
            "loss(total):-0.002383\n",
            "recons_loss:0.005009\n",
            "grad_loss:0.134913\n",
            "dice_loss:-0.874131\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:132\n",
            "loss(total):-0.004770\n",
            "recons_loss:0.003389\n",
            "grad_loss:0.078334\n",
            "dice_loss:-0.894242\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:133\n",
            "loss(total):-0.003563\n",
            "recons_loss:0.004256\n",
            "grad_loss:0.095397\n",
            "dice_loss:-0.877333\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:134\n",
            "loss(total):-0.002075\n",
            "recons_loss:0.005455\n",
            "grad_loss:0.131855\n",
            "dice_loss:-0.884824\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:135\n",
            "loss(total):-0.004186\n",
            "recons_loss:0.003891\n",
            "grad_loss:0.087845\n",
            "dice_loss:-0.895578\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:136\n",
            "loss(total):-0.002264\n",
            "recons_loss:0.005450\n",
            "grad_loss:0.103637\n",
            "dice_loss:-0.875016\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:137\n",
            "loss(total):-0.003959\n",
            "recons_loss:0.004066\n",
            "grad_loss:0.101321\n",
            "dice_loss:-0.903862\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:138\n",
            "loss(total):-0.004020\n",
            "recons_loss:0.003971\n",
            "grad_loss:0.094264\n",
            "dice_loss:-0.893369\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:139\n",
            "loss(total):-0.004341\n",
            "recons_loss:0.003489\n",
            "grad_loss:0.096357\n",
            "dice_loss:-0.879342\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:140\n",
            "loss(total):-0.004414\n",
            "recons_loss:0.003642\n",
            "grad_loss:0.080901\n",
            "dice_loss:-0.886481\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:141\n",
            "loss(total):-0.002337\n",
            "recons_loss:0.005212\n",
            "grad_loss:0.119557\n",
            "dice_loss:-0.874399\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:142\n",
            "loss(total):-0.002714\n",
            "recons_loss:0.004837\n",
            "grad_loss:0.114757\n",
            "dice_loss:-0.869791\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:143\n",
            "loss(total):-0.002189\n",
            "recons_loss:0.005462\n",
            "grad_loss:0.119200\n",
            "dice_loss:-0.884243\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:144\n",
            "loss(total):-0.004421\n",
            "recons_loss:0.003636\n",
            "grad_loss:0.088794\n",
            "dice_loss:-0.894478\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:145\n",
            "loss(total):-0.004385\n",
            "recons_loss:0.003575\n",
            "grad_loss:0.088824\n",
            "dice_loss:-0.884808\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:146\n",
            "loss(total):-0.002607\n",
            "recons_loss:0.005160\n",
            "grad_loss:0.116518\n",
            "dice_loss:-0.893163\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:147\n",
            "loss(total):-0.003614\n",
            "recons_loss:0.004195\n",
            "grad_loss:0.102337\n",
            "dice_loss:-0.883316\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:148\n",
            "loss(total):-0.003966\n",
            "recons_loss:0.003821\n",
            "grad_loss:0.100814\n",
            "dice_loss:-0.879497\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:149\n",
            "loss(total):-0.002467\n",
            "recons_loss:0.005172\n",
            "grad_loss:0.109627\n",
            "dice_loss:-0.873489\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:150\n",
            "loss(total):-0.003028\n",
            "recons_loss:0.004622\n",
            "grad_loss:0.116383\n",
            "dice_loss:-0.881321\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:151\n",
            "loss(total):-0.002579\n",
            "recons_loss:0.005073\n",
            "grad_loss:0.112625\n",
            "dice_loss:-0.877789\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:152\n",
            "loss(total):-0.003158\n",
            "recons_loss:0.004601\n",
            "grad_loss:0.109953\n",
            "dice_loss:-0.885765\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:153\n",
            "loss(total):-0.004058\n",
            "recons_loss:0.003768\n",
            "grad_loss:0.104833\n",
            "dice_loss:-0.887465\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:154\n",
            "loss(total):-0.002670\n",
            "recons_loss:0.004946\n",
            "grad_loss:0.118724\n",
            "dice_loss:-0.880278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:155\n",
            "loss(total):-0.003999\n",
            "recons_loss:0.003932\n",
            "grad_loss:0.097537\n",
            "dice_loss:-0.890613\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:156\n",
            "loss(total):-0.003395\n",
            "recons_loss:0.004386\n",
            "grad_loss:0.099927\n",
            "dice_loss:-0.878116\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:157\n",
            "loss(total):-0.003688\n",
            "recons_loss:0.004192\n",
            "grad_loss:0.107745\n",
            "dice_loss:-0.895763\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:158\n",
            "loss(total):-0.002181\n",
            "recons_loss:0.005475\n",
            "grad_loss:0.121226\n",
            "dice_loss:-0.886841\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:159\n",
            "loss(total):-0.003154\n",
            "recons_loss:0.004543\n",
            "grad_loss:0.114878\n",
            "dice_loss:-0.884636\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:160\n",
            "loss(total):-0.005060\n",
            "recons_loss:0.003162\n",
            "grad_loss:0.072513\n",
            "dice_loss:-0.894725\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:161\n",
            "loss(total):-0.002084\n",
            "recons_loss:0.005543\n",
            "grad_loss:0.122892\n",
            "dice_loss:-0.885621\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:162\n",
            "loss(total):-0.003951\n",
            "recons_loss:0.004155\n",
            "grad_loss:0.075472\n",
            "dice_loss:-0.886022\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:163\n",
            "loss(total):-0.004616\n",
            "recons_loss:0.003456\n",
            "grad_loss:0.081326\n",
            "dice_loss:-0.888462\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:164\n",
            "loss(total):-0.003149\n",
            "recons_loss:0.004656\n",
            "grad_loss:0.109363\n",
            "dice_loss:-0.889893\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:165\n",
            "loss(total):-0.004436\n",
            "recons_loss:0.003771\n",
            "grad_loss:0.080380\n",
            "dice_loss:-0.901093\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:166\n",
            "loss(total):-0.004126\n",
            "recons_loss:0.003706\n",
            "grad_loss:0.095969\n",
            "dice_loss:-0.879195\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:167\n",
            "loss(total):-0.003039\n",
            "recons_loss:0.004579\n",
            "grad_loss:0.110914\n",
            "dice_loss:-0.872759\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:168\n",
            "loss(total):-0.002277\n",
            "recons_loss:0.005337\n",
            "grad_loss:0.122769\n",
            "dice_loss:-0.884207\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:169\n",
            "loss(total):-0.003220\n",
            "recons_loss:0.004607\n",
            "grad_loss:0.099604\n",
            "dice_loss:-0.882304\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:170\n",
            "loss(total):-0.003783\n",
            "recons_loss:0.004145\n",
            "grad_loss:0.110926\n",
            "dice_loss:-0.903758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:171\n",
            "loss(total):-0.004781\n",
            "recons_loss:0.003368\n",
            "grad_loss:0.083992\n",
            "dice_loss:-0.898800\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:172\n",
            "loss(total):-0.003558\n",
            "recons_loss:0.004305\n",
            "grad_loss:0.098412\n",
            "dice_loss:-0.884724\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:173\n",
            "loss(total):-0.002679\n",
            "recons_loss:0.004896\n",
            "grad_loss:0.114601\n",
            "dice_loss:-0.872088\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:174\n",
            "loss(total):-0.004350\n",
            "recons_loss:0.003658\n",
            "grad_loss:0.083615\n",
            "dice_loss:-0.884369\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:175\n",
            "loss(total):-0.002496\n",
            "recons_loss:0.005289\n",
            "grad_loss:0.115993\n",
            "dice_loss:-0.894571\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:176\n",
            "loss(total):-0.004141\n",
            "recons_loss:0.003874\n",
            "grad_loss:0.089250\n",
            "dice_loss:-0.890705\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:177\n",
            "loss(total):-0.003641\n",
            "recons_loss:0.004253\n",
            "grad_loss:0.101591\n",
            "dice_loss:-0.890948\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:178\n",
            "loss(total):-0.002845\n",
            "recons_loss:0.004912\n",
            "grad_loss:0.100717\n",
            "dice_loss:-0.876359\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:179\n",
            "loss(total):-0.004103\n",
            "recons_loss:0.003728\n",
            "grad_loss:0.110302\n",
            "dice_loss:-0.893425\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:180\n",
            "loss(total):-0.003227\n",
            "recons_loss:0.004588\n",
            "grad_loss:0.103186\n",
            "dice_loss:-0.884657\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:181\n",
            "loss(total):-0.004064\n",
            "recons_loss:0.004057\n",
            "grad_loss:0.081752\n",
            "dice_loss:-0.893829\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:182\n",
            "loss(total):-0.003817\n",
            "recons_loss:0.004274\n",
            "grad_loss:0.077886\n",
            "dice_loss:-0.886964\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:183\n",
            "loss(total):-0.004964\n",
            "recons_loss:0.003197\n",
            "grad_loss:0.079903\n",
            "dice_loss:-0.896032\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:184\n",
            "loss(total):-0.003708\n",
            "recons_loss:0.004074\n",
            "grad_loss:0.100980\n",
            "dice_loss:-0.879148\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:185\n",
            "loss(total):-0.004610\n",
            "recons_loss:0.003453\n",
            "grad_loss:0.081379\n",
            "dice_loss:-0.887621\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:186\n",
            "loss(total):-0.003911\n",
            "recons_loss:0.004070\n",
            "grad_loss:0.086139\n",
            "dice_loss:-0.884198\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:187\n",
            "loss(total):-0.001791\n",
            "recons_loss:0.005725\n",
            "grad_loss:0.119298\n",
            "dice_loss:-0.870839\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:188\n",
            "loss(total):-0.001701\n",
            "recons_loss:0.005881\n",
            "grad_loss:0.112169\n",
            "dice_loss:-0.870376\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:189\n",
            "loss(total):-0.003344\n",
            "recons_loss:0.004402\n",
            "grad_loss:0.112740\n",
            "dice_loss:-0.887290\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:190\n",
            "loss(total):-0.004580\n",
            "recons_loss:0.003277\n",
            "grad_loss:0.090333\n",
            "dice_loss:-0.876027\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:191\n",
            "loss(total):-0.002407\n",
            "recons_loss:0.005310\n",
            "grad_loss:0.102529\n",
            "dice_loss:-0.874273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:192\n",
            "loss(total):-0.003704\n",
            "recons_loss:0.004189\n",
            "grad_loss:0.088526\n",
            "dice_loss:-0.877833\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:193\n",
            "loss(total):-0.005868\n",
            "recons_loss:0.002519\n",
            "grad_loss:0.067556\n",
            "dice_loss:-0.906291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:194\n",
            "loss(total):-0.003907\n",
            "recons_loss:0.004082\n",
            "grad_loss:0.092746\n",
            "dice_loss:-0.891671\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:195\n",
            "loss(total):-0.003624\n",
            "recons_loss:0.004238\n",
            "grad_loss:0.100577\n",
            "dice_loss:-0.886840\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:196\n",
            "loss(total):-0.003218\n",
            "recons_loss:0.004539\n",
            "grad_loss:0.105345\n",
            "dice_loss:-0.881087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:197\n",
            "loss(total):-0.004051\n",
            "recons_loss:0.003679\n",
            "grad_loss:0.105991\n",
            "dice_loss:-0.878978\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:198\n",
            "loss(total):-0.002801\n",
            "recons_loss:0.004955\n",
            "grad_loss:0.104367\n",
            "dice_loss:-0.880019\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:199\n",
            "loss(total):-0.002385\n",
            "recons_loss:0.005258\n",
            "grad_loss:0.126731\n",
            "dice_loss:-0.891123\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:200\n",
            "loss(total):-0.002027\n",
            "recons_loss:0.005652\n",
            "grad_loss:0.109847\n",
            "dice_loss:-0.877665\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:201\n",
            "loss(total):-0.003238\n",
            "recons_loss:0.004679\n",
            "grad_loss:0.095452\n",
            "dice_loss:-0.887214\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:202\n",
            "loss(total):-0.003038\n",
            "recons_loss:0.004935\n",
            "grad_loss:0.096093\n",
            "dice_loss:-0.893328\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:203\n",
            "loss(total):-0.003521\n",
            "recons_loss:0.004437\n",
            "grad_loss:0.087591\n",
            "dice_loss:-0.883419\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:204\n",
            "loss(total):-0.003742\n",
            "recons_loss:0.004224\n",
            "grad_loss:0.093504\n",
            "dice_loss:-0.890140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:205\n",
            "loss(total):-0.003760\n",
            "recons_loss:0.004143\n",
            "grad_loss:0.090134\n",
            "dice_loss:-0.880411\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:206\n",
            "loss(total):-0.002981\n",
            "recons_loss:0.004846\n",
            "grad_loss:0.104089\n",
            "dice_loss:-0.886858\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:207\n",
            "loss(total):-0.004006\n",
            "recons_loss:0.003777\n",
            "grad_loss:0.100260\n",
            "dice_loss:-0.878501\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:208\n",
            "loss(total):-0.003542\n",
            "recons_loss:0.004406\n",
            "grad_loss:0.094230\n",
            "dice_loss:-0.889040\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:209\n",
            "loss(total):-0.003610\n",
            "recons_loss:0.004280\n",
            "grad_loss:0.090593\n",
            "dice_loss:-0.879631\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:210\n",
            "loss(total):-0.003538\n",
            "recons_loss:0.004413\n",
            "grad_loss:0.098754\n",
            "dice_loss:-0.893892\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:211\n",
            "loss(total):-0.002487\n",
            "recons_loss:0.005239\n",
            "grad_loss:0.117863\n",
            "dice_loss:-0.890471\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:212\n",
            "loss(total):-0.002800\n",
            "recons_loss:0.004876\n",
            "grad_loss:0.111152\n",
            "dice_loss:-0.878801\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:213\n",
            "loss(total):-0.003990\n",
            "recons_loss:0.003916\n",
            "grad_loss:0.097393\n",
            "dice_loss:-0.887971\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:214\n",
            "loss(total):-0.004479\n",
            "recons_loss:0.003535\n",
            "grad_loss:0.097578\n",
            "dice_loss:-0.899002\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:215\n",
            "loss(total):-0.002101\n",
            "recons_loss:0.005443\n",
            "grad_loss:0.141322\n",
            "dice_loss:-0.895703\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:216\n",
            "loss(total):-0.003143\n",
            "recons_loss:0.004555\n",
            "grad_loss:0.114561\n",
            "dice_loss:-0.884352\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:217\n",
            "loss(total):-0.003423\n",
            "recons_loss:0.004511\n",
            "grad_loss:0.092140\n",
            "dice_loss:-0.885526\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:218\n",
            "loss(total):-0.003509\n",
            "recons_loss:0.004371\n",
            "grad_loss:0.101720\n",
            "dice_loss:-0.889693\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:219\n",
            "loss(total):-0.003132\n",
            "recons_loss:0.004779\n",
            "grad_loss:0.089640\n",
            "dice_loss:-0.880763\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:220\n",
            "loss(total):-0.002819\n",
            "recons_loss:0.004977\n",
            "grad_loss:0.109284\n",
            "dice_loss:-0.888928\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:221\n",
            "loss(total):-0.002145\n",
            "recons_loss:0.005360\n",
            "grad_loss:0.129097\n",
            "dice_loss:-0.879554\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:222\n",
            "loss(total):-0.003658\n",
            "recons_loss:0.004248\n",
            "grad_loss:0.107396\n",
            "dice_loss:-0.897946\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:223\n",
            "loss(total):-0.003235\n",
            "recons_loss:0.004569\n",
            "grad_loss:0.107159\n",
            "dice_loss:-0.887544\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:224\n",
            "loss(total):-0.004279\n",
            "recons_loss:0.003768\n",
            "grad_loss:0.090312\n",
            "dice_loss:-0.895028\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:225\n",
            "loss(total):-0.004607\n",
            "recons_loss:0.003537\n",
            "grad_loss:0.086715\n",
            "dice_loss:-0.901079\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:226\n",
            "loss(total):-0.003158\n",
            "recons_loss:0.004600\n",
            "grad_loss:0.109704\n",
            "dice_loss:-0.885505\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:227\n",
            "loss(total):-0.004238\n",
            "recons_loss:0.004037\n",
            "grad_loss:0.080706\n",
            "dice_loss:-0.908199\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:228\n",
            "loss(total):-0.002971\n",
            "recons_loss:0.004825\n",
            "grad_loss:0.097493\n",
            "dice_loss:-0.877052\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:229\n",
            "loss(total):-0.003558\n",
            "recons_loss:0.004405\n",
            "grad_loss:0.096353\n",
            "dice_loss:-0.892641\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:230\n",
            "loss(total):-0.002728\n",
            "recons_loss:0.005038\n",
            "grad_loss:0.107628\n",
            "dice_loss:-0.884140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:231\n",
            "loss(total):-0.001960\n",
            "recons_loss:0.005526\n",
            "grad_loss:0.119428\n",
            "dice_loss:-0.868120\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:232\n",
            "loss(total):-0.001398\n",
            "recons_loss:0.005937\n",
            "grad_loss:0.132128\n",
            "dice_loss:-0.865704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:233\n",
            "loss(total):-0.003549\n",
            "recons_loss:0.004310\n",
            "grad_loss:0.103340\n",
            "dice_loss:-0.889237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:234\n",
            "loss(total):-0.003839\n",
            "recons_loss:0.004166\n",
            "grad_loss:0.085904\n",
            "dice_loss:-0.886449\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:235\n",
            "loss(total):-0.002584\n",
            "recons_loss:0.005139\n",
            "grad_loss:0.103483\n",
            "dice_loss:-0.875789\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:236\n",
            "loss(total):-0.003383\n",
            "recons_loss:0.004534\n",
            "grad_loss:0.096553\n",
            "dice_loss:-0.888308\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:237\n",
            "loss(total):-0.003272\n",
            "recons_loss:0.004545\n",
            "grad_loss:0.111694\n",
            "dice_loss:-0.893379\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:238\n",
            "loss(total):-0.003178\n",
            "recons_loss:0.004601\n",
            "grad_loss:0.103901\n",
            "dice_loss:-0.881763\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:239\n",
            "loss(total):-0.002108\n",
            "recons_loss:0.005639\n",
            "grad_loss:0.115252\n",
            "dice_loss:-0.890024\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:240\n",
            "loss(total):-0.003985\n",
            "recons_loss:0.003963\n",
            "grad_loss:0.081715\n",
            "dice_loss:-0.876563\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:241\n",
            "loss(total):-0.003112\n",
            "recons_loss:0.004916\n",
            "grad_loss:0.090836\n",
            "dice_loss:-0.893629\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:242\n",
            "loss(total):-0.003968\n",
            "recons_loss:0.003975\n",
            "grad_loss:0.082241\n",
            "dice_loss:-0.876573\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:243\n",
            "loss(total):-0.002880\n",
            "recons_loss:0.004901\n",
            "grad_loss:0.109365\n",
            "dice_loss:-0.887518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:244\n",
            "loss(total):-0.003502\n",
            "recons_loss:0.004229\n",
            "grad_loss:0.107012\n",
            "dice_loss:-0.880137\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:245\n",
            "loss(total):-0.003805\n",
            "recons_loss:0.003852\n",
            "grad_loss:0.115738\n",
            "dice_loss:-0.881411\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:246\n",
            "loss(total):-0.003878\n",
            "recons_loss:0.004040\n",
            "grad_loss:0.096744\n",
            "dice_loss:-0.888531\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:247\n",
            "loss(total):-0.004261\n",
            "recons_loss:0.003729\n",
            "grad_loss:0.100466\n",
            "dice_loss:-0.899486\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:248\n",
            "loss(total):-0.003530\n",
            "recons_loss:0.004118\n",
            "grad_loss:0.106287\n",
            "dice_loss:-0.871127\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:249\n",
            "loss(total):-0.002733\n",
            "recons_loss:0.004899\n",
            "grad_loss:0.109461\n",
            "dice_loss:-0.872619\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:250\n",
            "loss(total):-0.002622\n",
            "recons_loss:0.005111\n",
            "grad_loss:0.096606\n",
            "dice_loss:-0.869867\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:251\n",
            "loss(total):-0.003179\n",
            "recons_loss:0.004622\n",
            "grad_loss:0.100943\n",
            "dice_loss:-0.880988\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:252\n",
            "loss(total):-0.003432\n",
            "recons_loss:0.004508\n",
            "grad_loss:0.096103\n",
            "dice_loss:-0.890092\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:253\n",
            "loss(total):-0.003869\n",
            "recons_loss:0.004069\n",
            "grad_loss:0.110707\n",
            "dice_loss:-0.904496\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:254\n",
            "loss(total):-0.003412\n",
            "recons_loss:0.004324\n",
            "grad_loss:0.101075\n",
            "dice_loss:-0.874662\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:255\n",
            "loss(total):-0.003344\n",
            "recons_loss:0.004588\n",
            "grad_loss:0.096586\n",
            "dice_loss:-0.889760\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:256\n",
            "loss(total):-0.003426\n",
            "recons_loss:0.004467\n",
            "grad_loss:0.100930\n",
            "dice_loss:-0.890191\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:257\n",
            "loss(total):-0.002618\n",
            "recons_loss:0.005131\n",
            "grad_loss:0.097922\n",
            "dice_loss:-0.872800\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:258\n",
            "loss(total):-0.003658\n",
            "recons_loss:0.004219\n",
            "grad_loss:0.105282\n",
            "dice_loss:-0.892997\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:259\n",
            "loss(total):-0.003943\n",
            "recons_loss:0.004115\n",
            "grad_loss:0.088078\n",
            "dice_loss:-0.893957\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:260\n",
            "loss(total):-0.003150\n",
            "recons_loss:0.004732\n",
            "grad_loss:0.105885\n",
            "dice_loss:-0.894066\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:261\n",
            "loss(total):-0.004074\n",
            "recons_loss:0.003940\n",
            "grad_loss:0.078096\n",
            "dice_loss:-0.879568\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:262\n",
            "loss(total):-0.003474\n",
            "recons_loss:0.004308\n",
            "grad_loss:0.103667\n",
            "dice_loss:-0.881924\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:263\n",
            "loss(total):-0.004241\n",
            "recons_loss:0.003761\n",
            "grad_loss:0.074913\n",
            "dice_loss:-0.875202\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:264\n",
            "loss(total):-0.003718\n",
            "recons_loss:0.004242\n",
            "grad_loss:0.094242\n",
            "dice_loss:-0.890209\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:265\n",
            "loss(total):-0.003678\n",
            "recons_loss:0.004130\n",
            "grad_loss:0.108441\n",
            "dice_loss:-0.889261\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:266\n",
            "loss(total):-0.003171\n",
            "recons_loss:0.004766\n",
            "grad_loss:0.102374\n",
            "dice_loss:-0.896112\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:267\n",
            "loss(total):-0.003745\n",
            "recons_loss:0.004202\n",
            "grad_loss:0.096703\n",
            "dice_loss:-0.891440\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:268\n",
            "loss(total):-0.002542\n",
            "recons_loss:0.005356\n",
            "grad_loss:0.103267\n",
            "dice_loss:-0.893141\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:269\n",
            "loss(total):-0.002701\n",
            "recons_loss:0.004963\n",
            "grad_loss:0.122660\n",
            "dice_loss:-0.889041\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:0\n",
            "loss(total):-0.003788\n",
            "recons_loss:0.004036\n",
            "grad_loss:0.093029\n",
            "dice_loss:-0.875405\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:1\n",
            "loss(total):-0.003885\n",
            "recons_loss:0.003979\n",
            "grad_loss:0.096573\n",
            "dice_loss:-0.883022\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:2\n",
            "loss(total):-0.002489\n",
            "recons_loss:0.005031\n",
            "grad_loss:0.110670\n",
            "dice_loss:-0.862661\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:3\n",
            "loss(total):-0.004393\n",
            "recons_loss:0.003698\n",
            "grad_loss:0.084244\n",
            "dice_loss:-0.893364\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:4\n",
            "loss(total):-0.003048\n",
            "recons_loss:0.004592\n",
            "grad_loss:0.119769\n",
            "dice_loss:-0.883775\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:5\n",
            "loss(total):-0.004212\n",
            "recons_loss:0.003904\n",
            "grad_loss:0.076977\n",
            "dice_loss:-0.888565\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:6\n",
            "loss(total):-0.003066\n",
            "recons_loss:0.004890\n",
            "grad_loss:0.091182\n",
            "dice_loss:-0.886772\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:7\n",
            "loss(total):-0.004585\n",
            "recons_loss:0.003594\n",
            "grad_loss:0.075980\n",
            "dice_loss:-0.893926\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:8\n",
            "loss(total):-0.003718\n",
            "recons_loss:0.004127\n",
            "grad_loss:0.102011\n",
            "dice_loss:-0.886496\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:9\n",
            "loss(total):-0.003415\n",
            "recons_loss:0.004351\n",
            "grad_loss:0.099669\n",
            "dice_loss:-0.876225\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:10\n",
            "loss(total):-0.003101\n",
            "recons_loss:0.004705\n",
            "grad_loss:0.094765\n",
            "dice_loss:-0.875298\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:11\n",
            "loss(total):-0.002184\n",
            "recons_loss:0.005285\n",
            "grad_loss:0.131112\n",
            "dice_loss:-0.877992\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:12\n",
            "loss(total):-0.003735\n",
            "recons_loss:0.004322\n",
            "grad_loss:0.094944\n",
            "dice_loss:-0.900598\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:13\n",
            "loss(total):-0.003162\n",
            "recons_loss:0.004775\n",
            "grad_loss:0.103425\n",
            "dice_loss:-0.897145\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:14\n",
            "loss(total):-0.003200\n",
            "recons_loss:0.004791\n",
            "grad_loss:0.087285\n",
            "dice_loss:-0.886388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:15\n",
            "loss(total):-0.002519\n",
            "recons_loss:0.005066\n",
            "grad_loss:0.103440\n",
            "dice_loss:-0.861939\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:16\n",
            "loss(total):-0.001857\n",
            "recons_loss:0.005449\n",
            "grad_loss:0.144152\n",
            "dice_loss:-0.874766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:17\n",
            "loss(total):-0.004125\n",
            "recons_loss:0.003883\n",
            "grad_loss:0.086671\n",
            "dice_loss:-0.887500\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:18\n",
            "loss(total):-0.003545\n",
            "recons_loss:0.004192\n",
            "grad_loss:0.105311\n",
            "dice_loss:-0.879012\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:19\n",
            "loss(total):-0.004056\n",
            "recons_loss:0.003937\n",
            "grad_loss:0.087118\n",
            "dice_loss:-0.886390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:20\n",
            "loss(total):-0.003340\n",
            "recons_loss:0.004582\n",
            "grad_loss:0.099626\n",
            "dice_loss:-0.891885\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:21\n",
            "loss(total):-0.003305\n",
            "recons_loss:0.004566\n",
            "grad_loss:0.102471\n",
            "dice_loss:-0.889582\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:22\n",
            "loss(total):-0.003019\n",
            "recons_loss:0.004675\n",
            "grad_loss:0.123160\n",
            "dice_loss:-0.892639\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:23\n",
            "loss(total):-0.004002\n",
            "recons_loss:0.003960\n",
            "grad_loss:0.093151\n",
            "dice_loss:-0.889306\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:24\n",
            "loss(total):-0.004324\n",
            "recons_loss:0.003560\n",
            "grad_loss:0.095777\n",
            "dice_loss:-0.884218\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:25\n",
            "loss(total):-0.002676\n",
            "recons_loss:0.005115\n",
            "grad_loss:0.110062\n",
            "dice_loss:-0.889235\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:26\n",
            "loss(total):-0.002211\n",
            "recons_loss:0.005474\n",
            "grad_loss:0.101372\n",
            "dice_loss:-0.869797\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:27\n",
            "loss(total):-0.002865\n",
            "recons_loss:0.004916\n",
            "grad_loss:0.095997\n",
            "dice_loss:-0.874093\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:28\n",
            "loss(total):-0.003239\n",
            "recons_loss:0.004550\n",
            "grad_loss:0.104329\n",
            "dice_loss:-0.883214\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:29\n",
            "loss(total):-0.003418\n",
            "recons_loss:0.004475\n",
            "grad_loss:0.098028\n",
            "dice_loss:-0.887289\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:30\n",
            "loss(total):-0.003530\n",
            "recons_loss:0.004377\n",
            "grad_loss:0.095242\n",
            "dice_loss:-0.885931\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:31\n",
            "loss(total):-0.004008\n",
            "recons_loss:0.003933\n",
            "grad_loss:0.086389\n",
            "dice_loss:-0.880560\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:32\n",
            "loss(total):-0.002022\n",
            "recons_loss:0.005639\n",
            "grad_loss:0.119185\n",
            "dice_loss:-0.885235\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:33\n",
            "loss(total):-0.003210\n",
            "recons_loss:0.004464\n",
            "grad_loss:0.091990\n",
            "dice_loss:-0.859366\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:34\n",
            "loss(total):-0.003058\n",
            "recons_loss:0.004578\n",
            "grad_loss:0.117588\n",
            "dice_loss:-0.881162\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:35\n",
            "loss(total):-0.004490\n",
            "recons_loss:0.003660\n",
            "grad_loss:0.082362\n",
            "dice_loss:-0.897296\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:36\n",
            "loss(total):-0.003402\n",
            "recons_loss:0.004527\n",
            "grad_loss:0.099175\n",
            "dice_loss:-0.892039\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:37\n",
            "loss(total):-0.003329\n",
            "recons_loss:0.004569\n",
            "grad_loss:0.101230\n",
            "dice_loss:-0.891048\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:38\n",
            "loss(total):-0.003340\n",
            "recons_loss:0.004544\n",
            "grad_loss:0.098618\n",
            "dice_loss:-0.887012\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:39\n",
            "loss(total):-0.003343\n",
            "recons_loss:0.004505\n",
            "grad_loss:0.088274\n",
            "dice_loss:-0.873060\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:40\n",
            "loss(total):-0.002933\n",
            "recons_loss:0.004638\n",
            "grad_loss:0.104733\n",
            "dice_loss:-0.861857\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:41\n",
            "loss(total):-0.003433\n",
            "recons_loss:0.004354\n",
            "grad_loss:0.109760\n",
            "dice_loss:-0.888530\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:42\n",
            "loss(total):-0.003322\n",
            "recons_loss:0.004638\n",
            "grad_loss:0.094543\n",
            "dice_loss:-0.890489\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:43\n",
            "loss(total):-0.003815\n",
            "recons_loss:0.004045\n",
            "grad_loss:0.097083\n",
            "dice_loss:-0.883118\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:44\n",
            "loss(total):-0.002608\n",
            "recons_loss:0.005225\n",
            "grad_loss:0.101098\n",
            "dice_loss:-0.884410\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:45\n",
            "loss(total):-0.003708\n",
            "recons_loss:0.004260\n",
            "grad_loss:0.095885\n",
            "dice_loss:-0.892699\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:46\n",
            "loss(total):-0.002090\n",
            "recons_loss:0.005492\n",
            "grad_loss:0.121032\n",
            "dice_loss:-0.879312\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:47\n",
            "loss(total):-0.004028\n",
            "recons_loss:0.003893\n",
            "grad_loss:0.090958\n",
            "dice_loss:-0.883054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:48\n",
            "loss(total):-0.003716\n",
            "recons_loss:0.004136\n",
            "grad_loss:0.101832\n",
            "dice_loss:-0.887052\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:49\n",
            "loss(total):-0.004173\n",
            "recons_loss:0.003815\n",
            "grad_loss:0.092584\n",
            "dice_loss:-0.891398\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:50\n",
            "loss(total):-0.002920\n",
            "recons_loss:0.004952\n",
            "grad_loss:0.105446\n",
            "dice_loss:-0.892641\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:51\n",
            "loss(total):-0.003969\n",
            "recons_loss:0.003971\n",
            "grad_loss:0.090933\n",
            "dice_loss:-0.884909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:52\n",
            "loss(total):-0.003944\n",
            "recons_loss:0.003872\n",
            "grad_loss:0.104390\n",
            "dice_loss:-0.886001\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:53\n",
            "loss(total):-0.003404\n",
            "recons_loss:0.004501\n",
            "grad_loss:0.092903\n",
            "dice_loss:-0.883357\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:54\n",
            "loss(total):-0.003967\n",
            "recons_loss:0.003936\n",
            "grad_loss:0.094794\n",
            "dice_loss:-0.885081\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:55\n",
            "loss(total):-0.003168\n",
            "recons_loss:0.004456\n",
            "grad_loss:0.112080\n",
            "dice_loss:-0.874475\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:56\n",
            "loss(total):-0.001594\n",
            "recons_loss:0.005659\n",
            "grad_loss:0.134950\n",
            "dice_loss:-0.860274\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:57\n",
            "loss(total):-0.004544\n",
            "recons_loss:0.003648\n",
            "grad_loss:0.092519\n",
            "dice_loss:-0.911666\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:58\n",
            "loss(total):-0.003423\n",
            "recons_loss:0.004458\n",
            "grad_loss:0.093499\n",
            "dice_loss:-0.881524\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:59\n",
            "loss(total):-0.003609\n",
            "recons_loss:0.004453\n",
            "grad_loss:0.090570\n",
            "dice_loss:-0.896729\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:60\n",
            "loss(total):-0.003477\n",
            "recons_loss:0.004449\n",
            "grad_loss:0.100916\n",
            "dice_loss:-0.893549\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:61\n",
            "loss(total):-0.003323\n",
            "recons_loss:0.004513\n",
            "grad_loss:0.101031\n",
            "dice_loss:-0.884603\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:62\n",
            "loss(total):-0.003751\n",
            "recons_loss:0.004193\n",
            "grad_loss:0.094757\n",
            "dice_loss:-0.889155\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:63\n",
            "loss(total):-0.003038\n",
            "recons_loss:0.004799\n",
            "grad_loss:0.110428\n",
            "dice_loss:-0.894131\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:64\n",
            "loss(total):-0.002418\n",
            "recons_loss:0.005314\n",
            "grad_loss:0.113472\n",
            "dice_loss:-0.886690\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:65\n",
            "loss(total):-0.000712\n",
            "recons_loss:0.006573\n",
            "grad_loss:0.135064\n",
            "dice_loss:-0.863568\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:66\n",
            "loss(total):-0.003904\n",
            "recons_loss:0.004044\n",
            "grad_loss:0.093494\n",
            "dice_loss:-0.888276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:67\n",
            "loss(total):-0.004036\n",
            "recons_loss:0.004016\n",
            "grad_loss:0.081237\n",
            "dice_loss:-0.886508\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:68\n",
            "loss(total):-0.003280\n",
            "recons_loss:0.004475\n",
            "grad_loss:0.100087\n",
            "dice_loss:-0.875516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:69\n",
            "loss(total):-0.003840\n",
            "recons_loss:0.004160\n",
            "grad_loss:0.086700\n",
            "dice_loss:-0.886758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:70\n",
            "loss(total):-0.004754\n",
            "recons_loss:0.003509\n",
            "grad_loss:0.085013\n",
            "dice_loss:-0.911327\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:71\n",
            "loss(total):-0.003033\n",
            "recons_loss:0.004851\n",
            "grad_loss:0.091312\n",
            "dice_loss:-0.879754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:72\n",
            "loss(total):-0.003060\n",
            "recons_loss:0.004722\n",
            "grad_loss:0.109541\n",
            "dice_loss:-0.887748\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:73\n",
            "loss(total):-0.003954\n",
            "recons_loss:0.003835\n",
            "grad_loss:0.104181\n",
            "dice_loss:-0.883052\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:74\n",
            "loss(total):-0.004407\n",
            "recons_loss:0.003554\n",
            "grad_loss:0.078125\n",
            "dice_loss:-0.874215\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:75\n",
            "loss(total):-0.004218\n",
            "recons_loss:0.003932\n",
            "grad_loss:0.073465\n",
            "dice_loss:-0.888429\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:76\n",
            "loss(total):-0.003458\n",
            "recons_loss:0.004456\n",
            "grad_loss:0.094169\n",
            "dice_loss:-0.885594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:77\n",
            "loss(total):-0.003236\n",
            "recons_loss:0.004736\n",
            "grad_loss:0.096420\n",
            "dice_loss:-0.893585\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:78\n",
            "loss(total):-0.003573\n",
            "recons_loss:0.004503\n",
            "grad_loss:0.089290\n",
            "dice_loss:-0.896855\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:79\n",
            "loss(total):-0.002960\n",
            "recons_loss:0.004637\n",
            "grad_loss:0.126751\n",
            "dice_loss:-0.886361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:80\n",
            "loss(total):-0.004323\n",
            "recons_loss:0.003594\n",
            "grad_loss:0.085727\n",
            "dice_loss:-0.877379\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:81\n",
            "loss(total):-0.003385\n",
            "recons_loss:0.004548\n",
            "grad_loss:0.088621\n",
            "dice_loss:-0.881841\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:82\n",
            "loss(total):-0.003224\n",
            "recons_loss:0.004656\n",
            "grad_loss:0.083806\n",
            "dice_loss:-0.871750\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:83\n",
            "loss(total):-0.004730\n",
            "recons_loss:0.003385\n",
            "grad_loss:0.069163\n",
            "dice_loss:-0.880682\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:84\n",
            "loss(total):-0.002077\n",
            "recons_loss:0.005470\n",
            "grad_loss:0.111535\n",
            "dice_loss:-0.866200\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:85\n",
            "loss(total):-0.003712\n",
            "recons_loss:0.004138\n",
            "grad_loss:0.101636\n",
            "dice_loss:-0.886615\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:86\n",
            "loss(total):-0.001757\n",
            "recons_loss:0.005732\n",
            "grad_loss:0.129366\n",
            "dice_loss:-0.878308\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:87\n",
            "loss(total):-0.005157\n",
            "recons_loss:0.003190\n",
            "grad_loss:0.074092\n",
            "dice_loss:-0.908822\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:88\n",
            "loss(total):-0.002344\n",
            "recons_loss:0.005431\n",
            "grad_loss:0.121520\n",
            "dice_loss:-0.899019\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:89\n",
            "loss(total):-0.002472\n",
            "recons_loss:0.005037\n",
            "grad_loss:0.122963\n",
            "dice_loss:-0.873797\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:90\n",
            "loss(total):-0.002768\n",
            "recons_loss:0.004949\n",
            "grad_loss:0.113344\n",
            "dice_loss:-0.885015\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:91\n",
            "loss(total):-0.004463\n",
            "recons_loss:0.003619\n",
            "grad_loss:0.083962\n",
            "dice_loss:-0.892207\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:92\n",
            "loss(total):-0.002231\n",
            "recons_loss:0.005361\n",
            "grad_loss:0.122120\n",
            "dice_loss:-0.881339\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:93\n",
            "loss(total):-0.002834\n",
            "recons_loss:0.004953\n",
            "grad_loss:0.101650\n",
            "dice_loss:-0.880354\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:94\n",
            "loss(total):-0.005873\n",
            "recons_loss:0.002555\n",
            "grad_loss:0.059985\n",
            "dice_loss:-0.902811\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:95\n",
            "loss(total):-0.004671\n",
            "recons_loss:0.003468\n",
            "grad_loss:0.087008\n",
            "dice_loss:-0.900932\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:96\n",
            "loss(total):-0.003349\n",
            "recons_loss:0.004843\n",
            "grad_loss:0.075203\n",
            "dice_loss:-0.894372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:97\n",
            "loss(total):-0.003231\n",
            "recons_loss:0.004626\n",
            "grad_loss:0.094048\n",
            "dice_loss:-0.879736\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:98\n",
            "loss(total):-0.002794\n",
            "recons_loss:0.004877\n",
            "grad_loss:0.106579\n",
            "dice_loss:-0.873635\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:99\n",
            "loss(total):-0.003230\n",
            "recons_loss:0.004496\n",
            "grad_loss:0.108085\n",
            "dice_loss:-0.880616\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:100\n",
            "loss(total):-0.004770\n",
            "recons_loss:0.003096\n",
            "grad_loss:0.098108\n",
            "dice_loss:-0.884624\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:101\n",
            "loss(total):-0.003273\n",
            "recons_loss:0.004503\n",
            "grad_loss:0.098362\n",
            "dice_loss:-0.875991\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:102\n",
            "loss(total):-0.003788\n",
            "recons_loss:0.004146\n",
            "grad_loss:0.084754\n",
            "dice_loss:-0.878140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:103\n",
            "loss(total):-0.003581\n",
            "recons_loss:0.004408\n",
            "grad_loss:0.097520\n",
            "dice_loss:-0.896429\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:104\n",
            "loss(total):-0.003746\n",
            "recons_loss:0.004084\n",
            "grad_loss:0.108949\n",
            "dice_loss:-0.891877\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:105\n",
            "loss(total):-0.003842\n",
            "recons_loss:0.004102\n",
            "grad_loss:0.098564\n",
            "dice_loss:-0.892925\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:106\n",
            "loss(total):-0.003631\n",
            "recons_loss:0.004283\n",
            "grad_loss:0.100743\n",
            "dice_loss:-0.892114\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:107\n",
            "loss(total):-0.002315\n",
            "recons_loss:0.005282\n",
            "grad_loss:0.114153\n",
            "dice_loss:-0.873849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:108\n",
            "loss(total):-0.004384\n",
            "recons_loss:0.003714\n",
            "grad_loss:0.080298\n",
            "dice_loss:-0.890130\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:109\n",
            "loss(total):-0.002477\n",
            "recons_loss:0.005442\n",
            "grad_loss:0.098132\n",
            "dice_loss:-0.890066\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:110\n",
            "loss(total):-0.003440\n",
            "recons_loss:0.004688\n",
            "grad_loss:0.080143\n",
            "dice_loss:-0.893017\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:111\n",
            "loss(total):-0.004108\n",
            "recons_loss:0.003984\n",
            "grad_loss:0.079477\n",
            "dice_loss:-0.888642\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:112\n",
            "loss(total):-0.002626\n",
            "recons_loss:0.005076\n",
            "grad_loss:0.116348\n",
            "dice_loss:-0.886536\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:113\n",
            "loss(total):-0.004598\n",
            "recons_loss:0.003295\n",
            "grad_loss:0.096760\n",
            "dice_loss:-0.886078\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:114\n",
            "loss(total):-0.003020\n",
            "recons_loss:0.004760\n",
            "grad_loss:0.104342\n",
            "dice_loss:-0.882250\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:115\n",
            "loss(total):-0.003621\n",
            "recons_loss:0.004280\n",
            "grad_loss:0.101929\n",
            "dice_loss:-0.891960\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:116\n",
            "loss(total):-0.003073\n",
            "recons_loss:0.004750\n",
            "grad_loss:0.107104\n",
            "dice_loss:-0.889377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:117\n",
            "loss(total):-0.003006\n",
            "recons_loss:0.004770\n",
            "grad_loss:0.108339\n",
            "dice_loss:-0.885972\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:118\n",
            "loss(total):-0.003206\n",
            "recons_loss:0.004723\n",
            "grad_loss:0.106726\n",
            "dice_loss:-0.899550\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:119\n",
            "loss(total):-0.003826\n",
            "recons_loss:0.004158\n",
            "grad_loss:0.092956\n",
            "dice_loss:-0.891389\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:120\n",
            "loss(total):-0.004453\n",
            "recons_loss:0.003641\n",
            "grad_loss:0.082789\n",
            "dice_loss:-0.892245\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:121\n",
            "loss(total):-0.002602\n",
            "recons_loss:0.005059\n",
            "grad_loss:0.113749\n",
            "dice_loss:-0.879798\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:122\n",
            "loss(total):-0.003558\n",
            "recons_loss:0.004448\n",
            "grad_loss:0.100645\n",
            "dice_loss:-0.901235\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:123\n",
            "loss(total):-0.002512\n",
            "recons_loss:0.005174\n",
            "grad_loss:0.117466\n",
            "dice_loss:-0.886088\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:124\n",
            "loss(total):-0.003220\n",
            "recons_loss:0.004612\n",
            "grad_loss:0.108812\n",
            "dice_loss:-0.892022\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:125\n",
            "loss(total):-0.001726\n",
            "recons_loss:0.005784\n",
            "grad_loss:0.133839\n",
            "dice_loss:-0.884874\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:126\n",
            "loss(total):-0.002960\n",
            "recons_loss:0.004668\n",
            "grad_loss:0.123650\n",
            "dice_loss:-0.886427\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:127\n",
            "loss(total):-0.004176\n",
            "recons_loss:0.003846\n",
            "grad_loss:0.094937\n",
            "dice_loss:-0.897062\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:128\n",
            "loss(total):-0.005354\n",
            "recons_loss:0.002978\n",
            "grad_loss:0.070706\n",
            "dice_loss:-0.903863\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:129\n",
            "loss(total):-0.003052\n",
            "recons_loss:0.004679\n",
            "grad_loss:0.108866\n",
            "dice_loss:-0.881902\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:130\n",
            "loss(total):-0.004805\n",
            "recons_loss:0.003291\n",
            "grad_loss:0.093968\n",
            "dice_loss:-0.903560\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:131\n",
            "loss(total):-0.004018\n",
            "recons_loss:0.004250\n",
            "grad_loss:0.072196\n",
            "dice_loss:-0.898956\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:132\n",
            "loss(total):-0.002166\n",
            "recons_loss:0.005607\n",
            "grad_loss:0.124372\n",
            "dice_loss:-0.901667\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:133\n",
            "loss(total):-0.004070\n",
            "recons_loss:0.003803\n",
            "grad_loss:0.097267\n",
            "dice_loss:-0.884554\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:134\n",
            "loss(total):-0.003611\n",
            "recons_loss:0.004362\n",
            "grad_loss:0.089564\n",
            "dice_loss:-0.886810\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:135\n",
            "loss(total):-0.004110\n",
            "recons_loss:0.003865\n",
            "grad_loss:0.082223\n",
            "dice_loss:-0.879770\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:136\n",
            "loss(total):-0.004426\n",
            "recons_loss:0.003614\n",
            "grad_loss:0.078695\n",
            "dice_loss:-0.882634\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:137\n",
            "loss(total):-0.001648\n",
            "recons_loss:0.005941\n",
            "grad_loss:0.124167\n",
            "dice_loss:-0.882978\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:138\n",
            "loss(total):-0.002584\n",
            "recons_loss:0.005135\n",
            "grad_loss:0.107100\n",
            "dice_loss:-0.879002\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:139\n",
            "loss(total):-0.003509\n",
            "recons_loss:0.004376\n",
            "grad_loss:0.090453\n",
            "dice_loss:-0.878884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:140\n",
            "loss(total):-0.002838\n",
            "recons_loss:0.004936\n",
            "grad_loss:0.104317\n",
            "dice_loss:-0.881771\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:141\n",
            "loss(total):-0.003417\n",
            "recons_loss:0.004343\n",
            "grad_loss:0.100428\n",
            "dice_loss:-0.876361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:142\n",
            "loss(total):-0.002995\n",
            "recons_loss:0.004873\n",
            "grad_loss:0.097642\n",
            "dice_loss:-0.884451\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:143\n",
            "loss(total):-0.003545\n",
            "recons_loss:0.004183\n",
            "grad_loss:0.114446\n",
            "dice_loss:-0.887239\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:144\n",
            "loss(total):-0.002547\n",
            "recons_loss:0.004906\n",
            "grad_loss:0.131658\n",
            "dice_loss:-0.876950\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:145\n",
            "loss(total):-0.002514\n",
            "recons_loss:0.005030\n",
            "grad_loss:0.128771\n",
            "dice_loss:-0.883118\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:146\n",
            "loss(total):-0.002164\n",
            "recons_loss:0.005375\n",
            "grad_loss:0.121378\n",
            "dice_loss:-0.875325\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:147\n",
            "loss(total):-0.004498\n",
            "recons_loss:0.003647\n",
            "grad_loss:0.084479\n",
            "dice_loss:-0.898994\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:148\n",
            "loss(total):-0.003200\n",
            "recons_loss:0.004920\n",
            "grad_loss:0.083302\n",
            "dice_loss:-0.895230\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:149\n",
            "loss(total):-0.003367\n",
            "recons_loss:0.004665\n",
            "grad_loss:0.088538\n",
            "dice_loss:-0.891799\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:150\n",
            "loss(total):-0.002403\n",
            "recons_loss:0.005346\n",
            "grad_loss:0.107750\n",
            "dice_loss:-0.882632\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:151\n",
            "loss(total):-0.003398\n",
            "recons_loss:0.004203\n",
            "grad_loss:0.113630\n",
            "dice_loss:-0.873705\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:152\n",
            "loss(total):-0.004517\n",
            "recons_loss:0.003538\n",
            "grad_loss:0.078936\n",
            "dice_loss:-0.884463\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:153\n",
            "loss(total):-0.003035\n",
            "recons_loss:0.004794\n",
            "grad_loss:0.115333\n",
            "dice_loss:-0.898245\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:154\n",
            "loss(total):-0.003456\n",
            "recons_loss:0.004524\n",
            "grad_loss:0.092930\n",
            "dice_loss:-0.890917\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:155\n",
            "loss(total):-0.002939\n",
            "recons_loss:0.004916\n",
            "grad_loss:0.105312\n",
            "dice_loss:-0.890801\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:156\n",
            "loss(total):-0.003501\n",
            "recons_loss:0.004474\n",
            "grad_loss:0.092680\n",
            "dice_loss:-0.890130\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:157\n",
            "loss(total):-0.002546\n",
            "recons_loss:0.005088\n",
            "grad_loss:0.118864\n",
            "dice_loss:-0.882321\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:158\n",
            "loss(total):-0.003948\n",
            "recons_loss:0.004057\n",
            "grad_loss:0.091708\n",
            "dice_loss:-0.892276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:159\n",
            "loss(total):-0.003645\n",
            "recons_loss:0.004277\n",
            "grad_loss:0.091948\n",
            "dice_loss:-0.884139\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:160\n",
            "loss(total):-0.003878\n",
            "recons_loss:0.004021\n",
            "grad_loss:0.093748\n",
            "dice_loss:-0.883652\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:161\n",
            "loss(total):-0.003686\n",
            "recons_loss:0.004151\n",
            "grad_loss:0.097841\n",
            "dice_loss:-0.881563\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:162\n",
            "loss(total):-0.003726\n",
            "recons_loss:0.004289\n",
            "grad_loss:0.096292\n",
            "dice_loss:-0.897791\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:163\n",
            "loss(total):-0.004054\n",
            "recons_loss:0.004046\n",
            "grad_loss:0.088296\n",
            "dice_loss:-0.898295\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:164\n",
            "loss(total):-0.002806\n",
            "recons_loss:0.004900\n",
            "grad_loss:0.102825\n",
            "dice_loss:-0.873388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:165\n",
            "loss(total):-0.003863\n",
            "recons_loss:0.003936\n",
            "grad_loss:0.098586\n",
            "dice_loss:-0.878470\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:166\n",
            "loss(total):-0.003578\n",
            "recons_loss:0.004284\n",
            "grad_loss:0.097589\n",
            "dice_loss:-0.883834\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:167\n",
            "loss(total):-0.004323\n",
            "recons_loss:0.003364\n",
            "grad_loss:0.096904\n",
            "dice_loss:-0.865606\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:168\n",
            "loss(total):-0.004757\n",
            "recons_loss:0.003214\n",
            "grad_loss:0.085872\n",
            "dice_loss:-0.882960\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:169\n",
            "loss(total):-0.003672\n",
            "recons_loss:0.004100\n",
            "grad_loss:0.100966\n",
            "dice_loss:-0.878184\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:170\n",
            "loss(total):-0.003974\n",
            "recons_loss:0.003909\n",
            "grad_loss:0.111031\n",
            "dice_loss:-0.899364\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:171\n",
            "loss(total):-0.003830\n",
            "recons_loss:0.003906\n",
            "grad_loss:0.103132\n",
            "dice_loss:-0.876656\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:172\n",
            "loss(total):-0.003146\n",
            "recons_loss:0.004711\n",
            "grad_loss:0.100369\n",
            "dice_loss:-0.886116\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:173\n",
            "loss(total):-0.003849\n",
            "recons_loss:0.004054\n",
            "grad_loss:0.107982\n",
            "dice_loss:-0.898220\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:174\n",
            "loss(total):-0.004016\n",
            "recons_loss:0.003774\n",
            "grad_loss:0.097686\n",
            "dice_loss:-0.876715\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:175\n",
            "loss(total):-0.001907\n",
            "recons_loss:0.005693\n",
            "grad_loss:0.121699\n",
            "dice_loss:-0.881710\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:176\n",
            "loss(total):-0.003891\n",
            "recons_loss:0.003983\n",
            "grad_loss:0.100460\n",
            "dice_loss:-0.887854\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:177\n",
            "loss(total):-0.003880\n",
            "recons_loss:0.003933\n",
            "grad_loss:0.106369\n",
            "dice_loss:-0.887593\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:178\n",
            "loss(total):-0.004563\n",
            "recons_loss:0.003633\n",
            "grad_loss:0.077635\n",
            "dice_loss:-0.897260\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:179\n",
            "loss(total):-0.002218\n",
            "recons_loss:0.005534\n",
            "grad_loss:0.109947\n",
            "dice_loss:-0.885180\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:180\n",
            "loss(total):-0.003811\n",
            "recons_loss:0.003991\n",
            "grad_loss:0.103778\n",
            "dice_loss:-0.883964\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:181\n",
            "loss(total):-0.003279\n",
            "recons_loss:0.004602\n",
            "grad_loss:0.103833\n",
            "dice_loss:-0.891907\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:182\n",
            "loss(total):-0.004667\n",
            "recons_loss:0.003388\n",
            "grad_loss:0.090103\n",
            "dice_loss:-0.895624\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:183\n",
            "loss(total):-0.003272\n",
            "recons_loss:0.004599\n",
            "grad_loss:0.094229\n",
            "dice_loss:-0.881305\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:184\n",
            "loss(total):-0.003157\n",
            "recons_loss:0.004561\n",
            "grad_loss:0.121560\n",
            "dice_loss:-0.893273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:185\n",
            "loss(total):-0.003900\n",
            "recons_loss:0.004176\n",
            "grad_loss:0.084038\n",
            "dice_loss:-0.891658\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:186\n",
            "loss(total):-0.004509\n",
            "recons_loss:0.003655\n",
            "grad_loss:0.074461\n",
            "dice_loss:-0.890866\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:187\n",
            "loss(total):-0.003499\n",
            "recons_loss:0.004429\n",
            "grad_loss:0.098997\n",
            "dice_loss:-0.891805\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:188\n",
            "loss(total):-0.004369\n",
            "recons_loss:0.003668\n",
            "grad_loss:0.087439\n",
            "dice_loss:-0.891093\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:189\n",
            "loss(total):-0.004276\n",
            "recons_loss:0.003584\n",
            "grad_loss:0.090549\n",
            "dice_loss:-0.876599\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:190\n",
            "loss(total):-0.005000\n",
            "recons_loss:0.003266\n",
            "grad_loss:0.073473\n",
            "dice_loss:-0.900072\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:191\n",
            "loss(total):-0.003240\n",
            "recons_loss:0.004603\n",
            "grad_loss:0.109879\n",
            "dice_loss:-0.894176\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:192\n",
            "loss(total):-0.005225\n",
            "recons_loss:0.003012\n",
            "grad_loss:0.084775\n",
            "dice_loss:-0.908490\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:193\n",
            "loss(total):-0.003903\n",
            "recons_loss:0.004235\n",
            "grad_loss:0.080326\n",
            "dice_loss:-0.894114\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:194\n",
            "loss(total):-0.002559\n",
            "recons_loss:0.004975\n",
            "grad_loss:0.110039\n",
            "dice_loss:-0.863397\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:195\n",
            "loss(total):-0.002621\n",
            "recons_loss:0.004857\n",
            "grad_loss:0.122489\n",
            "dice_loss:-0.870286\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:196\n",
            "loss(total):-0.003614\n",
            "recons_loss:0.004217\n",
            "grad_loss:0.109829\n",
            "dice_loss:-0.892911\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:197\n",
            "loss(total):-0.002136\n",
            "recons_loss:0.005351\n",
            "grad_loss:0.132342\n",
            "dice_loss:-0.881084\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:198\n",
            "loss(total):-0.003050\n",
            "recons_loss:0.004656\n",
            "grad_loss:0.108078\n",
            "dice_loss:-0.878646\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:199\n",
            "loss(total):-0.003788\n",
            "recons_loss:0.004095\n",
            "grad_loss:0.096165\n",
            "dice_loss:-0.884379\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:200\n",
            "loss(total):-0.005147\n",
            "recons_loss:0.003100\n",
            "grad_loss:0.080090\n",
            "dice_loss:-0.904809\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:201\n",
            "loss(total):-0.004148\n",
            "recons_loss:0.003804\n",
            "grad_loss:0.089040\n",
            "dice_loss:-0.884264\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:202\n",
            "loss(total):-0.004952\n",
            "recons_loss:0.003288\n",
            "grad_loss:0.074106\n",
            "dice_loss:-0.898104\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:203\n",
            "loss(total):-0.002342\n",
            "recons_loss:0.005115\n",
            "grad_loss:0.123395\n",
            "dice_loss:-0.869033\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:204\n",
            "loss(total):-0.004241\n",
            "recons_loss:0.003858\n",
            "grad_loss:0.091043\n",
            "dice_loss:-0.900929\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:205\n",
            "loss(total):-0.002092\n",
            "recons_loss:0.005604\n",
            "grad_loss:0.113639\n",
            "dice_loss:-0.883260\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:206\n",
            "loss(total):-0.002650\n",
            "recons_loss:0.005232\n",
            "grad_loss:0.090024\n",
            "dice_loss:-0.878232\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:207\n",
            "loss(total):-0.004340\n",
            "recons_loss:0.003568\n",
            "grad_loss:0.098497\n",
            "dice_loss:-0.889281\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:208\n",
            "loss(total):-0.003145\n",
            "recons_loss:0.004682\n",
            "grad_loss:0.114577\n",
            "dice_loss:-0.897299\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:209\n",
            "loss(total):-0.002831\n",
            "recons_loss:0.004909\n",
            "grad_loss:0.120508\n",
            "dice_loss:-0.894499\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:210\n",
            "loss(total):-0.005148\n",
            "recons_loss:0.003079\n",
            "grad_loss:0.075887\n",
            "dice_loss:-0.898646\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:211\n",
            "loss(total):-0.003538\n",
            "recons_loss:0.004208\n",
            "grad_loss:0.100044\n",
            "dice_loss:-0.874665\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:212\n",
            "loss(total):-0.002736\n",
            "recons_loss:0.005034\n",
            "grad_loss:0.109063\n",
            "dice_loss:-0.886090\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:213\n",
            "loss(total):-0.003541\n",
            "recons_loss:0.004437\n",
            "grad_loss:0.090645\n",
            "dice_loss:-0.888408\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:214\n",
            "loss(total):-0.003077\n",
            "recons_loss:0.004574\n",
            "grad_loss:0.105927\n",
            "dice_loss:-0.871027\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:215\n",
            "loss(total):-0.003081\n",
            "recons_loss:0.004714\n",
            "grad_loss:0.100591\n",
            "dice_loss:-0.880089\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:216\n",
            "loss(total):-0.003363\n",
            "recons_loss:0.004465\n",
            "grad_loss:0.109769\n",
            "dice_loss:-0.892601\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:217\n",
            "loss(total):-0.003432\n",
            "recons_loss:0.004326\n",
            "grad_loss:0.110445\n",
            "dice_loss:-0.886233\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:218\n",
            "loss(total):-0.003916\n",
            "recons_loss:0.004044\n",
            "grad_loss:0.084336\n",
            "dice_loss:-0.880348\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:219\n",
            "loss(total):-0.004363\n",
            "recons_loss:0.003763\n",
            "grad_loss:0.079302\n",
            "dice_loss:-0.891945\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:220\n",
            "loss(total):-0.004098\n",
            "recons_loss:0.003923\n",
            "grad_loss:0.094519\n",
            "dice_loss:-0.896649\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:221\n",
            "loss(total):-0.003859\n",
            "recons_loss:0.003970\n",
            "grad_loss:0.089312\n",
            "dice_loss:-0.872125\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:222\n",
            "loss(total):-0.004365\n",
            "recons_loss:0.003895\n",
            "grad_loss:0.070917\n",
            "dice_loss:-0.896937\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:223\n",
            "loss(total):-0.003313\n",
            "recons_loss:0.004609\n",
            "grad_loss:0.101929\n",
            "dice_loss:-0.894087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:224\n",
            "loss(total):-0.003283\n",
            "recons_loss:0.004573\n",
            "grad_loss:0.092960\n",
            "dice_loss:-0.878518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:225\n",
            "loss(total):-0.002375\n",
            "recons_loss:0.005257\n",
            "grad_loss:0.116631\n",
            "dice_loss:-0.879799\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:226\n",
            "loss(total):-0.002721\n",
            "recons_loss:0.004999\n",
            "grad_loss:0.123473\n",
            "dice_loss:-0.895478\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:227\n",
            "loss(total):-0.001741\n",
            "recons_loss:0.005889\n",
            "grad_loss:0.119469\n",
            "dice_loss:-0.882453\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:228\n",
            "loss(total):-0.001233\n",
            "recons_loss:0.006330\n",
            "grad_loss:0.120426\n",
            "dice_loss:-0.876694\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:229\n",
            "loss(total):-0.001826\n",
            "recons_loss:0.005619\n",
            "grad_loss:0.128694\n",
            "dice_loss:-0.873130\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:230\n",
            "loss(total):-0.002372\n",
            "recons_loss:0.005340\n",
            "grad_loss:0.104959\n",
            "dice_loss:-0.876146\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:231\n",
            "loss(total):-0.004188\n",
            "recons_loss:0.003900\n",
            "grad_loss:0.085908\n",
            "dice_loss:-0.894681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:232\n",
            "loss(total):-0.002971\n",
            "recons_loss:0.004753\n",
            "grad_loss:0.106554\n",
            "dice_loss:-0.878970\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:233\n",
            "loss(total):-0.003923\n",
            "recons_loss:0.003964\n",
            "grad_loss:0.099550\n",
            "dice_loss:-0.888276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:234\n",
            "loss(total):-0.003309\n",
            "recons_loss:0.004360\n",
            "grad_loss:0.111640\n",
            "dice_loss:-0.878536\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:235\n",
            "loss(total):-0.002652\n",
            "recons_loss:0.004961\n",
            "grad_loss:0.116701\n",
            "dice_loss:-0.878007\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:236\n",
            "loss(total):-0.003357\n",
            "recons_loss:0.004581\n",
            "grad_loss:0.101031\n",
            "dice_loss:-0.894829\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:237\n",
            "loss(total):-0.003269\n",
            "recons_loss:0.004543\n",
            "grad_loss:0.095079\n",
            "dice_loss:-0.876237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:238\n",
            "loss(total):-0.003113\n",
            "recons_loss:0.004564\n",
            "grad_loss:0.112020\n",
            "dice_loss:-0.879732\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:239\n",
            "loss(total):-0.003488\n",
            "recons_loss:0.004272\n",
            "grad_loss:0.100279\n",
            "dice_loss:-0.876194\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:240\n",
            "loss(total):-0.003354\n",
            "recons_loss:0.004618\n",
            "grad_loss:0.097685\n",
            "dice_loss:-0.894881\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:241\n",
            "loss(total):-0.003730\n",
            "recons_loss:0.004180\n",
            "grad_loss:0.092271\n",
            "dice_loss:-0.883326\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:242\n",
            "loss(total):-0.002892\n",
            "recons_loss:0.004784\n",
            "grad_loss:0.119011\n",
            "dice_loss:-0.886612\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:243\n",
            "loss(total):-0.002811\n",
            "recons_loss:0.004793\n",
            "grad_loss:0.114965\n",
            "dice_loss:-0.875283\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:244\n",
            "loss(total):-0.004273\n",
            "recons_loss:0.003616\n",
            "grad_loss:0.090908\n",
            "dice_loss:-0.879807\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:245\n",
            "loss(total):-0.003553\n",
            "recons_loss:0.004437\n",
            "grad_loss:0.092939\n",
            "dice_loss:-0.891874\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:246\n",
            "loss(total):-0.002910\n",
            "recons_loss:0.004676\n",
            "grad_loss:0.121490\n",
            "dice_loss:-0.880152\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:247\n",
            "loss(total):-0.003334\n",
            "recons_loss:0.004426\n",
            "grad_loss:0.113505\n",
            "dice_loss:-0.889522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:248\n",
            "loss(total):-0.003088\n",
            "recons_loss:0.004801\n",
            "grad_loss:0.095610\n",
            "dice_loss:-0.884473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:249\n",
            "loss(total):-0.003233\n",
            "recons_loss:0.004412\n",
            "grad_loss:0.111710\n",
            "dice_loss:-0.876168\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:250\n",
            "loss(total):-0.003146\n",
            "recons_loss:0.004481\n",
            "grad_loss:0.112522\n",
            "dice_loss:-0.875181\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:251\n",
            "loss(total):-0.003600\n",
            "recons_loss:0.004278\n",
            "grad_loss:0.097083\n",
            "dice_loss:-0.884912\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:252\n",
            "loss(total):-0.003131\n",
            "recons_loss:0.004649\n",
            "grad_loss:0.097258\n",
            "dice_loss:-0.875201\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:253\n",
            "loss(total):-0.004064\n",
            "recons_loss:0.003838\n",
            "grad_loss:0.089051\n",
            "dice_loss:-0.879279\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:254\n",
            "loss(total):-0.003760\n",
            "recons_loss:0.004227\n",
            "grad_loss:0.087929\n",
            "dice_loss:-0.886619\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:255\n",
            "loss(total):-0.003673\n",
            "recons_loss:0.004212\n",
            "grad_loss:0.105094\n",
            "dice_loss:-0.893658\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:256\n",
            "loss(total):-0.002582\n",
            "recons_loss:0.005071\n",
            "grad_loss:0.109965\n",
            "dice_loss:-0.875311\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:257\n",
            "loss(total):-0.004864\n",
            "recons_loss:0.003215\n",
            "grad_loss:0.092413\n",
            "dice_loss:-0.900292\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:258\n",
            "loss(total):-0.003975\n",
            "recons_loss:0.004033\n",
            "grad_loss:0.100055\n",
            "dice_loss:-0.900855\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:259\n",
            "loss(total):-0.001972\n",
            "recons_loss:0.005540\n",
            "grad_loss:0.129609\n",
            "dice_loss:-0.880851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:260\n",
            "loss(total):-0.003303\n",
            "recons_loss:0.004408\n",
            "grad_loss:0.109024\n",
            "dice_loss:-0.880165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:261\n",
            "loss(total):-0.002646\n",
            "recons_loss:0.005115\n",
            "grad_loss:0.119035\n",
            "dice_loss:-0.895164\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:262\n",
            "loss(total):-0.003940\n",
            "recons_loss:0.004030\n",
            "grad_loss:0.089854\n",
            "dice_loss:-0.886880\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:263\n",
            "loss(total):-0.002637\n",
            "recons_loss:0.005094\n",
            "grad_loss:0.122621\n",
            "dice_loss:-0.895792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:264\n",
            "loss(total):-0.003779\n",
            "recons_loss:0.004134\n",
            "grad_loss:0.104769\n",
            "dice_loss:-0.896077\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:265\n",
            "loss(total):-0.002303\n",
            "recons_loss:0.005325\n",
            "grad_loss:0.125601\n",
            "dice_loss:-0.888421\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:266\n",
            "loss(total):-0.002458\n",
            "recons_loss:0.005084\n",
            "grad_loss:0.132244\n",
            "dice_loss:-0.886424\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:267\n",
            "loss(total):-0.003823\n",
            "recons_loss:0.004008\n",
            "grad_loss:0.102307\n",
            "dice_loss:-0.885380\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:268\n",
            "loss(total):-0.003309\n",
            "recons_loss:0.004432\n",
            "grad_loss:0.093513\n",
            "dice_loss:-0.867556\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:269\n",
            "loss(total):-0.004189\n",
            "recons_loss:0.003644\n",
            "grad_loss:0.093764\n",
            "dice_loss:-0.876992\n",
            "---------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpwV58tr_G8X",
        "outputId": "6d35cd17-7abd-495e-c1a0-30b83e606b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(losses_4[1:])\n",
        "plt.show"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgddqgOD_MVY",
        "outputId": "b977b959-3717-47d3-f892-050eea666b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(validation_4)\n",
        "plt.show"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hen8_QPG7TPn"
      },
      "source": [
        "import csv\n",
        "with open('validation_4.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rymKGn6b3TX9"
      },
      "source": [
        "for h in range(0,len(validation_0)):\n",
        "  with open('validation_4.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, validation_4[h].numpy()])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_B9997wK470"
      },
      "source": [
        "import csv\n",
        "with open('loss_4.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n",
        "\n",
        "for h in range(0,len(losses_4)):\n",
        "  with open('loss_4.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h, losses_4[h].numpy()])"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVGzBN5e7auc"
      },
      "source": [
        "'''Training - hold out fold 5 for validation'''\n",
        "#Training\n",
        "gpu='0'\n",
        "atlas_file='/content/drive/My Drive/2020/Thesis/Data/atlas.npz'\n",
        "lr=1e-4\n",
        "n_iter=5000\n",
        "data_loss='mse'\n",
        "model='vm2'\n",
        "reg_param=0.01\n",
        "batch_size=10\n",
        "n_save_iter=100\n",
        "model_dir='/content/drive/My Drive/2020/Thesis/Data/validation_0/'\n",
        "valid = fold_5\n",
        "train_names = set_5\n",
        "EPOCH=30"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoA0g6v77f50",
        "outputId": "1a3c8991-0055-436d-feb5-e02ca5be2f63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses_5, validation_5=validate.train(data_dir,\n",
        "          train_names,\n",
        "          atlas_file,\n",
        "          lr,\n",
        "          data_loss,\n",
        "          model,\n",
        "          reg_param, \n",
        "          batch_size,\n",
        "          n_save_iter,\n",
        "          model_dir,Net(),EPOCH, valid)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch_number:185\n",
            "loss(total):-0.004388\n",
            "recons_loss:0.003559\n",
            "grad_loss:0.083641\n",
            "dice_loss:-0.878285\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:186\n",
            "loss(total):-0.003518\n",
            "recons_loss:0.004337\n",
            "grad_loss:0.106212\n",
            "dice_loss:-0.891757\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:187\n",
            "loss(total):-0.002978\n",
            "recons_loss:0.004830\n",
            "grad_loss:0.111850\n",
            "dice_loss:-0.892668\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:188\n",
            "loss(total):-0.004500\n",
            "recons_loss:0.003672\n",
            "grad_loss:0.074249\n",
            "dice_loss:-0.891478\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:189\n",
            "loss(total):-0.002640\n",
            "recons_loss:0.005256\n",
            "grad_loss:0.102587\n",
            "dice_loss:-0.892228\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:190\n",
            "loss(total):-0.004430\n",
            "recons_loss:0.003578\n",
            "grad_loss:0.083888\n",
            "dice_loss:-0.884701\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:191\n",
            "loss(total):-0.002630\n",
            "recons_loss:0.005119\n",
            "grad_loss:0.120839\n",
            "dice_loss:-0.895788\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:192\n",
            "loss(total):-0.004288\n",
            "recons_loss:0.003712\n",
            "grad_loss:0.100424\n",
            "dice_loss:-0.900421\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:193\n",
            "loss(total):-0.003770\n",
            "recons_loss:0.004192\n",
            "grad_loss:0.097535\n",
            "dice_loss:-0.893758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:194\n",
            "loss(total):-0.002856\n",
            "recons_loss:0.004831\n",
            "grad_loss:0.109373\n",
            "dice_loss:-0.878114\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:195\n",
            "loss(total):-0.003016\n",
            "recons_loss:0.004878\n",
            "grad_loss:0.104931\n",
            "dice_loss:-0.894310\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:196\n",
            "loss(total):-0.003358\n",
            "recons_loss:0.004648\n",
            "grad_loss:0.093447\n",
            "dice_loss:-0.893992\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:197\n",
            "loss(total):-0.004406\n",
            "recons_loss:0.003475\n",
            "grad_loss:0.089900\n",
            "dice_loss:-0.877923\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:198\n",
            "loss(total):-0.002647\n",
            "recons_loss:0.005138\n",
            "grad_loss:0.117237\n",
            "dice_loss:-0.895744\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:199\n",
            "loss(total):-0.003420\n",
            "recons_loss:0.004458\n",
            "grad_loss:0.086319\n",
            "dice_loss:-0.874099\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:200\n",
            "loss(total):-0.003772\n",
            "recons_loss:0.004371\n",
            "grad_loss:0.091863\n",
            "dice_loss:-0.906166\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:201\n",
            "loss(total):-0.004691\n",
            "recons_loss:0.003454\n",
            "grad_loss:0.082273\n",
            "dice_loss:-0.896761\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:202\n",
            "loss(total):-0.002702\n",
            "recons_loss:0.005060\n",
            "grad_loss:0.110795\n",
            "dice_loss:-0.887032\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:203\n",
            "loss(total):-0.003620\n",
            "recons_loss:0.004336\n",
            "grad_loss:0.096952\n",
            "dice_loss:-0.892581\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:204\n",
            "loss(total):-0.002911\n",
            "recons_loss:0.004915\n",
            "grad_loss:0.105176\n",
            "dice_loss:-0.887831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:205\n",
            "loss(total):-0.002264\n",
            "recons_loss:0.005493\n",
            "grad_loss:0.108206\n",
            "dice_loss:-0.883930\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:206\n",
            "loss(total):-0.001615\n",
            "recons_loss:0.005872\n",
            "grad_loss:0.135396\n",
            "dice_loss:-0.884088\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:207\n",
            "loss(total):-0.002287\n",
            "recons_loss:0.005392\n",
            "grad_loss:0.123211\n",
            "dice_loss:-0.891149\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:208\n",
            "loss(total):-0.004765\n",
            "recons_loss:0.003461\n",
            "grad_loss:0.075208\n",
            "dice_loss:-0.897800\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:209\n",
            "loss(total):-0.001208\n",
            "recons_loss:0.006241\n",
            "grad_loss:0.135630\n",
            "dice_loss:-0.880509\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:210\n",
            "loss(total):-0.004410\n",
            "recons_loss:0.003686\n",
            "grad_loss:0.079991\n",
            "dice_loss:-0.889545\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:211\n",
            "loss(total):-0.002770\n",
            "recons_loss:0.005107\n",
            "grad_loss:0.102122\n",
            "dice_loss:-0.889857\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:212\n",
            "loss(total):-0.002956\n",
            "recons_loss:0.004724\n",
            "grad_loss:0.114575\n",
            "dice_loss:-0.882516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:213\n",
            "loss(total):-0.003432\n",
            "recons_loss:0.004303\n",
            "grad_loss:0.109710\n",
            "dice_loss:-0.883261\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:214\n",
            "loss(total):-0.004181\n",
            "recons_loss:0.003898\n",
            "grad_loss:0.080284\n",
            "dice_loss:-0.888222\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:215\n",
            "loss(total):-0.002724\n",
            "recons_loss:0.005020\n",
            "grad_loss:0.109390\n",
            "dice_loss:-0.883839\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:216\n",
            "loss(total):-0.003779\n",
            "recons_loss:0.004188\n",
            "grad_loss:0.096708\n",
            "dice_loss:-0.893443\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:217\n",
            "loss(total):-0.001089\n",
            "recons_loss:0.006501\n",
            "grad_loss:0.118713\n",
            "dice_loss:-0.877680\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:218\n",
            "loss(total):-0.003202\n",
            "recons_loss:0.004647\n",
            "grad_loss:0.106246\n",
            "dice_loss:-0.891116\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:219\n",
            "loss(total):-0.003846\n",
            "recons_loss:0.004228\n",
            "grad_loss:0.086813\n",
            "dice_loss:-0.894178\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:220\n",
            "loss(total):-0.004738\n",
            "recons_loss:0.003556\n",
            "grad_loss:0.074239\n",
            "dice_loss:-0.903604\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:221\n",
            "loss(total):-0.003590\n",
            "recons_loss:0.004401\n",
            "grad_loss:0.098536\n",
            "dice_loss:-0.897666\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:222\n",
            "loss(total):-0.003600\n",
            "recons_loss:0.004418\n",
            "grad_loss:0.099048\n",
            "dice_loss:-0.900838\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:223\n",
            "loss(total):-0.004343\n",
            "recons_loss:0.003833\n",
            "grad_loss:0.081147\n",
            "dice_loss:-0.898792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:224\n",
            "loss(total):-0.004314\n",
            "recons_loss:0.003703\n",
            "grad_loss:0.084322\n",
            "dice_loss:-0.885991\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:225\n",
            "loss(total):-0.003268\n",
            "recons_loss:0.004692\n",
            "grad_loss:0.086832\n",
            "dice_loss:-0.882862\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:226\n",
            "loss(total):-0.004939\n",
            "recons_loss:0.003246\n",
            "grad_loss:0.070209\n",
            "dice_loss:-0.888764\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:227\n",
            "loss(total):-0.003866\n",
            "recons_loss:0.004300\n",
            "grad_loss:0.084333\n",
            "dice_loss:-0.900919\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:228\n",
            "loss(total):-0.001915\n",
            "recons_loss:0.005785\n",
            "grad_loss:0.114841\n",
            "dice_loss:-0.884790\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:229\n",
            "loss(total):-0.003210\n",
            "recons_loss:0.004661\n",
            "grad_loss:0.092661\n",
            "dice_loss:-0.879784\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:230\n",
            "loss(total):-0.004084\n",
            "recons_loss:0.003906\n",
            "grad_loss:0.094081\n",
            "dice_loss:-0.893084\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:231\n",
            "loss(total):-0.003561\n",
            "recons_loss:0.004383\n",
            "grad_loss:0.097486\n",
            "dice_loss:-0.891877\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:232\n",
            "loss(total):-0.003753\n",
            "recons_loss:0.004199\n",
            "grad_loss:0.091595\n",
            "dice_loss:-0.886713\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:233\n",
            "loss(total):-0.004839\n",
            "recons_loss:0.003225\n",
            "grad_loss:0.091521\n",
            "dice_loss:-0.897899\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:234\n",
            "loss(total):-0.001611\n",
            "recons_loss:0.006080\n",
            "grad_loss:0.122118\n",
            "dice_loss:-0.891180\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:235\n",
            "loss(total):-0.004212\n",
            "recons_loss:0.003780\n",
            "grad_loss:0.085030\n",
            "dice_loss:-0.884256\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:236\n",
            "loss(total):-0.003065\n",
            "recons_loss:0.004714\n",
            "grad_loss:0.106119\n",
            "dice_loss:-0.884078\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:237\n",
            "loss(total):-0.003804\n",
            "recons_loss:0.004238\n",
            "grad_loss:0.081297\n",
            "dice_loss:-0.885507\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:238\n",
            "loss(total):-0.003128\n",
            "recons_loss:0.004656\n",
            "grad_loss:0.093170\n",
            "dice_loss:-0.871532\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:239\n",
            "loss(total):-0.002847\n",
            "recons_loss:0.004946\n",
            "grad_loss:0.108216\n",
            "dice_loss:-0.887461\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:240\n",
            "loss(total):-0.004014\n",
            "recons_loss:0.003980\n",
            "grad_loss:0.081831\n",
            "dice_loss:-0.881254\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:241\n",
            "loss(total):-0.002673\n",
            "recons_loss:0.005126\n",
            "grad_loss:0.111105\n",
            "dice_loss:-0.890988\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:242\n",
            "loss(total):-0.003330\n",
            "recons_loss:0.004495\n",
            "grad_loss:0.108754\n",
            "dice_loss:-0.891183\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:243\n",
            "loss(total):-0.004123\n",
            "recons_loss:0.003820\n",
            "grad_loss:0.097127\n",
            "dice_loss:-0.891386\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:244\n",
            "loss(total):-0.001339\n",
            "recons_loss:0.006016\n",
            "grad_loss:0.139256\n",
            "dice_loss:-0.874715\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:245\n",
            "loss(total):-0.001627\n",
            "recons_loss:0.005855\n",
            "grad_loss:0.134430\n",
            "dice_loss:-0.882662\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:246\n",
            "loss(total):-0.002447\n",
            "recons_loss:0.005173\n",
            "grad_loss:0.120085\n",
            "dice_loss:-0.882148\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:247\n",
            "loss(total):-0.003283\n",
            "recons_loss:0.004478\n",
            "grad_loss:0.102001\n",
            "dice_loss:-0.878107\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:248\n",
            "loss(total):-0.003028\n",
            "recons_loss:0.004687\n",
            "grad_loss:0.115241\n",
            "dice_loss:-0.886795\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:249\n",
            "loss(total):-0.003760\n",
            "recons_loss:0.004109\n",
            "grad_loss:0.101105\n",
            "dice_loss:-0.888003\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:250\n",
            "loss(total):-0.000115\n",
            "recons_loss:0.007215\n",
            "grad_loss:0.138983\n",
            "dice_loss:-0.871930\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:251\n",
            "loss(total):-0.003919\n",
            "recons_loss:0.003894\n",
            "grad_loss:0.090636\n",
            "dice_loss:-0.871965\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:252\n",
            "loss(total):-0.004891\n",
            "recons_loss:0.003194\n",
            "grad_loss:0.085419\n",
            "dice_loss:-0.894000\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:253\n",
            "loss(total):-0.002428\n",
            "recons_loss:0.005304\n",
            "grad_loss:0.101239\n",
            "dice_loss:-0.874428\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:254\n",
            "loss(total):-0.002759\n",
            "recons_loss:0.004887\n",
            "grad_loss:0.105382\n",
            "dice_loss:-0.870012\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:255\n",
            "loss(total):-0.003239\n",
            "recons_loss:0.004519\n",
            "grad_loss:0.116748\n",
            "dice_loss:-0.892532\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:256\n",
            "loss(total):-0.002509\n",
            "recons_loss:0.005109\n",
            "grad_loss:0.122798\n",
            "dice_loss:-0.884541\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:257\n",
            "loss(total):-0.003605\n",
            "recons_loss:0.004299\n",
            "grad_loss:0.095047\n",
            "dice_loss:-0.885379\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:258\n",
            "loss(total):-0.003422\n",
            "recons_loss:0.004462\n",
            "grad_loss:0.097100\n",
            "dice_loss:-0.885528\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:259\n",
            "loss(total):-0.001872\n",
            "recons_loss:0.005881\n",
            "grad_loss:0.095081\n",
            "dice_loss:-0.870391\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:260\n",
            "loss(total):-0.003820\n",
            "recons_loss:0.004158\n",
            "grad_loss:0.100140\n",
            "dice_loss:-0.897944\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:261\n",
            "loss(total):-0.004467\n",
            "recons_loss:0.003671\n",
            "grad_loss:0.080849\n",
            "dice_loss:-0.894704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:262\n",
            "loss(total):-0.004847\n",
            "recons_loss:0.003319\n",
            "grad_loss:0.076224\n",
            "dice_loss:-0.892852\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:263\n",
            "loss(total):-0.003832\n",
            "recons_loss:0.004118\n",
            "grad_loss:0.100796\n",
            "dice_loss:-0.895788\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:264\n",
            "loss(total):-0.002716\n",
            "recons_loss:0.004991\n",
            "grad_loss:0.105226\n",
            "dice_loss:-0.875941\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:265\n",
            "loss(total):-0.003242\n",
            "recons_loss:0.004619\n",
            "grad_loss:0.103809\n",
            "dice_loss:-0.889974\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:266\n",
            "loss(total):-0.003698\n",
            "recons_loss:0.004309\n",
            "grad_loss:0.090069\n",
            "dice_loss:-0.890783\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:267\n",
            "loss(total):-0.003272\n",
            "recons_loss:0.004555\n",
            "grad_loss:0.103601\n",
            "dice_loss:-0.886366\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:268\n",
            "loss(total):-0.002857\n",
            "recons_loss:0.004840\n",
            "grad_loss:0.123143\n",
            "dice_loss:-0.892919\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:269\n",
            "loss(total):-0.002946\n",
            "recons_loss:0.005048\n",
            "grad_loss:0.091998\n",
            "dice_loss:-0.891450\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:0\n",
            "loss(total):-0.005643\n",
            "recons_loss:0.002735\n",
            "grad_loss:0.070608\n",
            "dice_loss:-0.908390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:1\n",
            "loss(total):-0.003545\n",
            "recons_loss:0.004320\n",
            "grad_loss:0.089098\n",
            "dice_loss:-0.875635\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:2\n",
            "loss(total):-0.003537\n",
            "recons_loss:0.004372\n",
            "grad_loss:0.094481\n",
            "dice_loss:-0.885403\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:3\n",
            "loss(total):-0.002673\n",
            "recons_loss:0.005160\n",
            "grad_loss:0.096142\n",
            "dice_loss:-0.879429\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:4\n",
            "loss(total):-0.003938\n",
            "recons_loss:0.004190\n",
            "grad_loss:0.079409\n",
            "dice_loss:-0.892193\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:5\n",
            "loss(total):-0.003743\n",
            "recons_loss:0.004211\n",
            "grad_loss:0.092328\n",
            "dice_loss:-0.887715\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:6\n",
            "loss(total):-0.003460\n",
            "recons_loss:0.004389\n",
            "grad_loss:0.092376\n",
            "dice_loss:-0.877255\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:7\n",
            "loss(total):-0.002450\n",
            "recons_loss:0.005384\n",
            "grad_loss:0.102088\n",
            "dice_loss:-0.885435\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:8\n",
            "loss(total):-0.004430\n",
            "recons_loss:0.003653\n",
            "grad_loss:0.094830\n",
            "dice_loss:-0.903186\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:9\n",
            "loss(total):-0.004233\n",
            "recons_loss:0.003768\n",
            "grad_loss:0.082607\n",
            "dice_loss:-0.882629\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:10\n",
            "loss(total):-0.003367\n",
            "recons_loss:0.004621\n",
            "grad_loss:0.083505\n",
            "dice_loss:-0.882247\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:11\n",
            "loss(total):-0.002467\n",
            "recons_loss:0.005493\n",
            "grad_loss:0.104655\n",
            "dice_loss:-0.900688\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:12\n",
            "loss(total):-0.003409\n",
            "recons_loss:0.004685\n",
            "grad_loss:0.088794\n",
            "dice_loss:-0.898192\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:13\n",
            "loss(total):-0.002137\n",
            "recons_loss:0.005462\n",
            "grad_loss:0.135098\n",
            "dice_loss:-0.895033\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:14\n",
            "loss(total):-0.003334\n",
            "recons_loss:0.004430\n",
            "grad_loss:0.104783\n",
            "dice_loss:-0.881175\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:15\n",
            "loss(total):-0.004351\n",
            "recons_loss:0.003666\n",
            "grad_loss:0.078436\n",
            "dice_loss:-0.880133\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:16\n",
            "loss(total):-0.002748\n",
            "recons_loss:0.005086\n",
            "grad_loss:0.099746\n",
            "dice_loss:-0.883119\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:17\n",
            "loss(total):-0.004809\n",
            "recons_loss:0.003287\n",
            "grad_loss:0.088895\n",
            "dice_loss:-0.898454\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:18\n",
            "loss(total):-0.002436\n",
            "recons_loss:0.005348\n",
            "grad_loss:0.106351\n",
            "dice_loss:-0.884711\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:19\n",
            "loss(total):-0.002807\n",
            "recons_loss:0.005048\n",
            "grad_loss:0.116429\n",
            "dice_loss:-0.901955\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:20\n",
            "loss(total):-0.005098\n",
            "recons_loss:0.003066\n",
            "grad_loss:0.087576\n",
            "dice_loss:-0.903916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:21\n",
            "loss(total):-0.002428\n",
            "recons_loss:0.005240\n",
            "grad_loss:0.118872\n",
            "dice_loss:-0.885689\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:22\n",
            "loss(total):-0.002587\n",
            "recons_loss:0.005127\n",
            "grad_loss:0.111378\n",
            "dice_loss:-0.882766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:23\n",
            "loss(total):-0.000484\n",
            "recons_loss:0.007002\n",
            "grad_loss:0.139744\n",
            "dice_loss:-0.888304\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:24\n",
            "loss(total):-0.003830\n",
            "recons_loss:0.004107\n",
            "grad_loss:0.092525\n",
            "dice_loss:-0.886165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:25\n",
            "loss(total):-0.003186\n",
            "recons_loss:0.004668\n",
            "grad_loss:0.091819\n",
            "dice_loss:-0.877167\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:26\n",
            "loss(total):-0.003792\n",
            "recons_loss:0.004000\n",
            "grad_loss:0.102266\n",
            "dice_loss:-0.881422\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:27\n",
            "loss(total):-0.003916\n",
            "recons_loss:0.003911\n",
            "grad_loss:0.093568\n",
            "dice_loss:-0.876249\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:28\n",
            "loss(total):-0.003897\n",
            "recons_loss:0.003953\n",
            "grad_loss:0.114506\n",
            "dice_loss:-0.899545\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:29\n",
            "loss(total):-0.002946\n",
            "recons_loss:0.004839\n",
            "grad_loss:0.108800\n",
            "dice_loss:-0.887235\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:30\n",
            "loss(total):-0.002985\n",
            "recons_loss:0.004832\n",
            "grad_loss:0.113629\n",
            "dice_loss:-0.895340\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:31\n",
            "loss(total):-0.002538\n",
            "recons_loss:0.005236\n",
            "grad_loss:0.104419\n",
            "dice_loss:-0.881879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:32\n",
            "loss(total):-0.002368\n",
            "recons_loss:0.005354\n",
            "grad_loss:0.108314\n",
            "dice_loss:-0.880464\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:33\n",
            "loss(total):-0.004257\n",
            "recons_loss:0.003821\n",
            "grad_loss:0.079583\n",
            "dice_loss:-0.887388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:34\n",
            "loss(total):-0.002592\n",
            "recons_loss:0.005219\n",
            "grad_loss:0.100100\n",
            "dice_loss:-0.881264\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:35\n",
            "loss(total):-0.004734\n",
            "recons_loss:0.003451\n",
            "grad_loss:0.074493\n",
            "dice_loss:-0.892972\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:36\n",
            "loss(total):-0.001944\n",
            "recons_loss:0.005616\n",
            "grad_loss:0.138472\n",
            "dice_loss:-0.894506\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:37\n",
            "loss(total):-0.004416\n",
            "recons_loss:0.003721\n",
            "grad_loss:0.075141\n",
            "dice_loss:-0.888836\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:38\n",
            "loss(total):-0.003757\n",
            "recons_loss:0.004216\n",
            "grad_loss:0.091454\n",
            "dice_loss:-0.888742\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:39\n",
            "loss(total):-0.004721\n",
            "recons_loss:0.003480\n",
            "grad_loss:0.079504\n",
            "dice_loss:-0.899590\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:40\n",
            "loss(total):-0.002868\n",
            "recons_loss:0.004934\n",
            "grad_loss:0.104340\n",
            "dice_loss:-0.884559\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:41\n",
            "loss(total):-0.002355\n",
            "recons_loss:0.005275\n",
            "grad_loss:0.119618\n",
            "dice_loss:-0.882581\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:42\n",
            "loss(total):-0.004092\n",
            "recons_loss:0.004108\n",
            "grad_loss:0.077224\n",
            "dice_loss:-0.897242\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:43\n",
            "loss(total):-0.003177\n",
            "recons_loss:0.004624\n",
            "grad_loss:0.119138\n",
            "dice_loss:-0.899238\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:44\n",
            "loss(total):-0.002832\n",
            "recons_loss:0.005200\n",
            "grad_loss:0.086116\n",
            "dice_loss:-0.889403\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:45\n",
            "loss(total):-0.003768\n",
            "recons_loss:0.004191\n",
            "grad_loss:0.098385\n",
            "dice_loss:-0.894282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:46\n",
            "loss(total):-0.002737\n",
            "recons_loss:0.004873\n",
            "grad_loss:0.115561\n",
            "dice_loss:-0.876494\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:47\n",
            "loss(total):-0.003269\n",
            "recons_loss:0.004475\n",
            "grad_loss:0.112214\n",
            "dice_loss:-0.886685\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:48\n",
            "loss(total):-0.002569\n",
            "recons_loss:0.005053\n",
            "grad_loss:0.118769\n",
            "dice_loss:-0.880957\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:49\n",
            "loss(total):-0.003038\n",
            "recons_loss:0.004743\n",
            "grad_loss:0.115082\n",
            "dice_loss:-0.893134\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:50\n",
            "loss(total):-0.003753\n",
            "recons_loss:0.004097\n",
            "grad_loss:0.102727\n",
            "dice_loss:-0.887787\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:51\n",
            "loss(total):-0.003223\n",
            "recons_loss:0.004525\n",
            "grad_loss:0.112110\n",
            "dice_loss:-0.886909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:52\n",
            "loss(total):-0.003844\n",
            "recons_loss:0.004159\n",
            "grad_loss:0.089516\n",
            "dice_loss:-0.889831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:53\n",
            "loss(total):-0.003803\n",
            "recons_loss:0.004225\n",
            "grad_loss:0.080970\n",
            "dice_loss:-0.883807\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:54\n",
            "loss(total):-0.002366\n",
            "recons_loss:0.005295\n",
            "grad_loss:0.122757\n",
            "dice_loss:-0.888849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:55\n",
            "loss(total):-0.001951\n",
            "recons_loss:0.005680\n",
            "grad_loss:0.121546\n",
            "dice_loss:-0.884629\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:56\n",
            "loss(total):-0.003736\n",
            "recons_loss:0.004150\n",
            "grad_loss:0.093209\n",
            "dice_loss:-0.881835\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:57\n",
            "loss(total):-0.004417\n",
            "recons_loss:0.003603\n",
            "grad_loss:0.097158\n",
            "dice_loss:-0.899181\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:58\n",
            "loss(total):-0.003039\n",
            "recons_loss:0.004533\n",
            "grad_loss:0.110174\n",
            "dice_loss:-0.867343\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:59\n",
            "loss(total):-0.003487\n",
            "recons_loss:0.004490\n",
            "grad_loss:0.107452\n",
            "dice_loss:-0.905110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:60\n",
            "loss(total):-0.002853\n",
            "recons_loss:0.005035\n",
            "grad_loss:0.112060\n",
            "dice_loss:-0.900879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:61\n",
            "loss(total):-0.002904\n",
            "recons_loss:0.004840\n",
            "grad_loss:0.110898\n",
            "dice_loss:-0.885279\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:62\n",
            "loss(total):-0.004362\n",
            "recons_loss:0.003627\n",
            "grad_loss:0.089430\n",
            "dice_loss:-0.888361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:63\n",
            "loss(total):-0.002093\n",
            "recons_loss:0.005636\n",
            "grad_loss:0.097690\n",
            "dice_loss:-0.870599\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:64\n",
            "loss(total):-0.004348\n",
            "recons_loss:0.003781\n",
            "grad_loss:0.084210\n",
            "dice_loss:-0.897095\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:65\n",
            "loss(total):-0.002698\n",
            "recons_loss:0.004914\n",
            "grad_loss:0.140675\n",
            "dice_loss:-0.901875\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:66\n",
            "loss(total):-0.004151\n",
            "recons_loss:0.003771\n",
            "grad_loss:0.095336\n",
            "dice_loss:-0.887508\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:67\n",
            "loss(total):-0.004219\n",
            "recons_loss:0.003765\n",
            "grad_loss:0.092563\n",
            "dice_loss:-0.890976\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:68\n",
            "loss(total):-0.002429\n",
            "recons_loss:0.005393\n",
            "grad_loss:0.115066\n",
            "dice_loss:-0.897211\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:69\n",
            "loss(total):-0.003267\n",
            "recons_loss:0.004709\n",
            "grad_loss:0.100786\n",
            "dice_loss:-0.898377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:70\n",
            "loss(total):-0.004132\n",
            "recons_loss:0.003796\n",
            "grad_loss:0.088202\n",
            "dice_loss:-0.881054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:71\n",
            "loss(total):-0.003165\n",
            "recons_loss:0.004452\n",
            "grad_loss:0.116818\n",
            "dice_loss:-0.878593\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:72\n",
            "loss(total):-0.003638\n",
            "recons_loss:0.004236\n",
            "grad_loss:0.099688\n",
            "dice_loss:-0.887111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:73\n",
            "loss(total):-0.002527\n",
            "recons_loss:0.004975\n",
            "grad_loss:0.133659\n",
            "dice_loss:-0.883864\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:74\n",
            "loss(total):-0.002619\n",
            "recons_loss:0.004929\n",
            "grad_loss:0.124838\n",
            "dice_loss:-0.879666\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:75\n",
            "loss(total):-0.002423\n",
            "recons_loss:0.005271\n",
            "grad_loss:0.112135\n",
            "dice_loss:-0.881514\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:76\n",
            "loss(total):-0.003151\n",
            "recons_loss:0.004677\n",
            "grad_loss:0.114001\n",
            "dice_loss:-0.896745\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:77\n",
            "loss(total):-0.004865\n",
            "recons_loss:0.003198\n",
            "grad_loss:0.081423\n",
            "dice_loss:-0.887731\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:78\n",
            "loss(total):-0.004814\n",
            "recons_loss:0.003272\n",
            "grad_loss:0.091542\n",
            "dice_loss:-0.900069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:79\n",
            "loss(total):-0.004849\n",
            "recons_loss:0.003248\n",
            "grad_loss:0.090488\n",
            "dice_loss:-0.900258\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:80\n",
            "loss(total):-0.003932\n",
            "recons_loss:0.003926\n",
            "grad_loss:0.101393\n",
            "dice_loss:-0.887206\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:81\n",
            "loss(total):-0.003952\n",
            "recons_loss:0.004101\n",
            "grad_loss:0.095095\n",
            "dice_loss:-0.900452\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:82\n",
            "loss(total):-0.001521\n",
            "recons_loss:0.005955\n",
            "grad_loss:0.133869\n",
            "dice_loss:-0.881553\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:83\n",
            "loss(total):-0.002692\n",
            "recons_loss:0.004941\n",
            "grad_loss:0.106599\n",
            "dice_loss:-0.869927\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:84\n",
            "loss(total):-0.002681\n",
            "recons_loss:0.005056\n",
            "grad_loss:0.107053\n",
            "dice_loss:-0.880771\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:85\n",
            "loss(total):-0.002801\n",
            "recons_loss:0.005298\n",
            "grad_loss:0.080476\n",
            "dice_loss:-0.890338\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:86\n",
            "loss(total):-0.004508\n",
            "recons_loss:0.003621\n",
            "grad_loss:0.080453\n",
            "dice_loss:-0.893313\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:87\n",
            "loss(total):-0.003085\n",
            "recons_loss:0.004815\n",
            "grad_loss:0.092481\n",
            "dice_loss:-0.882483\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:88\n",
            "loss(total):-0.003413\n",
            "recons_loss:0.004399\n",
            "grad_loss:0.108559\n",
            "dice_loss:-0.889722\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:89\n",
            "loss(total):-0.002246\n",
            "recons_loss:0.005495\n",
            "grad_loss:0.116175\n",
            "dice_loss:-0.890226\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:90\n",
            "loss(total):-0.002877\n",
            "recons_loss:0.004778\n",
            "grad_loss:0.130276\n",
            "dice_loss:-0.895807\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:91\n",
            "loss(total):-0.002764\n",
            "recons_loss:0.004953\n",
            "grad_loss:0.113539\n",
            "dice_loss:-0.885211\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:92\n",
            "loss(total):-0.002896\n",
            "recons_loss:0.005115\n",
            "grad_loss:0.091506\n",
            "dice_loss:-0.892583\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:93\n",
            "loss(total):-0.003602\n",
            "recons_loss:0.004299\n",
            "grad_loss:0.110043\n",
            "dice_loss:-0.900197\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:94\n",
            "loss(total):-0.002687\n",
            "recons_loss:0.005068\n",
            "grad_loss:0.119397\n",
            "dice_loss:-0.894834\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:95\n",
            "loss(total):-0.002193\n",
            "recons_loss:0.005391\n",
            "grad_loss:0.123279\n",
            "dice_loss:-0.881660\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:96\n",
            "loss(total):-0.003585\n",
            "recons_loss:0.004237\n",
            "grad_loss:0.114146\n",
            "dice_loss:-0.896431\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:97\n",
            "loss(total):-0.003224\n",
            "recons_loss:0.004421\n",
            "grad_loss:0.116793\n",
            "dice_loss:-0.881297\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:98\n",
            "loss(total):-0.003382\n",
            "recons_loss:0.004455\n",
            "grad_loss:0.104405\n",
            "dice_loss:-0.888031\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:99\n",
            "loss(total):-0.004864\n",
            "recons_loss:0.003147\n",
            "grad_loss:0.099165\n",
            "dice_loss:-0.900260\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:100\n",
            "loss(total):-0.003300\n",
            "recons_loss:0.004524\n",
            "grad_loss:0.113200\n",
            "dice_loss:-0.895610\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:101\n",
            "loss(total):-0.002343\n",
            "recons_loss:0.005421\n",
            "grad_loss:0.104065\n",
            "dice_loss:-0.880427\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:102\n",
            "loss(total):-0.003708\n",
            "recons_loss:0.004341\n",
            "grad_loss:0.089757\n",
            "dice_loss:-0.894690\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:103\n",
            "loss(total):-0.003967\n",
            "recons_loss:0.003974\n",
            "grad_loss:0.095673\n",
            "dice_loss:-0.889773\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:104\n",
            "loss(total):-0.003828\n",
            "recons_loss:0.004099\n",
            "grad_loss:0.086500\n",
            "dice_loss:-0.879125\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:105\n",
            "loss(total):-0.004021\n",
            "recons_loss:0.003969\n",
            "grad_loss:0.085381\n",
            "dice_loss:-0.884384\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:106\n",
            "loss(total):-0.001885\n",
            "recons_loss:0.005829\n",
            "grad_loss:0.122366\n",
            "dice_loss:-0.893754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:107\n",
            "loss(total):-0.004021\n",
            "recons_loss:0.004245\n",
            "grad_loss:0.077502\n",
            "dice_loss:-0.904185\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:108\n",
            "loss(total):-0.002227\n",
            "recons_loss:0.005428\n",
            "grad_loss:0.114349\n",
            "dice_loss:-0.879923\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:109\n",
            "loss(total):-0.003180\n",
            "recons_loss:0.004864\n",
            "grad_loss:0.097663\n",
            "dice_loss:-0.902057\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:110\n",
            "loss(total):-0.002350\n",
            "recons_loss:0.005509\n",
            "grad_loss:0.102775\n",
            "dice_loss:-0.888721\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:111\n",
            "loss(total):-0.003221\n",
            "recons_loss:0.004717\n",
            "grad_loss:0.092448\n",
            "dice_loss:-0.886325\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:112\n",
            "loss(total):-0.003864\n",
            "recons_loss:0.003966\n",
            "grad_loss:0.110180\n",
            "dice_loss:-0.893180\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:113\n",
            "loss(total):-0.003455\n",
            "recons_loss:0.004464\n",
            "grad_loss:0.114132\n",
            "dice_loss:-0.906052\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:114\n",
            "loss(total):-0.003156\n",
            "recons_loss:0.004695\n",
            "grad_loss:0.105155\n",
            "dice_loss:-0.890254\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:115\n",
            "loss(total):-0.002782\n",
            "recons_loss:0.004983\n",
            "grad_loss:0.100240\n",
            "dice_loss:-0.876771\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:116\n",
            "loss(total):-0.004406\n",
            "recons_loss:0.003847\n",
            "grad_loss:0.070282\n",
            "dice_loss:-0.895622\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:117\n",
            "loss(total):-0.004337\n",
            "recons_loss:0.003811\n",
            "grad_loss:0.067567\n",
            "dice_loss:-0.882417\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:118\n",
            "loss(total):-0.002894\n",
            "recons_loss:0.004929\n",
            "grad_loss:0.106086\n",
            "dice_loss:-0.888302\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:119\n",
            "loss(total):-0.003769\n",
            "recons_loss:0.004244\n",
            "grad_loss:0.090813\n",
            "dice_loss:-0.892117\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:120\n",
            "loss(total):-0.003046\n",
            "recons_loss:0.004860\n",
            "grad_loss:0.097343\n",
            "dice_loss:-0.887977\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:121\n",
            "loss(total):-0.004251\n",
            "recons_loss:0.003807\n",
            "grad_loss:0.097284\n",
            "dice_loss:-0.903101\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:122\n",
            "loss(total):-0.004032\n",
            "recons_loss:0.004083\n",
            "grad_loss:0.088346\n",
            "dice_loss:-0.899785\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:123\n",
            "loss(total):-0.004119\n",
            "recons_loss:0.003927\n",
            "grad_loss:0.103324\n",
            "dice_loss:-0.907932\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:124\n",
            "loss(total):-0.003830\n",
            "recons_loss:0.003994\n",
            "grad_loss:0.097961\n",
            "dice_loss:-0.880320\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:125\n",
            "loss(total):-0.003392\n",
            "recons_loss:0.004380\n",
            "grad_loss:0.104983\n",
            "dice_loss:-0.882233\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:126\n",
            "loss(total):-0.002840\n",
            "recons_loss:0.004974\n",
            "grad_loss:0.105824\n",
            "dice_loss:-0.887232\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:127\n",
            "loss(total):-0.002552\n",
            "recons_loss:0.005260\n",
            "grad_loss:0.106845\n",
            "dice_loss:-0.887977\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:128\n",
            "loss(total):-0.003015\n",
            "recons_loss:0.004900\n",
            "grad_loss:0.097558\n",
            "dice_loss:-0.889053\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:129\n",
            "loss(total):-0.002650\n",
            "recons_loss:0.005090\n",
            "grad_loss:0.105943\n",
            "dice_loss:-0.879927\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:130\n",
            "loss(total):-0.003268\n",
            "recons_loss:0.004556\n",
            "grad_loss:0.103876\n",
            "dice_loss:-0.886287\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:131\n",
            "loss(total):-0.002775\n",
            "recons_loss:0.004910\n",
            "grad_loss:0.119451\n",
            "dice_loss:-0.887933\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:132\n",
            "loss(total):-0.003600\n",
            "recons_loss:0.004209\n",
            "grad_loss:0.105345\n",
            "dice_loss:-0.886165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:133\n",
            "loss(total):-0.002341\n",
            "recons_loss:0.005304\n",
            "grad_loss:0.113396\n",
            "dice_loss:-0.877880\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:134\n",
            "loss(total):-0.003912\n",
            "recons_loss:0.004132\n",
            "grad_loss:0.091473\n",
            "dice_loss:-0.895828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:135\n",
            "loss(total):-0.003923\n",
            "recons_loss:0.004010\n",
            "grad_loss:0.085874\n",
            "dice_loss:-0.879192\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:136\n",
            "loss(total):-0.002127\n",
            "recons_loss:0.005554\n",
            "grad_loss:0.128446\n",
            "dice_loss:-0.896545\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:137\n",
            "loss(total):-0.004443\n",
            "recons_loss:0.003527\n",
            "grad_loss:0.093166\n",
            "dice_loss:-0.890151\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:138\n",
            "loss(total):-0.003969\n",
            "recons_loss:0.004104\n",
            "grad_loss:0.085100\n",
            "dice_loss:-0.892355\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:139\n",
            "loss(total):-0.004905\n",
            "recons_loss:0.003288\n",
            "grad_loss:0.076129\n",
            "dice_loss:-0.895381\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:140\n",
            "loss(total):-0.004225\n",
            "recons_loss:0.003949\n",
            "grad_loss:0.076847\n",
            "dice_loss:-0.894189\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:141\n",
            "loss(total):-0.002945\n",
            "recons_loss:0.004847\n",
            "grad_loss:0.108714\n",
            "dice_loss:-0.887874\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:142\n",
            "loss(total):-0.004531\n",
            "recons_loss:0.003605\n",
            "grad_loss:0.087616\n",
            "dice_loss:-0.901218\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:143\n",
            "loss(total):-0.003415\n",
            "recons_loss:0.004610\n",
            "grad_loss:0.099507\n",
            "dice_loss:-0.902015\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:144\n",
            "loss(total):-0.002344\n",
            "recons_loss:0.005193\n",
            "grad_loss:0.135440\n",
            "dice_loss:-0.889138\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:145\n",
            "loss(total):-0.003462\n",
            "recons_loss:0.004394\n",
            "grad_loss:0.111181\n",
            "dice_loss:-0.896700\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:146\n",
            "loss(total):-0.002514\n",
            "recons_loss:0.005166\n",
            "grad_loss:0.112476\n",
            "dice_loss:-0.880487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:147\n",
            "loss(total):-0.004321\n",
            "recons_loss:0.003693\n",
            "grad_loss:0.096006\n",
            "dice_loss:-0.897344\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:148\n",
            "loss(total):-0.002692\n",
            "recons_loss:0.005015\n",
            "grad_loss:0.120707\n",
            "dice_loss:-0.891450\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:149\n",
            "loss(total):-0.003121\n",
            "recons_loss:0.004521\n",
            "grad_loss:0.106746\n",
            "dice_loss:-0.870948\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:150\n",
            "loss(total):-0.004672\n",
            "recons_loss:0.003575\n",
            "grad_loss:0.076866\n",
            "dice_loss:-0.901470\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:151\n",
            "loss(total):-0.004567\n",
            "recons_loss:0.003526\n",
            "grad_loss:0.093344\n",
            "dice_loss:-0.902629\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:152\n",
            "loss(total):-0.003834\n",
            "recons_loss:0.004078\n",
            "grad_loss:0.093744\n",
            "dice_loss:-0.884920\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:153\n",
            "loss(total):-0.004007\n",
            "recons_loss:0.004078\n",
            "grad_loss:0.095622\n",
            "dice_loss:-0.904139\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:154\n",
            "loss(total):-0.003540\n",
            "recons_loss:0.004341\n",
            "grad_loss:0.101300\n",
            "dice_loss:-0.889452\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:155\n",
            "loss(total):-0.002041\n",
            "recons_loss:0.005729\n",
            "grad_loss:0.110512\n",
            "dice_loss:-0.887529\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:156\n",
            "loss(total):-0.003089\n",
            "recons_loss:0.004780\n",
            "grad_loss:0.099700\n",
            "dice_loss:-0.886598\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:157\n",
            "loss(total):-0.002593\n",
            "recons_loss:0.005088\n",
            "grad_loss:0.112386\n",
            "dice_loss:-0.880490\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:158\n",
            "loss(total):-0.003111\n",
            "recons_loss:0.004623\n",
            "grad_loss:0.118695\n",
            "dice_loss:-0.892101\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:159\n",
            "loss(total):-0.004976\n",
            "recons_loss:0.003311\n",
            "grad_loss:0.073644\n",
            "dice_loss:-0.902314\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:160\n",
            "loss(total):-0.002793\n",
            "recons_loss:0.004964\n",
            "grad_loss:0.110454\n",
            "dice_loss:-0.886079\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:161\n",
            "loss(total):-0.004759\n",
            "recons_loss:0.003263\n",
            "grad_loss:0.083011\n",
            "dice_loss:-0.885263\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:162\n",
            "loss(total):-0.004083\n",
            "recons_loss:0.003810\n",
            "grad_loss:0.101980\n",
            "dice_loss:-0.891299\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:163\n",
            "loss(total):-0.004544\n",
            "recons_loss:0.003567\n",
            "grad_loss:0.084568\n",
            "dice_loss:-0.895693\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:164\n",
            "loss(total):-0.002734\n",
            "recons_loss:0.005037\n",
            "grad_loss:0.106891\n",
            "dice_loss:-0.883994\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:165\n",
            "loss(total):-0.003196\n",
            "recons_loss:0.004791\n",
            "grad_loss:0.109739\n",
            "dice_loss:-0.908416\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:166\n",
            "loss(total):-0.004051\n",
            "recons_loss:0.003835\n",
            "grad_loss:0.096911\n",
            "dice_loss:-0.885456\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:167\n",
            "loss(total):-0.002726\n",
            "recons_loss:0.004962\n",
            "grad_loss:0.125454\n",
            "dice_loss:-0.894250\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:168\n",
            "loss(total):-0.002144\n",
            "recons_loss:0.005456\n",
            "grad_loss:0.122751\n",
            "dice_loss:-0.882814\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:169\n",
            "loss(total):-0.002970\n",
            "recons_loss:0.004681\n",
            "grad_loss:0.104721\n",
            "dice_loss:-0.869831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:170\n",
            "loss(total):-0.003494\n",
            "recons_loss:0.004435\n",
            "grad_loss:0.101880\n",
            "dice_loss:-0.894747\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:171\n",
            "loss(total):-0.004676\n",
            "recons_loss:0.003483\n",
            "grad_loss:0.081531\n",
            "dice_loss:-0.897513\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:172\n",
            "loss(total):-0.003612\n",
            "recons_loss:0.004116\n",
            "grad_loss:0.126070\n",
            "dice_loss:-0.898861\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:173\n",
            "loss(total):-0.003527\n",
            "recons_loss:0.004368\n",
            "grad_loss:0.095593\n",
            "dice_loss:-0.885163\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:174\n",
            "loss(total):-0.004459\n",
            "recons_loss:0.003585\n",
            "grad_loss:0.075776\n",
            "dice_loss:-0.880205\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:175\n",
            "loss(total):-0.004190\n",
            "recons_loss:0.003929\n",
            "grad_loss:0.080878\n",
            "dice_loss:-0.892744\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:176\n",
            "loss(total):-0.004816\n",
            "recons_loss:0.003414\n",
            "grad_loss:0.078026\n",
            "dice_loss:-0.901008\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:177\n",
            "loss(total):-0.002916\n",
            "recons_loss:0.005024\n",
            "grad_loss:0.087253\n",
            "dice_loss:-0.881298\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:178\n",
            "loss(total):-0.004510\n",
            "recons_loss:0.003610\n",
            "grad_loss:0.082980\n",
            "dice_loss:-0.895067\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:179\n",
            "loss(total):-0.003054\n",
            "recons_loss:0.004850\n",
            "grad_loss:0.105518\n",
            "dice_loss:-0.895881\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:180\n",
            "loss(total):-0.003308\n",
            "recons_loss:0.004417\n",
            "grad_loss:0.118333\n",
            "dice_loss:-0.890813\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:181\n",
            "loss(total):-0.004729\n",
            "recons_loss:0.003464\n",
            "grad_loss:0.076196\n",
            "dice_loss:-0.895500\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:182\n",
            "loss(total):-0.004044\n",
            "recons_loss:0.004062\n",
            "grad_loss:0.080477\n",
            "dice_loss:-0.891073\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:183\n",
            "loss(total):-0.004440\n",
            "recons_loss:0.003731\n",
            "grad_loss:0.082780\n",
            "dice_loss:-0.899850\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:184\n",
            "loss(total):-0.003995\n",
            "recons_loss:0.004023\n",
            "grad_loss:0.089188\n",
            "dice_loss:-0.891012\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:185\n",
            "loss(total):-0.004224\n",
            "recons_loss:0.003855\n",
            "grad_loss:0.087099\n",
            "dice_loss:-0.894984\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:186\n",
            "loss(total):-0.003219\n",
            "recons_loss:0.004817\n",
            "grad_loss:0.092172\n",
            "dice_loss:-0.895768\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:187\n",
            "loss(total):-0.003466\n",
            "recons_loss:0.004375\n",
            "grad_loss:0.101009\n",
            "dice_loss:-0.885109\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:188\n",
            "loss(total):-0.002777\n",
            "recons_loss:0.004984\n",
            "grad_loss:0.110472\n",
            "dice_loss:-0.886540\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:189\n",
            "loss(total):-0.003736\n",
            "recons_loss:0.004237\n",
            "grad_loss:0.096753\n",
            "dice_loss:-0.894042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:190\n",
            "loss(total):-0.002811\n",
            "recons_loss:0.004943\n",
            "grad_loss:0.100281\n",
            "dice_loss:-0.875699\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:191\n",
            "loss(total):-0.002596\n",
            "recons_loss:0.005195\n",
            "grad_loss:0.117960\n",
            "dice_loss:-0.897037\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:192\n",
            "loss(total):-0.001836\n",
            "recons_loss:0.005849\n",
            "grad_loss:0.130808\n",
            "dice_loss:-0.899312\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:193\n",
            "loss(total):-0.003995\n",
            "recons_loss:0.003986\n",
            "grad_loss:0.106030\n",
            "dice_loss:-0.904093\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:194\n",
            "loss(total):-0.004087\n",
            "recons_loss:0.003903\n",
            "grad_loss:0.094269\n",
            "dice_loss:-0.893273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:195\n",
            "loss(total):-0.003688\n",
            "recons_loss:0.004427\n",
            "grad_loss:0.084171\n",
            "dice_loss:-0.895703\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:196\n",
            "loss(total):-0.002567\n",
            "recons_loss:0.005140\n",
            "grad_loss:0.108703\n",
            "dice_loss:-0.879434\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:197\n",
            "loss(total):-0.003348\n",
            "recons_loss:0.004515\n",
            "grad_loss:0.103857\n",
            "dice_loss:-0.890166\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:198\n",
            "loss(total):-0.003777\n",
            "recons_loss:0.004186\n",
            "grad_loss:0.101952\n",
            "dice_loss:-0.898297\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:199\n",
            "loss(total):-0.005449\n",
            "recons_loss:0.002779\n",
            "grad_loss:0.076731\n",
            "dice_loss:-0.899595\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:200\n",
            "loss(total):-0.003723\n",
            "recons_loss:0.004330\n",
            "grad_loss:0.090201\n",
            "dice_loss:-0.895420\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:201\n",
            "loss(total):-0.003951\n",
            "recons_loss:0.004188\n",
            "grad_loss:0.083886\n",
            "dice_loss:-0.897797\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:202\n",
            "loss(total):-0.005055\n",
            "recons_loss:0.003212\n",
            "grad_loss:0.083637\n",
            "dice_loss:-0.910373\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:203\n",
            "loss(total):-0.004235\n",
            "recons_loss:0.003821\n",
            "grad_loss:0.079738\n",
            "dice_loss:-0.885288\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:204\n",
            "loss(total):-0.002492\n",
            "recons_loss:0.005111\n",
            "grad_loss:0.115146\n",
            "dice_loss:-0.875505\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:205\n",
            "loss(total):-0.003139\n",
            "recons_loss:0.004576\n",
            "grad_loss:0.107338\n",
            "dice_loss:-0.878849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:206\n",
            "loss(total):-0.002846\n",
            "recons_loss:0.004982\n",
            "grad_loss:0.108388\n",
            "dice_loss:-0.891235\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:207\n",
            "loss(total):-0.004052\n",
            "recons_loss:0.003841\n",
            "grad_loss:0.110959\n",
            "dice_loss:-0.900294\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:208\n",
            "loss(total):-0.002723\n",
            "recons_loss:0.005038\n",
            "grad_loss:0.117840\n",
            "dice_loss:-0.893928\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:209\n",
            "loss(total):-0.003820\n",
            "recons_loss:0.004171\n",
            "grad_loss:0.094477\n",
            "dice_loss:-0.893521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:210\n",
            "loss(total):-0.003299\n",
            "recons_loss:0.004720\n",
            "grad_loss:0.100411\n",
            "dice_loss:-0.902324\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:211\n",
            "loss(total):-0.004196\n",
            "recons_loss:0.003809\n",
            "grad_loss:0.085738\n",
            "dice_loss:-0.886313\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:212\n",
            "loss(total):-0.003681\n",
            "recons_loss:0.004340\n",
            "grad_loss:0.095367\n",
            "dice_loss:-0.897424\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:213\n",
            "loss(total):-0.004685\n",
            "recons_loss:0.003395\n",
            "grad_loss:0.080064\n",
            "dice_loss:-0.888012\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:214\n",
            "loss(total):-0.004080\n",
            "recons_loss:0.003841\n",
            "grad_loss:0.107584\n",
            "dice_loss:-0.899653\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:215\n",
            "loss(total):-0.003644\n",
            "recons_loss:0.004255\n",
            "grad_loss:0.105494\n",
            "dice_loss:-0.895440\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:216\n",
            "loss(total):-0.002176\n",
            "recons_loss:0.005324\n",
            "grad_loss:0.128099\n",
            "dice_loss:-0.878071\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:217\n",
            "loss(total):-0.003420\n",
            "recons_loss:0.004614\n",
            "grad_loss:0.097031\n",
            "dice_loss:-0.900438\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:218\n",
            "loss(total):-0.004891\n",
            "recons_loss:0.003385\n",
            "grad_loss:0.073356\n",
            "dice_loss:-0.901009\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:219\n",
            "loss(total):-0.003046\n",
            "recons_loss:0.004907\n",
            "grad_loss:0.090785\n",
            "dice_loss:-0.886087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:220\n",
            "loss(total):-0.003695\n",
            "recons_loss:0.004243\n",
            "grad_loss:0.093723\n",
            "dice_loss:-0.887558\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:221\n",
            "loss(total):-0.002286\n",
            "recons_loss:0.005436\n",
            "grad_loss:0.110069\n",
            "dice_loss:-0.882271\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:222\n",
            "loss(total):-0.003815\n",
            "recons_loss:0.004193\n",
            "grad_loss:0.090224\n",
            "dice_loss:-0.891064\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:223\n",
            "loss(total):-0.003134\n",
            "recons_loss:0.004577\n",
            "grad_loss:0.104428\n",
            "dice_loss:-0.875546\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:224\n",
            "loss(total):-0.003048\n",
            "recons_loss:0.004896\n",
            "grad_loss:0.096449\n",
            "dice_loss:-0.890813\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:225\n",
            "loss(total):-0.004009\n",
            "recons_loss:0.004044\n",
            "grad_loss:0.089196\n",
            "dice_loss:-0.894518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:226\n",
            "loss(total):-0.002690\n",
            "recons_loss:0.005062\n",
            "grad_loss:0.103664\n",
            "dice_loss:-0.878895\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:227\n",
            "loss(total):-0.002677\n",
            "recons_loss:0.004936\n",
            "grad_loss:0.124153\n",
            "dice_loss:-0.885430\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:228\n",
            "loss(total):-0.003413\n",
            "recons_loss:0.004276\n",
            "grad_loss:0.107161\n",
            "dice_loss:-0.876143\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:229\n",
            "loss(total):-0.003742\n",
            "recons_loss:0.004227\n",
            "grad_loss:0.078998\n",
            "dice_loss:-0.875953\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:230\n",
            "loss(total):-0.003635\n",
            "recons_loss:0.004403\n",
            "grad_loss:0.096704\n",
            "dice_loss:-0.900490\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:231\n",
            "loss(total):-0.003910\n",
            "recons_loss:0.004120\n",
            "grad_loss:0.089682\n",
            "dice_loss:-0.892710\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:232\n",
            "loss(total):-0.004447\n",
            "recons_loss:0.003525\n",
            "grad_loss:0.098551\n",
            "dice_loss:-0.895799\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:233\n",
            "loss(total):-0.003096\n",
            "recons_loss:0.004702\n",
            "grad_loss:0.111324\n",
            "dice_loss:-0.891197\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:234\n",
            "loss(total):-0.003514\n",
            "recons_loss:0.004572\n",
            "grad_loss:0.087125\n",
            "dice_loss:-0.895748\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:235\n",
            "loss(total):-0.002752\n",
            "recons_loss:0.005005\n",
            "grad_loss:0.105162\n",
            "dice_loss:-0.880879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:236\n",
            "loss(total):-0.003202\n",
            "recons_loss:0.004576\n",
            "grad_loss:0.107658\n",
            "dice_loss:-0.885465\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:237\n",
            "loss(total):-0.002744\n",
            "recons_loss:0.005272\n",
            "grad_loss:0.091737\n",
            "dice_loss:-0.893326\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:238\n",
            "loss(total):-0.003687\n",
            "recons_loss:0.004183\n",
            "grad_loss:0.089150\n",
            "dice_loss:-0.876243\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:239\n",
            "loss(total):-0.002998\n",
            "recons_loss:0.004950\n",
            "grad_loss:0.093913\n",
            "dice_loss:-0.888652\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:240\n",
            "loss(total):-0.005002\n",
            "recons_loss:0.003341\n",
            "grad_loss:0.067791\n",
            "dice_loss:-0.902142\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:241\n",
            "loss(total):-0.004230\n",
            "recons_loss:0.003816\n",
            "grad_loss:0.090113\n",
            "dice_loss:-0.894762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:242\n",
            "loss(total):-0.004151\n",
            "recons_loss:0.004058\n",
            "grad_loss:0.075965\n",
            "dice_loss:-0.896857\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:243\n",
            "loss(total):-0.003276\n",
            "recons_loss:0.004536\n",
            "grad_loss:0.108936\n",
            "dice_loss:-0.890100\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:244\n",
            "loss(total):-0.002712\n",
            "recons_loss:0.005188\n",
            "grad_loss:0.094223\n",
            "dice_loss:-0.884283\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:245\n",
            "loss(total):-0.004394\n",
            "recons_loss:0.003755\n",
            "grad_loss:0.083333\n",
            "dice_loss:-0.898210\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:246\n",
            "loss(total):-0.005380\n",
            "recons_loss:0.002873\n",
            "grad_loss:0.068807\n",
            "dice_loss:-0.894069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:247\n",
            "loss(total):-0.000781\n",
            "recons_loss:0.006733\n",
            "grad_loss:0.140494\n",
            "dice_loss:-0.891838\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:248\n",
            "loss(total):-0.004935\n",
            "recons_loss:0.003231\n",
            "grad_loss:0.079248\n",
            "dice_loss:-0.895837\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:249\n",
            "loss(total):-0.004039\n",
            "recons_loss:0.003813\n",
            "grad_loss:0.095769\n",
            "dice_loss:-0.881031\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:250\n",
            "loss(total):-0.004640\n",
            "recons_loss:0.003366\n",
            "grad_loss:0.090496\n",
            "dice_loss:-0.891153\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:251\n",
            "loss(total):-0.003275\n",
            "recons_loss:0.004433\n",
            "grad_loss:0.113466\n",
            "dice_loss:-0.884236\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:252\n",
            "loss(total):-0.002822\n",
            "recons_loss:0.005149\n",
            "grad_loss:0.088681\n",
            "dice_loss:-0.885775\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:253\n",
            "loss(total):-0.002705\n",
            "recons_loss:0.005254\n",
            "grad_loss:0.106397\n",
            "dice_loss:-0.902282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:254\n",
            "loss(total):-0.002463\n",
            "recons_loss:0.005222\n",
            "grad_loss:0.106083\n",
            "dice_loss:-0.874516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:255\n",
            "loss(total):-0.004475\n",
            "recons_loss:0.003614\n",
            "grad_loss:0.089569\n",
            "dice_loss:-0.898490\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:256\n",
            "loss(total):-0.003960\n",
            "recons_loss:0.004129\n",
            "grad_loss:0.084175\n",
            "dice_loss:-0.893100\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:257\n",
            "loss(total):-0.003438\n",
            "recons_loss:0.004283\n",
            "grad_loss:0.118136\n",
            "dice_loss:-0.890202\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:258\n",
            "loss(total):-0.003279\n",
            "recons_loss:0.004580\n",
            "grad_loss:0.101639\n",
            "dice_loss:-0.887521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:259\n",
            "loss(total):-0.003453\n",
            "recons_loss:0.004558\n",
            "grad_loss:0.099147\n",
            "dice_loss:-0.900302\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:260\n",
            "loss(total):-0.004797\n",
            "recons_loss:0.003354\n",
            "grad_loss:0.083396\n",
            "dice_loss:-0.898447\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:261\n",
            "loss(total):-0.003944\n",
            "recons_loss:0.003940\n",
            "grad_loss:0.108435\n",
            "dice_loss:-0.896830\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:262\n",
            "loss(total):-0.004986\n",
            "recons_loss:0.003167\n",
            "grad_loss:0.081792\n",
            "dice_loss:-0.897141\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:263\n",
            "loss(total):-0.004281\n",
            "recons_loss:0.003899\n",
            "grad_loss:0.085823\n",
            "dice_loss:-0.903753\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:264\n",
            "loss(total):-0.004395\n",
            "recons_loss:0.003632\n",
            "grad_loss:0.088055\n",
            "dice_loss:-0.890718\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:265\n",
            "loss(total):-0.004426\n",
            "recons_loss:0.003517\n",
            "grad_loss:0.088568\n",
            "dice_loss:-0.882820\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:266\n",
            "loss(total):-0.003909\n",
            "recons_loss:0.004156\n",
            "grad_loss:0.080033\n",
            "dice_loss:-0.886539\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:267\n",
            "loss(total):-0.002602\n",
            "recons_loss:0.005216\n",
            "grad_loss:0.098895\n",
            "dice_loss:-0.880622\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:268\n",
            "loss(total):-0.004023\n",
            "recons_loss:0.004023\n",
            "grad_loss:0.100850\n",
            "dice_loss:-0.905513\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:269\n",
            "loss(total):-0.004096\n",
            "recons_loss:0.003991\n",
            "grad_loss:0.090603\n",
            "dice_loss:-0.899332\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:0\n",
            "loss(total):-0.004061\n",
            "recons_loss:0.004151\n",
            "grad_loss:0.085704\n",
            "dice_loss:-0.906937\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:1\n",
            "loss(total):-0.004388\n",
            "recons_loss:0.003802\n",
            "grad_loss:0.078556\n",
            "dice_loss:-0.897572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:2\n",
            "loss(total):-0.004224\n",
            "recons_loss:0.003761\n",
            "grad_loss:0.087955\n",
            "dice_loss:-0.886445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:3\n",
            "loss(total):-0.004860\n",
            "recons_loss:0.003237\n",
            "grad_loss:0.086222\n",
            "dice_loss:-0.895956\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:4\n",
            "loss(total):-0.003891\n",
            "recons_loss:0.004058\n",
            "grad_loss:0.100394\n",
            "dice_loss:-0.895321\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:5\n",
            "loss(total):-0.003596\n",
            "recons_loss:0.004261\n",
            "grad_loss:0.100994\n",
            "dice_loss:-0.886744\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:6\n",
            "loss(total):-0.003844\n",
            "recons_loss:0.004118\n",
            "grad_loss:0.094353\n",
            "dice_loss:-0.890579\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:7\n",
            "loss(total):-0.003192\n",
            "recons_loss:0.004886\n",
            "grad_loss:0.085362\n",
            "dice_loss:-0.893131\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:8\n",
            "loss(total):-0.003254\n",
            "recons_loss:0.004667\n",
            "grad_loss:0.095198\n",
            "dice_loss:-0.887258\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:9\n",
            "loss(total):-0.003679\n",
            "recons_loss:0.004198\n",
            "grad_loss:0.109949\n",
            "dice_loss:-0.897618\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:10\n",
            "loss(total):-0.004739\n",
            "recons_loss:0.003392\n",
            "grad_loss:0.074553\n",
            "dice_loss:-0.887657\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:11\n",
            "loss(total):-0.001531\n",
            "recons_loss:0.006158\n",
            "grad_loss:0.117327\n",
            "dice_loss:-0.886231\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:12\n",
            "loss(total):-0.003237\n",
            "recons_loss:0.004593\n",
            "grad_loss:0.115926\n",
            "dice_loss:-0.898947\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:13\n",
            "loss(total):-0.003447\n",
            "recons_loss:0.004450\n",
            "grad_loss:0.094177\n",
            "dice_loss:-0.883887\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:14\n",
            "loss(total):-0.002395\n",
            "recons_loss:0.005363\n",
            "grad_loss:0.113623\n",
            "dice_loss:-0.889380\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:15\n",
            "loss(total):-0.003632\n",
            "recons_loss:0.004259\n",
            "grad_loss:0.092695\n",
            "dice_loss:-0.881777\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:16\n",
            "loss(total):-0.003645\n",
            "recons_loss:0.004525\n",
            "grad_loss:0.078477\n",
            "dice_loss:-0.895494\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:17\n",
            "loss(total):-0.002998\n",
            "recons_loss:0.004680\n",
            "grad_loss:0.116937\n",
            "dice_loss:-0.884733\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:18\n",
            "loss(total):-0.003042\n",
            "recons_loss:0.004830\n",
            "grad_loss:0.105178\n",
            "dice_loss:-0.892346\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:19\n",
            "loss(total):-0.002296\n",
            "recons_loss:0.005433\n",
            "grad_loss:0.114382\n",
            "dice_loss:-0.887272\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:20\n",
            "loss(total):-0.003717\n",
            "recons_loss:0.004132\n",
            "grad_loss:0.103218\n",
            "dice_loss:-0.888085\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:21\n",
            "loss(total):-0.002539\n",
            "recons_loss:0.005007\n",
            "grad_loss:0.134840\n",
            "dice_loss:-0.889392\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:22\n",
            "loss(total):-0.004158\n",
            "recons_loss:0.004024\n",
            "grad_loss:0.077939\n",
            "dice_loss:-0.896172\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:23\n",
            "loss(total):-0.003091\n",
            "recons_loss:0.004995\n",
            "grad_loss:0.092107\n",
            "dice_loss:-0.900669\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:24\n",
            "loss(total):-0.004287\n",
            "recons_loss:0.003733\n",
            "grad_loss:0.098966\n",
            "dice_loss:-0.900972\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:25\n",
            "loss(total):-0.002801\n",
            "recons_loss:0.004894\n",
            "grad_loss:0.118812\n",
            "dice_loss:-0.888407\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:26\n",
            "loss(total):-0.003580\n",
            "recons_loss:0.004477\n",
            "grad_loss:0.098572\n",
            "dice_loss:-0.904270\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:27\n",
            "loss(total):-0.003833\n",
            "recons_loss:0.004058\n",
            "grad_loss:0.100525\n",
            "dice_loss:-0.889614\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:28\n",
            "loss(total):-0.003404\n",
            "recons_loss:0.004471\n",
            "grad_loss:0.101541\n",
            "dice_loss:-0.888963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:29\n",
            "loss(total):-0.002414\n",
            "recons_loss:0.005276\n",
            "grad_loss:0.104786\n",
            "dice_loss:-0.873784\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:30\n",
            "loss(total):-0.004181\n",
            "recons_loss:0.003832\n",
            "grad_loss:0.088011\n",
            "dice_loss:-0.889365\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:31\n",
            "loss(total):-0.003902\n",
            "recons_loss:0.003950\n",
            "grad_loss:0.094827\n",
            "dice_loss:-0.880069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:32\n",
            "loss(total):-0.002905\n",
            "recons_loss:0.004787\n",
            "grad_loss:0.120107\n",
            "dice_loss:-0.889335\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:33\n",
            "loss(total):-0.002415\n",
            "recons_loss:0.005218\n",
            "grad_loss:0.122102\n",
            "dice_loss:-0.885383\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:34\n",
            "loss(total):-0.003288\n",
            "recons_loss:0.004472\n",
            "grad_loss:0.114837\n",
            "dice_loss:-0.890820\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:35\n",
            "loss(total):-0.003874\n",
            "recons_loss:0.003990\n",
            "grad_loss:0.107290\n",
            "dice_loss:-0.893725\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:36\n",
            "loss(total):-0.002759\n",
            "recons_loss:0.005095\n",
            "grad_loss:0.114683\n",
            "dice_loss:-0.900103\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:37\n",
            "loss(total):-0.002852\n",
            "recons_loss:0.005037\n",
            "grad_loss:0.099871\n",
            "dice_loss:-0.888795\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:38\n",
            "loss(total):-0.002856\n",
            "recons_loss:0.004918\n",
            "grad_loss:0.112156\n",
            "dice_loss:-0.889521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:39\n",
            "loss(total):-0.004033\n",
            "recons_loss:0.003976\n",
            "grad_loss:0.081175\n",
            "dice_loss:-0.882069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:40\n",
            "loss(total):-0.003294\n",
            "recons_loss:0.004505\n",
            "grad_loss:0.095255\n",
            "dice_loss:-0.875232\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:41\n",
            "loss(total):-0.005220\n",
            "recons_loss:0.003012\n",
            "grad_loss:0.074331\n",
            "dice_loss:-0.897556\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:42\n",
            "loss(total):-0.003142\n",
            "recons_loss:0.004674\n",
            "grad_loss:0.097780\n",
            "dice_loss:-0.879378\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:43\n",
            "loss(total):-0.002946\n",
            "recons_loss:0.004929\n",
            "grad_loss:0.112305\n",
            "dice_loss:-0.899752\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:44\n",
            "loss(total):-0.001449\n",
            "recons_loss:0.006063\n",
            "grad_loss:0.130695\n",
            "dice_loss:-0.881854\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:45\n",
            "loss(total):-0.002716\n",
            "recons_loss:0.005013\n",
            "grad_loss:0.098540\n",
            "dice_loss:-0.871491\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:46\n",
            "loss(total):-0.003813\n",
            "recons_loss:0.004101\n",
            "grad_loss:0.090054\n",
            "dice_loss:-0.881437\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:47\n",
            "loss(total):-0.003658\n",
            "recons_loss:0.004255\n",
            "grad_loss:0.092311\n",
            "dice_loss:-0.883680\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:48\n",
            "loss(total):-0.003977\n",
            "recons_loss:0.004157\n",
            "grad_loss:0.082381\n",
            "dice_loss:-0.895759\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:49\n",
            "loss(total):-0.002137\n",
            "recons_loss:0.005575\n",
            "grad_loss:0.128221\n",
            "dice_loss:-0.899482\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:50\n",
            "loss(total):-0.003780\n",
            "recons_loss:0.004149\n",
            "grad_loss:0.108965\n",
            "dice_loss:-0.901839\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:51\n",
            "loss(total):-0.003487\n",
            "recons_loss:0.004277\n",
            "grad_loss:0.109621\n",
            "dice_loss:-0.885993\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:52\n",
            "loss(total):-0.003048\n",
            "recons_loss:0.004740\n",
            "grad_loss:0.123619\n",
            "dice_loss:-0.902443\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:53\n",
            "loss(total):-0.004099\n",
            "recons_loss:0.003782\n",
            "grad_loss:0.104601\n",
            "dice_loss:-0.892757\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:54\n",
            "loss(total):-0.002939\n",
            "recons_loss:0.005001\n",
            "grad_loss:0.092769\n",
            "dice_loss:-0.886735\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:55\n",
            "loss(total):-0.002165\n",
            "recons_loss:0.005586\n",
            "grad_loss:0.107818\n",
            "dice_loss:-0.882911\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:56\n",
            "loss(total):-0.003423\n",
            "recons_loss:0.004642\n",
            "grad_loss:0.092327\n",
            "dice_loss:-0.898746\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:57\n",
            "loss(total):-0.003643\n",
            "recons_loss:0.004353\n",
            "grad_loss:0.089762\n",
            "dice_loss:-0.889444\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:58\n",
            "loss(total):-0.001530\n",
            "recons_loss:0.005954\n",
            "grad_loss:0.132934\n",
            "dice_loss:-0.881308\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:59\n",
            "loss(total):-0.003943\n",
            "recons_loss:0.003939\n",
            "grad_loss:0.104349\n",
            "dice_loss:-0.892542\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:60\n",
            "loss(total):-0.002438\n",
            "recons_loss:0.005416\n",
            "grad_loss:0.101064\n",
            "dice_loss:-0.886526\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:61\n",
            "loss(total):-0.005236\n",
            "recons_loss:0.003027\n",
            "grad_loss:0.071457\n",
            "dice_loss:-0.897754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:62\n",
            "loss(total):-0.003343\n",
            "recons_loss:0.004660\n",
            "grad_loss:0.097568\n",
            "dice_loss:-0.897933\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:63\n",
            "loss(total):-0.003649\n",
            "recons_loss:0.004096\n",
            "grad_loss:0.107830\n",
            "dice_loss:-0.882368\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:64\n",
            "loss(total):-0.005242\n",
            "recons_loss:0.002964\n",
            "grad_loss:0.079818\n",
            "dice_loss:-0.900417\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:65\n",
            "loss(total):-0.004037\n",
            "recons_loss:0.003944\n",
            "grad_loss:0.097550\n",
            "dice_loss:-0.895678\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:66\n",
            "loss(total):-0.003084\n",
            "recons_loss:0.004646\n",
            "grad_loss:0.120840\n",
            "dice_loss:-0.893872\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:67\n",
            "loss(total):-0.002971\n",
            "recons_loss:0.004916\n",
            "grad_loss:0.095725\n",
            "dice_loss:-0.884413\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:68\n",
            "loss(total):-0.002394\n",
            "recons_loss:0.005342\n",
            "grad_loss:0.109691\n",
            "dice_loss:-0.883277\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:69\n",
            "loss(total):-0.002891\n",
            "recons_loss:0.005072\n",
            "grad_loss:0.093281\n",
            "dice_loss:-0.889585\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:70\n",
            "loss(total):-0.003508\n",
            "recons_loss:0.004322\n",
            "grad_loss:0.120210\n",
            "dice_loss:-0.903149\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:71\n",
            "loss(total):-0.003482\n",
            "recons_loss:0.004301\n",
            "grad_loss:0.101309\n",
            "dice_loss:-0.879667\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:72\n",
            "loss(total):-0.004250\n",
            "recons_loss:0.003730\n",
            "grad_loss:0.092963\n",
            "dice_loss:-0.890978\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:73\n",
            "loss(total):-0.003537\n",
            "recons_loss:0.004313\n",
            "grad_loss:0.108039\n",
            "dice_loss:-0.893057\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:74\n",
            "loss(total):-0.002650\n",
            "recons_loss:0.004983\n",
            "grad_loss:0.122585\n",
            "dice_loss:-0.885861\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:75\n",
            "loss(total):-0.005529\n",
            "recons_loss:0.002715\n",
            "grad_loss:0.067879\n",
            "dice_loss:-0.892247\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:76\n",
            "loss(total):-0.001358\n",
            "recons_loss:0.006083\n",
            "grad_loss:0.141104\n",
            "dice_loss:-0.885204\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:77\n",
            "loss(total):-0.003784\n",
            "recons_loss:0.004167\n",
            "grad_loss:0.099259\n",
            "dice_loss:-0.894341\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:78\n",
            "loss(total):-0.003118\n",
            "recons_loss:0.004741\n",
            "grad_loss:0.115678\n",
            "dice_loss:-0.901556\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:79\n",
            "loss(total):-0.004121\n",
            "recons_loss:0.003893\n",
            "grad_loss:0.097222\n",
            "dice_loss:-0.898615\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:80\n",
            "loss(total):-0.002595\n",
            "recons_loss:0.005049\n",
            "grad_loss:0.122228\n",
            "dice_loss:-0.886694\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:81\n",
            "loss(total):-0.004005\n",
            "recons_loss:0.004056\n",
            "grad_loss:0.080909\n",
            "dice_loss:-0.887016\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:82\n",
            "loss(total):-0.003119\n",
            "recons_loss:0.004718\n",
            "grad_loss:0.106532\n",
            "dice_loss:-0.890209\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:83\n",
            "loss(total):-0.003851\n",
            "recons_loss:0.004243\n",
            "grad_loss:0.083243\n",
            "dice_loss:-0.892609\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:84\n",
            "loss(total):-0.004491\n",
            "recons_loss:0.003533\n",
            "grad_loss:0.087326\n",
            "dice_loss:-0.889674\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:85\n",
            "loss(total):-0.003093\n",
            "recons_loss:0.004665\n",
            "grad_loss:0.116374\n",
            "dice_loss:-0.892193\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:86\n",
            "loss(total):-0.004181\n",
            "recons_loss:0.003966\n",
            "grad_loss:0.075329\n",
            "dice_loss:-0.890029\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:87\n",
            "loss(total):-0.003107\n",
            "recons_loss:0.004676\n",
            "grad_loss:0.108690\n",
            "dice_loss:-0.887025\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:88\n",
            "loss(total):-0.002024\n",
            "recons_loss:0.005657\n",
            "grad_loss:0.118788\n",
            "dice_loss:-0.886915\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:89\n",
            "loss(total):-0.004881\n",
            "recons_loss:0.003347\n",
            "grad_loss:0.070782\n",
            "dice_loss:-0.893572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:90\n",
            "loss(total):-0.001457\n",
            "recons_loss:0.006038\n",
            "grad_loss:0.126713\n",
            "dice_loss:-0.876249\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:91\n",
            "loss(total):-0.001042\n",
            "recons_loss:0.006392\n",
            "grad_loss:0.132452\n",
            "dice_loss:-0.875802\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:92\n",
            "loss(total):-0.004567\n",
            "recons_loss:0.003556\n",
            "grad_loss:0.090858\n",
            "dice_loss:-0.903184\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:93\n",
            "loss(total):-0.004281\n",
            "recons_loss:0.003832\n",
            "grad_loss:0.081206\n",
            "dice_loss:-0.892547\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:94\n",
            "loss(total):-0.003335\n",
            "recons_loss:0.004414\n",
            "grad_loss:0.096663\n",
            "dice_loss:-0.871580\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:95\n",
            "loss(total):-0.003320\n",
            "recons_loss:0.004495\n",
            "grad_loss:0.097986\n",
            "dice_loss:-0.879487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:96\n",
            "loss(total):-0.003418\n",
            "recons_loss:0.004519\n",
            "grad_loss:0.099031\n",
            "dice_loss:-0.892750\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:97\n",
            "loss(total):-0.004165\n",
            "recons_loss:0.003856\n",
            "grad_loss:0.103607\n",
            "dice_loss:-0.905719\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:98\n",
            "loss(total):-0.003663\n",
            "recons_loss:0.004259\n",
            "grad_loss:0.093935\n",
            "dice_loss:-0.886138\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:99\n",
            "loss(total):-0.003721\n",
            "recons_loss:0.004190\n",
            "grad_loss:0.109178\n",
            "dice_loss:-0.900271\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:100\n",
            "loss(total):-0.002050\n",
            "recons_loss:0.005404\n",
            "grad_loss:0.132271\n",
            "dice_loss:-0.877657\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:101\n",
            "loss(total):-0.003034\n",
            "recons_loss:0.004888\n",
            "grad_loss:0.093514\n",
            "dice_loss:-0.885714\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:102\n",
            "loss(total):-0.002952\n",
            "recons_loss:0.004804\n",
            "grad_loss:0.114079\n",
            "dice_loss:-0.889696\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:103\n",
            "loss(total):-0.003417\n",
            "recons_loss:0.004388\n",
            "grad_loss:0.095709\n",
            "dice_loss:-0.876256\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:104\n",
            "loss(total):-0.004434\n",
            "recons_loss:0.003633\n",
            "grad_loss:0.080059\n",
            "dice_loss:-0.886761\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:105\n",
            "loss(total):-0.003576\n",
            "recons_loss:0.004522\n",
            "grad_loss:0.086206\n",
            "dice_loss:-0.896009\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:106\n",
            "loss(total):-0.004035\n",
            "recons_loss:0.004079\n",
            "grad_loss:0.078302\n",
            "dice_loss:-0.889657\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:107\n",
            "loss(total):-0.004098\n",
            "recons_loss:0.004256\n",
            "grad_loss:0.069475\n",
            "dice_loss:-0.904892\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:108\n",
            "loss(total):-0.003514\n",
            "recons_loss:0.004601\n",
            "grad_loss:0.090895\n",
            "dice_loss:-0.902393\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:109\n",
            "loss(total):-0.003191\n",
            "recons_loss:0.004618\n",
            "grad_loss:0.105209\n",
            "dice_loss:-0.886098\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:110\n",
            "loss(total):-0.003326\n",
            "recons_loss:0.004465\n",
            "grad_loss:0.114459\n",
            "dice_loss:-0.893564\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:111\n",
            "loss(total):-0.003318\n",
            "recons_loss:0.004462\n",
            "grad_loss:0.109926\n",
            "dice_loss:-0.887876\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:112\n",
            "loss(total):-0.003358\n",
            "recons_loss:0.004444\n",
            "grad_loss:0.107886\n",
            "dice_loss:-0.888070\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:113\n",
            "loss(total):-0.002120\n",
            "recons_loss:0.005461\n",
            "grad_loss:0.126980\n",
            "dice_loss:-0.885059\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:114\n",
            "loss(total):-0.002510\n",
            "recons_loss:0.005133\n",
            "grad_loss:0.112197\n",
            "dice_loss:-0.876484\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:115\n",
            "loss(total):-0.003993\n",
            "recons_loss:0.003973\n",
            "grad_loss:0.089011\n",
            "dice_loss:-0.885595\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:116\n",
            "loss(total):-0.003611\n",
            "recons_loss:0.004288\n",
            "grad_loss:0.095758\n",
            "dice_loss:-0.885669\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:117\n",
            "loss(total):-0.002375\n",
            "recons_loss:0.005429\n",
            "grad_loss:0.119035\n",
            "dice_loss:-0.899486\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:118\n",
            "loss(total):-0.002479\n",
            "recons_loss:0.005228\n",
            "grad_loss:0.102869\n",
            "dice_loss:-0.873647\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:119\n",
            "loss(total):-0.004084\n",
            "recons_loss:0.004007\n",
            "grad_loss:0.094966\n",
            "dice_loss:-0.904066\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:120\n",
            "loss(total):-0.003566\n",
            "recons_loss:0.004202\n",
            "grad_loss:0.095592\n",
            "dice_loss:-0.872409\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:121\n",
            "loss(total):-0.004141\n",
            "recons_loss:0.004117\n",
            "grad_loss:0.077957\n",
            "dice_loss:-0.903756\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:122\n",
            "loss(total):-0.003343\n",
            "recons_loss:0.004739\n",
            "grad_loss:0.087350\n",
            "dice_loss:-0.895539\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:123\n",
            "loss(total):-0.002296\n",
            "recons_loss:0.005460\n",
            "grad_loss:0.120108\n",
            "dice_loss:-0.895630\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:124\n",
            "loss(total):-0.002650\n",
            "recons_loss:0.005218\n",
            "grad_loss:0.107278\n",
            "dice_loss:-0.894120\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:125\n",
            "loss(total):-0.003726\n",
            "recons_loss:0.004354\n",
            "grad_loss:0.087329\n",
            "dice_loss:-0.895396\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:126\n",
            "loss(total):-0.003346\n",
            "recons_loss:0.004530\n",
            "grad_loss:0.098183\n",
            "dice_loss:-0.885873\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:127\n",
            "loss(total):-0.003465\n",
            "recons_loss:0.004559\n",
            "grad_loss:0.088261\n",
            "dice_loss:-0.890680\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:128\n",
            "loss(total):-0.002810\n",
            "recons_loss:0.005125\n",
            "grad_loss:0.090565\n",
            "dice_loss:-0.884017\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:129\n",
            "loss(total):-0.003390\n",
            "recons_loss:0.004567\n",
            "grad_loss:0.088197\n",
            "dice_loss:-0.883889\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:130\n",
            "loss(total):-0.002660\n",
            "recons_loss:0.005225\n",
            "grad_loss:0.083702\n",
            "dice_loss:-0.872179\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:131\n",
            "loss(total):-0.002166\n",
            "recons_loss:0.005461\n",
            "grad_loss:0.116930\n",
            "dice_loss:-0.879649\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:132\n",
            "loss(total):-0.003081\n",
            "recons_loss:0.004608\n",
            "grad_loss:0.102636\n",
            "dice_loss:-0.871514\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:133\n",
            "loss(total):-0.004230\n",
            "recons_loss:0.003885\n",
            "grad_loss:0.089280\n",
            "dice_loss:-0.900777\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:134\n",
            "loss(total):-0.003361\n",
            "recons_loss:0.004445\n",
            "grad_loss:0.102459\n",
            "dice_loss:-0.883111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:135\n",
            "loss(total):-0.003859\n",
            "recons_loss:0.004032\n",
            "grad_loss:0.094148\n",
            "dice_loss:-0.883303\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:136\n",
            "loss(total):-0.004240\n",
            "recons_loss:0.003829\n",
            "grad_loss:0.091715\n",
            "dice_loss:-0.898621\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:137\n",
            "loss(total):-0.004314\n",
            "recons_loss:0.003791\n",
            "grad_loss:0.091432\n",
            "dice_loss:-0.901972\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:138\n",
            "loss(total):-0.003921\n",
            "recons_loss:0.004046\n",
            "grad_loss:0.089804\n",
            "dice_loss:-0.886551\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:139\n",
            "loss(total):-0.004383\n",
            "recons_loss:0.003680\n",
            "grad_loss:0.087448\n",
            "dice_loss:-0.893795\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:140\n",
            "loss(total):-0.003581\n",
            "recons_loss:0.004494\n",
            "grad_loss:0.092557\n",
            "dice_loss:-0.900003\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:141\n",
            "loss(total):-0.003100\n",
            "recons_loss:0.004923\n",
            "grad_loss:0.085340\n",
            "dice_loss:-0.887680\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:142\n",
            "loss(total):-0.003462\n",
            "recons_loss:0.004455\n",
            "grad_loss:0.098595\n",
            "dice_loss:-0.890252\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:143\n",
            "loss(total):-0.003467\n",
            "recons_loss:0.004591\n",
            "grad_loss:0.095028\n",
            "dice_loss:-0.900847\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:144\n",
            "loss(total):-0.003357\n",
            "recons_loss:0.004645\n",
            "grad_loss:0.095215\n",
            "dice_loss:-0.895400\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:145\n",
            "loss(total):-0.004475\n",
            "recons_loss:0.003640\n",
            "grad_loss:0.089131\n",
            "dice_loss:-0.900548\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:146\n",
            "loss(total):-0.004157\n",
            "recons_loss:0.003800\n",
            "grad_loss:0.097103\n",
            "dice_loss:-0.892816\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:147\n",
            "loss(total):-0.004137\n",
            "recons_loss:0.003818\n",
            "grad_loss:0.102564\n",
            "dice_loss:-0.898027\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:148\n",
            "loss(total):-0.003801\n",
            "recons_loss:0.003974\n",
            "grad_loss:0.103009\n",
            "dice_loss:-0.880557\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:149\n",
            "loss(total):-0.003365\n",
            "recons_loss:0.004540\n",
            "grad_loss:0.097871\n",
            "dice_loss:-0.888447\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:150\n",
            "loss(total):-0.003653\n",
            "recons_loss:0.004156\n",
            "grad_loss:0.111971\n",
            "dice_loss:-0.892848\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:151\n",
            "loss(total):-0.003304\n",
            "recons_loss:0.004478\n",
            "grad_loss:0.116292\n",
            "dice_loss:-0.894505\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:152\n",
            "loss(total):-0.003185\n",
            "recons_loss:0.004584\n",
            "grad_loss:0.110772\n",
            "dice_loss:-0.887689\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:153\n",
            "loss(total):-0.003586\n",
            "recons_loss:0.004281\n",
            "grad_loss:0.104970\n",
            "dice_loss:-0.891649\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:154\n",
            "loss(total):-0.002949\n",
            "recons_loss:0.004777\n",
            "grad_loss:0.119094\n",
            "dice_loss:-0.891677\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:155\n",
            "loss(total):-0.004404\n",
            "recons_loss:0.003711\n",
            "grad_loss:0.086523\n",
            "dice_loss:-0.898011\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:156\n",
            "loss(total):-0.003383\n",
            "recons_loss:0.004442\n",
            "grad_loss:0.105491\n",
            "dice_loss:-0.887992\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:157\n",
            "loss(total):-0.003272\n",
            "recons_loss:0.004664\n",
            "grad_loss:0.097821\n",
            "dice_loss:-0.891404\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:158\n",
            "loss(total):-0.004177\n",
            "recons_loss:0.004013\n",
            "grad_loss:0.080094\n",
            "dice_loss:-0.899137\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:159\n",
            "loss(total):-0.003309\n",
            "recons_loss:0.004496\n",
            "grad_loss:0.117285\n",
            "dice_loss:-0.897844\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:160\n",
            "loss(total):-0.003582\n",
            "recons_loss:0.004215\n",
            "grad_loss:0.104693\n",
            "dice_loss:-0.884423\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:161\n",
            "loss(total):-0.003285\n",
            "recons_loss:0.004452\n",
            "grad_loss:0.100517\n",
            "dice_loss:-0.874250\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:162\n",
            "loss(total):-0.002760\n",
            "recons_loss:0.005127\n",
            "grad_loss:0.097928\n",
            "dice_loss:-0.886653\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:163\n",
            "loss(total):-0.005128\n",
            "recons_loss:0.003185\n",
            "grad_loss:0.079280\n",
            "dice_loss:-0.910594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:164\n",
            "loss(total):-0.002052\n",
            "recons_loss:0.005771\n",
            "grad_loss:0.101815\n",
            "dice_loss:-0.884194\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:165\n",
            "loss(total):-0.003457\n",
            "recons_loss:0.004499\n",
            "grad_loss:0.084047\n",
            "dice_loss:-0.879646\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:166\n",
            "loss(total):-0.004500\n",
            "recons_loss:0.003705\n",
            "grad_loss:0.073167\n",
            "dice_loss:-0.893714\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:167\n",
            "loss(total):-0.003296\n",
            "recons_loss:0.004791\n",
            "grad_loss:0.085458\n",
            "dice_loss:-0.894165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:168\n",
            "loss(total):-0.003340\n",
            "recons_loss:0.004483\n",
            "grad_loss:0.102979\n",
            "dice_loss:-0.885263\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:169\n",
            "loss(total):-0.003935\n",
            "recons_loss:0.003863\n",
            "grad_loss:0.099093\n",
            "dice_loss:-0.878857\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:170\n",
            "loss(total):-0.004191\n",
            "recons_loss:0.003672\n",
            "grad_loss:0.095069\n",
            "dice_loss:-0.881346\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:171\n",
            "loss(total):-0.004913\n",
            "recons_loss:0.003182\n",
            "grad_loss:0.077110\n",
            "dice_loss:-0.886637\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:172\n",
            "loss(total):-0.004641\n",
            "recons_loss:0.003446\n",
            "grad_loss:0.089536\n",
            "dice_loss:-0.898150\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:173\n",
            "loss(total):-0.004137\n",
            "recons_loss:0.003870\n",
            "grad_loss:0.104793\n",
            "dice_loss:-0.905551\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:174\n",
            "loss(total):-0.003280\n",
            "recons_loss:0.004471\n",
            "grad_loss:0.117263\n",
            "dice_loss:-0.892359\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:175\n",
            "loss(total):-0.003010\n",
            "recons_loss:0.004598\n",
            "grad_loss:0.109414\n",
            "dice_loss:-0.870259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:176\n",
            "loss(total):-0.003931\n",
            "recons_loss:0.003955\n",
            "grad_loss:0.100707\n",
            "dice_loss:-0.889264\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:177\n",
            "loss(total):-0.003672\n",
            "recons_loss:0.004245\n",
            "grad_loss:0.096500\n",
            "dice_loss:-0.888154\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:178\n",
            "loss(total):-0.003375\n",
            "recons_loss:0.004522\n",
            "grad_loss:0.104420\n",
            "dice_loss:-0.894086\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:179\n",
            "loss(total):-0.002731\n",
            "recons_loss:0.005075\n",
            "grad_loss:0.106324\n",
            "dice_loss:-0.886916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:180\n",
            "loss(total):-0.003012\n",
            "recons_loss:0.004827\n",
            "grad_loss:0.098317\n",
            "dice_loss:-0.882222\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:181\n",
            "loss(total):-0.003089\n",
            "recons_loss:0.004784\n",
            "grad_loss:0.098168\n",
            "dice_loss:-0.885420\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:182\n",
            "loss(total):-0.002442\n",
            "recons_loss:0.005294\n",
            "grad_loss:0.120215\n",
            "dice_loss:-0.893833\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:183\n",
            "loss(total):-0.004042\n",
            "recons_loss:0.004013\n",
            "grad_loss:0.091200\n",
            "dice_loss:-0.896749\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:184\n",
            "loss(total):-0.003745\n",
            "recons_loss:0.004222\n",
            "grad_loss:0.103892\n",
            "dice_loss:-0.900544\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:185\n",
            "loss(total):-0.004311\n",
            "recons_loss:0.003673\n",
            "grad_loss:0.096478\n",
            "dice_loss:-0.894881\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:186\n",
            "loss(total):-0.003647\n",
            "recons_loss:0.004272\n",
            "grad_loss:0.091645\n",
            "dice_loss:-0.883625\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:187\n",
            "loss(total):-0.004471\n",
            "recons_loss:0.003640\n",
            "grad_loss:0.078628\n",
            "dice_loss:-0.889774\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:188\n",
            "loss(total):-0.002824\n",
            "recons_loss:0.004842\n",
            "grad_loss:0.121572\n",
            "dice_loss:-0.888150\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:189\n",
            "loss(total):-0.003950\n",
            "recons_loss:0.003972\n",
            "grad_loss:0.093046\n",
            "dice_loss:-0.885240\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:190\n",
            "loss(total):-0.002883\n",
            "recons_loss:0.005055\n",
            "grad_loss:0.104527\n",
            "dice_loss:-0.898282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:191\n",
            "loss(total):-0.003059\n",
            "recons_loss:0.004776\n",
            "grad_loss:0.108822\n",
            "dice_loss:-0.892267\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:192\n",
            "loss(total):-0.003450\n",
            "recons_loss:0.004530\n",
            "grad_loss:0.089321\n",
            "dice_loss:-0.887323\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:193\n",
            "loss(total):-0.001967\n",
            "recons_loss:0.005511\n",
            "grad_loss:0.123708\n",
            "dice_loss:-0.871498\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:194\n",
            "loss(total):-0.004363\n",
            "recons_loss:0.003676\n",
            "grad_loss:0.095750\n",
            "dice_loss:-0.899654\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:195\n",
            "loss(total):-0.003898\n",
            "recons_loss:0.004071\n",
            "grad_loss:0.101774\n",
            "dice_loss:-0.898591\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:196\n",
            "loss(total):-0.002616\n",
            "recons_loss:0.005030\n",
            "grad_loss:0.119542\n",
            "dice_loss:-0.884154\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:197\n",
            "loss(total):-0.005158\n",
            "recons_loss:0.003002\n",
            "grad_loss:0.082948\n",
            "dice_loss:-0.898957\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:198\n",
            "loss(total):-0.002426\n",
            "recons_loss:0.005402\n",
            "grad_loss:0.115444\n",
            "dice_loss:-0.898220\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:199\n",
            "loss(total):-0.004245\n",
            "recons_loss:0.003733\n",
            "grad_loss:0.099924\n",
            "dice_loss:-0.897784\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:200\n",
            "loss(total):-0.004144\n",
            "recons_loss:0.003944\n",
            "grad_loss:0.083851\n",
            "dice_loss:-0.892632\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:201\n",
            "loss(total):-0.003051\n",
            "recons_loss:0.004717\n",
            "grad_loss:0.119162\n",
            "dice_loss:-0.895896\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:202\n",
            "loss(total):-0.004329\n",
            "recons_loss:0.003727\n",
            "grad_loss:0.103786\n",
            "dice_loss:-0.909429\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:203\n",
            "loss(total):-0.003358\n",
            "recons_loss:0.004590\n",
            "grad_loss:0.097185\n",
            "dice_loss:-0.891907\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:204\n",
            "loss(total):-0.004486\n",
            "recons_loss:0.003548\n",
            "grad_loss:0.083269\n",
            "dice_loss:-0.886618\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:205\n",
            "loss(total):-0.003716\n",
            "recons_loss:0.004475\n",
            "grad_loss:0.091340\n",
            "dice_loss:-0.910434\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:206\n",
            "loss(total):-0.002041\n",
            "recons_loss:0.005643\n",
            "grad_loss:0.128583\n",
            "dice_loss:-0.896920\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:207\n",
            "loss(total):-0.003845\n",
            "recons_loss:0.004051\n",
            "grad_loss:0.113137\n",
            "dice_loss:-0.902717\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:208\n",
            "loss(total):-0.003137\n",
            "recons_loss:0.004574\n",
            "grad_loss:0.117641\n",
            "dice_loss:-0.888816\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:209\n",
            "loss(total):-0.002722\n",
            "recons_loss:0.005015\n",
            "grad_loss:0.115316\n",
            "dice_loss:-0.889069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:210\n",
            "loss(total):-0.004596\n",
            "recons_loss:0.003421\n",
            "grad_loss:0.089345\n",
            "dice_loss:-0.891081\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:211\n",
            "loss(total):-0.004481\n",
            "recons_loss:0.003612\n",
            "grad_loss:0.074413\n",
            "dice_loss:-0.883706\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:212\n",
            "loss(total):-0.002967\n",
            "recons_loss:0.004906\n",
            "grad_loss:0.110483\n",
            "dice_loss:-0.897711\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:213\n",
            "loss(total):-0.003181\n",
            "recons_loss:0.004733\n",
            "grad_loss:0.090167\n",
            "dice_loss:-0.881536\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:214\n",
            "loss(total):-0.004477\n",
            "recons_loss:0.003499\n",
            "grad_loss:0.113299\n",
            "dice_loss:-0.910895\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:215\n",
            "loss(total):-0.004126\n",
            "recons_loss:0.003841\n",
            "grad_loss:0.095599\n",
            "dice_loss:-0.892258\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:216\n",
            "loss(total):-0.004374\n",
            "recons_loss:0.003841\n",
            "grad_loss:0.078094\n",
            "dice_loss:-0.899586\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:217\n",
            "loss(total):-0.002170\n",
            "recons_loss:0.005611\n",
            "grad_loss:0.104690\n",
            "dice_loss:-0.882789\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:218\n",
            "loss(total):-0.002248\n",
            "recons_loss:0.005439\n",
            "grad_loss:0.116837\n",
            "dice_loss:-0.885573\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:219\n",
            "loss(total):-0.003645\n",
            "recons_loss:0.004339\n",
            "grad_loss:0.097916\n",
            "dice_loss:-0.896312\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:220\n",
            "loss(total):-0.004263\n",
            "recons_loss:0.003708\n",
            "grad_loss:0.089813\n",
            "dice_loss:-0.886868\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:221\n",
            "loss(total):-0.004598\n",
            "recons_loss:0.003427\n",
            "grad_loss:0.093435\n",
            "dice_loss:-0.895947\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:222\n",
            "loss(total):-0.005199\n",
            "recons_loss:0.003014\n",
            "grad_loss:0.085367\n",
            "dice_loss:-0.906664\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:223\n",
            "loss(total):-0.003076\n",
            "recons_loss:0.004721\n",
            "grad_loss:0.112289\n",
            "dice_loss:-0.891968\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:224\n",
            "loss(total):-0.004619\n",
            "recons_loss:0.003566\n",
            "grad_loss:0.073514\n",
            "dice_loss:-0.891997\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:225\n",
            "loss(total):-0.003481\n",
            "recons_loss:0.004340\n",
            "grad_loss:0.105898\n",
            "dice_loss:-0.888045\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:226\n",
            "loss(total):-0.005045\n",
            "recons_loss:0.003059\n",
            "grad_loss:0.074439\n",
            "dice_loss:-0.884808\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:227\n",
            "loss(total):-0.003033\n",
            "recons_loss:0.004943\n",
            "grad_loss:0.088507\n",
            "dice_loss:-0.886063\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:228\n",
            "loss(total):-0.003290\n",
            "recons_loss:0.004559\n",
            "grad_loss:0.104474\n",
            "dice_loss:-0.889419\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:229\n",
            "loss(total):-0.003628\n",
            "recons_loss:0.004255\n",
            "grad_loss:0.098977\n",
            "dice_loss:-0.887308\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:230\n",
            "loss(total):-0.003022\n",
            "recons_loss:0.004705\n",
            "grad_loss:0.113393\n",
            "dice_loss:-0.886110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:231\n",
            "loss(total):-0.003876\n",
            "recons_loss:0.004099\n",
            "grad_loss:0.096956\n",
            "dice_loss:-0.894421\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:232\n",
            "loss(total):-0.003062\n",
            "recons_loss:0.004749\n",
            "grad_loss:0.113208\n",
            "dice_loss:-0.894362\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:233\n",
            "loss(total):-0.004741\n",
            "recons_loss:0.003441\n",
            "grad_loss:0.084735\n",
            "dice_loss:-0.902947\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:234\n",
            "loss(total):-0.004477\n",
            "recons_loss:0.003611\n",
            "grad_loss:0.076707\n",
            "dice_loss:-0.885518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:235\n",
            "loss(total):-0.002664\n",
            "recons_loss:0.005219\n",
            "grad_loss:0.096294\n",
            "dice_loss:-0.884516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:236\n",
            "loss(total):-0.003241\n",
            "recons_loss:0.004658\n",
            "grad_loss:0.095604\n",
            "dice_loss:-0.885552\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:237\n",
            "loss(total):-0.002825\n",
            "recons_loss:0.004978\n",
            "grad_loss:0.114619\n",
            "dice_loss:-0.894939\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:238\n",
            "loss(total):-0.003828\n",
            "recons_loss:0.004070\n",
            "grad_loss:0.098814\n",
            "dice_loss:-0.888579\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:239\n",
            "loss(total):-0.003706\n",
            "recons_loss:0.004259\n",
            "grad_loss:0.090786\n",
            "dice_loss:-0.887200\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:240\n",
            "loss(total):-0.002280\n",
            "recons_loss:0.005407\n",
            "grad_loss:0.105758\n",
            "dice_loss:-0.874390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:241\n",
            "loss(total):-0.002577\n",
            "recons_loss:0.005226\n",
            "grad_loss:0.115907\n",
            "dice_loss:-0.896183\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:242\n",
            "loss(total):-0.003767\n",
            "recons_loss:0.004058\n",
            "grad_loss:0.123096\n",
            "dice_loss:-0.905594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:243\n",
            "loss(total):-0.003458\n",
            "recons_loss:0.004421\n",
            "grad_loss:0.100345\n",
            "dice_loss:-0.888219\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:244\n",
            "loss(total):-0.004893\n",
            "recons_loss:0.003424\n",
            "grad_loss:0.073779\n",
            "dice_loss:-0.905493\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:245\n",
            "loss(total):-0.004395\n",
            "recons_loss:0.003779\n",
            "grad_loss:0.076661\n",
            "dice_loss:-0.893995\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:246\n",
            "loss(total):-0.004179\n",
            "recons_loss:0.004139\n",
            "grad_loss:0.073948\n",
            "dice_loss:-0.905709\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:247\n",
            "loss(total):-0.002033\n",
            "recons_loss:0.005715\n",
            "grad_loss:0.105827\n",
            "dice_loss:-0.880653\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:248\n",
            "loss(total):-0.003328\n",
            "recons_loss:0.004408\n",
            "grad_loss:0.104542\n",
            "dice_loss:-0.878239\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:249\n",
            "loss(total):-0.004858\n",
            "recons_loss:0.003315\n",
            "grad_loss:0.074604\n",
            "dice_loss:-0.891870\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:250\n",
            "loss(total):-0.005242\n",
            "recons_loss:0.003090\n",
            "grad_loss:0.072197\n",
            "dice_loss:-0.905388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:251\n",
            "loss(total):-0.000907\n",
            "recons_loss:0.006549\n",
            "grad_loss:0.140133\n",
            "dice_loss:-0.885738\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:252\n",
            "loss(total):-0.004232\n",
            "recons_loss:0.003733\n",
            "grad_loss:0.096574\n",
            "dice_loss:-0.893129\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:253\n",
            "loss(total):-0.002910\n",
            "recons_loss:0.004853\n",
            "grad_loss:0.113848\n",
            "dice_loss:-0.890156\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:254\n",
            "loss(total):-0.004390\n",
            "recons_loss:0.003646\n",
            "grad_loss:0.090301\n",
            "dice_loss:-0.893902\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:255\n",
            "loss(total):-0.003779\n",
            "recons_loss:0.004188\n",
            "grad_loss:0.090380\n",
            "dice_loss:-0.887008\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:256\n",
            "loss(total):-0.003824\n",
            "recons_loss:0.003908\n",
            "grad_loss:0.108059\n",
            "dice_loss:-0.881242\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:257\n",
            "loss(total):-0.003363\n",
            "recons_loss:0.004522\n",
            "grad_loss:0.107354\n",
            "dice_loss:-0.895815\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:258\n",
            "loss(total):-0.003994\n",
            "recons_loss:0.004105\n",
            "grad_loss:0.088388\n",
            "dice_loss:-0.898311\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:259\n",
            "loss(total):-0.001871\n",
            "recons_loss:0.005621\n",
            "grad_loss:0.123963\n",
            "dice_loss:-0.873219\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:260\n",
            "loss(total):-0.005188\n",
            "recons_loss:0.003143\n",
            "grad_loss:0.070537\n",
            "dice_loss:-0.903632\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:261\n",
            "loss(total):-0.002562\n",
            "recons_loss:0.005052\n",
            "grad_loss:0.111834\n",
            "dice_loss:-0.873242\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:262\n",
            "loss(total):-0.004290\n",
            "recons_loss:0.003622\n",
            "grad_loss:0.084749\n",
            "dice_loss:-0.875905\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:263\n",
            "loss(total):-0.003465\n",
            "recons_loss:0.004428\n",
            "grad_loss:0.099080\n",
            "dice_loss:-0.888379\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:264\n",
            "loss(total):-0.002839\n",
            "recons_loss:0.004973\n",
            "grad_loss:0.113583\n",
            "dice_loss:-0.894830\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:265\n",
            "loss(total):-0.003259\n",
            "recons_loss:0.004346\n",
            "grad_loss:0.121553\n",
            "dice_loss:-0.882078\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:266\n",
            "loss(total):-0.002974\n",
            "recons_loss:0.004746\n",
            "grad_loss:0.125249\n",
            "dice_loss:-0.897254\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:267\n",
            "loss(total):-0.003318\n",
            "recons_loss:0.004611\n",
            "grad_loss:0.103501\n",
            "dice_loss:-0.896377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:268\n",
            "loss(total):-0.002185\n",
            "recons_loss:0.005448\n",
            "grad_loss:0.127563\n",
            "dice_loss:-0.890813\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:269\n",
            "loss(total):-0.004228\n",
            "recons_loss:0.003838\n",
            "grad_loss:0.076622\n",
            "dice_loss:-0.883234\n",
            "---------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtwYCBYIDDWw",
        "outputId": "b854ae2d-b28a-4eb2-9b19-8f341c1a1c29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(losses_5[1:])\n",
        "plt.show"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15FawcLaDIoM",
        "outputId": "1f2286e9-60fc-4b46-ed47-dccb0ae90790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(validation_5)\n",
        "plt.show"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfd1DkHVDPAb"
      },
      "source": [
        "import csv\n",
        "with open('validation_5.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1pD9dMj6Vzp"
      },
      "source": [
        "for h in range(0,len(validation_0)):\n",
        "  with open('validation_5.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, validation_5[h].numpy()])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKXY90ocK9qX"
      },
      "source": [
        "import csv\n",
        "with open('loss_5.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n",
        "\n",
        "for h in range(0,len(losses_5)):\n",
        "  with open('loss_5.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h, losses_5[h].numpy()])"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4yrAc1JDVQp"
      },
      "source": [
        "'''Training - hold out fold 6 for validation'''\n",
        "#Training\n",
        "gpu='0'\n",
        "atlas_file='/content/drive/My Drive/2020/Thesis/Data/atlas.npz'\n",
        "lr=1e-4\n",
        "n_iter=5000\n",
        "data_loss='mse'\n",
        "model='vm2'\n",
        "reg_param=0.01\n",
        "batch_size=10\n",
        "n_save_iter=100\n",
        "model_dir='/content/drive/My Drive/2020/Thesis/Data/validation_0/'\n",
        "valid = fold_6\n",
        "train_names = set_6\n",
        "EPOCH=30"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGbE9Ag_Da5F",
        "outputId": "fb1aa44e-5a7c-442e-9239-2a4e1c74ec2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses_6, validation_6=validate.train(data_dir,\n",
        "          train_names,\n",
        "          atlas_file,\n",
        "          lr,\n",
        "          data_loss,\n",
        "          model,\n",
        "          reg_param, \n",
        "          batch_size,\n",
        "          n_save_iter,\n",
        "          model_dir,Net(),EPOCH, valid)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch_number:185\n",
            "loss(total):-0.002724\n",
            "recons_loss:0.005104\n",
            "grad_loss:0.103125\n",
            "dice_loss:-0.885925\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:186\n",
            "loss(total):-0.002390\n",
            "recons_loss:0.005203\n",
            "grad_loss:0.105084\n",
            "dice_loss:-0.864408\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:187\n",
            "loss(total):-0.003067\n",
            "recons_loss:0.004900\n",
            "grad_loss:0.097072\n",
            "dice_loss:-0.893818\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:188\n",
            "loss(total):-0.003289\n",
            "recons_loss:0.004476\n",
            "grad_loss:0.085148\n",
            "dice_loss:-0.861692\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:189\n",
            "loss(total):-0.003091\n",
            "recons_loss:0.004651\n",
            "grad_loss:0.096304\n",
            "dice_loss:-0.870530\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:190\n",
            "loss(total):-0.003570\n",
            "recons_loss:0.004244\n",
            "grad_loss:0.094160\n",
            "dice_loss:-0.875522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:191\n",
            "loss(total):-0.003315\n",
            "recons_loss:0.004299\n",
            "grad_loss:0.097462\n",
            "dice_loss:-0.858887\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:192\n",
            "loss(total):-0.003492\n",
            "recons_loss:0.004461\n",
            "grad_loss:0.084291\n",
            "dice_loss:-0.879525\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:193\n",
            "loss(total):-0.002990\n",
            "recons_loss:0.004526\n",
            "grad_loss:0.096829\n",
            "dice_loss:-0.848369\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:194\n",
            "loss(total):-0.003357\n",
            "recons_loss:0.004352\n",
            "grad_loss:0.092985\n",
            "dice_loss:-0.863905\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:195\n",
            "loss(total):-0.002640\n",
            "recons_loss:0.005319\n",
            "grad_loss:0.100440\n",
            "dice_loss:-0.896371\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:196\n",
            "loss(total):-0.003301\n",
            "recons_loss:0.004638\n",
            "grad_loss:0.093245\n",
            "dice_loss:-0.887222\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:197\n",
            "loss(total):-0.002945\n",
            "recons_loss:0.004602\n",
            "grad_loss:0.115056\n",
            "dice_loss:-0.869778\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:198\n",
            "loss(total):-0.003361\n",
            "recons_loss:0.004377\n",
            "grad_loss:0.101979\n",
            "dice_loss:-0.875795\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:199\n",
            "loss(total):-0.003226\n",
            "recons_loss:0.004542\n",
            "grad_loss:0.102411\n",
            "dice_loss:-0.879182\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:200\n",
            "loss(total):-0.004115\n",
            "recons_loss:0.003817\n",
            "grad_loss:0.075134\n",
            "dice_loss:-0.868319\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:201\n",
            "loss(total):-0.003502\n",
            "recons_loss:0.004340\n",
            "grad_loss:0.091877\n",
            "dice_loss:-0.875997\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:202\n",
            "loss(total):-0.002494\n",
            "recons_loss:0.005244\n",
            "grad_loss:0.106300\n",
            "dice_loss:-0.880087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:203\n",
            "loss(total):-0.002901\n",
            "recons_loss:0.004868\n",
            "grad_loss:0.109514\n",
            "dice_loss:-0.886340\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:204\n",
            "loss(total):-0.002569\n",
            "recons_loss:0.004971\n",
            "grad_loss:0.113577\n",
            "dice_loss:-0.867571\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:205\n",
            "loss(total):-0.003903\n",
            "recons_loss:0.004164\n",
            "grad_loss:0.082621\n",
            "dice_loss:-0.889294\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:206\n",
            "loss(total):-0.003427\n",
            "recons_loss:0.004467\n",
            "grad_loss:0.091267\n",
            "dice_loss:-0.880656\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:207\n",
            "loss(total):-0.003551\n",
            "recons_loss:0.004277\n",
            "grad_loss:0.090484\n",
            "dice_loss:-0.873247\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:208\n",
            "loss(total):-0.003952\n",
            "recons_loss:0.004168\n",
            "grad_loss:0.076098\n",
            "dice_loss:-0.888036\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:209\n",
            "loss(total):-0.002005\n",
            "recons_loss:0.005521\n",
            "grad_loss:0.112077\n",
            "dice_loss:-0.864674\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:210\n",
            "loss(total):-0.003355\n",
            "recons_loss:0.004557\n",
            "grad_loss:0.093659\n",
            "dice_loss:-0.884873\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:211\n",
            "loss(total):-0.004103\n",
            "recons_loss:0.003769\n",
            "grad_loss:0.099412\n",
            "dice_loss:-0.886641\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:212\n",
            "loss(total):-0.002295\n",
            "recons_loss:0.005424\n",
            "grad_loss:0.118407\n",
            "dice_loss:-0.890379\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:213\n",
            "loss(total):-0.004344\n",
            "recons_loss:0.003628\n",
            "grad_loss:0.091462\n",
            "dice_loss:-0.888641\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:214\n",
            "loss(total):-0.003750\n",
            "recons_loss:0.004224\n",
            "grad_loss:0.096753\n",
            "dice_loss:-0.894175\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:215\n",
            "loss(total):-0.003641\n",
            "recons_loss:0.004104\n",
            "grad_loss:0.107882\n",
            "dice_loss:-0.882378\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:216\n",
            "loss(total):-0.003211\n",
            "recons_loss:0.004717\n",
            "grad_loss:0.093903\n",
            "dice_loss:-0.886762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:217\n",
            "loss(total):-0.001920\n",
            "recons_loss:0.005680\n",
            "grad_loss:0.124694\n",
            "dice_loss:-0.884718\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:218\n",
            "loss(total):-0.003439\n",
            "recons_loss:0.004319\n",
            "grad_loss:0.111794\n",
            "dice_loss:-0.887634\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:219\n",
            "loss(total):-0.001668\n",
            "recons_loss:0.005919\n",
            "grad_loss:0.133381\n",
            "dice_loss:-0.892129\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:220\n",
            "loss(total):-0.001171\n",
            "recons_loss:0.006219\n",
            "grad_loss:0.123505\n",
            "dice_loss:-0.862459\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:221\n",
            "loss(total):-0.003020\n",
            "recons_loss:0.004708\n",
            "grad_loss:0.107547\n",
            "dice_loss:-0.880405\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:222\n",
            "loss(total):-0.003082\n",
            "recons_loss:0.004618\n",
            "grad_loss:0.100618\n",
            "dice_loss:-0.870585\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:223\n",
            "loss(total):-0.002842\n",
            "recons_loss:0.004928\n",
            "grad_loss:0.099519\n",
            "dice_loss:-0.876567\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:224\n",
            "loss(total):-0.004256\n",
            "recons_loss:0.003641\n",
            "grad_loss:0.077080\n",
            "dice_loss:-0.866767\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:225\n",
            "loss(total):-0.002282\n",
            "recons_loss:0.005308\n",
            "grad_loss:0.114550\n",
            "dice_loss:-0.873516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:226\n",
            "loss(total):-0.003252\n",
            "recons_loss:0.004441\n",
            "grad_loss:0.113334\n",
            "dice_loss:-0.882543\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:227\n",
            "loss(total):-0.003507\n",
            "recons_loss:0.004427\n",
            "grad_loss:0.083702\n",
            "dice_loss:-0.877086\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:228\n",
            "loss(total):-0.005181\n",
            "recons_loss:0.003044\n",
            "grad_loss:0.070795\n",
            "dice_loss:-0.893367\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:229\n",
            "loss(total):-0.003411\n",
            "recons_loss:0.004365\n",
            "grad_loss:0.100734\n",
            "dice_loss:-0.878327\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:230\n",
            "loss(total):-0.002305\n",
            "recons_loss:0.005432\n",
            "grad_loss:0.103842\n",
            "dice_loss:-0.877498\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:231\n",
            "loss(total):-0.003201\n",
            "recons_loss:0.004513\n",
            "grad_loss:0.107116\n",
            "dice_loss:-0.878525\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:232\n",
            "loss(total):-0.004635\n",
            "recons_loss:0.003529\n",
            "grad_loss:0.076911\n",
            "dice_loss:-0.893265\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:233\n",
            "loss(total):-0.004742\n",
            "recons_loss:0.003297\n",
            "grad_loss:0.076194\n",
            "dice_loss:-0.880144\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:234\n",
            "loss(total):-0.002705\n",
            "recons_loss:0.005085\n",
            "grad_loss:0.110499\n",
            "dice_loss:-0.889445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:235\n",
            "loss(total):-0.004657\n",
            "recons_loss:0.003452\n",
            "grad_loss:0.086966\n",
            "dice_loss:-0.897871\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:236\n",
            "loss(total):-0.000235\n",
            "recons_loss:0.007030\n",
            "grad_loss:0.150580\n",
            "dice_loss:-0.877049\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:237\n",
            "loss(total):-0.003232\n",
            "recons_loss:0.004578\n",
            "grad_loss:0.094916\n",
            "dice_loss:-0.875886\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:238\n",
            "loss(total):-0.003013\n",
            "recons_loss:0.004860\n",
            "grad_loss:0.089552\n",
            "dice_loss:-0.876853\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:239\n",
            "loss(total):-0.003539\n",
            "recons_loss:0.004420\n",
            "grad_loss:0.087449\n",
            "dice_loss:-0.883299\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:240\n",
            "loss(total):-0.003848\n",
            "recons_loss:0.004194\n",
            "grad_loss:0.089444\n",
            "dice_loss:-0.893593\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:241\n",
            "loss(total):-0.002317\n",
            "recons_loss:0.005422\n",
            "grad_loss:0.118350\n",
            "dice_loss:-0.892312\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:242\n",
            "loss(total):-0.004544\n",
            "recons_loss:0.003401\n",
            "grad_loss:0.090823\n",
            "dice_loss:-0.885315\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:243\n",
            "loss(total):-0.002918\n",
            "recons_loss:0.004891\n",
            "grad_loss:0.110435\n",
            "dice_loss:-0.891325\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:244\n",
            "loss(total):-0.003569\n",
            "recons_loss:0.004429\n",
            "grad_loss:0.102728\n",
            "dice_loss:-0.902486\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:245\n",
            "loss(total):-0.004042\n",
            "recons_loss:0.003923\n",
            "grad_loss:0.090238\n",
            "dice_loss:-0.886822\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:246\n",
            "loss(total):-0.002176\n",
            "recons_loss:0.005327\n",
            "grad_loss:0.123535\n",
            "dice_loss:-0.873745\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:247\n",
            "loss(total):-0.004553\n",
            "recons_loss:0.003503\n",
            "grad_loss:0.080303\n",
            "dice_loss:-0.885844\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:248\n",
            "loss(total):-0.002538\n",
            "recons_loss:0.005090\n",
            "grad_loss:0.096551\n",
            "dice_loss:-0.859339\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:249\n",
            "loss(total):-0.004618\n",
            "recons_loss:0.003372\n",
            "grad_loss:0.079683\n",
            "dice_loss:-0.878669\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:250\n",
            "loss(total):-0.004032\n",
            "recons_loss:0.003914\n",
            "grad_loss:0.090675\n",
            "dice_loss:-0.885217\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:251\n",
            "loss(total):-0.004812\n",
            "recons_loss:0.003341\n",
            "grad_loss:0.085659\n",
            "dice_loss:-0.901002\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:252\n",
            "loss(total):-0.004629\n",
            "recons_loss:0.003561\n",
            "grad_loss:0.088945\n",
            "dice_loss:-0.907859\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:253\n",
            "loss(total):-0.002667\n",
            "recons_loss:0.004926\n",
            "grad_loss:0.113238\n",
            "dice_loss:-0.872474\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:254\n",
            "loss(total):-0.003391\n",
            "recons_loss:0.004607\n",
            "grad_loss:0.082578\n",
            "dice_loss:-0.882374\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:255\n",
            "loss(total):-0.004501\n",
            "recons_loss:0.003581\n",
            "grad_loss:0.067766\n",
            "dice_loss:-0.875950\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:256\n",
            "loss(total):-0.003654\n",
            "recons_loss:0.004440\n",
            "grad_loss:0.081048\n",
            "dice_loss:-0.890525\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:257\n",
            "loss(total):-0.003440\n",
            "recons_loss:0.004459\n",
            "grad_loss:0.093666\n",
            "dice_loss:-0.883539\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:258\n",
            "loss(total):-0.002710\n",
            "recons_loss:0.004788\n",
            "grad_loss:0.116764\n",
            "dice_loss:-0.866567\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:259\n",
            "loss(total):-0.003480\n",
            "recons_loss:0.004604\n",
            "grad_loss:0.084417\n",
            "dice_loss:-0.892829\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:260\n",
            "loss(total):-0.002216\n",
            "recons_loss:0.005608\n",
            "grad_loss:0.099310\n",
            "dice_loss:-0.881690\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:261\n",
            "loss(total):-0.003333\n",
            "recons_loss:0.004452\n",
            "grad_loss:0.097407\n",
            "dice_loss:-0.875858\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:262\n",
            "loss(total):-0.002716\n",
            "recons_loss:0.005098\n",
            "grad_loss:0.108790\n",
            "dice_loss:-0.890148\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:263\n",
            "loss(total):-0.003558\n",
            "recons_loss:0.004304\n",
            "grad_loss:0.090814\n",
            "dice_loss:-0.876962\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:264\n",
            "loss(total):-0.004733\n",
            "recons_loss:0.003637\n",
            "grad_loss:0.063459\n",
            "dice_loss:-0.900448\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:265\n",
            "loss(total):-0.001134\n",
            "recons_loss:0.006282\n",
            "grad_loss:0.146969\n",
            "dice_loss:-0.888518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:266\n",
            "loss(total):-0.003023\n",
            "recons_loss:0.004656\n",
            "grad_loss:0.111116\n",
            "dice_loss:-0.879048\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:267\n",
            "loss(total):-0.005015\n",
            "recons_loss:0.003088\n",
            "grad_loss:0.078666\n",
            "dice_loss:-0.888984\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:268\n",
            "loss(total):-0.003338\n",
            "recons_loss:0.004405\n",
            "grad_loss:0.094487\n",
            "dice_loss:-0.868809\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:269\n",
            "loss(total):-0.002287\n",
            "recons_loss:0.005563\n",
            "grad_loss:0.097857\n",
            "dice_loss:-0.882879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:0\n",
            "loss(total):-0.003474\n",
            "recons_loss:0.004452\n",
            "grad_loss:0.097368\n",
            "dice_loss:-0.889937\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:1\n",
            "loss(total):-0.001965\n",
            "recons_loss:0.005581\n",
            "grad_loss:0.121201\n",
            "dice_loss:-0.875831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:2\n",
            "loss(total):-0.003817\n",
            "recons_loss:0.004133\n",
            "grad_loss:0.102703\n",
            "dice_loss:-0.897726\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:3\n",
            "loss(total):-0.004682\n",
            "recons_loss:0.003323\n",
            "grad_loss:0.085839\n",
            "dice_loss:-0.886347\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:4\n",
            "loss(total):-0.003313\n",
            "recons_loss:0.004707\n",
            "grad_loss:0.086165\n",
            "dice_loss:-0.888169\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:5\n",
            "loss(total):-0.003194\n",
            "recons_loss:0.004696\n",
            "grad_loss:0.096256\n",
            "dice_loss:-0.885237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:6\n",
            "loss(total):-0.002496\n",
            "recons_loss:0.005353\n",
            "grad_loss:0.104108\n",
            "dice_loss:-0.888936\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:7\n",
            "loss(total):-0.004076\n",
            "recons_loss:0.003885\n",
            "grad_loss:0.100135\n",
            "dice_loss:-0.896251\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:8\n",
            "loss(total):-0.003447\n",
            "recons_loss:0.004340\n",
            "grad_loss:0.110075\n",
            "dice_loss:-0.888829\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:9\n",
            "loss(total):-0.004432\n",
            "recons_loss:0.003875\n",
            "grad_loss:0.066077\n",
            "dice_loss:-0.896768\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:10\n",
            "loss(total):-0.003853\n",
            "recons_loss:0.004095\n",
            "grad_loss:0.087191\n",
            "dice_loss:-0.882008\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:11\n",
            "loss(total):-0.002324\n",
            "recons_loss:0.005249\n",
            "grad_loss:0.116178\n",
            "dice_loss:-0.873532\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:12\n",
            "loss(total):-0.003352\n",
            "recons_loss:0.004567\n",
            "grad_loss:0.086586\n",
            "dice_loss:-0.878577\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:13\n",
            "loss(total):-0.003781\n",
            "recons_loss:0.004145\n",
            "grad_loss:0.083707\n",
            "dice_loss:-0.876310\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:14\n",
            "loss(total):-0.002718\n",
            "recons_loss:0.005213\n",
            "grad_loss:0.085369\n",
            "dice_loss:-0.878445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:15\n",
            "loss(total):-0.005169\n",
            "recons_loss:0.003032\n",
            "grad_loss:0.074622\n",
            "dice_loss:-0.894687\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:16\n",
            "loss(total):-0.002792\n",
            "recons_loss:0.004988\n",
            "grad_loss:0.110332\n",
            "dice_loss:-0.888382\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:17\n",
            "loss(total):-0.004748\n",
            "recons_loss:0.003510\n",
            "grad_loss:0.074402\n",
            "dice_loss:-0.900217\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:18\n",
            "loss(total):-0.003527\n",
            "recons_loss:0.004341\n",
            "grad_loss:0.093142\n",
            "dice_loss:-0.879991\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:19\n",
            "loss(total):-0.003468\n",
            "recons_loss:0.004456\n",
            "grad_loss:0.099839\n",
            "dice_loss:-0.892288\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:20\n",
            "loss(total):-0.002809\n",
            "recons_loss:0.004911\n",
            "grad_loss:0.094276\n",
            "dice_loss:-0.866295\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:21\n",
            "loss(total):-0.002309\n",
            "recons_loss:0.005301\n",
            "grad_loss:0.117540\n",
            "dice_loss:-0.878510\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:22\n",
            "loss(total):-0.004869\n",
            "recons_loss:0.003209\n",
            "grad_loss:0.084602\n",
            "dice_loss:-0.892432\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:23\n",
            "loss(total):-0.003109\n",
            "recons_loss:0.004799\n",
            "grad_loss:0.103091\n",
            "dice_loss:-0.893822\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:24\n",
            "loss(total):-0.002054\n",
            "recons_loss:0.005319\n",
            "grad_loss:0.125810\n",
            "dice_loss:-0.863132\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:25\n",
            "loss(total):-0.002874\n",
            "recons_loss:0.004811\n",
            "grad_loss:0.104242\n",
            "dice_loss:-0.872758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:26\n",
            "loss(total):-0.004518\n",
            "recons_loss:0.003602\n",
            "grad_loss:0.075583\n",
            "dice_loss:-0.887577\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:27\n",
            "loss(total):-0.003996\n",
            "recons_loss:0.004017\n",
            "grad_loss:0.098973\n",
            "dice_loss:-0.900357\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:28\n",
            "loss(total):-0.003733\n",
            "recons_loss:0.004173\n",
            "grad_loss:0.094737\n",
            "dice_loss:-0.885343\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:29\n",
            "loss(total):-0.003925\n",
            "recons_loss:0.004092\n",
            "grad_loss:0.089875\n",
            "dice_loss:-0.891581\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:30\n",
            "loss(total):-0.003859\n",
            "recons_loss:0.004113\n",
            "grad_loss:0.083626\n",
            "dice_loss:-0.880863\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:31\n",
            "loss(total):-0.002000\n",
            "recons_loss:0.005532\n",
            "grad_loss:0.118229\n",
            "dice_loss:-0.871432\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:32\n",
            "loss(total):-0.001689\n",
            "recons_loss:0.005791\n",
            "grad_loss:0.123154\n",
            "dice_loss:-0.871141\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:33\n",
            "loss(total):-0.002818\n",
            "recons_loss:0.005102\n",
            "grad_loss:0.091917\n",
            "dice_loss:-0.883851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:34\n",
            "loss(total):-0.000984\n",
            "recons_loss:0.006424\n",
            "grad_loss:0.132024\n",
            "dice_loss:-0.872792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:35\n",
            "loss(total):-0.003211\n",
            "recons_loss:0.004774\n",
            "grad_loss:0.087726\n",
            "dice_loss:-0.886237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:36\n",
            "loss(total):-0.003070\n",
            "recons_loss:0.004810\n",
            "grad_loss:0.087362\n",
            "dice_loss:-0.875451\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:37\n",
            "loss(total):-0.002947\n",
            "recons_loss:0.004980\n",
            "grad_loss:0.108804\n",
            "dice_loss:-0.901514\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:38\n",
            "loss(total):-0.002231\n",
            "recons_loss:0.005133\n",
            "grad_loss:0.120613\n",
            "dice_loss:-0.856937\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:39\n",
            "loss(total):-0.003624\n",
            "recons_loss:0.004382\n",
            "grad_loss:0.086607\n",
            "dice_loss:-0.887190\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:40\n",
            "loss(total):-0.003712\n",
            "recons_loss:0.004152\n",
            "grad_loss:0.079402\n",
            "dice_loss:-0.865792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:41\n",
            "loss(total):-0.003214\n",
            "recons_loss:0.004690\n",
            "grad_loss:0.098291\n",
            "dice_loss:-0.888740\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:42\n",
            "loss(total):-0.003485\n",
            "recons_loss:0.004365\n",
            "grad_loss:0.093307\n",
            "dice_loss:-0.878261\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:43\n",
            "loss(total):-0.003846\n",
            "recons_loss:0.004000\n",
            "grad_loss:0.103876\n",
            "dice_loss:-0.888428\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:44\n",
            "loss(total):-0.002580\n",
            "recons_loss:0.005054\n",
            "grad_loss:0.134694\n",
            "dice_loss:-0.898041\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:45\n",
            "loss(total):-0.002755\n",
            "recons_loss:0.005069\n",
            "grad_loss:0.106438\n",
            "dice_loss:-0.888778\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:46\n",
            "loss(total):-0.003267\n",
            "recons_loss:0.004538\n",
            "grad_loss:0.097045\n",
            "dice_loss:-0.877492\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:47\n",
            "loss(total):-0.003602\n",
            "recons_loss:0.004365\n",
            "grad_loss:0.087971\n",
            "dice_loss:-0.884719\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:48\n",
            "loss(total):-0.002359\n",
            "recons_loss:0.005331\n",
            "grad_loss:0.109987\n",
            "dice_loss:-0.879000\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:49\n",
            "loss(total):-0.004441\n",
            "recons_loss:0.003550\n",
            "grad_loss:0.084669\n",
            "dice_loss:-0.883810\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:50\n",
            "loss(total):-0.003048\n",
            "recons_loss:0.004727\n",
            "grad_loss:0.100789\n",
            "dice_loss:-0.878282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:51\n",
            "loss(total):-0.004201\n",
            "recons_loss:0.003672\n",
            "grad_loss:0.095180\n",
            "dice_loss:-0.882434\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:52\n",
            "loss(total):-0.004181\n",
            "recons_loss:0.003761\n",
            "grad_loss:0.091210\n",
            "dice_loss:-0.885473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:53\n",
            "loss(total):-0.002803\n",
            "recons_loss:0.004744\n",
            "grad_loss:0.132834\n",
            "dice_loss:-0.887559\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:54\n",
            "loss(total):-0.003487\n",
            "recons_loss:0.004485\n",
            "grad_loss:0.096690\n",
            "dice_loss:-0.893948\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:55\n",
            "loss(total):-0.003634\n",
            "recons_loss:0.004368\n",
            "grad_loss:0.096167\n",
            "dice_loss:-0.896434\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:56\n",
            "loss(total):-0.003792\n",
            "recons_loss:0.004046\n",
            "grad_loss:0.098745\n",
            "dice_loss:-0.882548\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:57\n",
            "loss(total):-0.004706\n",
            "recons_loss:0.003262\n",
            "grad_loss:0.089085\n",
            "dice_loss:-0.885888\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:58\n",
            "loss(total):-0.003491\n",
            "recons_loss:0.004550\n",
            "grad_loss:0.089891\n",
            "dice_loss:-0.894022\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:59\n",
            "loss(total):-0.004741\n",
            "recons_loss:0.003416\n",
            "grad_loss:0.071859\n",
            "dice_loss:-0.887572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:60\n",
            "loss(total):-0.004367\n",
            "recons_loss:0.003676\n",
            "grad_loss:0.092950\n",
            "dice_loss:-0.897327\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:61\n",
            "loss(total):-0.004687\n",
            "recons_loss:0.003410\n",
            "grad_loss:0.083403\n",
            "dice_loss:-0.893160\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:62\n",
            "loss(total):-0.003035\n",
            "recons_loss:0.004751\n",
            "grad_loss:0.093365\n",
            "dice_loss:-0.871927\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:63\n",
            "loss(total):-0.003528\n",
            "recons_loss:0.004545\n",
            "grad_loss:0.087969\n",
            "dice_loss:-0.895251\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:64\n",
            "loss(total):-0.003427\n",
            "recons_loss:0.004356\n",
            "grad_loss:0.099923\n",
            "dice_loss:-0.878171\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:65\n",
            "loss(total):-0.005226\n",
            "recons_loss:0.002931\n",
            "grad_loss:0.081993\n",
            "dice_loss:-0.897644\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:66\n",
            "loss(total):-0.003823\n",
            "recons_loss:0.004259\n",
            "grad_loss:0.077442\n",
            "dice_loss:-0.885682\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:67\n",
            "loss(total):-0.004136\n",
            "recons_loss:0.003758\n",
            "grad_loss:0.105662\n",
            "dice_loss:-0.895053\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:68\n",
            "loss(total):-0.003353\n",
            "recons_loss:0.004572\n",
            "grad_loss:0.084387\n",
            "dice_loss:-0.876824\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:69\n",
            "loss(total):-0.003237\n",
            "recons_loss:0.004494\n",
            "grad_loss:0.113404\n",
            "dice_loss:-0.886499\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:70\n",
            "loss(total):-0.004226\n",
            "recons_loss:0.003735\n",
            "grad_loss:0.103257\n",
            "dice_loss:-0.899314\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:71\n",
            "loss(total):-0.003566\n",
            "recons_loss:0.004399\n",
            "grad_loss:0.088783\n",
            "dice_loss:-0.885300\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:72\n",
            "loss(total):-0.003208\n",
            "recons_loss:0.004542\n",
            "grad_loss:0.105216\n",
            "dice_loss:-0.880210\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:73\n",
            "loss(total):-0.001427\n",
            "recons_loss:0.005890\n",
            "grad_loss:0.127570\n",
            "dice_loss:-0.859303\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:74\n",
            "loss(total):-0.003535\n",
            "recons_loss:0.004298\n",
            "grad_loss:0.095477\n",
            "dice_loss:-0.878745\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:75\n",
            "loss(total):-0.005551\n",
            "recons_loss:0.002830\n",
            "grad_loss:0.063493\n",
            "dice_loss:-0.901555\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:76\n",
            "loss(total):-0.004400\n",
            "recons_loss:0.003768\n",
            "grad_loss:0.076179\n",
            "dice_loss:-0.893014\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:77\n",
            "loss(total):-0.002212\n",
            "recons_loss:0.005586\n",
            "grad_loss:0.106317\n",
            "dice_loss:-0.886168\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:78\n",
            "loss(total):-0.003522\n",
            "recons_loss:0.004375\n",
            "grad_loss:0.092165\n",
            "dice_loss:-0.881946\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:79\n",
            "loss(total):-0.001546\n",
            "recons_loss:0.005688\n",
            "grad_loss:0.130522\n",
            "dice_loss:-0.853893\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:80\n",
            "loss(total):-0.003058\n",
            "recons_loss:0.004420\n",
            "grad_loss:0.107758\n",
            "dice_loss:-0.855508\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:81\n",
            "loss(total):-0.004261\n",
            "recons_loss:0.003557\n",
            "grad_loss:0.083591\n",
            "dice_loss:-0.865419\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:82\n",
            "loss(total):-0.003144\n",
            "recons_loss:0.004621\n",
            "grad_loss:0.103762\n",
            "dice_loss:-0.880253\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:83\n",
            "loss(total):-0.003366\n",
            "recons_loss:0.004704\n",
            "grad_loss:0.093559\n",
            "dice_loss:-0.900589\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:84\n",
            "loss(total):-0.003173\n",
            "recons_loss:0.004671\n",
            "grad_loss:0.101814\n",
            "dice_loss:-0.886212\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:85\n",
            "loss(total):-0.003822\n",
            "recons_loss:0.004103\n",
            "grad_loss:0.100574\n",
            "dice_loss:-0.893061\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:86\n",
            "loss(total):-0.003113\n",
            "recons_loss:0.004607\n",
            "grad_loss:0.108714\n",
            "dice_loss:-0.880672\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:87\n",
            "loss(total):-0.003512\n",
            "recons_loss:0.004275\n",
            "grad_loss:0.099844\n",
            "dice_loss:-0.878562\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:88\n",
            "loss(total):-0.004661\n",
            "recons_loss:0.003454\n",
            "grad_loss:0.084881\n",
            "dice_loss:-0.896382\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:89\n",
            "loss(total):-0.002930\n",
            "recons_loss:0.004826\n",
            "grad_loss:0.109890\n",
            "dice_loss:-0.885438\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:90\n",
            "loss(total):-0.002931\n",
            "recons_loss:0.004769\n",
            "grad_loss:0.101796\n",
            "dice_loss:-0.871779\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:91\n",
            "loss(total):-0.003388\n",
            "recons_loss:0.004394\n",
            "grad_loss:0.096117\n",
            "dice_loss:-0.874370\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:92\n",
            "loss(total):-0.004535\n",
            "recons_loss:0.003448\n",
            "grad_loss:0.093362\n",
            "dice_loss:-0.891601\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:93\n",
            "loss(total):-0.002422\n",
            "recons_loss:0.005227\n",
            "grad_loss:0.130708\n",
            "dice_loss:-0.895605\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:94\n",
            "loss(total):-0.004669\n",
            "recons_loss:0.003346\n",
            "grad_loss:0.086229\n",
            "dice_loss:-0.887752\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:95\n",
            "loss(total):-0.004938\n",
            "recons_loss:0.003405\n",
            "grad_loss:0.061849\n",
            "dice_loss:-0.896152\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:96\n",
            "loss(total):-0.003568\n",
            "recons_loss:0.004458\n",
            "grad_loss:0.085802\n",
            "dice_loss:-0.888387\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:97\n",
            "loss(total):-0.003941\n",
            "recons_loss:0.003932\n",
            "grad_loss:0.092722\n",
            "dice_loss:-0.880056\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:98\n",
            "loss(total):-0.003194\n",
            "recons_loss:0.004587\n",
            "grad_loss:0.098741\n",
            "dice_loss:-0.876884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:99\n",
            "loss(total):-0.004950\n",
            "recons_loss:0.003234\n",
            "grad_loss:0.085914\n",
            "dice_loss:-0.904310\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:100\n",
            "loss(total):-0.004811\n",
            "recons_loss:0.003375\n",
            "grad_loss:0.071116\n",
            "dice_loss:-0.889754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:101\n",
            "loss(total):-0.002970\n",
            "recons_loss:0.004841\n",
            "grad_loss:0.104699\n",
            "dice_loss:-0.885771\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:102\n",
            "loss(total):-0.003231\n",
            "recons_loss:0.004679\n",
            "grad_loss:0.097275\n",
            "dice_loss:-0.888291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:103\n",
            "loss(total):-0.002859\n",
            "recons_loss:0.004900\n",
            "grad_loss:0.096046\n",
            "dice_loss:-0.871988\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:104\n",
            "loss(total):-0.002293\n",
            "recons_loss:0.005548\n",
            "grad_loss:0.102527\n",
            "dice_loss:-0.886630\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:105\n",
            "loss(total):-0.003982\n",
            "recons_loss:0.004054\n",
            "grad_loss:0.084834\n",
            "dice_loss:-0.888431\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:106\n",
            "loss(total):-0.002323\n",
            "recons_loss:0.005349\n",
            "grad_loss:0.111204\n",
            "dice_loss:-0.878387\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:107\n",
            "loss(total):-0.004528\n",
            "recons_loss:0.003419\n",
            "grad_loss:0.097483\n",
            "dice_loss:-0.892215\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:108\n",
            "loss(total):-0.002842\n",
            "recons_loss:0.005063\n",
            "grad_loss:0.089652\n",
            "dice_loss:-0.880136\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:109\n",
            "loss(total):-0.003911\n",
            "recons_loss:0.003984\n",
            "grad_loss:0.090090\n",
            "dice_loss:-0.879573\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:110\n",
            "loss(total):-0.003114\n",
            "recons_loss:0.004782\n",
            "grad_loss:0.091731\n",
            "dice_loss:-0.881270\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:111\n",
            "loss(total):-0.001814\n",
            "recons_loss:0.005831\n",
            "grad_loss:0.130341\n",
            "dice_loss:-0.894879\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:112\n",
            "loss(total):-0.003078\n",
            "recons_loss:0.004626\n",
            "grad_loss:0.107826\n",
            "dice_loss:-0.878249\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:113\n",
            "loss(total):-0.003354\n",
            "recons_loss:0.004354\n",
            "grad_loss:0.107514\n",
            "dice_loss:-0.878251\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:114\n",
            "loss(total):-0.004715\n",
            "recons_loss:0.003307\n",
            "grad_loss:0.077627\n",
            "dice_loss:-0.879769\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:115\n",
            "loss(total):-0.003968\n",
            "recons_loss:0.003864\n",
            "grad_loss:0.095702\n",
            "dice_loss:-0.878988\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:116\n",
            "loss(total):-0.001989\n",
            "recons_loss:0.005395\n",
            "grad_loss:0.119899\n",
            "dice_loss:-0.858301\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:117\n",
            "loss(total):-0.003336\n",
            "recons_loss:0.004484\n",
            "grad_loss:0.109445\n",
            "dice_loss:-0.891454\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:118\n",
            "loss(total):-0.003299\n",
            "recons_loss:0.004610\n",
            "grad_loss:0.098439\n",
            "dice_loss:-0.889399\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:119\n",
            "loss(total):-0.003060\n",
            "recons_loss:0.004786\n",
            "grad_loss:0.103367\n",
            "dice_loss:-0.887978\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:120\n",
            "loss(total):-0.003175\n",
            "recons_loss:0.004575\n",
            "grad_loss:0.099871\n",
            "dice_loss:-0.874800\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:121\n",
            "loss(total):-0.004223\n",
            "recons_loss:0.003866\n",
            "grad_loss:0.080311\n",
            "dice_loss:-0.889254\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:122\n",
            "loss(total):-0.004560\n",
            "recons_loss:0.003494\n",
            "grad_loss:0.075717\n",
            "dice_loss:-0.881148\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:123\n",
            "loss(total):-0.003525\n",
            "recons_loss:0.004315\n",
            "grad_loss:0.091412\n",
            "dice_loss:-0.875483\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:124\n",
            "loss(total):-0.001432\n",
            "recons_loss:0.006140\n",
            "grad_loss:0.119433\n",
            "dice_loss:-0.876570\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:125\n",
            "loss(total):-0.002913\n",
            "recons_loss:0.004788\n",
            "grad_loss:0.106382\n",
            "dice_loss:-0.876450\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:126\n",
            "loss(total):-0.003215\n",
            "recons_loss:0.004604\n",
            "grad_loss:0.108813\n",
            "dice_loss:-0.890711\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:127\n",
            "loss(total):-0.004207\n",
            "recons_loss:0.003820\n",
            "grad_loss:0.086022\n",
            "dice_loss:-0.888733\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:128\n",
            "loss(total):-0.001869\n",
            "recons_loss:0.005954\n",
            "grad_loss:0.103502\n",
            "dice_loss:-0.885849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:129\n",
            "loss(total):-0.003774\n",
            "recons_loss:0.004241\n",
            "grad_loss:0.092566\n",
            "dice_loss:-0.894043\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:130\n",
            "loss(total):-0.003464\n",
            "recons_loss:0.004340\n",
            "grad_loss:0.092528\n",
            "dice_loss:-0.872884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:131\n",
            "loss(total):-0.003449\n",
            "recons_loss:0.004302\n",
            "grad_loss:0.096379\n",
            "dice_loss:-0.871436\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:132\n",
            "loss(total):-0.003085\n",
            "recons_loss:0.004351\n",
            "grad_loss:0.124077\n",
            "dice_loss:-0.867740\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:133\n",
            "loss(total):-0.003764\n",
            "recons_loss:0.004338\n",
            "grad_loss:0.086138\n",
            "dice_loss:-0.896324\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:134\n",
            "loss(total):-0.002227\n",
            "recons_loss:0.005407\n",
            "grad_loss:0.118180\n",
            "dice_loss:-0.881627\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:135\n",
            "loss(total):-0.004484\n",
            "recons_loss:0.003487\n",
            "grad_loss:0.092613\n",
            "dice_loss:-0.889681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:136\n",
            "loss(total):-0.003458\n",
            "recons_loss:0.004258\n",
            "grad_loss:0.106756\n",
            "dice_loss:-0.878390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:137\n",
            "loss(total):-0.002469\n",
            "recons_loss:0.005054\n",
            "grad_loss:0.118456\n",
            "dice_loss:-0.870739\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:138\n",
            "loss(total):-0.002714\n",
            "recons_loss:0.004874\n",
            "grad_loss:0.109881\n",
            "dice_loss:-0.868756\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:139\n",
            "loss(total):-0.004178\n",
            "recons_loss:0.003752\n",
            "grad_loss:0.082516\n",
            "dice_loss:-0.875556\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:140\n",
            "loss(total):-0.004509\n",
            "recons_loss:0.003479\n",
            "grad_loss:0.078648\n",
            "dice_loss:-0.877454\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:141\n",
            "loss(total):-0.003805\n",
            "recons_loss:0.004154\n",
            "grad_loss:0.096107\n",
            "dice_loss:-0.891982\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:142\n",
            "loss(total):-0.000974\n",
            "recons_loss:0.006617\n",
            "grad_loss:0.122786\n",
            "dice_loss:-0.881841\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:143\n",
            "loss(total):-0.004445\n",
            "recons_loss:0.003591\n",
            "grad_loss:0.097930\n",
            "dice_loss:-0.901582\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:144\n",
            "loss(total):-0.003281\n",
            "recons_loss:0.004506\n",
            "grad_loss:0.103246\n",
            "dice_loss:-0.881970\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:145\n",
            "loss(total):-0.003036\n",
            "recons_loss:0.004985\n",
            "grad_loss:0.085673\n",
            "dice_loss:-0.887723\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:146\n",
            "loss(total):-0.004091\n",
            "recons_loss:0.003803\n",
            "grad_loss:0.092830\n",
            "dice_loss:-0.882190\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:147\n",
            "loss(total):-0.004993\n",
            "recons_loss:0.003120\n",
            "grad_loss:0.076336\n",
            "dice_loss:-0.887673\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:148\n",
            "loss(total):-0.004200\n",
            "recons_loss:0.003765\n",
            "grad_loss:0.089204\n",
            "dice_loss:-0.885698\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:149\n",
            "loss(total):-0.003459\n",
            "recons_loss:0.004390\n",
            "grad_loss:0.105064\n",
            "dice_loss:-0.889918\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:150\n",
            "loss(total):-0.004612\n",
            "recons_loss:0.003604\n",
            "grad_loss:0.070350\n",
            "dice_loss:-0.891963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:151\n",
            "loss(total):-0.001830\n",
            "recons_loss:0.005821\n",
            "grad_loss:0.119968\n",
            "dice_loss:-0.885054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:152\n",
            "loss(total):-0.003205\n",
            "recons_loss:0.004615\n",
            "grad_loss:0.106244\n",
            "dice_loss:-0.888316\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:153\n",
            "loss(total):-0.003848\n",
            "recons_loss:0.004194\n",
            "grad_loss:0.088722\n",
            "dice_loss:-0.892928\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:154\n",
            "loss(total):-0.002251\n",
            "recons_loss:0.005422\n",
            "grad_loss:0.127210\n",
            "dice_loss:-0.894539\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:155\n",
            "loss(total):-0.003251\n",
            "recons_loss:0.004570\n",
            "grad_loss:0.104772\n",
            "dice_loss:-0.886883\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:156\n",
            "loss(total):-0.003697\n",
            "recons_loss:0.004108\n",
            "grad_loss:0.093041\n",
            "dice_loss:-0.873517\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:157\n",
            "loss(total):-0.003410\n",
            "recons_loss:0.004439\n",
            "grad_loss:0.090470\n",
            "dice_loss:-0.875306\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:158\n",
            "loss(total):-0.003079\n",
            "recons_loss:0.004672\n",
            "grad_loss:0.104974\n",
            "dice_loss:-0.880028\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:159\n",
            "loss(total):-0.001607\n",
            "recons_loss:0.005903\n",
            "grad_loss:0.117697\n",
            "dice_loss:-0.868634\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:160\n",
            "loss(total):-0.003349\n",
            "recons_loss:0.004339\n",
            "grad_loss:0.093869\n",
            "dice_loss:-0.862763\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:161\n",
            "loss(total):-0.003587\n",
            "recons_loss:0.004278\n",
            "grad_loss:0.111079\n",
            "dice_loss:-0.897620\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:162\n",
            "loss(total):-0.003917\n",
            "recons_loss:0.004034\n",
            "grad_loss:0.090465\n",
            "dice_loss:-0.885571\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:163\n",
            "loss(total):-0.002535\n",
            "recons_loss:0.005081\n",
            "grad_loss:0.115812\n",
            "dice_loss:-0.877462\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:164\n",
            "loss(total):-0.003238\n",
            "recons_loss:0.004668\n",
            "grad_loss:0.083773\n",
            "dice_loss:-0.874439\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:165\n",
            "loss(total):-0.002007\n",
            "recons_loss:0.005897\n",
            "grad_loss:0.097219\n",
            "dice_loss:-0.887657\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:166\n",
            "loss(total):-0.004354\n",
            "recons_loss:0.003690\n",
            "grad_loss:0.080934\n",
            "dice_loss:-0.885290\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:167\n",
            "loss(total):-0.004894\n",
            "recons_loss:0.003298\n",
            "grad_loss:0.071573\n",
            "dice_loss:-0.890835\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:168\n",
            "loss(total):-0.003274\n",
            "recons_loss:0.004387\n",
            "grad_loss:0.105428\n",
            "dice_loss:-0.871535\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:169\n",
            "loss(total):-0.004593\n",
            "recons_loss:0.003438\n",
            "grad_loss:0.089832\n",
            "dice_loss:-0.892936\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:170\n",
            "loss(total):-0.003143\n",
            "recons_loss:0.004575\n",
            "grad_loss:0.102280\n",
            "dice_loss:-0.874152\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:171\n",
            "loss(total):-0.003127\n",
            "recons_loss:0.004718\n",
            "grad_loss:0.096294\n",
            "dice_loss:-0.880787\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:172\n",
            "loss(total):-0.002173\n",
            "recons_loss:0.005505\n",
            "grad_loss:0.117969\n",
            "dice_loss:-0.885745\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:173\n",
            "loss(total):-0.002441\n",
            "recons_loss:0.005181\n",
            "grad_loss:0.111297\n",
            "dice_loss:-0.873509\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:174\n",
            "loss(total):-0.004142\n",
            "recons_loss:0.003928\n",
            "grad_loss:0.081557\n",
            "dice_loss:-0.888560\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:175\n",
            "loss(total):-0.005372\n",
            "recons_loss:0.002829\n",
            "grad_loss:0.078832\n",
            "dice_loss:-0.898925\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:176\n",
            "loss(total):-0.003742\n",
            "recons_loss:0.004281\n",
            "grad_loss:0.087739\n",
            "dice_loss:-0.890077\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:177\n",
            "loss(total):-0.003424\n",
            "recons_loss:0.004542\n",
            "grad_loss:0.096036\n",
            "dice_loss:-0.892604\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:178\n",
            "loss(total):-0.003259\n",
            "recons_loss:0.004386\n",
            "grad_loss:0.099015\n",
            "dice_loss:-0.863567\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:179\n",
            "loss(total):-0.003113\n",
            "recons_loss:0.004560\n",
            "grad_loss:0.111379\n",
            "dice_loss:-0.878627\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:180\n",
            "loss(total):-0.003966\n",
            "recons_loss:0.003918\n",
            "grad_loss:0.095907\n",
            "dice_loss:-0.884270\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:181\n",
            "loss(total):-0.003328\n",
            "recons_loss:0.004448\n",
            "grad_loss:0.095339\n",
            "dice_loss:-0.873009\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:182\n",
            "loss(total):-0.003242\n",
            "recons_loss:0.004404\n",
            "grad_loss:0.110552\n",
            "dice_loss:-0.875165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:183\n",
            "loss(total):-0.004047\n",
            "recons_loss:0.004034\n",
            "grad_loss:0.088205\n",
            "dice_loss:-0.896293\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:184\n",
            "loss(total):-0.003920\n",
            "recons_loss:0.004095\n",
            "grad_loss:0.084602\n",
            "dice_loss:-0.886157\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:185\n",
            "loss(total):-0.004172\n",
            "recons_loss:0.003842\n",
            "grad_loss:0.092908\n",
            "dice_loss:-0.894231\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:186\n",
            "loss(total):-0.002814\n",
            "recons_loss:0.004892\n",
            "grad_loss:0.114432\n",
            "dice_loss:-0.884960\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:187\n",
            "loss(total):-0.003612\n",
            "recons_loss:0.004217\n",
            "grad_loss:0.104794\n",
            "dice_loss:-0.887687\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:188\n",
            "loss(total):-0.002874\n",
            "recons_loss:0.004850\n",
            "grad_loss:0.112902\n",
            "dice_loss:-0.885378\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:189\n",
            "loss(total):-0.001888\n",
            "recons_loss:0.005604\n",
            "grad_loss:0.123934\n",
            "dice_loss:-0.873101\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:190\n",
            "loss(total):-0.003766\n",
            "recons_loss:0.004253\n",
            "grad_loss:0.091641\n",
            "dice_loss:-0.893509\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:191\n",
            "loss(total):-0.001389\n",
            "recons_loss:0.005968\n",
            "grad_loss:0.143812\n",
            "dice_loss:-0.879532\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:192\n",
            "loss(total):-0.003916\n",
            "recons_loss:0.004094\n",
            "grad_loss:0.098065\n",
            "dice_loss:-0.899122\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:193\n",
            "loss(total):-0.004448\n",
            "recons_loss:0.003509\n",
            "grad_loss:0.086614\n",
            "dice_loss:-0.882240\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:194\n",
            "loss(total):-0.001430\n",
            "recons_loss:0.006080\n",
            "grad_loss:0.122936\n",
            "dice_loss:-0.873934\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:195\n",
            "loss(total):-0.003114\n",
            "recons_loss:0.004673\n",
            "grad_loss:0.108817\n",
            "dice_loss:-0.887480\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:196\n",
            "loss(total):-0.002627\n",
            "recons_loss:0.005064\n",
            "grad_loss:0.106794\n",
            "dice_loss:-0.875862\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:197\n",
            "loss(total):-0.001748\n",
            "recons_loss:0.005759\n",
            "grad_loss:0.128953\n",
            "dice_loss:-0.879619\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:198\n",
            "loss(total):-0.002729\n",
            "recons_loss:0.004890\n",
            "grad_loss:0.111914\n",
            "dice_loss:-0.873840\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:199\n",
            "loss(total):-0.004184\n",
            "recons_loss:0.003887\n",
            "grad_loss:0.082161\n",
            "dice_loss:-0.889235\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:200\n",
            "loss(total):-0.002189\n",
            "recons_loss:0.005260\n",
            "grad_loss:0.118046\n",
            "dice_loss:-0.862973\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:201\n",
            "loss(total):-0.002693\n",
            "recons_loss:0.005091\n",
            "grad_loss:0.103691\n",
            "dice_loss:-0.882078\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:202\n",
            "loss(total):-0.003712\n",
            "recons_loss:0.004109\n",
            "grad_loss:0.097211\n",
            "dice_loss:-0.879359\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:203\n",
            "loss(total):-0.004163\n",
            "recons_loss:0.004083\n",
            "grad_loss:0.078653\n",
            "dice_loss:-0.903271\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:204\n",
            "loss(total):-0.003366\n",
            "recons_loss:0.004467\n",
            "grad_loss:0.109707\n",
            "dice_loss:-0.892989\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:205\n",
            "loss(total):-0.003600\n",
            "recons_loss:0.004407\n",
            "grad_loss:0.096181\n",
            "dice_loss:-0.896920\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:206\n",
            "loss(total):-0.004023\n",
            "recons_loss:0.004084\n",
            "grad_loss:0.089629\n",
            "dice_loss:-0.900276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:207\n",
            "loss(total):-0.003445\n",
            "recons_loss:0.004540\n",
            "grad_loss:0.092262\n",
            "dice_loss:-0.890729\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:208\n",
            "loss(total):-0.003375\n",
            "recons_loss:0.004425\n",
            "grad_loss:0.097445\n",
            "dice_loss:-0.877462\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:209\n",
            "loss(total):-0.004877\n",
            "recons_loss:0.003201\n",
            "grad_loss:0.093421\n",
            "dice_loss:-0.901274\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:210\n",
            "loss(total):-0.003366\n",
            "recons_loss:0.004412\n",
            "grad_loss:0.094858\n",
            "dice_loss:-0.872663\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:211\n",
            "loss(total):-0.002568\n",
            "recons_loss:0.004940\n",
            "grad_loss:0.106377\n",
            "dice_loss:-0.857173\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:212\n",
            "loss(total):-0.003659\n",
            "recons_loss:0.004186\n",
            "grad_loss:0.097524\n",
            "dice_loss:-0.882020\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:213\n",
            "loss(total):-0.002239\n",
            "recons_loss:0.005383\n",
            "grad_loss:0.118424\n",
            "dice_loss:-0.880637\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:214\n",
            "loss(total):-0.001859\n",
            "recons_loss:0.005703\n",
            "grad_loss:0.115584\n",
            "dice_loss:-0.871801\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:215\n",
            "loss(total):-0.004250\n",
            "recons_loss:0.003718\n",
            "grad_loss:0.093190\n",
            "dice_loss:-0.889950\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:216\n",
            "loss(total):-0.003502\n",
            "recons_loss:0.004359\n",
            "grad_loss:0.094123\n",
            "dice_loss:-0.880253\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:217\n",
            "loss(total):-0.002379\n",
            "recons_loss:0.005248\n",
            "grad_loss:0.118399\n",
            "dice_loss:-0.881084\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:218\n",
            "loss(total):-0.004464\n",
            "recons_loss:0.003512\n",
            "grad_loss:0.095859\n",
            "dice_loss:-0.893453\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:219\n",
            "loss(total):-0.002393\n",
            "recons_loss:0.005328\n",
            "grad_loss:0.121606\n",
            "dice_loss:-0.893704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:220\n",
            "loss(total):-0.004007\n",
            "recons_loss:0.003869\n",
            "grad_loss:0.082604\n",
            "dice_loss:-0.870173\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:221\n",
            "loss(total):-0.002883\n",
            "recons_loss:0.004862\n",
            "grad_loss:0.116649\n",
            "dice_loss:-0.891184\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:222\n",
            "loss(total):-0.004008\n",
            "recons_loss:0.004120\n",
            "grad_loss:0.074886\n",
            "dice_loss:-0.887651\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:223\n",
            "loss(total):-0.003370\n",
            "recons_loss:0.004538\n",
            "grad_loss:0.092444\n",
            "dice_loss:-0.883298\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:224\n",
            "loss(total):-0.002647\n",
            "recons_loss:0.005212\n",
            "grad_loss:0.102168\n",
            "dice_loss:-0.888094\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:225\n",
            "loss(total):-0.003117\n",
            "recons_loss:0.004756\n",
            "grad_loss:0.090223\n",
            "dice_loss:-0.877486\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:226\n",
            "loss(total):-0.002890\n",
            "recons_loss:0.004912\n",
            "grad_loss:0.102796\n",
            "dice_loss:-0.883045\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:227\n",
            "loss(total):-0.002873\n",
            "recons_loss:0.004715\n",
            "grad_loss:0.107181\n",
            "dice_loss:-0.866021\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:228\n",
            "loss(total):-0.003556\n",
            "recons_loss:0.004024\n",
            "grad_loss:0.114683\n",
            "dice_loss:-0.872762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:229\n",
            "loss(total):-0.003334\n",
            "recons_loss:0.004469\n",
            "grad_loss:0.096596\n",
            "dice_loss:-0.876934\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:230\n",
            "loss(total):-0.004351\n",
            "recons_loss:0.003711\n",
            "grad_loss:0.083466\n",
            "dice_loss:-0.889636\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:231\n",
            "loss(total):-0.003348\n",
            "recons_loss:0.004701\n",
            "grad_loss:0.097290\n",
            "dice_loss:-0.902189\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:232\n",
            "loss(total):-0.003386\n",
            "recons_loss:0.004312\n",
            "grad_loss:0.099209\n",
            "dice_loss:-0.868980\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:233\n",
            "loss(total):-0.002753\n",
            "recons_loss:0.005126\n",
            "grad_loss:0.102315\n",
            "dice_loss:-0.890237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:234\n",
            "loss(total):-0.003037\n",
            "recons_loss:0.004652\n",
            "grad_loss:0.108052\n",
            "dice_loss:-0.876936\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:235\n",
            "loss(total):-0.002594\n",
            "recons_loss:0.004954\n",
            "grad_loss:0.110309\n",
            "dice_loss:-0.865150\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:236\n",
            "loss(total):-0.003407\n",
            "recons_loss:0.004446\n",
            "grad_loss:0.095922\n",
            "dice_loss:-0.881291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:237\n",
            "loss(total):-0.003885\n",
            "recons_loss:0.004120\n",
            "grad_loss:0.088264\n",
            "dice_loss:-0.888729\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:238\n",
            "loss(total):-0.003908\n",
            "recons_loss:0.004156\n",
            "grad_loss:0.082574\n",
            "dice_loss:-0.888954\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:239\n",
            "loss(total):-0.004704\n",
            "recons_loss:0.003320\n",
            "grad_loss:0.094065\n",
            "dice_loss:-0.896424\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:240\n",
            "loss(total):-0.004294\n",
            "recons_loss:0.003916\n",
            "grad_loss:0.078307\n",
            "dice_loss:-0.899238\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:241\n",
            "loss(total):-0.003937\n",
            "recons_loss:0.003949\n",
            "grad_loss:0.097102\n",
            "dice_loss:-0.885732\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:242\n",
            "loss(total):-0.003636\n",
            "recons_loss:0.004169\n",
            "grad_loss:0.095538\n",
            "dice_loss:-0.876044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:243\n",
            "loss(total):-0.003019\n",
            "recons_loss:0.004632\n",
            "grad_loss:0.122725\n",
            "dice_loss:-0.887843\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:244\n",
            "loss(total):-0.004844\n",
            "recons_loss:0.003572\n",
            "grad_loss:0.062084\n",
            "dice_loss:-0.903684\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:245\n",
            "loss(total):-0.003891\n",
            "recons_loss:0.004012\n",
            "grad_loss:0.086896\n",
            "dice_loss:-0.877266\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:246\n",
            "loss(total):-0.002364\n",
            "recons_loss:0.005209\n",
            "grad_loss:0.122799\n",
            "dice_loss:-0.880152\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:247\n",
            "loss(total):-0.002305\n",
            "recons_loss:0.005208\n",
            "grad_loss:0.119074\n",
            "dice_loss:-0.870408\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:248\n",
            "loss(total):-0.004130\n",
            "recons_loss:0.003801\n",
            "grad_loss:0.091998\n",
            "dice_loss:-0.885075\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:249\n",
            "loss(total):-0.004316\n",
            "recons_loss:0.003696\n",
            "grad_loss:0.086792\n",
            "dice_loss:-0.888056\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:250\n",
            "loss(total):-0.003307\n",
            "recons_loss:0.004537\n",
            "grad_loss:0.103804\n",
            "dice_loss:-0.888156\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:251\n",
            "loss(total):-0.003909\n",
            "recons_loss:0.003997\n",
            "grad_loss:0.092725\n",
            "dice_loss:-0.883395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:252\n",
            "loss(total):-0.003985\n",
            "recons_loss:0.003734\n",
            "grad_loss:0.085637\n",
            "dice_loss:-0.857556\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:253\n",
            "loss(total):-0.004112\n",
            "recons_loss:0.003858\n",
            "grad_loss:0.101205\n",
            "dice_loss:-0.898217\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:254\n",
            "loss(total):-0.004602\n",
            "recons_loss:0.003503\n",
            "grad_loss:0.087671\n",
            "dice_loss:-0.898146\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:255\n",
            "loss(total):-0.003606\n",
            "recons_loss:0.004710\n",
            "grad_loss:0.074357\n",
            "dice_loss:-0.905965\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:256\n",
            "loss(total):-0.004236\n",
            "recons_loss:0.003684\n",
            "grad_loss:0.090545\n",
            "dice_loss:-0.882519\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:257\n",
            "loss(total):-0.003239\n",
            "recons_loss:0.004612\n",
            "grad_loss:0.101008\n",
            "dice_loss:-0.886112\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:258\n",
            "loss(total):-0.004116\n",
            "recons_loss:0.003898\n",
            "grad_loss:0.088273\n",
            "dice_loss:-0.889700\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:259\n",
            "loss(total):-0.003376\n",
            "recons_loss:0.004671\n",
            "grad_loss:0.087152\n",
            "dice_loss:-0.891866\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:260\n",
            "loss(total):-0.005146\n",
            "recons_loss:0.003256\n",
            "grad_loss:0.063486\n",
            "dice_loss:-0.903758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:261\n",
            "loss(total):-0.002347\n",
            "recons_loss:0.005323\n",
            "grad_loss:0.118452\n",
            "dice_loss:-0.885404\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:262\n",
            "loss(total):-0.002663\n",
            "recons_loss:0.004834\n",
            "grad_loss:0.113424\n",
            "dice_loss:-0.863159\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:263\n",
            "loss(total):-0.002549\n",
            "recons_loss:0.005049\n",
            "grad_loss:0.110473\n",
            "dice_loss:-0.870290\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:264\n",
            "loss(total):-0.004024\n",
            "recons_loss:0.003907\n",
            "grad_loss:0.083644\n",
            "dice_loss:-0.876805\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:265\n",
            "loss(total):-0.003998\n",
            "recons_loss:0.003766\n",
            "grad_loss:0.097491\n",
            "dice_loss:-0.873836\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:266\n",
            "loss(total):-0.003962\n",
            "recons_loss:0.004111\n",
            "grad_loss:0.084581\n",
            "dice_loss:-0.891809\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:267\n",
            "loss(total):-0.002931\n",
            "recons_loss:0.004903\n",
            "grad_loss:0.109073\n",
            "dice_loss:-0.892480\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:268\n",
            "loss(total):-0.004776\n",
            "recons_loss:0.003417\n",
            "grad_loss:0.076904\n",
            "dice_loss:-0.896207\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:269\n",
            "loss(total):-0.003303\n",
            "recons_loss:0.004500\n",
            "grad_loss:0.094861\n",
            "dice_loss:-0.875139\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:0\n",
            "loss(total):-0.003428\n",
            "recons_loss:0.004173\n",
            "grad_loss:0.101367\n",
            "dice_loss:-0.861494\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:1\n",
            "loss(total):-0.002892\n",
            "recons_loss:0.004939\n",
            "grad_loss:0.113853\n",
            "dice_loss:-0.896970\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:2\n",
            "loss(total):-0.004688\n",
            "recons_loss:0.003564\n",
            "grad_loss:0.082328\n",
            "dice_loss:-0.907518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:3\n",
            "loss(total):-0.002395\n",
            "recons_loss:0.005460\n",
            "grad_loss:0.108579\n",
            "dice_loss:-0.894057\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:4\n",
            "loss(total):-0.005289\n",
            "recons_loss:0.002995\n",
            "grad_loss:0.068504\n",
            "dice_loss:-0.896900\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:5\n",
            "loss(total):-0.004139\n",
            "recons_loss:0.003974\n",
            "grad_loss:0.084134\n",
            "dice_loss:-0.895374\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:6\n",
            "loss(total):-0.004763\n",
            "recons_loss:0.003366\n",
            "grad_loss:0.073417\n",
            "dice_loss:-0.886371\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:7\n",
            "loss(total):-0.003269\n",
            "recons_loss:0.004582\n",
            "grad_loss:0.100446\n",
            "dice_loss:-0.885471\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:8\n",
            "loss(total):-0.004303\n",
            "recons_loss:0.003871\n",
            "grad_loss:0.085437\n",
            "dice_loss:-0.902823\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:9\n",
            "loss(total):-0.002917\n",
            "recons_loss:0.004736\n",
            "grad_loss:0.113829\n",
            "dice_loss:-0.879106\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:10\n",
            "loss(total):-0.003018\n",
            "recons_loss:0.004699\n",
            "grad_loss:0.106883\n",
            "dice_loss:-0.878650\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:11\n",
            "loss(total):-0.002756\n",
            "recons_loss:0.004827\n",
            "grad_loss:0.102145\n",
            "dice_loss:-0.860415\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:12\n",
            "loss(total):-0.004264\n",
            "recons_loss:0.003650\n",
            "grad_loss:0.089959\n",
            "dice_loss:-0.881307\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:13\n",
            "loss(total):-0.001576\n",
            "recons_loss:0.005991\n",
            "grad_loss:0.133057\n",
            "dice_loss:-0.889732\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:14\n",
            "loss(total):-0.002630\n",
            "recons_loss:0.005054\n",
            "grad_loss:0.108965\n",
            "dice_loss:-0.877424\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:15\n",
            "loss(total):-0.003256\n",
            "recons_loss:0.004532\n",
            "grad_loss:0.103304\n",
            "dice_loss:-0.882034\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:16\n",
            "loss(total):-0.003932\n",
            "recons_loss:0.004041\n",
            "grad_loss:0.085208\n",
            "dice_loss:-0.882546\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:17\n",
            "loss(total):-0.004004\n",
            "recons_loss:0.004080\n",
            "grad_loss:0.085577\n",
            "dice_loss:-0.893962\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:18\n",
            "loss(total):-0.004100\n",
            "recons_loss:0.003727\n",
            "grad_loss:0.091247\n",
            "dice_loss:-0.873904\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:19\n",
            "loss(total):-0.003731\n",
            "recons_loss:0.004275\n",
            "grad_loss:0.093610\n",
            "dice_loss:-0.894181\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:20\n",
            "loss(total):-0.003038\n",
            "recons_loss:0.004780\n",
            "grad_loss:0.101380\n",
            "dice_loss:-0.883185\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:21\n",
            "loss(total):-0.002566\n",
            "recons_loss:0.005234\n",
            "grad_loss:0.110440\n",
            "dice_loss:-0.890449\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:22\n",
            "loss(total):-0.003220\n",
            "recons_loss:0.004546\n",
            "grad_loss:0.105977\n",
            "dice_loss:-0.882560\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:23\n",
            "loss(total):-0.004311\n",
            "recons_loss:0.003634\n",
            "grad_loss:0.097962\n",
            "dice_loss:-0.892500\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:24\n",
            "loss(total):-0.001737\n",
            "recons_loss:0.005776\n",
            "grad_loss:0.126414\n",
            "dice_loss:-0.877716\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:25\n",
            "loss(total):-0.002714\n",
            "recons_loss:0.004909\n",
            "grad_loss:0.108688\n",
            "dice_loss:-0.871023\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:26\n",
            "loss(total):-0.003461\n",
            "recons_loss:0.004452\n",
            "grad_loss:0.103826\n",
            "dice_loss:-0.895153\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:27\n",
            "loss(total):-0.002594\n",
            "recons_loss:0.005231\n",
            "grad_loss:0.097802\n",
            "dice_loss:-0.880335\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:28\n",
            "loss(total):-0.002987\n",
            "recons_loss:0.004905\n",
            "grad_loss:0.108159\n",
            "dice_loss:-0.897344\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:29\n",
            "loss(total):-0.005178\n",
            "recons_loss:0.003052\n",
            "grad_loss:0.075781\n",
            "dice_loss:-0.898742\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:30\n",
            "loss(total):-0.002660\n",
            "recons_loss:0.004962\n",
            "grad_loss:0.119251\n",
            "dice_loss:-0.881414\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:31\n",
            "loss(total):-0.003899\n",
            "recons_loss:0.003931\n",
            "grad_loss:0.096900\n",
            "dice_loss:-0.879940\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:32\n",
            "loss(total):-0.003073\n",
            "recons_loss:0.004761\n",
            "grad_loss:0.104527\n",
            "dice_loss:-0.887932\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:33\n",
            "loss(total):-0.003194\n",
            "recons_loss:0.004638\n",
            "grad_loss:0.104171\n",
            "dice_loss:-0.887352\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:34\n",
            "loss(total):-0.004119\n",
            "recons_loss:0.003949\n",
            "grad_loss:0.082465\n",
            "dice_loss:-0.889291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:35\n",
            "loss(total):-0.003763\n",
            "recons_loss:0.004197\n",
            "grad_loss:0.089664\n",
            "dice_loss:-0.885681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:36\n",
            "loss(total):-0.002107\n",
            "recons_loss:0.005520\n",
            "grad_loss:0.111489\n",
            "dice_loss:-0.874183\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:37\n",
            "loss(total):-0.005654\n",
            "recons_loss:0.002864\n",
            "grad_loss:0.059142\n",
            "dice_loss:-0.910970\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:38\n",
            "loss(total):-0.003309\n",
            "recons_loss:0.004350\n",
            "grad_loss:0.100193\n",
            "dice_loss:-0.866044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:39\n",
            "loss(total):-0.003086\n",
            "recons_loss:0.004686\n",
            "grad_loss:0.104435\n",
            "dice_loss:-0.881626\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:40\n",
            "loss(total):-0.004280\n",
            "recons_loss:0.003813\n",
            "grad_loss:0.084573\n",
            "dice_loss:-0.893869\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:41\n",
            "loss(total):-0.003148\n",
            "recons_loss:0.004670\n",
            "grad_loss:0.100768\n",
            "dice_loss:-0.882639\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:42\n",
            "loss(total):-0.001921\n",
            "recons_loss:0.005462\n",
            "grad_loss:0.121233\n",
            "dice_loss:-0.859525\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:43\n",
            "loss(total):-0.004193\n",
            "recons_loss:0.003771\n",
            "grad_loss:0.087972\n",
            "dice_loss:-0.884396\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:44\n",
            "loss(total):-0.003920\n",
            "recons_loss:0.004057\n",
            "grad_loss:0.088553\n",
            "dice_loss:-0.886212\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:45\n",
            "loss(total):-0.003282\n",
            "recons_loss:0.004799\n",
            "grad_loss:0.095160\n",
            "dice_loss:-0.903242\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:46\n",
            "loss(total):-0.003925\n",
            "recons_loss:0.003850\n",
            "grad_loss:0.104605\n",
            "dice_loss:-0.882111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:47\n",
            "loss(total):-0.003641\n",
            "recons_loss:0.004178\n",
            "grad_loss:0.102867\n",
            "dice_loss:-0.884831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:48\n",
            "loss(total):-0.004341\n",
            "recons_loss:0.003819\n",
            "grad_loss:0.084851\n",
            "dice_loss:-0.900824\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:49\n",
            "loss(total):-0.003287\n",
            "recons_loss:0.004700\n",
            "grad_loss:0.087819\n",
            "dice_loss:-0.886491\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:50\n",
            "loss(total):-0.004076\n",
            "recons_loss:0.003954\n",
            "grad_loss:0.086152\n",
            "dice_loss:-0.889158\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:51\n",
            "loss(total):-0.002870\n",
            "recons_loss:0.004707\n",
            "grad_loss:0.098201\n",
            "dice_loss:-0.855954\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:52\n",
            "loss(total):-0.002288\n",
            "recons_loss:0.005179\n",
            "grad_loss:0.120524\n",
            "dice_loss:-0.867261\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:53\n",
            "loss(total):-0.002841\n",
            "recons_loss:0.004838\n",
            "grad_loss:0.101110\n",
            "dice_loss:-0.869042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:54\n",
            "loss(total):-0.003052\n",
            "recons_loss:0.004666\n",
            "grad_loss:0.109017\n",
            "dice_loss:-0.880764\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:55\n",
            "loss(total):-0.004283\n",
            "recons_loss:0.003871\n",
            "grad_loss:0.088983\n",
            "dice_loss:-0.904370\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:56\n",
            "loss(total):-0.004239\n",
            "recons_loss:0.003816\n",
            "grad_loss:0.069070\n",
            "dice_loss:-0.874521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:57\n",
            "loss(total):-0.003196\n",
            "recons_loss:0.004363\n",
            "grad_loss:0.093668\n",
            "dice_loss:-0.849597\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:58\n",
            "loss(total):-0.003036\n",
            "recons_loss:0.004657\n",
            "grad_loss:0.107608\n",
            "dice_loss:-0.876944\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:59\n",
            "loss(total):-0.002844\n",
            "recons_loss:0.004710\n",
            "grad_loss:0.119665\n",
            "dice_loss:-0.875105\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:60\n",
            "loss(total):-0.003762\n",
            "recons_loss:0.004140\n",
            "grad_loss:0.091431\n",
            "dice_loss:-0.881644\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:61\n",
            "loss(total):-0.002821\n",
            "recons_loss:0.005150\n",
            "grad_loss:0.099591\n",
            "dice_loss:-0.896691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:62\n",
            "loss(total):-0.002529\n",
            "recons_loss:0.005327\n",
            "grad_loss:0.102376\n",
            "dice_loss:-0.887979\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:63\n",
            "loss(total):-0.005563\n",
            "recons_loss:0.002613\n",
            "grad_loss:0.072970\n",
            "dice_loss:-0.890497\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:64\n",
            "loss(total):-0.004327\n",
            "recons_loss:0.003677\n",
            "grad_loss:0.096824\n",
            "dice_loss:-0.897298\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:65\n",
            "loss(total):-0.005328\n",
            "recons_loss:0.002888\n",
            "grad_loss:0.083095\n",
            "dice_loss:-0.904711\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:66\n",
            "loss(total):-0.002080\n",
            "recons_loss:0.005467\n",
            "grad_loss:0.116149\n",
            "dice_loss:-0.870851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:67\n",
            "loss(total):-0.003375\n",
            "recons_loss:0.004665\n",
            "grad_loss:0.088731\n",
            "dice_loss:-0.892754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:68\n",
            "loss(total):-0.003485\n",
            "recons_loss:0.004374\n",
            "grad_loss:0.098228\n",
            "dice_loss:-0.884194\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:69\n",
            "loss(total):-0.001806\n",
            "recons_loss:0.005476\n",
            "grad_loss:0.131185\n",
            "dice_loss:-0.859395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:70\n",
            "loss(total):-0.003020\n",
            "recons_loss:0.004597\n",
            "grad_loss:0.110652\n",
            "dice_loss:-0.872344\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:71\n",
            "loss(total):-0.003507\n",
            "recons_loss:0.004252\n",
            "grad_loss:0.107494\n",
            "dice_loss:-0.883425\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:72\n",
            "loss(total):-0.003467\n",
            "recons_loss:0.004231\n",
            "grad_loss:0.113265\n",
            "dice_loss:-0.883053\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:73\n",
            "loss(total):-0.002979\n",
            "recons_loss:0.004737\n",
            "grad_loss:0.113820\n",
            "dice_loss:-0.885441\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:74\n",
            "loss(total):-0.002717\n",
            "recons_loss:0.005088\n",
            "grad_loss:0.100451\n",
            "dice_loss:-0.880857\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:75\n",
            "loss(total):-0.002787\n",
            "recons_loss:0.005122\n",
            "grad_loss:0.099658\n",
            "dice_loss:-0.890572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:76\n",
            "loss(total):-0.003527\n",
            "recons_loss:0.004277\n",
            "grad_loss:0.103216\n",
            "dice_loss:-0.883580\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:77\n",
            "loss(total):-0.004529\n",
            "recons_loss:0.003498\n",
            "grad_loss:0.083698\n",
            "dice_loss:-0.886406\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:78\n",
            "loss(total):-0.002537\n",
            "recons_loss:0.005154\n",
            "grad_loss:0.113896\n",
            "dice_loss:-0.883088\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:79\n",
            "loss(total):-0.003873\n",
            "recons_loss:0.003897\n",
            "grad_loss:0.094339\n",
            "dice_loss:-0.871417\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:80\n",
            "loss(total):-0.003564\n",
            "recons_loss:0.004211\n",
            "grad_loss:0.100152\n",
            "dice_loss:-0.877651\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:81\n",
            "loss(total):-0.002969\n",
            "recons_loss:0.004720\n",
            "grad_loss:0.109025\n",
            "dice_loss:-0.877984\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:82\n",
            "loss(total):-0.003661\n",
            "recons_loss:0.004546\n",
            "grad_loss:0.085182\n",
            "dice_loss:-0.905946\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:83\n",
            "loss(total):-0.003724\n",
            "recons_loss:0.004149\n",
            "grad_loss:0.093703\n",
            "dice_loss:-0.881044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:84\n",
            "loss(total):-0.003015\n",
            "recons_loss:0.004730\n",
            "grad_loss:0.116407\n",
            "dice_loss:-0.890969\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:85\n",
            "loss(total):-0.004429\n",
            "recons_loss:0.003819\n",
            "grad_loss:0.084520\n",
            "dice_loss:-0.909304\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:86\n",
            "loss(total):-0.003127\n",
            "recons_loss:0.004594\n",
            "grad_loss:0.110077\n",
            "dice_loss:-0.882141\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:87\n",
            "loss(total):-0.003152\n",
            "recons_loss:0.004613\n",
            "grad_loss:0.105125\n",
            "dice_loss:-0.881611\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:88\n",
            "loss(total):-0.003238\n",
            "recons_loss:0.004399\n",
            "grad_loss:0.104541\n",
            "dice_loss:-0.868165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:89\n",
            "loss(total):-0.002785\n",
            "recons_loss:0.004907\n",
            "grad_loss:0.104129\n",
            "dice_loss:-0.873317\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:90\n",
            "loss(total):-0.004302\n",
            "recons_loss:0.003635\n",
            "grad_loss:0.094825\n",
            "dice_loss:-0.888530\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:91\n",
            "loss(total):-0.003401\n",
            "recons_loss:0.004284\n",
            "grad_loss:0.097046\n",
            "dice_loss:-0.865560\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:92\n",
            "loss(total):-0.003701\n",
            "recons_loss:0.004183\n",
            "grad_loss:0.096082\n",
            "dice_loss:-0.884460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:93\n",
            "loss(total):-0.004064\n",
            "recons_loss:0.003848\n",
            "grad_loss:0.104819\n",
            "dice_loss:-0.896057\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:94\n",
            "loss(total):-0.002909\n",
            "recons_loss:0.004814\n",
            "grad_loss:0.109559\n",
            "dice_loss:-0.881904\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:95\n",
            "loss(total):-0.004989\n",
            "recons_loss:0.003115\n",
            "grad_loss:0.083838\n",
            "dice_loss:-0.894244\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:96\n",
            "loss(total):-0.003641\n",
            "recons_loss:0.004279\n",
            "grad_loss:0.104861\n",
            "dice_loss:-0.896813\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:97\n",
            "loss(total):-0.002932\n",
            "recons_loss:0.004800\n",
            "grad_loss:0.113864\n",
            "dice_loss:-0.887094\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:98\n",
            "loss(total):-0.004726\n",
            "recons_loss:0.003354\n",
            "grad_loss:0.085428\n",
            "dice_loss:-0.893504\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:99\n",
            "loss(total):-0.003791\n",
            "recons_loss:0.004126\n",
            "grad_loss:0.098304\n",
            "dice_loss:-0.890008\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:100\n",
            "loss(total):-0.004836\n",
            "recons_loss:0.003258\n",
            "grad_loss:0.081572\n",
            "dice_loss:-0.891052\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:101\n",
            "loss(total):-0.004780\n",
            "recons_loss:0.003409\n",
            "grad_loss:0.069949\n",
            "dice_loss:-0.888881\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:102\n",
            "loss(total):-0.003403\n",
            "recons_loss:0.004145\n",
            "grad_loss:0.092465\n",
            "dice_loss:-0.847198\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:103\n",
            "loss(total):-0.003249\n",
            "recons_loss:0.004640\n",
            "grad_loss:0.094714\n",
            "dice_loss:-0.883584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:104\n",
            "loss(total):-0.004803\n",
            "recons_loss:0.003414\n",
            "grad_loss:0.064889\n",
            "dice_loss:-0.886567\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:105\n",
            "loss(total):-0.002791\n",
            "recons_loss:0.004855\n",
            "grad_loss:0.114948\n",
            "dice_loss:-0.879523\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:106\n",
            "loss(total):-0.002070\n",
            "recons_loss:0.005549\n",
            "grad_loss:0.121177\n",
            "dice_loss:-0.883048\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:107\n",
            "loss(total):-0.003324\n",
            "recons_loss:0.004493\n",
            "grad_loss:0.104973\n",
            "dice_loss:-0.886670\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:108\n",
            "loss(total):-0.004314\n",
            "recons_loss:0.003881\n",
            "grad_loss:0.072513\n",
            "dice_loss:-0.891992\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:109\n",
            "loss(total):-0.004225\n",
            "recons_loss:0.003736\n",
            "grad_loss:0.083962\n",
            "dice_loss:-0.880156\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:110\n",
            "loss(total):-0.002835\n",
            "recons_loss:0.004980\n",
            "grad_loss:0.106573\n",
            "dice_loss:-0.888170\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:111\n",
            "loss(total):-0.003272\n",
            "recons_loss:0.004697\n",
            "grad_loss:0.091617\n",
            "dice_loss:-0.888507\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:112\n",
            "loss(total):-0.003021\n",
            "recons_loss:0.004681\n",
            "grad_loss:0.120119\n",
            "dice_loss:-0.890316\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:113\n",
            "loss(total):-0.001655\n",
            "recons_loss:0.006025\n",
            "grad_loss:0.127504\n",
            "dice_loss:-0.895505\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:114\n",
            "loss(total):-0.003980\n",
            "recons_loss:0.004189\n",
            "grad_loss:0.082818\n",
            "dice_loss:-0.899775\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:115\n",
            "loss(total):-0.003003\n",
            "recons_loss:0.004936\n",
            "grad_loss:0.094261\n",
            "dice_loss:-0.888135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:116\n",
            "loss(total):-0.004168\n",
            "recons_loss:0.003724\n",
            "grad_loss:0.097476\n",
            "dice_loss:-0.886685\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:117\n",
            "loss(total):-0.003562\n",
            "recons_loss:0.004254\n",
            "grad_loss:0.100754\n",
            "dice_loss:-0.882323\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:118\n",
            "loss(total):-0.004346\n",
            "recons_loss:0.003602\n",
            "grad_loss:0.085193\n",
            "dice_loss:-0.879966\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:119\n",
            "loss(total):-0.004014\n",
            "recons_loss:0.003950\n",
            "grad_loss:0.085580\n",
            "dice_loss:-0.881998\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:120\n",
            "loss(total):-0.004617\n",
            "recons_loss:0.003529\n",
            "grad_loss:0.083936\n",
            "dice_loss:-0.898458\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:121\n",
            "loss(total):-0.002128\n",
            "recons_loss:0.005725\n",
            "grad_loss:0.105326\n",
            "dice_loss:-0.890689\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:122\n",
            "loss(total):-0.004128\n",
            "recons_loss:0.003987\n",
            "grad_loss:0.081955\n",
            "dice_loss:-0.893524\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:123\n",
            "loss(total):-0.003267\n",
            "recons_loss:0.004412\n",
            "grad_loss:0.110261\n",
            "dice_loss:-0.878234\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:124\n",
            "loss(total):-0.004596\n",
            "recons_loss:0.003427\n",
            "grad_loss:0.083104\n",
            "dice_loss:-0.885440\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:125\n",
            "loss(total):-0.004181\n",
            "recons_loss:0.003965\n",
            "grad_loss:0.075860\n",
            "dice_loss:-0.890471\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:126\n",
            "loss(total):-0.003048\n",
            "recons_loss:0.004844\n",
            "grad_loss:0.090217\n",
            "dice_loss:-0.879364\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:127\n",
            "loss(total):-0.002897\n",
            "recons_loss:0.004782\n",
            "grad_loss:0.113888\n",
            "dice_loss:-0.881755\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:128\n",
            "loss(total):-0.002717\n",
            "recons_loss:0.004959\n",
            "grad_loss:0.103220\n",
            "dice_loss:-0.870799\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:129\n",
            "loss(total):-0.004443\n",
            "recons_loss:0.003610\n",
            "grad_loss:0.090971\n",
            "dice_loss:-0.896253\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:130\n",
            "loss(total):-0.001882\n",
            "recons_loss:0.005655\n",
            "grad_loss:0.129663\n",
            "dice_loss:-0.883427\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:131\n",
            "loss(total):-0.004468\n",
            "recons_loss:0.003475\n",
            "grad_loss:0.090025\n",
            "dice_loss:-0.884377\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:132\n",
            "loss(total):-0.002560\n",
            "recons_loss:0.004956\n",
            "grad_loss:0.123419\n",
            "dice_loss:-0.874978\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:133\n",
            "loss(total):-0.003164\n",
            "recons_loss:0.004797\n",
            "grad_loss:0.097056\n",
            "dice_loss:-0.893126\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:134\n",
            "loss(total):-0.003598\n",
            "recons_loss:0.004435\n",
            "grad_loss:0.088815\n",
            "dice_loss:-0.892065\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:135\n",
            "loss(total):-0.003448\n",
            "recons_loss:0.004443\n",
            "grad_loss:0.106376\n",
            "dice_loss:-0.895482\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:136\n",
            "loss(total):-0.002278\n",
            "recons_loss:0.005473\n",
            "grad_loss:0.114118\n",
            "dice_loss:-0.889237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:137\n",
            "loss(total):-0.003760\n",
            "recons_loss:0.004099\n",
            "grad_loss:0.089956\n",
            "dice_loss:-0.875880\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:138\n",
            "loss(total):-0.002288\n",
            "recons_loss:0.005192\n",
            "grad_loss:0.112184\n",
            "dice_loss:-0.860217\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:139\n",
            "loss(total):-0.003423\n",
            "recons_loss:0.004376\n",
            "grad_loss:0.093691\n",
            "dice_loss:-0.873622\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:140\n",
            "loss(total):-0.003488\n",
            "recons_loss:0.004488\n",
            "grad_loss:0.086058\n",
            "dice_loss:-0.883662\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:141\n",
            "loss(total):-0.003229\n",
            "recons_loss:0.004673\n",
            "grad_loss:0.082222\n",
            "dice_loss:-0.872401\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:142\n",
            "loss(total):-0.002393\n",
            "recons_loss:0.005160\n",
            "grad_loss:0.100326\n",
            "dice_loss:-0.855610\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:143\n",
            "loss(total):-0.001287\n",
            "recons_loss:0.006204\n",
            "grad_loss:0.138856\n",
            "dice_loss:-0.887916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:144\n",
            "loss(total):-0.003961\n",
            "recons_loss:0.003909\n",
            "grad_loss:0.090660\n",
            "dice_loss:-0.877580\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:145\n",
            "loss(total):-0.003508\n",
            "recons_loss:0.004490\n",
            "grad_loss:0.088137\n",
            "dice_loss:-0.887921\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:146\n",
            "loss(total):-0.004206\n",
            "recons_loss:0.003933\n",
            "grad_loss:0.080903\n",
            "dice_loss:-0.894811\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:147\n",
            "loss(total):-0.003233\n",
            "recons_loss:0.004770\n",
            "grad_loss:0.098561\n",
            "dice_loss:-0.898848\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:148\n",
            "loss(total):-0.002765\n",
            "recons_loss:0.004967\n",
            "grad_loss:0.121885\n",
            "dice_loss:-0.895060\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:149\n",
            "loss(total):-0.002709\n",
            "recons_loss:0.005033\n",
            "grad_loss:0.106866\n",
            "dice_loss:-0.881053\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:150\n",
            "loss(total):-0.004563\n",
            "recons_loss:0.003377\n",
            "grad_loss:0.085173\n",
            "dice_loss:-0.879214\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:151\n",
            "loss(total):-0.003321\n",
            "recons_loss:0.004196\n",
            "grad_loss:0.101251\n",
            "dice_loss:-0.852975\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:152\n",
            "loss(total):-0.003791\n",
            "recons_loss:0.004044\n",
            "grad_loss:0.096148\n",
            "dice_loss:-0.879735\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:153\n",
            "loss(total):-0.002265\n",
            "recons_loss:0.005193\n",
            "grad_loss:0.119990\n",
            "dice_loss:-0.865838\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:154\n",
            "loss(total):-0.003960\n",
            "recons_loss:0.004036\n",
            "grad_loss:0.086130\n",
            "dice_loss:-0.885700\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:155\n",
            "loss(total):-0.003575\n",
            "recons_loss:0.004320\n",
            "grad_loss:0.094504\n",
            "dice_loss:-0.884043\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:156\n",
            "loss(total):-0.002482\n",
            "recons_loss:0.005109\n",
            "grad_loss:0.107653\n",
            "dice_loss:-0.866702\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:157\n",
            "loss(total):-0.001059\n",
            "recons_loss:0.006339\n",
            "grad_loss:0.126393\n",
            "dice_loss:-0.866172\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:158\n",
            "loss(total):-0.004005\n",
            "recons_loss:0.003942\n",
            "grad_loss:0.078465\n",
            "dice_loss:-0.873160\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:159\n",
            "loss(total):-0.002372\n",
            "recons_loss:0.005435\n",
            "grad_loss:0.100983\n",
            "dice_loss:-0.881721\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:160\n",
            "loss(total):-0.003839\n",
            "recons_loss:0.003897\n",
            "grad_loss:0.101180\n",
            "dice_loss:-0.874805\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:161\n",
            "loss(total):-0.004668\n",
            "recons_loss:0.003410\n",
            "grad_loss:0.083059\n",
            "dice_loss:-0.890893\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:162\n",
            "loss(total):-0.004455\n",
            "recons_loss:0.003565\n",
            "grad_loss:0.085220\n",
            "dice_loss:-0.887174\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:163\n",
            "loss(total):-0.003900\n",
            "recons_loss:0.003984\n",
            "grad_loss:0.097125\n",
            "dice_loss:-0.885444\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:164\n",
            "loss(total):-0.003998\n",
            "recons_loss:0.004038\n",
            "grad_loss:0.084224\n",
            "dice_loss:-0.887839\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:165\n",
            "loss(total):-0.003282\n",
            "recons_loss:0.004516\n",
            "grad_loss:0.111930\n",
            "dice_loss:-0.891708\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:166\n",
            "loss(total):-0.002571\n",
            "recons_loss:0.005173\n",
            "grad_loss:0.090794\n",
            "dice_loss:-0.865172\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:167\n",
            "loss(total):-0.004453\n",
            "recons_loss:0.003527\n",
            "grad_loss:0.094044\n",
            "dice_loss:-0.892072\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:168\n",
            "loss(total):-0.003894\n",
            "recons_loss:0.004157\n",
            "grad_loss:0.091299\n",
            "dice_loss:-0.896462\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:169\n",
            "loss(total):-0.004622\n",
            "recons_loss:0.003538\n",
            "grad_loss:0.086976\n",
            "dice_loss:-0.902982\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:170\n",
            "loss(total):-0.003570\n",
            "recons_loss:0.004305\n",
            "grad_loss:0.090590\n",
            "dice_loss:-0.878035\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:171\n",
            "loss(total):-0.003562\n",
            "recons_loss:0.004217\n",
            "grad_loss:0.084251\n",
            "dice_loss:-0.862119\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:172\n",
            "loss(total):-0.002847\n",
            "recons_loss:0.004751\n",
            "grad_loss:0.118449\n",
            "dice_loss:-0.878264\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:173\n",
            "loss(total):-0.002785\n",
            "recons_loss:0.005114\n",
            "grad_loss:0.107860\n",
            "dice_loss:-0.897691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:174\n",
            "loss(total):-0.003186\n",
            "recons_loss:0.004727\n",
            "grad_loss:0.108041\n",
            "dice_loss:-0.899384\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:175\n",
            "loss(total):-0.004628\n",
            "recons_loss:0.003325\n",
            "grad_loss:0.097117\n",
            "dice_loss:-0.892384\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:176\n",
            "loss(total):-0.003066\n",
            "recons_loss:0.004593\n",
            "grad_loss:0.100061\n",
            "dice_loss:-0.865969\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:177\n",
            "loss(total):-0.004155\n",
            "recons_loss:0.003446\n",
            "grad_loss:0.101970\n",
            "dice_loss:-0.862039\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:178\n",
            "loss(total):-0.004862\n",
            "recons_loss:0.003105\n",
            "grad_loss:0.097303\n",
            "dice_loss:-0.894084\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:179\n",
            "loss(total):-0.003174\n",
            "recons_loss:0.004803\n",
            "grad_loss:0.084137\n",
            "dice_loss:-0.881909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:180\n",
            "loss(total):-0.003723\n",
            "recons_loss:0.004306\n",
            "grad_loss:0.088317\n",
            "dice_loss:-0.891160\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:181\n",
            "loss(total):-0.005071\n",
            "recons_loss:0.003147\n",
            "grad_loss:0.073370\n",
            "dice_loss:-0.895240\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:182\n",
            "loss(total):-0.002652\n",
            "recons_loss:0.005145\n",
            "grad_loss:0.098702\n",
            "dice_loss:-0.878338\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:183\n",
            "loss(total):-0.003046\n",
            "recons_loss:0.004722\n",
            "grad_loss:0.104850\n",
            "dice_loss:-0.881638\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:184\n",
            "loss(total):-0.002938\n",
            "recons_loss:0.004876\n",
            "grad_loss:0.110222\n",
            "dice_loss:-0.891559\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:185\n",
            "loss(total):-0.003895\n",
            "recons_loss:0.004080\n",
            "grad_loss:0.085661\n",
            "dice_loss:-0.883140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:186\n",
            "loss(total):-0.004167\n",
            "recons_loss:0.003652\n",
            "grad_loss:0.091432\n",
            "dice_loss:-0.873267\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:187\n",
            "loss(total):-0.004041\n",
            "recons_loss:0.003645\n",
            "grad_loss:0.096596\n",
            "dice_loss:-0.865158\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:188\n",
            "loss(total):-0.001883\n",
            "recons_loss:0.005551\n",
            "grad_loss:0.136117\n",
            "dice_loss:-0.879572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:189\n",
            "loss(total):-0.004286\n",
            "recons_loss:0.003454\n",
            "grad_loss:0.097815\n",
            "dice_loss:-0.871845\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:190\n",
            "loss(total):-0.002302\n",
            "recons_loss:0.005321\n",
            "grad_loss:0.105928\n",
            "dice_loss:-0.868257\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:191\n",
            "loss(total):-0.003807\n",
            "recons_loss:0.004150\n",
            "grad_loss:0.075150\n",
            "dice_loss:-0.870831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:192\n",
            "loss(total):-0.003446\n",
            "recons_loss:0.004590\n",
            "grad_loss:0.091857\n",
            "dice_loss:-0.895504\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:193\n",
            "loss(total):-0.003884\n",
            "recons_loss:0.004063\n",
            "grad_loss:0.089131\n",
            "dice_loss:-0.883847\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:194\n",
            "loss(total):-0.003372\n",
            "recons_loss:0.004380\n",
            "grad_loss:0.113766\n",
            "dice_loss:-0.888955\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:195\n",
            "loss(total):-0.002950\n",
            "recons_loss:0.004764\n",
            "grad_loss:0.109371\n",
            "dice_loss:-0.880691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:196\n",
            "loss(total):-0.003266\n",
            "recons_loss:0.004724\n",
            "grad_loss:0.087993\n",
            "dice_loss:-0.886950\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:197\n",
            "loss(total):-0.004175\n",
            "recons_loss:0.003725\n",
            "grad_loss:0.090126\n",
            "dice_loss:-0.880069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:198\n",
            "loss(total):-0.003479\n",
            "recons_loss:0.004342\n",
            "grad_loss:0.091638\n",
            "dice_loss:-0.873706\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:199\n",
            "loss(total):-0.003395\n",
            "recons_loss:0.004628\n",
            "grad_loss:0.096493\n",
            "dice_loss:-0.898868\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:200\n",
            "loss(total):-0.003614\n",
            "recons_loss:0.004160\n",
            "grad_loss:0.101399\n",
            "dice_loss:-0.878769\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:201\n",
            "loss(total):-0.003358\n",
            "recons_loss:0.004579\n",
            "grad_loss:0.097065\n",
            "dice_loss:-0.890740\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:202\n",
            "loss(total):-0.003424\n",
            "recons_loss:0.004459\n",
            "grad_loss:0.094689\n",
            "dice_loss:-0.882923\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:203\n",
            "loss(total):-0.002634\n",
            "recons_loss:0.005123\n",
            "grad_loss:0.105117\n",
            "dice_loss:-0.880832\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:204\n",
            "loss(total):-0.003533\n",
            "recons_loss:0.004341\n",
            "grad_loss:0.088898\n",
            "dice_loss:-0.876245\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:205\n",
            "loss(total):-0.004397\n",
            "recons_loss:0.003512\n",
            "grad_loss:0.092856\n",
            "dice_loss:-0.883736\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:206\n",
            "loss(total):-0.003330\n",
            "recons_loss:0.004622\n",
            "grad_loss:0.106849\n",
            "dice_loss:-0.901964\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:207\n",
            "loss(total):-0.003180\n",
            "recons_loss:0.004643\n",
            "grad_loss:0.102310\n",
            "dice_loss:-0.884655\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:208\n",
            "loss(total):-0.002850\n",
            "recons_loss:0.005029\n",
            "grad_loss:0.099294\n",
            "dice_loss:-0.887175\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:209\n",
            "loss(total):-0.003406\n",
            "recons_loss:0.004528\n",
            "grad_loss:0.104281\n",
            "dice_loss:-0.897681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:210\n",
            "loss(total):-0.004130\n",
            "recons_loss:0.004076\n",
            "grad_loss:0.072341\n",
            "dice_loss:-0.893003\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:211\n",
            "loss(total):-0.002928\n",
            "recons_loss:0.004852\n",
            "grad_loss:0.101062\n",
            "dice_loss:-0.879036\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:212\n",
            "loss(total):-0.002869\n",
            "recons_loss:0.004854\n",
            "grad_loss:0.097039\n",
            "dice_loss:-0.869352\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:213\n",
            "loss(total):-0.003677\n",
            "recons_loss:0.004310\n",
            "grad_loss:0.094563\n",
            "dice_loss:-0.893235\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:214\n",
            "loss(total):-0.002951\n",
            "recons_loss:0.004955\n",
            "grad_loss:0.099803\n",
            "dice_loss:-0.890394\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:215\n",
            "loss(total):-0.003620\n",
            "recons_loss:0.004404\n",
            "grad_loss:0.094275\n",
            "dice_loss:-0.896601\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:216\n",
            "loss(total):-0.003729\n",
            "recons_loss:0.004201\n",
            "grad_loss:0.085548\n",
            "dice_loss:-0.878542\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:217\n",
            "loss(total):-0.003142\n",
            "recons_loss:0.004897\n",
            "grad_loss:0.093294\n",
            "dice_loss:-0.897179\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:218\n",
            "loss(total):-0.003523\n",
            "recons_loss:0.004462\n",
            "grad_loss:0.085159\n",
            "dice_loss:-0.883697\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:219\n",
            "loss(total):-0.003230\n",
            "recons_loss:0.004643\n",
            "grad_loss:0.103007\n",
            "dice_loss:-0.890380\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:220\n",
            "loss(total):-0.002312\n",
            "recons_loss:0.005250\n",
            "grad_loss:0.124937\n",
            "dice_loss:-0.881111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:221\n",
            "loss(total):-0.002118\n",
            "recons_loss:0.005285\n",
            "grad_loss:0.124941\n",
            "dice_loss:-0.865265\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:222\n",
            "loss(total):-0.004548\n",
            "recons_loss:0.003567\n",
            "grad_loss:0.080800\n",
            "dice_loss:-0.892307\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:223\n",
            "loss(total):-0.003651\n",
            "recons_loss:0.004258\n",
            "grad_loss:0.095441\n",
            "dice_loss:-0.886434\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:224\n",
            "loss(total):-0.004371\n",
            "recons_loss:0.003663\n",
            "grad_loss:0.078995\n",
            "dice_loss:-0.882479\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:225\n",
            "loss(total):-0.004188\n",
            "recons_loss:0.004021\n",
            "grad_loss:0.068364\n",
            "dice_loss:-0.889311\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:226\n",
            "loss(total):-0.004372\n",
            "recons_loss:0.003670\n",
            "grad_loss:0.084784\n",
            "dice_loss:-0.889026\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:227\n",
            "loss(total):-0.004606\n",
            "recons_loss:0.003376\n",
            "grad_loss:0.086111\n",
            "dice_loss:-0.884327\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:228\n",
            "loss(total):-0.003273\n",
            "recons_loss:0.004509\n",
            "grad_loss:0.103802\n",
            "dice_loss:-0.882039\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:229\n",
            "loss(total):-0.003692\n",
            "recons_loss:0.004186\n",
            "grad_loss:0.093675\n",
            "dice_loss:-0.881501\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:230\n",
            "loss(total):-0.004127\n",
            "recons_loss:0.003975\n",
            "grad_loss:0.081053\n",
            "dice_loss:-0.891238\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:231\n",
            "loss(total):-0.003617\n",
            "recons_loss:0.004434\n",
            "grad_loss:0.091752\n",
            "dice_loss:-0.896865\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:232\n",
            "loss(total):-0.001938\n",
            "recons_loss:0.005575\n",
            "grad_loss:0.129362\n",
            "dice_loss:-0.880672\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:233\n",
            "loss(total):-0.001357\n",
            "recons_loss:0.005979\n",
            "grad_loss:0.136565\n",
            "dice_loss:-0.870173\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:234\n",
            "loss(total):-0.003076\n",
            "recons_loss:0.004812\n",
            "grad_loss:0.118365\n",
            "dice_loss:-0.907101\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:235\n",
            "loss(total):-0.003785\n",
            "recons_loss:0.004199\n",
            "grad_loss:0.093375\n",
            "dice_loss:-0.891769\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:236\n",
            "loss(total):-0.003213\n",
            "recons_loss:0.004807\n",
            "grad_loss:0.093393\n",
            "dice_loss:-0.895361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:237\n",
            "loss(total):-0.000935\n",
            "recons_loss:0.006454\n",
            "grad_loss:0.135297\n",
            "dice_loss:-0.874218\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:238\n",
            "loss(total):-0.002079\n",
            "recons_loss:0.005373\n",
            "grad_loss:0.113157\n",
            "dice_loss:-0.858283\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:239\n",
            "loss(total):-0.003283\n",
            "recons_loss:0.004453\n",
            "grad_loss:0.105740\n",
            "dice_loss:-0.879336\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:240\n",
            "loss(total):-0.001880\n",
            "recons_loss:0.005695\n",
            "grad_loss:0.135694\n",
            "dice_loss:-0.893225\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:241\n",
            "loss(total):-0.004241\n",
            "recons_loss:0.003834\n",
            "grad_loss:0.090031\n",
            "dice_loss:-0.897573\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:242\n",
            "loss(total):-0.002778\n",
            "recons_loss:0.005004\n",
            "grad_loss:0.113365\n",
            "dice_loss:-0.891539\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:243\n",
            "loss(total):-0.003134\n",
            "recons_loss:0.004747\n",
            "grad_loss:0.095962\n",
            "dice_loss:-0.884112\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:244\n",
            "loss(total):-0.003364\n",
            "recons_loss:0.004349\n",
            "grad_loss:0.100979\n",
            "dice_loss:-0.872304\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:245\n",
            "loss(total):-0.002778\n",
            "recons_loss:0.004834\n",
            "grad_loss:0.103620\n",
            "dice_loss:-0.864887\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:246\n",
            "loss(total):-0.003320\n",
            "recons_loss:0.004510\n",
            "grad_loss:0.099614\n",
            "dice_loss:-0.882571\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:247\n",
            "loss(total):-0.004112\n",
            "recons_loss:0.003882\n",
            "grad_loss:0.091064\n",
            "dice_loss:-0.890431\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:248\n",
            "loss(total):-0.005044\n",
            "recons_loss:0.003115\n",
            "grad_loss:0.075694\n",
            "dice_loss:-0.891603\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:249\n",
            "loss(total):-0.003456\n",
            "recons_loss:0.004534\n",
            "grad_loss:0.094215\n",
            "dice_loss:-0.893158\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:250\n",
            "loss(total):-0.003863\n",
            "recons_loss:0.004053\n",
            "grad_loss:0.089666\n",
            "dice_loss:-0.881294\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:251\n",
            "loss(total):-0.003968\n",
            "recons_loss:0.003877\n",
            "grad_loss:0.095869\n",
            "dice_loss:-0.880376\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:252\n",
            "loss(total):-0.003306\n",
            "recons_loss:0.004484\n",
            "grad_loss:0.100184\n",
            "dice_loss:-0.879184\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:253\n",
            "loss(total):-0.004641\n",
            "recons_loss:0.003574\n",
            "grad_loss:0.075066\n",
            "dice_loss:-0.896561\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:254\n",
            "loss(total):-0.005082\n",
            "recons_loss:0.003121\n",
            "grad_loss:0.064459\n",
            "dice_loss:-0.884738\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:255\n",
            "loss(total):-0.003112\n",
            "recons_loss:0.004825\n",
            "grad_loss:0.103074\n",
            "dice_loss:-0.896753\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:256\n",
            "loss(total):-0.003028\n",
            "recons_loss:0.004842\n",
            "grad_loss:0.096586\n",
            "dice_loss:-0.883529\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:257\n",
            "loss(total):-0.004394\n",
            "recons_loss:0.003632\n",
            "grad_loss:0.096972\n",
            "dice_loss:-0.899514\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:258\n",
            "loss(total):-0.003528\n",
            "recons_loss:0.004499\n",
            "grad_loss:0.104380\n",
            "dice_loss:-0.907140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:259\n",
            "loss(total):-0.003196\n",
            "recons_loss:0.004499\n",
            "grad_loss:0.115875\n",
            "dice_loss:-0.885369\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:260\n",
            "loss(total):-0.003287\n",
            "recons_loss:0.004575\n",
            "grad_loss:0.099993\n",
            "dice_loss:-0.886211\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:261\n",
            "loss(total):-0.003768\n",
            "recons_loss:0.004194\n",
            "grad_loss:0.094474\n",
            "dice_loss:-0.890700\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:262\n",
            "loss(total):-0.003531\n",
            "recons_loss:0.004314\n",
            "grad_loss:0.095023\n",
            "dice_loss:-0.879489\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:263\n",
            "loss(total):-0.004039\n",
            "recons_loss:0.003850\n",
            "grad_loss:0.090438\n",
            "dice_loss:-0.879327\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:264\n",
            "loss(total):-0.003437\n",
            "recons_loss:0.004359\n",
            "grad_loss:0.110752\n",
            "dice_loss:-0.890352\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:265\n",
            "loss(total):-0.004513\n",
            "recons_loss:0.003437\n",
            "grad_loss:0.095324\n",
            "dice_loss:-0.890366\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:266\n",
            "loss(total):-0.004372\n",
            "recons_loss:0.003705\n",
            "grad_loss:0.086667\n",
            "dice_loss:-0.894292\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:267\n",
            "loss(total):-0.004166\n",
            "recons_loss:0.003897\n",
            "grad_loss:0.083277\n",
            "dice_loss:-0.889592\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:268\n",
            "loss(total):-0.003211\n",
            "recons_loss:0.004820\n",
            "grad_loss:0.089624\n",
            "dice_loss:-0.892762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:269\n",
            "loss(total):-0.003017\n",
            "recons_loss:0.004618\n",
            "grad_loss:0.120214\n",
            "dice_loss:-0.883749\n",
            "---------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxLk5-bgHIi2",
        "outputId": "756f382b-9741-41c5-dba5-d6938182594f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(losses_6[1:])\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d0CIhjpHKeu",
        "outputId": "2f78e80c-f0fc-48e3-bf7b-204c0ac3ce7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(validation_6)\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6KsbDQwHRqT"
      },
      "source": [
        "import csv\n",
        "with open('validation_6.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byeI8KEp-jNS"
      },
      "source": [
        "for h in range(0,len(validation_0)):\n",
        "  with open('validation_6.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, validation_6[h].numpy()])"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCXXbRszLDkN"
      },
      "source": [
        "import csv\n",
        "with open('loss_6.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n",
        "\n",
        "for h in range(0,len(losses_6)):\n",
        "  with open('loss_6.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h, losses_6[h].numpy()])"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51WHUcdkHbDy"
      },
      "source": [
        "'''Training - hold out fold 7 for validation'''\n",
        "#Training\n",
        "gpu='0'\n",
        "atlas_file='/content/drive/My Drive/2020/Thesis/Data/atlas.npz'\n",
        "lr=1e-4\n",
        "n_iter=5000\n",
        "data_loss='mse'\n",
        "model='vm2'\n",
        "reg_param=0.01\n",
        "batch_size=10\n",
        "n_save_iter=100\n",
        "model_dir='/content/drive/My Drive/2020/Thesis/Data/validation_0/'\n",
        "valid = fold_7\n",
        "train_names = set_7\n",
        "EPOCH=30"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR9FKzNWHiSN",
        "outputId": "db952467-cf04-47a3-ab4f-92a57525c9b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses_7, validation_7=validate.train(data_dir,\n",
        "          train_names,\n",
        "          atlas_file,\n",
        "          lr,\n",
        "          data_loss,\n",
        "          model,\n",
        "          reg_param, \n",
        "          batch_size,\n",
        "          n_save_iter,\n",
        "          model_dir,Net(),EPOCH, valid)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch_number:185\n",
            "loss(total):-0.003426\n",
            "recons_loss:0.004279\n",
            "grad_loss:0.114125\n",
            "dice_loss:-0.884625\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:186\n",
            "loss(total):-0.003730\n",
            "recons_loss:0.004085\n",
            "grad_loss:0.091460\n",
            "dice_loss:-0.872870\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:187\n",
            "loss(total):-0.002165\n",
            "recons_loss:0.005364\n",
            "grad_loss:0.121960\n",
            "dice_loss:-0.874849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:188\n",
            "loss(total):-0.002409\n",
            "recons_loss:0.005283\n",
            "grad_loss:0.119333\n",
            "dice_loss:-0.888546\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:189\n",
            "loss(total):-0.004644\n",
            "recons_loss:0.003548\n",
            "grad_loss:0.081201\n",
            "dice_loss:-0.900396\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:190\n",
            "loss(total):-0.002599\n",
            "recons_loss:0.004966\n",
            "grad_loss:0.113088\n",
            "dice_loss:-0.869583\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:191\n",
            "loss(total):-0.003155\n",
            "recons_loss:0.004718\n",
            "grad_loss:0.092733\n",
            "dice_loss:-0.880100\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:192\n",
            "loss(total):-0.002841\n",
            "recons_loss:0.004997\n",
            "grad_loss:0.102739\n",
            "dice_loss:-0.886574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:193\n",
            "loss(total):-0.001331\n",
            "recons_loss:0.006085\n",
            "grad_loss:0.127458\n",
            "dice_loss:-0.869072\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:194\n",
            "loss(total):-0.001604\n",
            "recons_loss:0.005872\n",
            "grad_loss:0.126077\n",
            "dice_loss:-0.873616\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:195\n",
            "loss(total):-0.003867\n",
            "recons_loss:0.004266\n",
            "grad_loss:0.086368\n",
            "dice_loss:-0.899678\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:196\n",
            "loss(total):-0.002402\n",
            "recons_loss:0.005452\n",
            "grad_loss:0.104902\n",
            "dice_loss:-0.890310\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:197\n",
            "loss(total):-0.004032\n",
            "recons_loss:0.003950\n",
            "grad_loss:0.095007\n",
            "dice_loss:-0.893197\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:198\n",
            "loss(total):-0.002093\n",
            "recons_loss:0.005667\n",
            "grad_loss:0.111236\n",
            "dice_loss:-0.887242\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:199\n",
            "loss(total):-0.002985\n",
            "recons_loss:0.004886\n",
            "grad_loss:0.105808\n",
            "dice_loss:-0.892829\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:200\n",
            "loss(total):-0.003577\n",
            "recons_loss:0.004133\n",
            "grad_loss:0.110794\n",
            "dice_loss:-0.881819\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:201\n",
            "loss(total):-0.003972\n",
            "recons_loss:0.004017\n",
            "grad_loss:0.101322\n",
            "dice_loss:-0.900294\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:202\n",
            "loss(total):-0.004596\n",
            "recons_loss:0.003508\n",
            "grad_loss:0.092042\n",
            "dice_loss:-0.902490\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:203\n",
            "loss(total):-0.002243\n",
            "recons_loss:0.005371\n",
            "grad_loss:0.117551\n",
            "dice_loss:-0.878851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:204\n",
            "loss(total):-0.003305\n",
            "recons_loss:0.004467\n",
            "grad_loss:0.103185\n",
            "dice_loss:-0.880395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:205\n",
            "loss(total):-0.004550\n",
            "recons_loss:0.003627\n",
            "grad_loss:0.079944\n",
            "dice_loss:-0.897668\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:206\n",
            "loss(total):-0.002124\n",
            "recons_loss:0.005480\n",
            "grad_loss:0.119168\n",
            "dice_loss:-0.879633\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:207\n",
            "loss(total):-0.003168\n",
            "recons_loss:0.004698\n",
            "grad_loss:0.101545\n",
            "dice_loss:-0.888215\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:208\n",
            "loss(total):-0.003405\n",
            "recons_loss:0.004485\n",
            "grad_loss:0.095213\n",
            "dice_loss:-0.884198\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:209\n",
            "loss(total):-0.004100\n",
            "recons_loss:0.004008\n",
            "grad_loss:0.078132\n",
            "dice_loss:-0.888968\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:210\n",
            "loss(total):-0.002316\n",
            "recons_loss:0.005317\n",
            "grad_loss:0.108469\n",
            "dice_loss:-0.871778\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:211\n",
            "loss(total):-0.003906\n",
            "recons_loss:0.004071\n",
            "grad_loss:0.089454\n",
            "dice_loss:-0.887159\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:212\n",
            "loss(total):-0.002628\n",
            "recons_loss:0.005271\n",
            "grad_loss:0.109256\n",
            "dice_loss:-0.899221\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:213\n",
            "loss(total):-0.004419\n",
            "recons_loss:0.003726\n",
            "grad_loss:0.086122\n",
            "dice_loss:-0.900576\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:214\n",
            "loss(total):-0.003261\n",
            "recons_loss:0.004524\n",
            "grad_loss:0.117078\n",
            "dice_loss:-0.895630\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:215\n",
            "loss(total):-0.003189\n",
            "recons_loss:0.004660\n",
            "grad_loss:0.102765\n",
            "dice_loss:-0.887677\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:216\n",
            "loss(total):-0.002099\n",
            "recons_loss:0.005612\n",
            "grad_loss:0.116089\n",
            "dice_loss:-0.887103\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:217\n",
            "loss(total):-0.004269\n",
            "recons_loss:0.003885\n",
            "grad_loss:0.092904\n",
            "dice_loss:-0.908336\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:218\n",
            "loss(total):-0.004425\n",
            "recons_loss:0.003580\n",
            "grad_loss:0.094177\n",
            "dice_loss:-0.894690\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:219\n",
            "loss(total):-0.003444\n",
            "recons_loss:0.004466\n",
            "grad_loss:0.104093\n",
            "dice_loss:-0.895013\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:220\n",
            "loss(total):-0.002597\n",
            "recons_loss:0.005162\n",
            "grad_loss:0.096161\n",
            "dice_loss:-0.872017\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:221\n",
            "loss(total):-0.003730\n",
            "recons_loss:0.004293\n",
            "grad_loss:0.093467\n",
            "dice_loss:-0.895766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:222\n",
            "loss(total):-0.004015\n",
            "recons_loss:0.003960\n",
            "grad_loss:0.098535\n",
            "dice_loss:-0.896082\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:223\n",
            "loss(total):-0.002839\n",
            "recons_loss:0.005101\n",
            "grad_loss:0.084547\n",
            "dice_loss:-0.878563\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:224\n",
            "loss(total):-0.005116\n",
            "recons_loss:0.003138\n",
            "grad_loss:0.085058\n",
            "dice_loss:-0.910476\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:225\n",
            "loss(total):-0.004840\n",
            "recons_loss:0.003194\n",
            "grad_loss:0.089303\n",
            "dice_loss:-0.892700\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:226\n",
            "loss(total):-0.002514\n",
            "recons_loss:0.005190\n",
            "grad_loss:0.113387\n",
            "dice_loss:-0.883848\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:227\n",
            "loss(total):-0.003814\n",
            "recons_loss:0.004420\n",
            "grad_loss:0.077019\n",
            "dice_loss:-0.900454\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:228\n",
            "loss(total):-0.003329\n",
            "recons_loss:0.004555\n",
            "grad_loss:0.100314\n",
            "dice_loss:-0.888729\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:229\n",
            "loss(total):-0.004816\n",
            "recons_loss:0.003280\n",
            "grad_loss:0.084552\n",
            "dice_loss:-0.894159\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:230\n",
            "loss(total):-0.004172\n",
            "recons_loss:0.003849\n",
            "grad_loss:0.076858\n",
            "dice_loss:-0.878960\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:231\n",
            "loss(total):-0.003741\n",
            "recons_loss:0.004318\n",
            "grad_loss:0.095552\n",
            "dice_loss:-0.901486\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:232\n",
            "loss(total):-0.002511\n",
            "recons_loss:0.005351\n",
            "grad_loss:0.108785\n",
            "dice_loss:-0.895044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:233\n",
            "loss(total):-0.003386\n",
            "recons_loss:0.004661\n",
            "grad_loss:0.094931\n",
            "dice_loss:-0.899682\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:234\n",
            "loss(total):-0.004804\n",
            "recons_loss:0.003195\n",
            "grad_loss:0.095792\n",
            "dice_loss:-0.895692\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:235\n",
            "loss(total):-0.003950\n",
            "recons_loss:0.004045\n",
            "grad_loss:0.084449\n",
            "dice_loss:-0.883907\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:236\n",
            "loss(total):-0.002877\n",
            "recons_loss:0.004956\n",
            "grad_loss:0.107360\n",
            "dice_loss:-0.890709\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:237\n",
            "loss(total):-0.003917\n",
            "recons_loss:0.003993\n",
            "grad_loss:0.095831\n",
            "dice_loss:-0.886762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:238\n",
            "loss(total):-0.003626\n",
            "recons_loss:0.004446\n",
            "grad_loss:0.086349\n",
            "dice_loss:-0.893473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:239\n",
            "loss(total):-0.002452\n",
            "recons_loss:0.005253\n",
            "grad_loss:0.113729\n",
            "dice_loss:-0.884242\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:240\n",
            "loss(total):-0.003315\n",
            "recons_loss:0.004802\n",
            "grad_loss:0.092105\n",
            "dice_loss:-0.903856\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:241\n",
            "loss(total):-0.003103\n",
            "recons_loss:0.004822\n",
            "grad_loss:0.094104\n",
            "dice_loss:-0.886590\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:242\n",
            "loss(total):-0.005861\n",
            "recons_loss:0.002639\n",
            "grad_loss:0.065563\n",
            "dice_loss:-0.915601\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:243\n",
            "loss(total):-0.004608\n",
            "recons_loss:0.003529\n",
            "grad_loss:0.084469\n",
            "dice_loss:-0.898129\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:244\n",
            "loss(total):-0.004012\n",
            "recons_loss:0.004028\n",
            "grad_loss:0.087363\n",
            "dice_loss:-0.891379\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:245\n",
            "loss(total):-0.005715\n",
            "recons_loss:0.002722\n",
            "grad_loss:0.076558\n",
            "dice_loss:-0.920270\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:246\n",
            "loss(total):-0.001821\n",
            "recons_loss:0.005916\n",
            "grad_loss:0.117032\n",
            "dice_loss:-0.890748\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:247\n",
            "loss(total):-0.004212\n",
            "recons_loss:0.003803\n",
            "grad_loss:0.088971\n",
            "dice_loss:-0.890474\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:248\n",
            "loss(total):-0.001877\n",
            "recons_loss:0.005632\n",
            "grad_loss:0.115975\n",
            "dice_loss:-0.866920\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:249\n",
            "loss(total):-0.003285\n",
            "recons_loss:0.004690\n",
            "grad_loss:0.090922\n",
            "dice_loss:-0.888501\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:250\n",
            "loss(total):-0.003805\n",
            "recons_loss:0.004191\n",
            "grad_loss:0.085243\n",
            "dice_loss:-0.884858\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:251\n",
            "loss(total):-0.004008\n",
            "recons_loss:0.003988\n",
            "grad_loss:0.089174\n",
            "dice_loss:-0.888744\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:252\n",
            "loss(total):-0.003030\n",
            "recons_loss:0.004811\n",
            "grad_loss:0.110974\n",
            "dice_loss:-0.895100\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:253\n",
            "loss(total):-0.004804\n",
            "recons_loss:0.003152\n",
            "grad_loss:0.098709\n",
            "dice_loss:-0.894289\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:254\n",
            "loss(total):-0.003996\n",
            "recons_loss:0.003947\n",
            "grad_loss:0.087082\n",
            "dice_loss:-0.881343\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:255\n",
            "loss(total):-0.004883\n",
            "recons_loss:0.003297\n",
            "grad_loss:0.079684\n",
            "dice_loss:-0.897727\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:256\n",
            "loss(total):-0.001988\n",
            "recons_loss:0.005744\n",
            "grad_loss:0.113310\n",
            "dice_loss:-0.886534\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:257\n",
            "loss(total):-0.003775\n",
            "recons_loss:0.003948\n",
            "grad_loss:0.096289\n",
            "dice_loss:-0.868672\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:258\n",
            "loss(total):-0.004131\n",
            "recons_loss:0.003828\n",
            "grad_loss:0.092634\n",
            "dice_loss:-0.888565\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:259\n",
            "loss(total):-0.003245\n",
            "recons_loss:0.004386\n",
            "grad_loss:0.103899\n",
            "dice_loss:-0.866989\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:260\n",
            "loss(total):-0.002279\n",
            "recons_loss:0.005394\n",
            "grad_loss:0.116629\n",
            "dice_loss:-0.883900\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:261\n",
            "loss(total):-0.003679\n",
            "recons_loss:0.004264\n",
            "grad_loss:0.088650\n",
            "dice_loss:-0.882903\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:262\n",
            "loss(total):-0.002744\n",
            "recons_loss:0.005211\n",
            "grad_loss:0.096621\n",
            "dice_loss:-0.892047\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:263\n",
            "loss(total):-0.001995\n",
            "recons_loss:0.005729\n",
            "grad_loss:0.118127\n",
            "dice_loss:-0.890460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:264\n",
            "loss(total):-0.001541\n",
            "recons_loss:0.006039\n",
            "grad_loss:0.133196\n",
            "dice_loss:-0.891168\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:265\n",
            "loss(total):-0.003884\n",
            "recons_loss:0.003994\n",
            "grad_loss:0.112872\n",
            "dice_loss:-0.900674\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:266\n",
            "loss(total):-0.003813\n",
            "recons_loss:0.004125\n",
            "grad_loss:0.094639\n",
            "dice_loss:-0.888466\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:267\n",
            "loss(total):-0.003257\n",
            "recons_loss:0.004711\n",
            "grad_loss:0.096485\n",
            "dice_loss:-0.893319\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:268\n",
            "loss(total):-0.003921\n",
            "recons_loss:0.004244\n",
            "grad_loss:0.084629\n",
            "dice_loss:-0.901042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:269\n",
            "loss(total):-0.002921\n",
            "recons_loss:0.004975\n",
            "grad_loss:0.096870\n",
            "dice_loss:-0.886478\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:0\n",
            "loss(total):-0.003750\n",
            "recons_loss:0.004277\n",
            "grad_loss:0.081265\n",
            "dice_loss:-0.883916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:1\n",
            "loss(total):-0.003185\n",
            "recons_loss:0.004547\n",
            "grad_loss:0.117301\n",
            "dice_loss:-0.890535\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:2\n",
            "loss(total):-0.004374\n",
            "recons_loss:0.003678\n",
            "grad_loss:0.082433\n",
            "dice_loss:-0.887589\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:3\n",
            "loss(total):-0.004309\n",
            "recons_loss:0.003537\n",
            "grad_loss:0.093710\n",
            "dice_loss:-0.878247\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:4\n",
            "loss(total):-0.003729\n",
            "recons_loss:0.004264\n",
            "grad_loss:0.085672\n",
            "dice_loss:-0.884943\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:5\n",
            "loss(total):-0.003306\n",
            "recons_loss:0.004658\n",
            "grad_loss:0.098573\n",
            "dice_loss:-0.894946\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:6\n",
            "loss(total):-0.003237\n",
            "recons_loss:0.004766\n",
            "grad_loss:0.097357\n",
            "dice_loss:-0.897656\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:7\n",
            "loss(total):-0.003912\n",
            "recons_loss:0.004172\n",
            "grad_loss:0.093164\n",
            "dice_loss:-0.901546\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:8\n",
            "loss(total):-0.002503\n",
            "recons_loss:0.005422\n",
            "grad_loss:0.101556\n",
            "dice_loss:-0.894040\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:9\n",
            "loss(total):-0.004054\n",
            "recons_loss:0.004010\n",
            "grad_loss:0.091652\n",
            "dice_loss:-0.898058\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:10\n",
            "loss(total):-0.003944\n",
            "recons_loss:0.003996\n",
            "grad_loss:0.098597\n",
            "dice_loss:-0.892606\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:11\n",
            "loss(total):-0.003727\n",
            "recons_loss:0.004208\n",
            "grad_loss:0.105898\n",
            "dice_loss:-0.899387\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:12\n",
            "loss(total):-0.003249\n",
            "recons_loss:0.004565\n",
            "grad_loss:0.085994\n",
            "dice_loss:-0.867405\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:13\n",
            "loss(total):-0.004164\n",
            "recons_loss:0.003813\n",
            "grad_loss:0.084372\n",
            "dice_loss:-0.882021\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:14\n",
            "loss(total):-0.002939\n",
            "recons_loss:0.004901\n",
            "grad_loss:0.106022\n",
            "dice_loss:-0.890056\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:15\n",
            "loss(total):-0.003173\n",
            "recons_loss:0.004613\n",
            "grad_loss:0.120967\n",
            "dice_loss:-0.899640\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:16\n",
            "loss(total):-0.003915\n",
            "recons_loss:0.004063\n",
            "grad_loss:0.096207\n",
            "dice_loss:-0.894068\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:17\n",
            "loss(total):-0.002319\n",
            "recons_loss:0.005363\n",
            "grad_loss:0.114173\n",
            "dice_loss:-0.882450\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:18\n",
            "loss(total):-0.003660\n",
            "recons_loss:0.004373\n",
            "grad_loss:0.090903\n",
            "dice_loss:-0.894127\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:19\n",
            "loss(total):-0.004133\n",
            "recons_loss:0.003809\n",
            "grad_loss:0.097878\n",
            "dice_loss:-0.892064\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:20\n",
            "loss(total):-0.004308\n",
            "recons_loss:0.003852\n",
            "grad_loss:0.088236\n",
            "dice_loss:-0.904198\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:21\n",
            "loss(total):-0.003704\n",
            "recons_loss:0.004330\n",
            "grad_loss:0.096385\n",
            "dice_loss:-0.899770\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:22\n",
            "loss(total):-0.003877\n",
            "recons_loss:0.004061\n",
            "grad_loss:0.093680\n",
            "dice_loss:-0.887500\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:23\n",
            "loss(total):-0.002716\n",
            "recons_loss:0.005021\n",
            "grad_loss:0.117942\n",
            "dice_loss:-0.891710\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:24\n",
            "loss(total):-0.003729\n",
            "recons_loss:0.004201\n",
            "grad_loss:0.102988\n",
            "dice_loss:-0.895979\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:25\n",
            "loss(total):-0.003723\n",
            "recons_loss:0.004191\n",
            "grad_loss:0.103087\n",
            "dice_loss:-0.894427\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:26\n",
            "loss(total):-0.002731\n",
            "recons_loss:0.005023\n",
            "grad_loss:0.098562\n",
            "dice_loss:-0.874000\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:27\n",
            "loss(total):-0.003110\n",
            "recons_loss:0.004807\n",
            "grad_loss:0.097721\n",
            "dice_loss:-0.889418\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:28\n",
            "loss(total):-0.004059\n",
            "recons_loss:0.003908\n",
            "grad_loss:0.094559\n",
            "dice_loss:-0.891225\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:29\n",
            "loss(total):-0.003724\n",
            "recons_loss:0.004246\n",
            "grad_loss:0.087345\n",
            "dice_loss:-0.884362\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:30\n",
            "loss(total):-0.002469\n",
            "recons_loss:0.005210\n",
            "grad_loss:0.122917\n",
            "dice_loss:-0.890805\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:31\n",
            "loss(total):-0.004074\n",
            "recons_loss:0.003988\n",
            "grad_loss:0.085094\n",
            "dice_loss:-0.891337\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:32\n",
            "loss(total):-0.003170\n",
            "recons_loss:0.004563\n",
            "grad_loss:0.105544\n",
            "dice_loss:-0.878839\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:33\n",
            "loss(total):-0.002336\n",
            "recons_loss:0.005197\n",
            "grad_loss:0.127681\n",
            "dice_loss:-0.880942\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:34\n",
            "loss(total):-0.003925\n",
            "recons_loss:0.004243\n",
            "grad_loss:0.076407\n",
            "dice_loss:-0.893241\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:35\n",
            "loss(total):-0.003710\n",
            "recons_loss:0.004370\n",
            "grad_loss:0.099117\n",
            "dice_loss:-0.907088\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:36\n",
            "loss(total):-0.001659\n",
            "recons_loss:0.005930\n",
            "grad_loss:0.136202\n",
            "dice_loss:-0.895135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:37\n",
            "loss(total):-0.005101\n",
            "recons_loss:0.003154\n",
            "grad_loss:0.071728\n",
            "dice_loss:-0.897249\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:38\n",
            "loss(total):-0.001633\n",
            "recons_loss:0.005700\n",
            "grad_loss:0.141779\n",
            "dice_loss:-0.875144\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:39\n",
            "loss(total):-0.001090\n",
            "recons_loss:0.006196\n",
            "grad_loss:0.152062\n",
            "dice_loss:-0.880719\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:40\n",
            "loss(total):-0.003748\n",
            "recons_loss:0.004089\n",
            "grad_loss:0.098025\n",
            "dice_loss:-0.881683\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:41\n",
            "loss(total):-0.003176\n",
            "recons_loss:0.004919\n",
            "grad_loss:0.082519\n",
            "dice_loss:-0.892085\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:42\n",
            "loss(total):-0.003263\n",
            "recons_loss:0.004722\n",
            "grad_loss:0.084962\n",
            "dice_loss:-0.883444\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:43\n",
            "loss(total):-0.003186\n",
            "recons_loss:0.004899\n",
            "grad_loss:0.099211\n",
            "dice_loss:-0.907625\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:44\n",
            "loss(total):-0.004045\n",
            "recons_loss:0.003886\n",
            "grad_loss:0.091224\n",
            "dice_loss:-0.884293\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:45\n",
            "loss(total):-0.003738\n",
            "recons_loss:0.004147\n",
            "grad_loss:0.096746\n",
            "dice_loss:-0.885323\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:46\n",
            "loss(total):-0.002110\n",
            "recons_loss:0.005407\n",
            "grad_loss:0.112695\n",
            "dice_loss:-0.864437\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:47\n",
            "loss(total):-0.002389\n",
            "recons_loss:0.005376\n",
            "grad_loss:0.109103\n",
            "dice_loss:-0.885602\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:48\n",
            "loss(total):-0.004373\n",
            "recons_loss:0.003700\n",
            "grad_loss:0.086389\n",
            "dice_loss:-0.893638\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:49\n",
            "loss(total):-0.003741\n",
            "recons_loss:0.004483\n",
            "grad_loss:0.078716\n",
            "dice_loss:-0.901100\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:50\n",
            "loss(total):-0.003339\n",
            "recons_loss:0.004826\n",
            "grad_loss:0.071954\n",
            "dice_loss:-0.888468\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:51\n",
            "loss(total):-0.003322\n",
            "recons_loss:0.004654\n",
            "grad_loss:0.084961\n",
            "dice_loss:-0.882611\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:52\n",
            "loss(total):-0.003895\n",
            "recons_loss:0.004157\n",
            "grad_loss:0.084068\n",
            "dice_loss:-0.889233\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:53\n",
            "loss(total):-0.002247\n",
            "recons_loss:0.005613\n",
            "grad_loss:0.110297\n",
            "dice_loss:-0.896330\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:54\n",
            "loss(total):-0.002160\n",
            "recons_loss:0.005509\n",
            "grad_loss:0.114999\n",
            "dice_loss:-0.881874\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:55\n",
            "loss(total):-0.003117\n",
            "recons_loss:0.004662\n",
            "grad_loss:0.101622\n",
            "dice_loss:-0.879507\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:56\n",
            "loss(total):-0.002485\n",
            "recons_loss:0.005164\n",
            "grad_loss:0.114077\n",
            "dice_loss:-0.878924\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:57\n",
            "loss(total):-0.003086\n",
            "recons_loss:0.004790\n",
            "grad_loss:0.099575\n",
            "dice_loss:-0.887202\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:58\n",
            "loss(total):-0.002097\n",
            "recons_loss:0.005637\n",
            "grad_loss:0.099306\n",
            "dice_loss:-0.872710\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:59\n",
            "loss(total):-0.003238\n",
            "recons_loss:0.004785\n",
            "grad_loss:0.075593\n",
            "dice_loss:-0.877923\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:60\n",
            "loss(total):-0.003293\n",
            "recons_loss:0.004630\n",
            "grad_loss:0.094236\n",
            "dice_loss:-0.886530\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:61\n",
            "loss(total):-0.003453\n",
            "recons_loss:0.004534\n",
            "grad_loss:0.090109\n",
            "dice_loss:-0.888852\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:62\n",
            "loss(total):-0.004409\n",
            "recons_loss:0.003596\n",
            "grad_loss:0.088662\n",
            "dice_loss:-0.889170\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:63\n",
            "loss(total):-0.001433\n",
            "recons_loss:0.006031\n",
            "grad_loss:0.132319\n",
            "dice_loss:-0.878675\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:64\n",
            "loss(total):-0.002824\n",
            "recons_loss:0.005116\n",
            "grad_loss:0.104775\n",
            "dice_loss:-0.898788\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:65\n",
            "loss(total):-0.003764\n",
            "recons_loss:0.004397\n",
            "grad_loss:0.079717\n",
            "dice_loss:-0.895824\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:66\n",
            "loss(total):-0.002275\n",
            "recons_loss:0.005535\n",
            "grad_loss:0.094876\n",
            "dice_loss:-0.875874\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:67\n",
            "loss(total):-0.004038\n",
            "recons_loss:0.004078\n",
            "grad_loss:0.075447\n",
            "dice_loss:-0.887036\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:68\n",
            "loss(total):-0.003627\n",
            "recons_loss:0.004397\n",
            "grad_loss:0.083680\n",
            "dice_loss:-0.886153\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:69\n",
            "loss(total):-0.003989\n",
            "recons_loss:0.003981\n",
            "grad_loss:0.096437\n",
            "dice_loss:-0.893372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:70\n",
            "loss(total):-0.003713\n",
            "recons_loss:0.004246\n",
            "grad_loss:0.101902\n",
            "dice_loss:-0.897790\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:71\n",
            "loss(total):-0.003494\n",
            "recons_loss:0.004492\n",
            "grad_loss:0.092118\n",
            "dice_loss:-0.890743\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:72\n",
            "loss(total):-0.003226\n",
            "recons_loss:0.004688\n",
            "grad_loss:0.105689\n",
            "dice_loss:-0.897041\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:73\n",
            "loss(total):-0.003775\n",
            "recons_loss:0.004149\n",
            "grad_loss:0.095828\n",
            "dice_loss:-0.888253\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:74\n",
            "loss(total):-0.003057\n",
            "recons_loss:0.004772\n",
            "grad_loss:0.109572\n",
            "dice_loss:-0.892441\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:75\n",
            "loss(total):-0.004261\n",
            "recons_loss:0.003880\n",
            "grad_loss:0.083575\n",
            "dice_loss:-0.897691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:76\n",
            "loss(total):-0.002934\n",
            "recons_loss:0.004735\n",
            "grad_loss:0.115925\n",
            "dice_loss:-0.882765\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:77\n",
            "loss(total):-0.003739\n",
            "recons_loss:0.004096\n",
            "grad_loss:0.096751\n",
            "dice_loss:-0.880322\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:78\n",
            "loss(total):-0.002980\n",
            "recons_loss:0.004827\n",
            "grad_loss:0.108032\n",
            "dice_loss:-0.888825\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:79\n",
            "loss(total):-0.004550\n",
            "recons_loss:0.003608\n",
            "grad_loss:0.078231\n",
            "dice_loss:-0.894032\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:80\n",
            "loss(total):-0.003826\n",
            "recons_loss:0.004165\n",
            "grad_loss:0.090286\n",
            "dice_loss:-0.889361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:81\n",
            "loss(total):-0.003293\n",
            "recons_loss:0.004511\n",
            "grad_loss:0.104791\n",
            "dice_loss:-0.885187\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:82\n",
            "loss(total):-0.004604\n",
            "recons_loss:0.003430\n",
            "grad_loss:0.081148\n",
            "dice_loss:-0.884518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:83\n",
            "loss(total):-0.003846\n",
            "recons_loss:0.004095\n",
            "grad_loss:0.078805\n",
            "dice_loss:-0.872964\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:84\n",
            "loss(total):-0.003957\n",
            "recons_loss:0.004004\n",
            "grad_loss:0.088796\n",
            "dice_loss:-0.884916\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:85\n",
            "loss(total):-0.002820\n",
            "recons_loss:0.004954\n",
            "grad_loss:0.112087\n",
            "dice_loss:-0.889431\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:86\n",
            "loss(total):-0.004083\n",
            "recons_loss:0.004060\n",
            "grad_loss:0.076899\n",
            "dice_loss:-0.891208\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:87\n",
            "loss(total):-0.002233\n",
            "recons_loss:0.005495\n",
            "grad_loss:0.108583\n",
            "dice_loss:-0.881372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:88\n",
            "loss(total):-0.003612\n",
            "recons_loss:0.004296\n",
            "grad_loss:0.097791\n",
            "dice_loss:-0.888659\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:89\n",
            "loss(total):-0.003512\n",
            "recons_loss:0.004436\n",
            "grad_loss:0.095928\n",
            "dice_loss:-0.890725\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:90\n",
            "loss(total):-0.003683\n",
            "recons_loss:0.004244\n",
            "grad_loss:0.094809\n",
            "dice_loss:-0.887537\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:91\n",
            "loss(total):-0.002547\n",
            "recons_loss:0.005206\n",
            "grad_loss:0.110124\n",
            "dice_loss:-0.885444\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:92\n",
            "loss(total):-0.004779\n",
            "recons_loss:0.003491\n",
            "grad_loss:0.071606\n",
            "dice_loss:-0.898657\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:93\n",
            "loss(total):-0.004890\n",
            "recons_loss:0.003160\n",
            "grad_loss:0.086760\n",
            "dice_loss:-0.891792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:94\n",
            "loss(total):-0.003785\n",
            "recons_loss:0.004060\n",
            "grad_loss:0.104629\n",
            "dice_loss:-0.889137\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:95\n",
            "loss(total):-0.004323\n",
            "recons_loss:0.003690\n",
            "grad_loss:0.091227\n",
            "dice_loss:-0.892484\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:96\n",
            "loss(total):-0.004180\n",
            "recons_loss:0.003891\n",
            "grad_loss:0.071979\n",
            "dice_loss:-0.879095\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:97\n",
            "loss(total):-0.003185\n",
            "recons_loss:0.004831\n",
            "grad_loss:0.085378\n",
            "dice_loss:-0.886963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:98\n",
            "loss(total):-0.002575\n",
            "recons_loss:0.005323\n",
            "grad_loss:0.103166\n",
            "dice_loss:-0.892885\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:99\n",
            "loss(total):-0.002300\n",
            "recons_loss:0.005466\n",
            "grad_loss:0.106142\n",
            "dice_loss:-0.882793\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:100\n",
            "loss(total):-0.001824\n",
            "recons_loss:0.005587\n",
            "grad_loss:0.133427\n",
            "dice_loss:-0.874507\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:101\n",
            "loss(total):-0.002555\n",
            "recons_loss:0.005229\n",
            "grad_loss:0.108462\n",
            "dice_loss:-0.886814\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:102\n",
            "loss(total):-0.002559\n",
            "recons_loss:0.005100\n",
            "grad_loss:0.117775\n",
            "dice_loss:-0.883697\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:103\n",
            "loss(total):-0.003338\n",
            "recons_loss:0.004495\n",
            "grad_loss:0.106015\n",
            "dice_loss:-0.889305\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:104\n",
            "loss(total):-0.002176\n",
            "recons_loss:0.005521\n",
            "grad_loss:0.116034\n",
            "dice_loss:-0.885657\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:105\n",
            "loss(total):-0.003113\n",
            "recons_loss:0.004877\n",
            "grad_loss:0.102373\n",
            "dice_loss:-0.901400\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:106\n",
            "loss(total):-0.004943\n",
            "recons_loss:0.003234\n",
            "grad_loss:0.081547\n",
            "dice_loss:-0.899316\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:107\n",
            "loss(total):-0.003509\n",
            "recons_loss:0.004418\n",
            "grad_loss:0.099502\n",
            "dice_loss:-0.892146\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:108\n",
            "loss(total):-0.003389\n",
            "recons_loss:0.004355\n",
            "grad_loss:0.104655\n",
            "dice_loss:-0.878974\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:109\n",
            "loss(total):-0.002797\n",
            "recons_loss:0.005005\n",
            "grad_loss:0.114054\n",
            "dice_loss:-0.894247\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:110\n",
            "loss(total):-0.004248\n",
            "recons_loss:0.003812\n",
            "grad_loss:0.078776\n",
            "dice_loss:-0.884766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:111\n",
            "loss(total):-0.001716\n",
            "recons_loss:0.005861\n",
            "grad_loss:0.119322\n",
            "dice_loss:-0.877048\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:112\n",
            "loss(total):-0.003900\n",
            "recons_loss:0.004120\n",
            "grad_loss:0.086185\n",
            "dice_loss:-0.888175\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:113\n",
            "loss(total):-0.004125\n",
            "recons_loss:0.004044\n",
            "grad_loss:0.078348\n",
            "dice_loss:-0.895330\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:114\n",
            "loss(total):-0.004209\n",
            "recons_loss:0.003899\n",
            "grad_loss:0.085463\n",
            "dice_loss:-0.896220\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:115\n",
            "loss(total):-0.003665\n",
            "recons_loss:0.004202\n",
            "grad_loss:0.100454\n",
            "dice_loss:-0.887110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:116\n",
            "loss(total):-0.003196\n",
            "recons_loss:0.004617\n",
            "grad_loss:0.101100\n",
            "dice_loss:-0.882445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:117\n",
            "loss(total):-0.003795\n",
            "recons_loss:0.004186\n",
            "grad_loss:0.084074\n",
            "dice_loss:-0.882139\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:118\n",
            "loss(total):-0.002557\n",
            "recons_loss:0.005018\n",
            "grad_loss:0.109551\n",
            "dice_loss:-0.867031\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:119\n",
            "loss(total):-0.004240\n",
            "recons_loss:0.003843\n",
            "grad_loss:0.092009\n",
            "dice_loss:-0.900336\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:120\n",
            "loss(total):-0.004405\n",
            "recons_loss:0.003703\n",
            "grad_loss:0.089178\n",
            "dice_loss:-0.900073\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:121\n",
            "loss(total):-0.003532\n",
            "recons_loss:0.004548\n",
            "grad_loss:0.084659\n",
            "dice_loss:-0.892701\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:122\n",
            "loss(total):-0.002852\n",
            "recons_loss:0.004975\n",
            "grad_loss:0.097381\n",
            "dice_loss:-0.880126\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:123\n",
            "loss(total):-0.003042\n",
            "recons_loss:0.004651\n",
            "grad_loss:0.119145\n",
            "dice_loss:-0.888435\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:124\n",
            "loss(total):-0.004706\n",
            "recons_loss:0.003345\n",
            "grad_loss:0.086258\n",
            "dice_loss:-0.891386\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:125\n",
            "loss(total):-0.003382\n",
            "recons_loss:0.004525\n",
            "grad_loss:0.085808\n",
            "dice_loss:-0.876578\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:126\n",
            "loss(total):-0.003715\n",
            "recons_loss:0.004232\n",
            "grad_loss:0.094105\n",
            "dice_loss:-0.888788\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:127\n",
            "loss(total):-0.004092\n",
            "recons_loss:0.004071\n",
            "grad_loss:0.088960\n",
            "dice_loss:-0.905250\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:128\n",
            "loss(total):-0.004255\n",
            "recons_loss:0.003833\n",
            "grad_loss:0.078926\n",
            "dice_loss:-0.887731\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:129\n",
            "loss(total):-0.003615\n",
            "recons_loss:0.004475\n",
            "grad_loss:0.078576\n",
            "dice_loss:-0.887623\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:130\n",
            "loss(total):-0.002652\n",
            "recons_loss:0.005052\n",
            "grad_loss:0.106973\n",
            "dice_loss:-0.877391\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:131\n",
            "loss(total):-0.002784\n",
            "recons_loss:0.004957\n",
            "grad_loss:0.105731\n",
            "dice_loss:-0.879825\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:132\n",
            "loss(total):-0.003600\n",
            "recons_loss:0.004431\n",
            "grad_loss:0.097641\n",
            "dice_loss:-0.900711\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:133\n",
            "loss(total):-0.004962\n",
            "recons_loss:0.003167\n",
            "grad_loss:0.078686\n",
            "dice_loss:-0.891516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:134\n",
            "loss(total):-0.004617\n",
            "recons_loss:0.003511\n",
            "grad_loss:0.074563\n",
            "dice_loss:-0.887358\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:135\n",
            "loss(total):-0.003473\n",
            "recons_loss:0.004550\n",
            "grad_loss:0.095705\n",
            "dice_loss:-0.897999\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:136\n",
            "loss(total):-0.003386\n",
            "recons_loss:0.004586\n",
            "grad_loss:0.082903\n",
            "dice_loss:-0.880121\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:137\n",
            "loss(total):-0.004013\n",
            "recons_loss:0.003995\n",
            "grad_loss:0.089145\n",
            "dice_loss:-0.889955\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:138\n",
            "loss(total):-0.002672\n",
            "recons_loss:0.005125\n",
            "grad_loss:0.118842\n",
            "dice_loss:-0.898540\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:139\n",
            "loss(total):-0.003999\n",
            "recons_loss:0.003821\n",
            "grad_loss:0.103025\n",
            "dice_loss:-0.885101\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:140\n",
            "loss(total):-0.002031\n",
            "recons_loss:0.005768\n",
            "grad_loss:0.118173\n",
            "dice_loss:-0.897999\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:141\n",
            "loss(total):-0.001845\n",
            "recons_loss:0.005704\n",
            "grad_loss:0.130428\n",
            "dice_loss:-0.885348\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:142\n",
            "loss(total):-0.004237\n",
            "recons_loss:0.004000\n",
            "grad_loss:0.076077\n",
            "dice_loss:-0.899781\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:143\n",
            "loss(total):-0.003027\n",
            "recons_loss:0.004760\n",
            "grad_loss:0.100930\n",
            "dice_loss:-0.879631\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:144\n",
            "loss(total):-0.004084\n",
            "recons_loss:0.003862\n",
            "grad_loss:0.089131\n",
            "dice_loss:-0.883767\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:145\n",
            "loss(total):-0.000969\n",
            "recons_loss:0.006473\n",
            "grad_loss:0.129398\n",
            "dice_loss:-0.873613\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:146\n",
            "loss(total):-0.001811\n",
            "recons_loss:0.005798\n",
            "grad_loss:0.113626\n",
            "dice_loss:-0.874606\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:147\n",
            "loss(total):-0.003092\n",
            "recons_loss:0.004725\n",
            "grad_loss:0.098634\n",
            "dice_loss:-0.880309\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:148\n",
            "loss(total):-0.003176\n",
            "recons_loss:0.004610\n",
            "grad_loss:0.105081\n",
            "dice_loss:-0.883678\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:149\n",
            "loss(total):-0.003129\n",
            "recons_loss:0.004720\n",
            "grad_loss:0.106304\n",
            "dice_loss:-0.891168\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:150\n",
            "loss(total):-0.002228\n",
            "recons_loss:0.005498\n",
            "grad_loss:0.106652\n",
            "dice_loss:-0.879272\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:151\n",
            "loss(total):-0.001959\n",
            "recons_loss:0.005525\n",
            "grad_loss:0.141305\n",
            "dice_loss:-0.889699\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:152\n",
            "loss(total):-0.002144\n",
            "recons_loss:0.005296\n",
            "grad_loss:0.133702\n",
            "dice_loss:-0.877666\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:153\n",
            "loss(total):-0.003541\n",
            "recons_loss:0.004536\n",
            "grad_loss:0.093149\n",
            "dice_loss:-0.900845\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:154\n",
            "loss(total):-0.004011\n",
            "recons_loss:0.003881\n",
            "grad_loss:0.106800\n",
            "dice_loss:-0.896008\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:155\n",
            "loss(total):-0.003475\n",
            "recons_loss:0.004347\n",
            "grad_loss:0.101557\n",
            "dice_loss:-0.883755\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:156\n",
            "loss(total):-0.003620\n",
            "recons_loss:0.004314\n",
            "grad_loss:0.105082\n",
            "dice_loss:-0.898417\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:157\n",
            "loss(total):-0.001336\n",
            "recons_loss:0.006178\n",
            "grad_loss:0.126340\n",
            "dice_loss:-0.877753\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:158\n",
            "loss(total):-0.003565\n",
            "recons_loss:0.004537\n",
            "grad_loss:0.099097\n",
            "dice_loss:-0.909310\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:159\n",
            "loss(total):-0.002965\n",
            "recons_loss:0.004954\n",
            "grad_loss:0.101622\n",
            "dice_loss:-0.893501\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:160\n",
            "loss(total):-0.001947\n",
            "recons_loss:0.005689\n",
            "grad_loss:0.115005\n",
            "dice_loss:-0.878593\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:161\n",
            "loss(total):-0.003846\n",
            "recons_loss:0.004133\n",
            "grad_loss:0.106191\n",
            "dice_loss:-0.904126\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:162\n",
            "loss(total):-0.004314\n",
            "recons_loss:0.003832\n",
            "grad_loss:0.080111\n",
            "dice_loss:-0.894736\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:163\n",
            "loss(total):-0.004329\n",
            "recons_loss:0.003598\n",
            "grad_loss:0.098940\n",
            "dice_loss:-0.891626\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:164\n",
            "loss(total):-0.002179\n",
            "recons_loss:0.005668\n",
            "grad_loss:0.105015\n",
            "dice_loss:-0.889634\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:165\n",
            "loss(total):-0.003959\n",
            "recons_loss:0.004055\n",
            "grad_loss:0.082771\n",
            "dice_loss:-0.884224\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:166\n",
            "loss(total):-0.003834\n",
            "recons_loss:0.004267\n",
            "grad_loss:0.086088\n",
            "dice_loss:-0.896154\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:167\n",
            "loss(total):-0.001779\n",
            "recons_loss:0.005580\n",
            "grad_loss:0.133712\n",
            "dice_loss:-0.869522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:168\n",
            "loss(total):-0.002263\n",
            "recons_loss:0.005289\n",
            "grad_loss:0.125298\n",
            "dice_loss:-0.880505\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:169\n",
            "loss(total):-0.003538\n",
            "recons_loss:0.004225\n",
            "grad_loss:0.105784\n",
            "dice_loss:-0.882150\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:170\n",
            "loss(total):-0.006022\n",
            "recons_loss:0.002373\n",
            "grad_loss:0.061706\n",
            "dice_loss:-0.901148\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:171\n",
            "loss(total):-0.004636\n",
            "recons_loss:0.003580\n",
            "grad_loss:0.085021\n",
            "dice_loss:-0.906655\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:172\n",
            "loss(total):-0.005009\n",
            "recons_loss:0.003215\n",
            "grad_loss:0.079789\n",
            "dice_loss:-0.902223\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:173\n",
            "loss(total):-0.004364\n",
            "recons_loss:0.003722\n",
            "grad_loss:0.089882\n",
            "dice_loss:-0.898561\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:174\n",
            "loss(total):-0.003690\n",
            "recons_loss:0.004316\n",
            "grad_loss:0.097789\n",
            "dice_loss:-0.898362\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:175\n",
            "loss(total):-0.005773\n",
            "recons_loss:0.002658\n",
            "grad_loss:0.067369\n",
            "dice_loss:-0.910418\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:176\n",
            "loss(total):-0.003195\n",
            "recons_loss:0.004731\n",
            "grad_loss:0.091644\n",
            "dice_loss:-0.884259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:177\n",
            "loss(total):-0.004344\n",
            "recons_loss:0.003650\n",
            "grad_loss:0.090758\n",
            "dice_loss:-0.890252\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:178\n",
            "loss(total):-0.005104\n",
            "recons_loss:0.003170\n",
            "grad_loss:0.092312\n",
            "dice_loss:-0.919762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:179\n",
            "loss(total):-0.003058\n",
            "recons_loss:0.004768\n",
            "grad_loss:0.111445\n",
            "dice_loss:-0.893952\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:180\n",
            "loss(total):-0.005138\n",
            "recons_loss:0.003105\n",
            "grad_loss:0.065315\n",
            "dice_loss:-0.889594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:181\n",
            "loss(total):-0.003883\n",
            "recons_loss:0.004217\n",
            "grad_loss:0.083105\n",
            "dice_loss:-0.893077\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:182\n",
            "loss(total):-0.003518\n",
            "recons_loss:0.004576\n",
            "grad_loss:0.083173\n",
            "dice_loss:-0.892581\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:183\n",
            "loss(total):-0.003687\n",
            "recons_loss:0.004068\n",
            "grad_loss:0.099875\n",
            "dice_loss:-0.875445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:184\n",
            "loss(total):-0.003301\n",
            "recons_loss:0.004718\n",
            "grad_loss:0.090131\n",
            "dice_loss:-0.892022\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:185\n",
            "loss(total):-0.003387\n",
            "recons_loss:0.004360\n",
            "grad_loss:0.109612\n",
            "dice_loss:-0.884266\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:186\n",
            "loss(total):-0.003657\n",
            "recons_loss:0.004330\n",
            "grad_loss:0.098290\n",
            "dice_loss:-0.896942\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:187\n",
            "loss(total):-0.002323\n",
            "recons_loss:0.005394\n",
            "grad_loss:0.109083\n",
            "dice_loss:-0.880807\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:188\n",
            "loss(total):-0.003503\n",
            "recons_loss:0.004404\n",
            "grad_loss:0.110032\n",
            "dice_loss:-0.900685\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:189\n",
            "loss(total):-0.004269\n",
            "recons_loss:0.003586\n",
            "grad_loss:0.111296\n",
            "dice_loss:-0.896815\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:190\n",
            "loss(total):-0.003413\n",
            "recons_loss:0.004376\n",
            "grad_loss:0.118420\n",
            "dice_loss:-0.897355\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:191\n",
            "loss(total):-0.003171\n",
            "recons_loss:0.004428\n",
            "grad_loss:0.134444\n",
            "dice_loss:-0.894370\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:192\n",
            "loss(total):-0.003900\n",
            "recons_loss:0.004049\n",
            "grad_loss:0.093441\n",
            "dice_loss:-0.888315\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:193\n",
            "loss(total):-0.003397\n",
            "recons_loss:0.004475\n",
            "grad_loss:0.092949\n",
            "dice_loss:-0.880132\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:194\n",
            "loss(total):-0.004009\n",
            "recons_loss:0.004036\n",
            "grad_loss:0.086228\n",
            "dice_loss:-0.890755\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:195\n",
            "loss(total):-0.004120\n",
            "recons_loss:0.003790\n",
            "grad_loss:0.088352\n",
            "dice_loss:-0.879348\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:196\n",
            "loss(total):-0.003020\n",
            "recons_loss:0.004732\n",
            "grad_loss:0.108226\n",
            "dice_loss:-0.883453\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:197\n",
            "loss(total):-0.001759\n",
            "recons_loss:0.005865\n",
            "grad_loss:0.120250\n",
            "dice_loss:-0.882655\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:198\n",
            "loss(total):-0.003593\n",
            "recons_loss:0.004380\n",
            "grad_loss:0.089717\n",
            "dice_loss:-0.887035\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:199\n",
            "loss(total):-0.003993\n",
            "recons_loss:0.003821\n",
            "grad_loss:0.099151\n",
            "dice_loss:-0.880614\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:200\n",
            "loss(total):-0.004786\n",
            "recons_loss:0.003636\n",
            "grad_loss:0.063563\n",
            "dice_loss:-0.905702\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:201\n",
            "loss(total):-0.000391\n",
            "recons_loss:0.007168\n",
            "grad_loss:0.125021\n",
            "dice_loss:-0.880954\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:202\n",
            "loss(total):-0.004309\n",
            "recons_loss:0.003835\n",
            "grad_loss:0.079601\n",
            "dice_loss:-0.894027\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:203\n",
            "loss(total):-0.003126\n",
            "recons_loss:0.004727\n",
            "grad_loss:0.098891\n",
            "dice_loss:-0.884135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:204\n",
            "loss(total):-0.002801\n",
            "recons_loss:0.005045\n",
            "grad_loss:0.104491\n",
            "dice_loss:-0.889108\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:205\n",
            "loss(total):-0.003112\n",
            "recons_loss:0.004530\n",
            "grad_loss:0.112852\n",
            "dice_loss:-0.877047\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:206\n",
            "loss(total):-0.003247\n",
            "recons_loss:0.004668\n",
            "grad_loss:0.083963\n",
            "dice_loss:-0.875442\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:207\n",
            "loss(total):-0.003437\n",
            "recons_loss:0.004682\n",
            "grad_loss:0.091773\n",
            "dice_loss:-0.903681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:208\n",
            "loss(total):-0.004254\n",
            "recons_loss:0.004011\n",
            "grad_loss:0.073287\n",
            "dice_loss:-0.899854\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:209\n",
            "loss(total):-0.001900\n",
            "recons_loss:0.005992\n",
            "grad_loss:0.104203\n",
            "dice_loss:-0.893388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:210\n",
            "loss(total):-0.002459\n",
            "recons_loss:0.005425\n",
            "grad_loss:0.096006\n",
            "dice_loss:-0.884424\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:211\n",
            "loss(total):-0.003621\n",
            "recons_loss:0.004383\n",
            "grad_loss:0.100854\n",
            "dice_loss:-0.901265\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:212\n",
            "loss(total):-0.002524\n",
            "recons_loss:0.005125\n",
            "grad_loss:0.128170\n",
            "dice_loss:-0.893094\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:213\n",
            "loss(total):-0.002261\n",
            "recons_loss:0.005326\n",
            "grad_loss:0.135792\n",
            "dice_loss:-0.894504\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:214\n",
            "loss(total):-0.003551\n",
            "recons_loss:0.004354\n",
            "grad_loss:0.096048\n",
            "dice_loss:-0.886583\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:215\n",
            "loss(total):-0.002771\n",
            "recons_loss:0.005173\n",
            "grad_loss:0.101738\n",
            "dice_loss:-0.896132\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:216\n",
            "loss(total):-0.002206\n",
            "recons_loss:0.005670\n",
            "grad_loss:0.102369\n",
            "dice_loss:-0.889947\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:217\n",
            "loss(total):-0.003026\n",
            "recons_loss:0.004707\n",
            "grad_loss:0.105088\n",
            "dice_loss:-0.878403\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:218\n",
            "loss(total):-0.003426\n",
            "recons_loss:0.004365\n",
            "grad_loss:0.101734\n",
            "dice_loss:-0.880801\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:219\n",
            "loss(total):-0.004641\n",
            "recons_loss:0.003343\n",
            "grad_loss:0.086188\n",
            "dice_loss:-0.884571\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:220\n",
            "loss(total):-0.002849\n",
            "recons_loss:0.004954\n",
            "grad_loss:0.109269\n",
            "dice_loss:-0.889503\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:221\n",
            "loss(total):-0.002229\n",
            "recons_loss:0.005440\n",
            "grad_loss:0.120887\n",
            "dice_loss:-0.887764\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:222\n",
            "loss(total):-0.003464\n",
            "recons_loss:0.004388\n",
            "grad_loss:0.105977\n",
            "dice_loss:-0.891164\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:223\n",
            "loss(total):-0.003325\n",
            "recons_loss:0.004671\n",
            "grad_loss:0.089405\n",
            "dice_loss:-0.889046\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:224\n",
            "loss(total):-0.002395\n",
            "recons_loss:0.005523\n",
            "grad_loss:0.099392\n",
            "dice_loss:-0.891126\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:225\n",
            "loss(total):-0.003937\n",
            "recons_loss:0.003941\n",
            "grad_loss:0.092407\n",
            "dice_loss:-0.880188\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:226\n",
            "loss(total):-0.003343\n",
            "recons_loss:0.004726\n",
            "grad_loss:0.087661\n",
            "dice_loss:-0.894621\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:227\n",
            "loss(total):-0.002402\n",
            "recons_loss:0.005286\n",
            "grad_loss:0.114500\n",
            "dice_loss:-0.883316\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:228\n",
            "loss(total):-0.005430\n",
            "recons_loss:0.002834\n",
            "grad_loss:0.074690\n",
            "dice_loss:-0.901137\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:229\n",
            "loss(total):-0.006126\n",
            "recons_loss:0.002390\n",
            "grad_loss:0.055346\n",
            "dice_loss:-0.906935\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:230\n",
            "loss(total):-0.004557\n",
            "recons_loss:0.003602\n",
            "grad_loss:0.080557\n",
            "dice_loss:-0.896430\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:231\n",
            "loss(total):-0.003563\n",
            "recons_loss:0.004323\n",
            "grad_loss:0.088432\n",
            "dice_loss:-0.877036\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:232\n",
            "loss(total):-0.003672\n",
            "recons_loss:0.004271\n",
            "grad_loss:0.083050\n",
            "dice_loss:-0.877349\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:233\n",
            "loss(total):-0.004306\n",
            "recons_loss:0.003869\n",
            "grad_loss:0.077597\n",
            "dice_loss:-0.895129\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:234\n",
            "loss(total):-0.002673\n",
            "recons_loss:0.005159\n",
            "grad_loss:0.109515\n",
            "dice_loss:-0.892670\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:235\n",
            "loss(total):-0.003962\n",
            "recons_loss:0.004005\n",
            "grad_loss:0.097364\n",
            "dice_loss:-0.894050\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:236\n",
            "loss(total):-0.002669\n",
            "recons_loss:0.005100\n",
            "grad_loss:0.113744\n",
            "dice_loss:-0.890664\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:237\n",
            "loss(total):-0.002977\n",
            "recons_loss:0.004835\n",
            "grad_loss:0.104047\n",
            "dice_loss:-0.885238\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:238\n",
            "loss(total):-0.003526\n",
            "recons_loss:0.004321\n",
            "grad_loss:0.097853\n",
            "dice_loss:-0.882579\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:239\n",
            "loss(total):-0.002466\n",
            "recons_loss:0.005269\n",
            "grad_loss:0.112979\n",
            "dice_loss:-0.886467\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:240\n",
            "loss(total):-0.002486\n",
            "recons_loss:0.005281\n",
            "grad_loss:0.105381\n",
            "dice_loss:-0.882083\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:241\n",
            "loss(total):-0.004772\n",
            "recons_loss:0.003568\n",
            "grad_loss:0.063100\n",
            "dice_loss:-0.897098\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:242\n",
            "loss(total):-0.003787\n",
            "recons_loss:0.004307\n",
            "grad_loss:0.095987\n",
            "dice_loss:-0.905355\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:243\n",
            "loss(total):-0.003529\n",
            "recons_loss:0.004386\n",
            "grad_loss:0.090363\n",
            "dice_loss:-0.881838\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:244\n",
            "loss(total):-0.002788\n",
            "recons_loss:0.005005\n",
            "grad_loss:0.116695\n",
            "dice_loss:-0.896004\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:245\n",
            "loss(total):-0.004377\n",
            "recons_loss:0.003862\n",
            "grad_loss:0.074873\n",
            "dice_loss:-0.898803\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:246\n",
            "loss(total):-0.004926\n",
            "recons_loss:0.003168\n",
            "grad_loss:0.092135\n",
            "dice_loss:-0.901541\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:247\n",
            "loss(total):-0.004235\n",
            "recons_loss:0.003845\n",
            "grad_loss:0.088928\n",
            "dice_loss:-0.896939\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:248\n",
            "loss(total):-0.002806\n",
            "recons_loss:0.004891\n",
            "grad_loss:0.107461\n",
            "dice_loss:-0.877163\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:249\n",
            "loss(total):-0.003079\n",
            "recons_loss:0.004635\n",
            "grad_loss:0.105034\n",
            "dice_loss:-0.876404\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:250\n",
            "loss(total):-0.002623\n",
            "recons_loss:0.005140\n",
            "grad_loss:0.108589\n",
            "dice_loss:-0.884878\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:251\n",
            "loss(total):-0.003952\n",
            "recons_loss:0.004060\n",
            "grad_loss:0.088173\n",
            "dice_loss:-0.889362\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:252\n",
            "loss(total):-0.002411\n",
            "recons_loss:0.005180\n",
            "grad_loss:0.106848\n",
            "dice_loss:-0.865996\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:253\n",
            "loss(total):-0.003024\n",
            "recons_loss:0.004812\n",
            "grad_loss:0.089388\n",
            "dice_loss:-0.873011\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:254\n",
            "loss(total):-0.003124\n",
            "recons_loss:0.004798\n",
            "grad_loss:0.094252\n",
            "dice_loss:-0.886417\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:255\n",
            "loss(total):-0.003609\n",
            "recons_loss:0.004331\n",
            "grad_loss:0.093862\n",
            "dice_loss:-0.887837\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:256\n",
            "loss(total):-0.003567\n",
            "recons_loss:0.004278\n",
            "grad_loss:0.104355\n",
            "dice_loss:-0.888847\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:257\n",
            "loss(total):-0.002975\n",
            "recons_loss:0.004746\n",
            "grad_loss:0.108304\n",
            "dice_loss:-0.880364\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:258\n",
            "loss(total):-0.002267\n",
            "recons_loss:0.005438\n",
            "grad_loss:0.113637\n",
            "dice_loss:-0.884111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:259\n",
            "loss(total):-0.004502\n",
            "recons_loss:0.003535\n",
            "grad_loss:0.085765\n",
            "dice_loss:-0.889493\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:260\n",
            "loss(total):-0.003191\n",
            "recons_loss:0.004756\n",
            "grad_loss:0.096001\n",
            "dice_loss:-0.890669\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:261\n",
            "loss(total):-0.003589\n",
            "recons_loss:0.004329\n",
            "grad_loss:0.099097\n",
            "dice_loss:-0.890876\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:262\n",
            "loss(total):-0.003584\n",
            "recons_loss:0.004236\n",
            "grad_loss:0.105343\n",
            "dice_loss:-0.887359\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:263\n",
            "loss(total):-0.003612\n",
            "recons_loss:0.004363\n",
            "grad_loss:0.088796\n",
            "dice_loss:-0.886325\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:264\n",
            "loss(total):-0.003894\n",
            "recons_loss:0.004021\n",
            "grad_loss:0.102749\n",
            "dice_loss:-0.894265\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:265\n",
            "loss(total):-0.004193\n",
            "recons_loss:0.003922\n",
            "grad_loss:0.075309\n",
            "dice_loss:-0.886790\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:266\n",
            "loss(total):-0.002692\n",
            "recons_loss:0.005090\n",
            "grad_loss:0.107366\n",
            "dice_loss:-0.885521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:267\n",
            "loss(total):-0.003966\n",
            "recons_loss:0.003943\n",
            "grad_loss:0.099180\n",
            "dice_loss:-0.890147\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:268\n",
            "loss(total):-0.003296\n",
            "recons_loss:0.004672\n",
            "grad_loss:0.102032\n",
            "dice_loss:-0.898825\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:269\n",
            "loss(total):-0.002798\n",
            "recons_loss:0.005040\n",
            "grad_loss:0.113902\n",
            "dice_loss:-0.897663\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:0\n",
            "loss(total):-0.003785\n",
            "recons_loss:0.004218\n",
            "grad_loss:0.093062\n",
            "dice_loss:-0.893433\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:1\n",
            "loss(total):-0.003637\n",
            "recons_loss:0.004089\n",
            "grad_loss:0.110538\n",
            "dice_loss:-0.883159\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:2\n",
            "loss(total):-0.004032\n",
            "recons_loss:0.003941\n",
            "grad_loss:0.081092\n",
            "dice_loss:-0.878413\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:3\n",
            "loss(total):-0.003108\n",
            "recons_loss:0.004739\n",
            "grad_loss:0.091673\n",
            "dice_loss:-0.876367\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:4\n",
            "loss(total):-0.004072\n",
            "recons_loss:0.003953\n",
            "grad_loss:0.083135\n",
            "dice_loss:-0.885606\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:5\n",
            "loss(total):-0.003472\n",
            "recons_loss:0.004377\n",
            "grad_loss:0.100853\n",
            "dice_loss:-0.885775\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:6\n",
            "loss(total):-0.002284\n",
            "recons_loss:0.005497\n",
            "grad_loss:0.116548\n",
            "dice_loss:-0.894609\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:7\n",
            "loss(total):-0.003388\n",
            "recons_loss:0.004384\n",
            "grad_loss:0.115755\n",
            "dice_loss:-0.892932\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:8\n",
            "loss(total):-0.004052\n",
            "recons_loss:0.003857\n",
            "grad_loss:0.108308\n",
            "dice_loss:-0.899182\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:9\n",
            "loss(total):-0.003812\n",
            "recons_loss:0.004116\n",
            "grad_loss:0.097681\n",
            "dice_loss:-0.890509\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:10\n",
            "loss(total):-0.003501\n",
            "recons_loss:0.004459\n",
            "grad_loss:0.093728\n",
            "dice_loss:-0.889719\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:11\n",
            "loss(total):-0.001555\n",
            "recons_loss:0.005923\n",
            "grad_loss:0.116271\n",
            "dice_loss:-0.864071\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:12\n",
            "loss(total):-0.002981\n",
            "recons_loss:0.004843\n",
            "grad_loss:0.099833\n",
            "dice_loss:-0.882270\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:13\n",
            "loss(total):-0.001522\n",
            "recons_loss:0.006099\n",
            "grad_loss:0.120175\n",
            "dice_loss:-0.882218\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:14\n",
            "loss(total):-0.003303\n",
            "recons_loss:0.004647\n",
            "grad_loss:0.096673\n",
            "dice_loss:-0.891705\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:15\n",
            "loss(total):-0.002819\n",
            "recons_loss:0.005040\n",
            "grad_loss:0.116533\n",
            "dice_loss:-0.902416\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:16\n",
            "loss(total):-0.004102\n",
            "recons_loss:0.004067\n",
            "grad_loss:0.074418\n",
            "dice_loss:-0.891330\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:17\n",
            "loss(total):-0.002319\n",
            "recons_loss:0.005297\n",
            "grad_loss:0.134477\n",
            "dice_loss:-0.896076\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:18\n",
            "loss(total):-0.002898\n",
            "recons_loss:0.004891\n",
            "grad_loss:0.099500\n",
            "dice_loss:-0.878358\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:19\n",
            "loss(total):-0.002790\n",
            "recons_loss:0.004957\n",
            "grad_loss:0.122018\n",
            "dice_loss:-0.896738\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:20\n",
            "loss(total):-0.002518\n",
            "recons_loss:0.005218\n",
            "grad_loss:0.108205\n",
            "dice_loss:-0.881803\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:21\n",
            "loss(total):-0.004432\n",
            "recons_loss:0.003693\n",
            "grad_loss:0.086221\n",
            "dice_loss:-0.898664\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:22\n",
            "loss(total):-0.003270\n",
            "recons_loss:0.004542\n",
            "grad_loss:0.090663\n",
            "dice_loss:-0.871814\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:23\n",
            "loss(total):-0.002216\n",
            "recons_loss:0.005308\n",
            "grad_loss:0.131684\n",
            "dice_loss:-0.884069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:24\n",
            "loss(total):-0.003063\n",
            "recons_loss:0.004775\n",
            "grad_loss:0.091052\n",
            "dice_loss:-0.874896\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:25\n",
            "loss(total):-0.002415\n",
            "recons_loss:0.005059\n",
            "grad_loss:0.124257\n",
            "dice_loss:-0.871710\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:26\n",
            "loss(total):-0.003897\n",
            "recons_loss:0.004013\n",
            "grad_loss:0.089954\n",
            "dice_loss:-0.880984\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:27\n",
            "loss(total):-0.004038\n",
            "recons_loss:0.003925\n",
            "grad_loss:0.098327\n",
            "dice_loss:-0.894574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:28\n",
            "loss(total):-0.002468\n",
            "recons_loss:0.005264\n",
            "grad_loss:0.109508\n",
            "dice_loss:-0.882784\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:29\n",
            "loss(total):-0.003409\n",
            "recons_loss:0.004449\n",
            "grad_loss:0.087297\n",
            "dice_loss:-0.873045\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:30\n",
            "loss(total):-0.003797\n",
            "recons_loss:0.004251\n",
            "grad_loss:0.092929\n",
            "dice_loss:-0.897711\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:31\n",
            "loss(total):-0.002984\n",
            "recons_loss:0.004758\n",
            "grad_loss:0.108622\n",
            "dice_loss:-0.882820\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:32\n",
            "loss(total):-0.002607\n",
            "recons_loss:0.005200\n",
            "grad_loss:0.116718\n",
            "dice_loss:-0.897341\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:33\n",
            "loss(total):-0.004333\n",
            "recons_loss:0.003774\n",
            "grad_loss:0.088724\n",
            "dice_loss:-0.899385\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:34\n",
            "loss(total):-0.003364\n",
            "recons_loss:0.004459\n",
            "grad_loss:0.102123\n",
            "dice_loss:-0.884397\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:35\n",
            "loss(total):-0.004018\n",
            "recons_loss:0.003923\n",
            "grad_loss:0.102193\n",
            "dice_loss:-0.896317\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:36\n",
            "loss(total):-0.003354\n",
            "recons_loss:0.004647\n",
            "grad_loss:0.086017\n",
            "dice_loss:-0.886167\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:37\n",
            "loss(total):-0.005061\n",
            "recons_loss:0.003228\n",
            "grad_loss:0.077911\n",
            "dice_loss:-0.906778\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:38\n",
            "loss(total):-0.004795\n",
            "recons_loss:0.003338\n",
            "grad_loss:0.069832\n",
            "dice_loss:-0.883111\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:39\n",
            "loss(total):-0.003872\n",
            "recons_loss:0.004183\n",
            "grad_loss:0.085200\n",
            "dice_loss:-0.890646\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:40\n",
            "loss(total):-0.004829\n",
            "recons_loss:0.003368\n",
            "grad_loss:0.074218\n",
            "dice_loss:-0.893936\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:41\n",
            "loss(total):-0.001846\n",
            "recons_loss:0.005692\n",
            "grad_loss:0.120787\n",
            "dice_loss:-0.874582\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:42\n",
            "loss(total):-0.004368\n",
            "recons_loss:0.003879\n",
            "grad_loss:0.072051\n",
            "dice_loss:-0.896773\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:43\n",
            "loss(total):-0.002424\n",
            "recons_loss:0.005162\n",
            "grad_loss:0.120538\n",
            "dice_loss:-0.879098\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:44\n",
            "loss(total):-0.003486\n",
            "recons_loss:0.004286\n",
            "grad_loss:0.104419\n",
            "dice_loss:-0.881612\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:45\n",
            "loss(total):-0.003721\n",
            "recons_loss:0.004072\n",
            "grad_loss:0.106640\n",
            "dice_loss:-0.885935\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:46\n",
            "loss(total):-0.004482\n",
            "recons_loss:0.003554\n",
            "grad_loss:0.090890\n",
            "dice_loss:-0.894477\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:47\n",
            "loss(total):-0.002859\n",
            "recons_loss:0.005198\n",
            "grad_loss:0.091915\n",
            "dice_loss:-0.897571\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:48\n",
            "loss(total):-0.004372\n",
            "recons_loss:0.003808\n",
            "grad_loss:0.087018\n",
            "dice_loss:-0.904950\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:49\n",
            "loss(total):-0.005436\n",
            "recons_loss:0.002842\n",
            "grad_loss:0.078126\n",
            "dice_loss:-0.905964\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:50\n",
            "loss(total):-0.004057\n",
            "recons_loss:0.003906\n",
            "grad_loss:0.090858\n",
            "dice_loss:-0.887135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:51\n",
            "loss(total):-0.003689\n",
            "recons_loss:0.004159\n",
            "grad_loss:0.102118\n",
            "dice_loss:-0.886891\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:52\n",
            "loss(total):-0.003921\n",
            "recons_loss:0.003891\n",
            "grad_loss:0.095858\n",
            "dice_loss:-0.877010\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:53\n",
            "loss(total):-0.003774\n",
            "recons_loss:0.004160\n",
            "grad_loss:0.095936\n",
            "dice_loss:-0.889342\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:54\n",
            "loss(total):-0.002852\n",
            "recons_loss:0.004846\n",
            "grad_loss:0.116307\n",
            "dice_loss:-0.886140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:55\n",
            "loss(total):-0.003232\n",
            "recons_loss:0.004752\n",
            "grad_loss:0.097901\n",
            "dice_loss:-0.896362\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:56\n",
            "loss(total):-0.003563\n",
            "recons_loss:0.004213\n",
            "grad_loss:0.101162\n",
            "dice_loss:-0.878698\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:57\n",
            "loss(total):-0.002706\n",
            "recons_loss:0.004916\n",
            "grad_loss:0.120658\n",
            "dice_loss:-0.882806\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:58\n",
            "loss(total):-0.003763\n",
            "recons_loss:0.004287\n",
            "grad_loss:0.087465\n",
            "dice_loss:-0.892407\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:59\n",
            "loss(total):-0.004941\n",
            "recons_loss:0.003243\n",
            "grad_loss:0.086155\n",
            "dice_loss:-0.904542\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:60\n",
            "loss(total):-0.002807\n",
            "recons_loss:0.004868\n",
            "grad_loss:0.120447\n",
            "dice_loss:-0.887929\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:61\n",
            "loss(total):-0.004563\n",
            "recons_loss:0.003637\n",
            "grad_loss:0.064312\n",
            "dice_loss:-0.884363\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:62\n",
            "loss(total):-0.003186\n",
            "recons_loss:0.004836\n",
            "grad_loss:0.094221\n",
            "dice_loss:-0.896383\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:63\n",
            "loss(total):-0.003002\n",
            "recons_loss:0.004897\n",
            "grad_loss:0.101494\n",
            "dice_loss:-0.891463\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:64\n",
            "loss(total):-0.004055\n",
            "recons_loss:0.003943\n",
            "grad_loss:0.085457\n",
            "dice_loss:-0.885267\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:65\n",
            "loss(total):-0.003073\n",
            "recons_loss:0.004753\n",
            "grad_loss:0.114139\n",
            "dice_loss:-0.896764\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:66\n",
            "loss(total):-0.002925\n",
            "recons_loss:0.004992\n",
            "grad_loss:0.100932\n",
            "dice_loss:-0.892622\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:67\n",
            "loss(total):-0.003960\n",
            "recons_loss:0.004177\n",
            "grad_loss:0.088132\n",
            "dice_loss:-0.901857\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:68\n",
            "loss(total):-0.003348\n",
            "recons_loss:0.004478\n",
            "grad_loss:0.108933\n",
            "dice_loss:-0.891458\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:69\n",
            "loss(total):-0.003971\n",
            "recons_loss:0.003878\n",
            "grad_loss:0.098400\n",
            "dice_loss:-0.883266\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:70\n",
            "loss(total):-0.003516\n",
            "recons_loss:0.004511\n",
            "grad_loss:0.096421\n",
            "dice_loss:-0.899143\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:71\n",
            "loss(total):-0.001500\n",
            "recons_loss:0.006042\n",
            "grad_loss:0.143252\n",
            "dice_loss:-0.897370\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:72\n",
            "loss(total):-0.002864\n",
            "recons_loss:0.004913\n",
            "grad_loss:0.109410\n",
            "dice_loss:-0.887093\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:73\n",
            "loss(total):-0.004007\n",
            "recons_loss:0.003958\n",
            "grad_loss:0.084205\n",
            "dice_loss:-0.880725\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:74\n",
            "loss(total):-0.002998\n",
            "recons_loss:0.004843\n",
            "grad_loss:0.102337\n",
            "dice_loss:-0.886466\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:75\n",
            "loss(total):-0.005396\n",
            "recons_loss:0.003003\n",
            "grad_loss:0.067524\n",
            "dice_loss:-0.907482\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:76\n",
            "loss(total):-0.001977\n",
            "recons_loss:0.005734\n",
            "grad_loss:0.110389\n",
            "dice_loss:-0.881475\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:77\n",
            "loss(total):-0.000486\n",
            "recons_loss:0.006783\n",
            "grad_loss:0.156474\n",
            "dice_loss:-0.883441\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:78\n",
            "loss(total):-0.004094\n",
            "recons_loss:0.003824\n",
            "grad_loss:0.101335\n",
            "dice_loss:-0.893152\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:79\n",
            "loss(total):-0.002643\n",
            "recons_loss:0.005130\n",
            "grad_loss:0.105048\n",
            "dice_loss:-0.882322\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:80\n",
            "loss(total):-0.005053\n",
            "recons_loss:0.003095\n",
            "grad_loss:0.076380\n",
            "dice_loss:-0.891174\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:81\n",
            "loss(total):-0.004445\n",
            "recons_loss:0.003710\n",
            "grad_loss:0.078095\n",
            "dice_loss:-0.893602\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:82\n",
            "loss(total):-0.004111\n",
            "recons_loss:0.003815\n",
            "grad_loss:0.094429\n",
            "dice_loss:-0.887028\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:83\n",
            "loss(total):-0.004341\n",
            "recons_loss:0.003684\n",
            "grad_loss:0.080712\n",
            "dice_loss:-0.883274\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:84\n",
            "loss(total):-0.004931\n",
            "recons_loss:0.003240\n",
            "grad_loss:0.083649\n",
            "dice_loss:-0.900774\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:85\n",
            "loss(total):-0.004306\n",
            "recons_loss:0.003722\n",
            "grad_loss:0.088982\n",
            "dice_loss:-0.891821\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:86\n",
            "loss(total):-0.004066\n",
            "recons_loss:0.003936\n",
            "grad_loss:0.100842\n",
            "dice_loss:-0.901009\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:87\n",
            "loss(total):-0.003490\n",
            "recons_loss:0.004553\n",
            "grad_loss:0.091689\n",
            "dice_loss:-0.895956\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:88\n",
            "loss(total):-0.003298\n",
            "recons_loss:0.004458\n",
            "grad_loss:0.097652\n",
            "dice_loss:-0.873254\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:89\n",
            "loss(total):-0.002832\n",
            "recons_loss:0.004907\n",
            "grad_loss:0.113278\n",
            "dice_loss:-0.887110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:90\n",
            "loss(total):-0.004169\n",
            "recons_loss:0.004007\n",
            "grad_loss:0.080571\n",
            "dice_loss:-0.898115\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:91\n",
            "loss(total):-0.002904\n",
            "recons_loss:0.004926\n",
            "grad_loss:0.110807\n",
            "dice_loss:-0.893869\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:92\n",
            "loss(total):-0.004322\n",
            "recons_loss:0.003765\n",
            "grad_loss:0.085363\n",
            "dice_loss:-0.894014\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:93\n",
            "loss(total):-0.003355\n",
            "recons_loss:0.004652\n",
            "grad_loss:0.090780\n",
            "dice_loss:-0.891427\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:94\n",
            "loss(total):-0.002195\n",
            "recons_loss:0.005443\n",
            "grad_loss:0.120535\n",
            "dice_loss:-0.884344\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:95\n",
            "loss(total):-0.003477\n",
            "recons_loss:0.004337\n",
            "grad_loss:0.108879\n",
            "dice_loss:-0.890291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:96\n",
            "loss(total):-0.004437\n",
            "recons_loss:0.003672\n",
            "grad_loss:0.077906\n",
            "dice_loss:-0.888785\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:97\n",
            "loss(total):-0.002367\n",
            "recons_loss:0.005334\n",
            "grad_loss:0.120892\n",
            "dice_loss:-0.891044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:98\n",
            "loss(total):-0.002563\n",
            "recons_loss:0.005188\n",
            "grad_loss:0.109349\n",
            "dice_loss:-0.884521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:99\n",
            "loss(total):-0.003136\n",
            "recons_loss:0.004603\n",
            "grad_loss:0.117426\n",
            "dice_loss:-0.891419\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:100\n",
            "loss(total):-0.002918\n",
            "recons_loss:0.004799\n",
            "grad_loss:0.109296\n",
            "dice_loss:-0.881059\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:101\n",
            "loss(total):-0.003503\n",
            "recons_loss:0.004287\n",
            "grad_loss:0.091594\n",
            "dice_loss:-0.870600\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:102\n",
            "loss(total):-0.003512\n",
            "recons_loss:0.004343\n",
            "grad_loss:0.101329\n",
            "dice_loss:-0.886835\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:103\n",
            "loss(total):-0.004888\n",
            "recons_loss:0.003265\n",
            "grad_loss:0.086325\n",
            "dice_loss:-0.901666\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:104\n",
            "loss(total):-0.004619\n",
            "recons_loss:0.003447\n",
            "grad_loss:0.088733\n",
            "dice_loss:-0.895303\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:105\n",
            "loss(total):-0.003267\n",
            "recons_loss:0.004621\n",
            "grad_loss:0.106636\n",
            "dice_loss:-0.895444\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:106\n",
            "loss(total):-0.002923\n",
            "recons_loss:0.004725\n",
            "grad_loss:0.122152\n",
            "dice_loss:-0.886968\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:107\n",
            "loss(total):-0.002041\n",
            "recons_loss:0.005591\n",
            "grad_loss:0.124495\n",
            "dice_loss:-0.887616\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:108\n",
            "loss(total):-0.003677\n",
            "recons_loss:0.004273\n",
            "grad_loss:0.090008\n",
            "dice_loss:-0.884945\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:109\n",
            "loss(total):-0.003155\n",
            "recons_loss:0.004933\n",
            "grad_loss:0.098303\n",
            "dice_loss:-0.907056\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:110\n",
            "loss(total):-0.004203\n",
            "recons_loss:0.003993\n",
            "grad_loss:0.090342\n",
            "dice_loss:-0.909963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:111\n",
            "loss(total):-0.003686\n",
            "recons_loss:0.004288\n",
            "grad_loss:0.092531\n",
            "dice_loss:-0.889961\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:112\n",
            "loss(total):-0.003793\n",
            "recons_loss:0.004031\n",
            "grad_loss:0.101535\n",
            "dice_loss:-0.883958\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:113\n",
            "loss(total):-0.003144\n",
            "recons_loss:0.004741\n",
            "grad_loss:0.109529\n",
            "dice_loss:-0.898044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:114\n",
            "loss(total):-0.002343\n",
            "recons_loss:0.005464\n",
            "grad_loss:0.104141\n",
            "dice_loss:-0.884786\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:115\n",
            "loss(total):-0.003707\n",
            "recons_loss:0.004462\n",
            "grad_loss:0.088771\n",
            "dice_loss:-0.905624\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:116\n",
            "loss(total):-0.004016\n",
            "recons_loss:0.003999\n",
            "grad_loss:0.090630\n",
            "dice_loss:-0.892120\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:117\n",
            "loss(total):-0.004287\n",
            "recons_loss:0.003855\n",
            "grad_loss:0.091918\n",
            "dice_loss:-0.906145\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:118\n",
            "loss(total):-0.002149\n",
            "recons_loss:0.005389\n",
            "grad_loss:0.142150\n",
            "dice_loss:-0.895997\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:119\n",
            "loss(total):-0.002682\n",
            "recons_loss:0.005017\n",
            "grad_loss:0.123694\n",
            "dice_loss:-0.893570\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:120\n",
            "loss(total):-0.004084\n",
            "recons_loss:0.003845\n",
            "grad_loss:0.088945\n",
            "dice_loss:-0.881825\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:121\n",
            "loss(total):-0.003423\n",
            "recons_loss:0.004277\n",
            "grad_loss:0.099203\n",
            "dice_loss:-0.869259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:122\n",
            "loss(total):-0.003294\n",
            "recons_loss:0.004674\n",
            "grad_loss:0.091047\n",
            "dice_loss:-0.887808\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:123\n",
            "loss(total):-0.003184\n",
            "recons_loss:0.004600\n",
            "grad_loss:0.096471\n",
            "dice_loss:-0.874901\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:124\n",
            "loss(total):-0.002154\n",
            "recons_loss:0.005461\n",
            "grad_loss:0.124726\n",
            "dice_loss:-0.886200\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:125\n",
            "loss(total):-0.003530\n",
            "recons_loss:0.004312\n",
            "grad_loss:0.093443\n",
            "dice_loss:-0.877579\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:126\n",
            "loss(total):-0.004433\n",
            "recons_loss:0.003554\n",
            "grad_loss:0.099113\n",
            "dice_loss:-0.897841\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:127\n",
            "loss(total):-0.002476\n",
            "recons_loss:0.005100\n",
            "grad_loss:0.128599\n",
            "dice_loss:-0.886208\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:128\n",
            "loss(total):-0.004243\n",
            "recons_loss:0.003703\n",
            "grad_loss:0.098195\n",
            "dice_loss:-0.892741\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:129\n",
            "loss(total):-0.003399\n",
            "recons_loss:0.004575\n",
            "grad_loss:0.089703\n",
            "dice_loss:-0.887109\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:130\n",
            "loss(total):-0.002134\n",
            "recons_loss:0.005661\n",
            "grad_loss:0.106616\n",
            "dice_loss:-0.886104\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:131\n",
            "loss(total):-0.003798\n",
            "recons_loss:0.004332\n",
            "grad_loss:0.079978\n",
            "dice_loss:-0.892974\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:132\n",
            "loss(total):-0.002887\n",
            "recons_loss:0.005055\n",
            "grad_loss:0.110309\n",
            "dice_loss:-0.904527\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:133\n",
            "loss(total):-0.003751\n",
            "recons_loss:0.004180\n",
            "grad_loss:0.094977\n",
            "dice_loss:-0.888134\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:134\n",
            "loss(total):-0.004301\n",
            "recons_loss:0.003830\n",
            "grad_loss:0.086282\n",
            "dice_loss:-0.899420\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:135\n",
            "loss(total):-0.003268\n",
            "recons_loss:0.004709\n",
            "grad_loss:0.112288\n",
            "dice_loss:-0.909958\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:136\n",
            "loss(total):-0.002991\n",
            "recons_loss:0.004866\n",
            "grad_loss:0.107969\n",
            "dice_loss:-0.893620\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:137\n",
            "loss(total):-0.003387\n",
            "recons_loss:0.004629\n",
            "grad_loss:0.094480\n",
            "dice_loss:-0.896133\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:138\n",
            "loss(total):-0.003946\n",
            "recons_loss:0.004257\n",
            "grad_loss:0.081128\n",
            "dice_loss:-0.901424\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:139\n",
            "loss(total):-0.004093\n",
            "recons_loss:0.003768\n",
            "grad_loss:0.101806\n",
            "dice_loss:-0.887867\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:140\n",
            "loss(total):-0.004678\n",
            "recons_loss:0.003545\n",
            "grad_loss:0.079882\n",
            "dice_loss:-0.902234\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:141\n",
            "loss(total):-0.003486\n",
            "recons_loss:0.004322\n",
            "grad_loss:0.113439\n",
            "dice_loss:-0.894162\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:142\n",
            "loss(total):-0.004481\n",
            "recons_loss:0.003536\n",
            "grad_loss:0.096911\n",
            "dice_loss:-0.898637\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:143\n",
            "loss(total):-0.003695\n",
            "recons_loss:0.004189\n",
            "grad_loss:0.103267\n",
            "dice_loss:-0.891746\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:144\n",
            "loss(total):-0.004156\n",
            "recons_loss:0.003900\n",
            "grad_loss:0.080490\n",
            "dice_loss:-0.886102\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:145\n",
            "loss(total):-0.003986\n",
            "recons_loss:0.004182\n",
            "grad_loss:0.080568\n",
            "dice_loss:-0.897347\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:146\n",
            "loss(total):-0.005346\n",
            "recons_loss:0.003046\n",
            "grad_loss:0.067147\n",
            "dice_loss:-0.906406\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:147\n",
            "loss(total):-0.003463\n",
            "recons_loss:0.004449\n",
            "grad_loss:0.108429\n",
            "dice_loss:-0.899644\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:148\n",
            "loss(total):-0.004301\n",
            "recons_loss:0.003641\n",
            "grad_loss:0.095312\n",
            "dice_loss:-0.889528\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:149\n",
            "loss(total):-0.003793\n",
            "recons_loss:0.003990\n",
            "grad_loss:0.111094\n",
            "dice_loss:-0.889355\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:150\n",
            "loss(total):-0.002971\n",
            "recons_loss:0.004761\n",
            "grad_loss:0.121834\n",
            "dice_loss:-0.895034\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:151\n",
            "loss(total):-0.002625\n",
            "recons_loss:0.005183\n",
            "grad_loss:0.110195\n",
            "dice_loss:-0.890995\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:152\n",
            "loss(total):-0.003447\n",
            "recons_loss:0.004227\n",
            "grad_loss:0.113506\n",
            "dice_loss:-0.880849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:153\n",
            "loss(total):-0.004609\n",
            "recons_loss:0.003584\n",
            "grad_loss:0.077028\n",
            "dice_loss:-0.896385\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:154\n",
            "loss(total):-0.003281\n",
            "recons_loss:0.004739\n",
            "grad_loss:0.091450\n",
            "dice_loss:-0.893448\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:155\n",
            "loss(total):-0.004548\n",
            "recons_loss:0.003541\n",
            "grad_loss:0.080739\n",
            "dice_loss:-0.889715\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:156\n",
            "loss(total):-0.002994\n",
            "recons_loss:0.004789\n",
            "grad_loss:0.088613\n",
            "dice_loss:-0.866924\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:157\n",
            "loss(total):-0.004665\n",
            "recons_loss:0.003509\n",
            "grad_loss:0.077716\n",
            "dice_loss:-0.895129\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:158\n",
            "loss(total):-0.004193\n",
            "recons_loss:0.003772\n",
            "grad_loss:0.090928\n",
            "dice_loss:-0.887482\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:159\n",
            "loss(total):-0.004181\n",
            "recons_loss:0.003883\n",
            "grad_loss:0.093130\n",
            "dice_loss:-0.899529\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:160\n",
            "loss(total):-0.002750\n",
            "recons_loss:0.005064\n",
            "grad_loss:0.100527\n",
            "dice_loss:-0.881884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:161\n",
            "loss(total):-0.003877\n",
            "recons_loss:0.004338\n",
            "grad_loss:0.076593\n",
            "dice_loss:-0.898070\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:162\n",
            "loss(total):-0.001814\n",
            "recons_loss:0.005916\n",
            "grad_loss:0.117981\n",
            "dice_loss:-0.890937\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:163\n",
            "loss(total):-0.004841\n",
            "recons_loss:0.003115\n",
            "grad_loss:0.097508\n",
            "dice_loss:-0.893051\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:164\n",
            "loss(total):-0.003635\n",
            "recons_loss:0.004219\n",
            "grad_loss:0.104916\n",
            "dice_loss:-0.890365\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:165\n",
            "loss(total):-0.003956\n",
            "recons_loss:0.003814\n",
            "grad_loss:0.111288\n",
            "dice_loss:-0.888278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:166\n",
            "loss(total):-0.002326\n",
            "recons_loss:0.005104\n",
            "grad_loss:0.119475\n",
            "dice_loss:-0.862542\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:167\n",
            "loss(total):-0.003722\n",
            "recons_loss:0.004213\n",
            "grad_loss:0.101695\n",
            "dice_loss:-0.895248\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:168\n",
            "loss(total):-0.002756\n",
            "recons_loss:0.005040\n",
            "grad_loss:0.111451\n",
            "dice_loss:-0.891036\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:169\n",
            "loss(total):-0.002983\n",
            "recons_loss:0.004886\n",
            "grad_loss:0.095494\n",
            "dice_loss:-0.882368\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:170\n",
            "loss(total):-0.002577\n",
            "recons_loss:0.005158\n",
            "grad_loss:0.100537\n",
            "dice_loss:-0.874025\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:171\n",
            "loss(total):-0.002405\n",
            "recons_loss:0.005295\n",
            "grad_loss:0.112821\n",
            "dice_loss:-0.882778\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:172\n",
            "loss(total):-0.002172\n",
            "recons_loss:0.005555\n",
            "grad_loss:0.116052\n",
            "dice_loss:-0.888728\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:173\n",
            "loss(total):-0.003844\n",
            "recons_loss:0.004038\n",
            "grad_loss:0.092254\n",
            "dice_loss:-0.880511\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:174\n",
            "loss(total):-0.003141\n",
            "recons_loss:0.004599\n",
            "grad_loss:0.098423\n",
            "dice_loss:-0.872446\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:175\n",
            "loss(total):-0.003057\n",
            "recons_loss:0.004893\n",
            "grad_loss:0.090981\n",
            "dice_loss:-0.885952\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:176\n",
            "loss(total):-0.004277\n",
            "recons_loss:0.003781\n",
            "grad_loss:0.089178\n",
            "dice_loss:-0.895036\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:177\n",
            "loss(total):-0.003400\n",
            "recons_loss:0.004661\n",
            "grad_loss:0.092662\n",
            "dice_loss:-0.898696\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:178\n",
            "loss(total):-0.002943\n",
            "recons_loss:0.005028\n",
            "grad_loss:0.097175\n",
            "dice_loss:-0.894278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:179\n",
            "loss(total):-0.004341\n",
            "recons_loss:0.003662\n",
            "grad_loss:0.091833\n",
            "dice_loss:-0.892074\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:180\n",
            "loss(total):-0.002887\n",
            "recons_loss:0.004746\n",
            "grad_loss:0.105251\n",
            "dice_loss:-0.868548\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:181\n",
            "loss(total):-0.003755\n",
            "recons_loss:0.004032\n",
            "grad_loss:0.091368\n",
            "dice_loss:-0.870132\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:182\n",
            "loss(total):-0.003490\n",
            "recons_loss:0.004525\n",
            "grad_loss:0.093420\n",
            "dice_loss:-0.894900\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:183\n",
            "loss(total):-0.004416\n",
            "recons_loss:0.003777\n",
            "grad_loss:0.080226\n",
            "dice_loss:-0.899507\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:184\n",
            "loss(total):-0.002346\n",
            "recons_loss:0.005429\n",
            "grad_loss:0.108935\n",
            "dice_loss:-0.886452\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:185\n",
            "loss(total):-0.004445\n",
            "recons_loss:0.003803\n",
            "grad_loss:0.088300\n",
            "dice_loss:-0.913083\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:186\n",
            "loss(total):-0.003371\n",
            "recons_loss:0.004424\n",
            "grad_loss:0.111773\n",
            "dice_loss:-0.891208\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:187\n",
            "loss(total):-0.004468\n",
            "recons_loss:0.003492\n",
            "grad_loss:0.082302\n",
            "dice_loss:-0.878317\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:188\n",
            "loss(total):-0.004145\n",
            "recons_loss:0.003794\n",
            "grad_loss:0.073663\n",
            "dice_loss:-0.867526\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:189\n",
            "loss(total):-0.002900\n",
            "recons_loss:0.005023\n",
            "grad_loss:0.097742\n",
            "dice_loss:-0.890081\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:190\n",
            "loss(total):-0.004700\n",
            "recons_loss:0.003400\n",
            "grad_loss:0.084372\n",
            "dice_loss:-0.894368\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:191\n",
            "loss(total):-0.000717\n",
            "recons_loss:0.006705\n",
            "grad_loss:0.137499\n",
            "dice_loss:-0.879704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:192\n",
            "loss(total):-0.001527\n",
            "recons_loss:0.005921\n",
            "grad_loss:0.132119\n",
            "dice_loss:-0.876942\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:193\n",
            "loss(total):-0.004125\n",
            "recons_loss:0.003963\n",
            "grad_loss:0.082572\n",
            "dice_loss:-0.891462\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:194\n",
            "loss(total):-0.002184\n",
            "recons_loss:0.005419\n",
            "grad_loss:0.117837\n",
            "dice_loss:-0.878091\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:195\n",
            "loss(total):-0.002844\n",
            "recons_loss:0.005045\n",
            "grad_loss:0.108013\n",
            "dice_loss:-0.896819\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:196\n",
            "loss(total):-0.003352\n",
            "recons_loss:0.004632\n",
            "grad_loss:0.095955\n",
            "dice_loss:-0.894372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:197\n",
            "loss(total):-0.003437\n",
            "recons_loss:0.004559\n",
            "grad_loss:0.091085\n",
            "dice_loss:-0.890631\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:198\n",
            "loss(total):-0.003877\n",
            "recons_loss:0.004094\n",
            "grad_loss:0.089626\n",
            "dice_loss:-0.886751\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:199\n",
            "loss(total):-0.002969\n",
            "recons_loss:0.004835\n",
            "grad_loss:0.105511\n",
            "dice_loss:-0.885859\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:200\n",
            "loss(total):-0.003593\n",
            "recons_loss:0.004519\n",
            "grad_loss:0.093840\n",
            "dice_loss:-0.905048\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:201\n",
            "loss(total):-0.003421\n",
            "recons_loss:0.004470\n",
            "grad_loss:0.104764\n",
            "dice_loss:-0.893883\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:202\n",
            "loss(total):-0.004152\n",
            "recons_loss:0.003770\n",
            "grad_loss:0.099375\n",
            "dice_loss:-0.891649\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:203\n",
            "loss(total):-0.003552\n",
            "recons_loss:0.004242\n",
            "grad_loss:0.109631\n",
            "dice_loss:-0.888974\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:204\n",
            "loss(total):-0.002457\n",
            "recons_loss:0.005285\n",
            "grad_loss:0.124916\n",
            "dice_loss:-0.899158\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:205\n",
            "loss(total):-0.004761\n",
            "recons_loss:0.003323\n",
            "grad_loss:0.077346\n",
            "dice_loss:-0.885780\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:206\n",
            "loss(total):-0.003501\n",
            "recons_loss:0.004401\n",
            "grad_loss:0.096596\n",
            "dice_loss:-0.886831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:207\n",
            "loss(total):-0.003297\n",
            "recons_loss:0.004611\n",
            "grad_loss:0.092670\n",
            "dice_loss:-0.883411\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:208\n",
            "loss(total):-0.002795\n",
            "recons_loss:0.004937\n",
            "grad_loss:0.107959\n",
            "dice_loss:-0.881239\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:209\n",
            "loss(total):-0.004691\n",
            "recons_loss:0.003574\n",
            "grad_loss:0.070123\n",
            "dice_loss:-0.896582\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:210\n",
            "loss(total):-0.003115\n",
            "recons_loss:0.004651\n",
            "grad_loss:0.098734\n",
            "dice_loss:-0.875300\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:211\n",
            "loss(total):-0.003769\n",
            "recons_loss:0.004192\n",
            "grad_loss:0.100965\n",
            "dice_loss:-0.897056\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:212\n",
            "loss(total):-0.003156\n",
            "recons_loss:0.004765\n",
            "grad_loss:0.100103\n",
            "dice_loss:-0.892204\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:213\n",
            "loss(total):-0.004242\n",
            "recons_loss:0.003901\n",
            "grad_loss:0.078969\n",
            "dice_loss:-0.893230\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:214\n",
            "loss(total):-0.003177\n",
            "recons_loss:0.004621\n",
            "grad_loss:0.107606\n",
            "dice_loss:-0.887475\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:215\n",
            "loss(total):-0.002641\n",
            "recons_loss:0.005103\n",
            "grad_loss:0.116293\n",
            "dice_loss:-0.890642\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:216\n",
            "loss(total):-0.003181\n",
            "recons_loss:0.004682\n",
            "grad_loss:0.102704\n",
            "dice_loss:-0.889005\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:217\n",
            "loss(total):-0.004039\n",
            "recons_loss:0.004046\n",
            "grad_loss:0.085736\n",
            "dice_loss:-0.894266\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:218\n",
            "loss(total):-0.003146\n",
            "recons_loss:0.004623\n",
            "grad_loss:0.108627\n",
            "dice_loss:-0.885504\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:219\n",
            "loss(total):-0.003434\n",
            "recons_loss:0.004377\n",
            "grad_loss:0.104213\n",
            "dice_loss:-0.885305\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:220\n",
            "loss(total):-0.003619\n",
            "recons_loss:0.004345\n",
            "grad_loss:0.087702\n",
            "dice_loss:-0.884096\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:221\n",
            "loss(total):-0.001996\n",
            "recons_loss:0.005545\n",
            "grad_loss:0.132760\n",
            "dice_loss:-0.886815\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:222\n",
            "loss(total):-0.003884\n",
            "recons_loss:0.004106\n",
            "grad_loss:0.091911\n",
            "dice_loss:-0.891004\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:223\n",
            "loss(total):-0.002616\n",
            "recons_loss:0.005061\n",
            "grad_loss:0.108596\n",
            "dice_loss:-0.876372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:224\n",
            "loss(total):-0.003107\n",
            "recons_loss:0.004690\n",
            "grad_loss:0.102526\n",
            "dice_loss:-0.882170\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:225\n",
            "loss(total):-0.003761\n",
            "recons_loss:0.004254\n",
            "grad_loss:0.087873\n",
            "dice_loss:-0.889378\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:226\n",
            "loss(total):-0.003184\n",
            "recons_loss:0.004713\n",
            "grad_loss:0.098109\n",
            "dice_loss:-0.887801\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:227\n",
            "loss(total):-0.003720\n",
            "recons_loss:0.004351\n",
            "grad_loss:0.089094\n",
            "dice_loss:-0.896255\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:228\n",
            "loss(total):-0.004032\n",
            "recons_loss:0.003909\n",
            "grad_loss:0.089038\n",
            "dice_loss:-0.883165\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:229\n",
            "loss(total):-0.003928\n",
            "recons_loss:0.004229\n",
            "grad_loss:0.094150\n",
            "dice_loss:-0.909872\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:230\n",
            "loss(total):-0.003003\n",
            "recons_loss:0.004873\n",
            "grad_loss:0.094660\n",
            "dice_loss:-0.882259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:231\n",
            "loss(total):-0.004577\n",
            "recons_loss:0.003471\n",
            "grad_loss:0.086510\n",
            "dice_loss:-0.891319\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:232\n",
            "loss(total):-0.004140\n",
            "recons_loss:0.003894\n",
            "grad_loss:0.080187\n",
            "dice_loss:-0.883625\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:233\n",
            "loss(total):-0.002719\n",
            "recons_loss:0.004958\n",
            "grad_loss:0.107046\n",
            "dice_loss:-0.874725\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:234\n",
            "loss(total):-0.003833\n",
            "recons_loss:0.004279\n",
            "grad_loss:0.082588\n",
            "dice_loss:-0.893773\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:235\n",
            "loss(total):-0.003933\n",
            "recons_loss:0.004031\n",
            "grad_loss:0.084484\n",
            "dice_loss:-0.880936\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:236\n",
            "loss(total):-0.003723\n",
            "recons_loss:0.004156\n",
            "grad_loss:0.105921\n",
            "dice_loss:-0.893859\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:237\n",
            "loss(total):-0.003687\n",
            "recons_loss:0.004404\n",
            "grad_loss:0.096128\n",
            "dice_loss:-0.905264\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:238\n",
            "loss(total):-0.004771\n",
            "recons_loss:0.003320\n",
            "grad_loss:0.098597\n",
            "dice_loss:-0.907691\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:239\n",
            "loss(total):-0.003573\n",
            "recons_loss:0.004514\n",
            "grad_loss:0.091236\n",
            "dice_loss:-0.900001\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:240\n",
            "loss(total):-0.003177\n",
            "recons_loss:0.004925\n",
            "grad_loss:0.080599\n",
            "dice_loss:-0.890836\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:241\n",
            "loss(total):-0.002389\n",
            "recons_loss:0.005193\n",
            "grad_loss:0.118912\n",
            "dice_loss:-0.877051\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:242\n",
            "loss(total):-0.003436\n",
            "recons_loss:0.004478\n",
            "grad_loss:0.102220\n",
            "dice_loss:-0.893638\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:243\n",
            "loss(total):-0.003247\n",
            "recons_loss:0.004556\n",
            "grad_loss:0.107592\n",
            "dice_loss:-0.887904\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:244\n",
            "loss(total):-0.003658\n",
            "recons_loss:0.004285\n",
            "grad_loss:0.093687\n",
            "dice_loss:-0.887980\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:245\n",
            "loss(total):-0.002497\n",
            "recons_loss:0.005250\n",
            "grad_loss:0.104395\n",
            "dice_loss:-0.879163\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:246\n",
            "loss(total):-0.003656\n",
            "recons_loss:0.004315\n",
            "grad_loss:0.098672\n",
            "dice_loss:-0.895754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:247\n",
            "loss(total):-0.003743\n",
            "recons_loss:0.004229\n",
            "grad_loss:0.098566\n",
            "dice_loss:-0.895804\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:248\n",
            "loss(total):-0.004363\n",
            "recons_loss:0.003781\n",
            "grad_loss:0.099186\n",
            "dice_loss:-0.913617\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:249\n",
            "loss(total):-0.004271\n",
            "recons_loss:0.003761\n",
            "grad_loss:0.088904\n",
            "dice_loss:-0.892082\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:250\n",
            "loss(total):-0.002512\n",
            "recons_loss:0.005138\n",
            "grad_loss:0.113086\n",
            "dice_loss:-0.878059\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:251\n",
            "loss(total):-0.002314\n",
            "recons_loss:0.005148\n",
            "grad_loss:0.123312\n",
            "dice_loss:-0.869511\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:252\n",
            "loss(total):-0.003491\n",
            "recons_loss:0.004245\n",
            "grad_loss:0.108442\n",
            "dice_loss:-0.882106\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:253\n",
            "loss(total):-0.002970\n",
            "recons_loss:0.004863\n",
            "grad_loss:0.100076\n",
            "dice_loss:-0.883388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:254\n",
            "loss(total):-0.003889\n",
            "recons_loss:0.004190\n",
            "grad_loss:0.091009\n",
            "dice_loss:-0.898988\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:255\n",
            "loss(total):-0.005293\n",
            "recons_loss:0.002907\n",
            "grad_loss:0.079850\n",
            "dice_loss:-0.899892\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:256\n",
            "loss(total):-0.003309\n",
            "recons_loss:0.004631\n",
            "grad_loss:0.091024\n",
            "dice_loss:-0.885035\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:257\n",
            "loss(total):-0.003939\n",
            "recons_loss:0.004117\n",
            "grad_loss:0.086021\n",
            "dice_loss:-0.891599\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:258\n",
            "loss(total):-0.002271\n",
            "recons_loss:0.005385\n",
            "grad_loss:0.116336\n",
            "dice_loss:-0.881968\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:259\n",
            "loss(total):-0.004307\n",
            "recons_loss:0.003795\n",
            "grad_loss:0.086790\n",
            "dice_loss:-0.896984\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:260\n",
            "loss(total):-0.003144\n",
            "recons_loss:0.004871\n",
            "grad_loss:0.104475\n",
            "dice_loss:-0.906047\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:261\n",
            "loss(total):-0.003239\n",
            "recons_loss:0.004662\n",
            "grad_loss:0.096581\n",
            "dice_loss:-0.886665\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:262\n",
            "loss(total):-0.005093\n",
            "recons_loss:0.003077\n",
            "grad_loss:0.084795\n",
            "dice_loss:-0.901745\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:263\n",
            "loss(total):-0.003004\n",
            "recons_loss:0.004984\n",
            "grad_loss:0.094784\n",
            "dice_loss:-0.893596\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:264\n",
            "loss(total):-0.003625\n",
            "recons_loss:0.004441\n",
            "grad_loss:0.080692\n",
            "dice_loss:-0.887248\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:265\n",
            "loss(total):-0.001505\n",
            "recons_loss:0.005953\n",
            "grad_loss:0.132005\n",
            "dice_loss:-0.877774\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:266\n",
            "loss(total):-0.004699\n",
            "recons_loss:0.003381\n",
            "grad_loss:0.089560\n",
            "dice_loss:-0.897623\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:267\n",
            "loss(total):-0.003160\n",
            "recons_loss:0.004798\n",
            "grad_loss:0.103118\n",
            "dice_loss:-0.898935\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:268\n",
            "loss(total):-0.004412\n",
            "recons_loss:0.003578\n",
            "grad_loss:0.094869\n",
            "dice_loss:-0.893908\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:269\n",
            "loss(total):-0.005020\n",
            "recons_loss:0.003184\n",
            "grad_loss:0.080215\n",
            "dice_loss:-0.900577\n",
            "---------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmpHHfS_Lgho",
        "outputId": "dcfd8f42-b1a4-41a2-f4c3-d929936d3411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(losses_7[1:])\n",
        "plt.show"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bAR01keLi4Y",
        "outputId": "a07630e4-cc44-447e-fb5f-7150771f1871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(validation_7)\n",
        "plt.show"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzRgo2GVLo0h"
      },
      "source": [
        "import csv\n",
        "with open('validation_7.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5fiL6QpBaHS"
      },
      "source": [
        "for h in range(0,len(validation_0)):\n",
        "  with open('validation_7.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, validation_7[h].numpy()])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWVkJZ2ALIzV"
      },
      "source": [
        "import csv\n",
        "with open('loss_7.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n",
        "\n",
        "for h in range(0,len(losses_7)):\n",
        "  with open('loss_7.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h, losses_7[h].numpy()])"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ezQp7zOLvmy"
      },
      "source": [
        "'''Training - hold out fold 8 for validation'''\n",
        "#Training\n",
        "gpu='0'\n",
        "atlas_file='/content/drive/My Drive/2020/Thesis/Data/atlas.npz'\n",
        "lr=1e-4\n",
        "n_iter=5000\n",
        "data_loss='mse'\n",
        "model='vm2'\n",
        "reg_param=0.01\n",
        "batch_size=10\n",
        "n_save_iter=100\n",
        "model_dir='/content/drive/My Drive/2020/Thesis/Data/validation_0/'\n",
        "valid = fold_8\n",
        "train_names = set_8\n",
        "EPOCH=30"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5zouePZL0xu",
        "outputId": "e1173c2a-4122-4853-f44f-d19c5d490b59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses_8, validation_8=validate.train(data_dir,\n",
        "          train_names,\n",
        "          atlas_file,\n",
        "          lr,\n",
        "          data_loss,\n",
        "          model,\n",
        "          reg_param, \n",
        "          batch_size,\n",
        "          n_save_iter,\n",
        "          model_dir,Net(),EPOCH, valid)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch_number:185\n",
            "loss(total):-0.004819\n",
            "recons_loss:0.003412\n",
            "grad_loss:0.065821\n",
            "dice_loss:-0.888872\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:186\n",
            "loss(total):-0.004427\n",
            "recons_loss:0.003636\n",
            "grad_loss:0.089598\n",
            "dice_loss:-0.895950\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:187\n",
            "loss(total):-0.003654\n",
            "recons_loss:0.004207\n",
            "grad_loss:0.103109\n",
            "dice_loss:-0.889275\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:188\n",
            "loss(total):-0.004760\n",
            "recons_loss:0.003303\n",
            "grad_loss:0.090239\n",
            "dice_loss:-0.896510\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:189\n",
            "loss(total):-0.004333\n",
            "recons_loss:0.003765\n",
            "grad_loss:0.091175\n",
            "dice_loss:-0.901039\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:190\n",
            "loss(total):-0.003314\n",
            "recons_loss:0.004790\n",
            "grad_loss:0.087161\n",
            "dice_loss:-0.897588\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:191\n",
            "loss(total):-0.003938\n",
            "recons_loss:0.004157\n",
            "grad_loss:0.096111\n",
            "dice_loss:-0.905610\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:192\n",
            "loss(total):-0.004043\n",
            "recons_loss:0.004073\n",
            "grad_loss:0.088724\n",
            "dice_loss:-0.900237\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:193\n",
            "loss(total):-0.002987\n",
            "recons_loss:0.004834\n",
            "grad_loss:0.112708\n",
            "dice_loss:-0.894760\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:194\n",
            "loss(total):-0.003350\n",
            "recons_loss:0.004492\n",
            "grad_loss:0.101430\n",
            "dice_loss:-0.885663\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:195\n",
            "loss(total):-0.002696\n",
            "recons_loss:0.004995\n",
            "grad_loss:0.120084\n",
            "dice_loss:-0.889118\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:196\n",
            "loss(total):-0.004313\n",
            "recons_loss:0.003754\n",
            "grad_loss:0.086062\n",
            "dice_loss:-0.892745\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:197\n",
            "loss(total):-0.003856\n",
            "recons_loss:0.004136\n",
            "grad_loss:0.099258\n",
            "dice_loss:-0.898426\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:198\n",
            "loss(total):-0.004570\n",
            "recons_loss:0.003540\n",
            "grad_loss:0.084326\n",
            "dice_loss:-0.895307\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:199\n",
            "loss(total):-0.003671\n",
            "recons_loss:0.004101\n",
            "grad_loss:0.099426\n",
            "dice_loss:-0.876711\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:200\n",
            "loss(total):-0.004166\n",
            "recons_loss:0.003820\n",
            "grad_loss:0.110895\n",
            "dice_loss:-0.909586\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:201\n",
            "loss(total):-0.005165\n",
            "recons_loss:0.003080\n",
            "grad_loss:0.076127\n",
            "dice_loss:-0.900613\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:202\n",
            "loss(total):-0.004268\n",
            "recons_loss:0.003692\n",
            "grad_loss:0.090174\n",
            "dice_loss:-0.886234\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:203\n",
            "loss(total):-0.003187\n",
            "recons_loss:0.004608\n",
            "grad_loss:0.097105\n",
            "dice_loss:-0.876588\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:204\n",
            "loss(total):-0.003026\n",
            "recons_loss:0.004679\n",
            "grad_loss:0.109314\n",
            "dice_loss:-0.879780\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:205\n",
            "loss(total):-0.004492\n",
            "recons_loss:0.003715\n",
            "grad_loss:0.081463\n",
            "dice_loss:-0.902228\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:206\n",
            "loss(total):-0.003132\n",
            "recons_loss:0.004697\n",
            "grad_loss:0.101012\n",
            "dice_loss:-0.883939\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:207\n",
            "loss(total):-0.004071\n",
            "recons_loss:0.003911\n",
            "grad_loss:0.084193\n",
            "dice_loss:-0.882439\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:208\n",
            "loss(total):-0.004892\n",
            "recons_loss:0.003248\n",
            "grad_loss:0.082326\n",
            "dice_loss:-0.896276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:209\n",
            "loss(total):-0.004025\n",
            "recons_loss:0.003901\n",
            "grad_loss:0.094900\n",
            "dice_loss:-0.887527\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:210\n",
            "loss(total):-0.001905\n",
            "recons_loss:0.005673\n",
            "grad_loss:0.125000\n",
            "dice_loss:-0.882846\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:211\n",
            "loss(total):-0.003691\n",
            "recons_loss:0.004273\n",
            "grad_loss:0.099280\n",
            "dice_loss:-0.895740\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:212\n",
            "loss(total):-0.002950\n",
            "recons_loss:0.004876\n",
            "grad_loss:0.109568\n",
            "dice_loss:-0.892161\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:213\n",
            "loss(total):-0.004595\n",
            "recons_loss:0.003600\n",
            "grad_loss:0.082877\n",
            "dice_loss:-0.902373\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:214\n",
            "loss(total):-0.002490\n",
            "recons_loss:0.005145\n",
            "grad_loss:0.126986\n",
            "dice_loss:-0.890521\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:215\n",
            "loss(total):-0.002857\n",
            "recons_loss:0.004931\n",
            "grad_loss:0.105753\n",
            "dice_loss:-0.884470\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:216\n",
            "loss(total):-0.003576\n",
            "recons_loss:0.004253\n",
            "grad_loss:0.100033\n",
            "dice_loss:-0.882910\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:217\n",
            "loss(total):-0.003323\n",
            "recons_loss:0.004486\n",
            "grad_loss:0.104843\n",
            "dice_loss:-0.885656\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:218\n",
            "loss(total):-0.002747\n",
            "recons_loss:0.005172\n",
            "grad_loss:0.097412\n",
            "dice_loss:-0.889277\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:219\n",
            "loss(total):-0.004307\n",
            "recons_loss:0.003838\n",
            "grad_loss:0.095344\n",
            "dice_loss:-0.909828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:220\n",
            "loss(total):-0.003949\n",
            "recons_loss:0.004073\n",
            "grad_loss:0.088370\n",
            "dice_loss:-0.890512\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:221\n",
            "loss(total):-0.004851\n",
            "recons_loss:0.003344\n",
            "grad_loss:0.079669\n",
            "dice_loss:-0.899233\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:222\n",
            "loss(total):-0.001981\n",
            "recons_loss:0.005544\n",
            "grad_loss:0.118078\n",
            "dice_loss:-0.870583\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:223\n",
            "loss(total):-0.003289\n",
            "recons_loss:0.004634\n",
            "grad_loss:0.105658\n",
            "dice_loss:-0.897945\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:224\n",
            "loss(total):-0.003706\n",
            "recons_loss:0.004132\n",
            "grad_loss:0.111905\n",
            "dice_loss:-0.895739\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:225\n",
            "loss(total):-0.003324\n",
            "recons_loss:0.004568\n",
            "grad_loss:0.107427\n",
            "dice_loss:-0.896564\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:226\n",
            "loss(total):-0.003735\n",
            "recons_loss:0.004368\n",
            "grad_loss:0.091880\n",
            "dice_loss:-0.902192\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:227\n",
            "loss(total):-0.004314\n",
            "recons_loss:0.003709\n",
            "grad_loss:0.100709\n",
            "dice_loss:-0.903010\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:228\n",
            "loss(total):-0.003593\n",
            "recons_loss:0.004218\n",
            "grad_loss:0.096597\n",
            "dice_loss:-0.877676\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:229\n",
            "loss(total):-0.003301\n",
            "recons_loss:0.004513\n",
            "grad_loss:0.096061\n",
            "dice_loss:-0.877417\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:230\n",
            "loss(total):-0.003564\n",
            "recons_loss:0.004262\n",
            "grad_loss:0.097372\n",
            "dice_loss:-0.879971\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:231\n",
            "loss(total):-0.003231\n",
            "recons_loss:0.004625\n",
            "grad_loss:0.103856\n",
            "dice_loss:-0.889507\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:232\n",
            "loss(total):-0.004031\n",
            "recons_loss:0.004033\n",
            "grad_loss:0.086533\n",
            "dice_loss:-0.892867\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:233\n",
            "loss(total):-0.001334\n",
            "recons_loss:0.006196\n",
            "grad_loss:0.128264\n",
            "dice_loss:-0.881298\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:234\n",
            "loss(total):-0.002703\n",
            "recons_loss:0.005165\n",
            "grad_loss:0.098929\n",
            "dice_loss:-0.885703\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:235\n",
            "loss(total):-0.003060\n",
            "recons_loss:0.004751\n",
            "grad_loss:0.117601\n",
            "dice_loss:-0.898660\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:236\n",
            "loss(total):-0.003013\n",
            "recons_loss:0.004894\n",
            "grad_loss:0.105296\n",
            "dice_loss:-0.895913\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:237\n",
            "loss(total):-0.003467\n",
            "recons_loss:0.004420\n",
            "grad_loss:0.101228\n",
            "dice_loss:-0.889995\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:238\n",
            "loss(total):-0.003263\n",
            "recons_loss:0.004615\n",
            "grad_loss:0.106820\n",
            "dice_loss:-0.894551\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:239\n",
            "loss(total):-0.004730\n",
            "recons_loss:0.003468\n",
            "grad_loss:0.076905\n",
            "dice_loss:-0.896668\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:240\n",
            "loss(total):-0.003457\n",
            "recons_loss:0.004533\n",
            "grad_loss:0.092805\n",
            "dice_loss:-0.891815\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:241\n",
            "loss(total):-0.002880\n",
            "recons_loss:0.004986\n",
            "grad_loss:0.097971\n",
            "dice_loss:-0.884566\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:242\n",
            "loss(total):-0.003945\n",
            "recons_loss:0.003958\n",
            "grad_loss:0.111860\n",
            "dice_loss:-0.902168\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:243\n",
            "loss(total):-0.003557\n",
            "recons_loss:0.004252\n",
            "grad_loss:0.099379\n",
            "dice_loss:-0.880282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:244\n",
            "loss(total):-0.002862\n",
            "recons_loss:0.005001\n",
            "grad_loss:0.106951\n",
            "dice_loss:-0.893277\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:245\n",
            "loss(total):-0.003599\n",
            "recons_loss:0.004369\n",
            "grad_loss:0.103592\n",
            "dice_loss:-0.900432\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:246\n",
            "loss(total):-0.003329\n",
            "recons_loss:0.004470\n",
            "grad_loss:0.101246\n",
            "dice_loss:-0.881190\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:247\n",
            "loss(total):-0.004375\n",
            "recons_loss:0.003747\n",
            "grad_loss:0.085593\n",
            "dice_loss:-0.897810\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:248\n",
            "loss(total):-0.003949\n",
            "recons_loss:0.004100\n",
            "grad_loss:0.102179\n",
            "dice_loss:-0.907071\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:249\n",
            "loss(total):-0.004285\n",
            "recons_loss:0.003688\n",
            "grad_loss:0.084888\n",
            "dice_loss:-0.882186\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:250\n",
            "loss(total):-0.004165\n",
            "recons_loss:0.003863\n",
            "grad_loss:0.081396\n",
            "dice_loss:-0.884187\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:251\n",
            "loss(total):-0.003522\n",
            "recons_loss:0.004405\n",
            "grad_loss:0.105156\n",
            "dice_loss:-0.897913\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:252\n",
            "loss(total):-0.003746\n",
            "recons_loss:0.004098\n",
            "grad_loss:0.097795\n",
            "dice_loss:-0.882224\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:253\n",
            "loss(total):-0.003954\n",
            "recons_loss:0.003940\n",
            "grad_loss:0.099098\n",
            "dice_loss:-0.888464\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:254\n",
            "loss(total):-0.004026\n",
            "recons_loss:0.003949\n",
            "grad_loss:0.095944\n",
            "dice_loss:-0.893426\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:255\n",
            "loss(total):-0.003157\n",
            "recons_loss:0.004640\n",
            "grad_loss:0.115330\n",
            "dice_loss:-0.895069\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:256\n",
            "loss(total):-0.004513\n",
            "recons_loss:0.003559\n",
            "grad_loss:0.092414\n",
            "dice_loss:-0.899646\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:257\n",
            "loss(total):-0.004015\n",
            "recons_loss:0.003957\n",
            "grad_loss:0.100899\n",
            "dice_loss:-0.898097\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:258\n",
            "loss(total):-0.003135\n",
            "recons_loss:0.004693\n",
            "grad_loss:0.116308\n",
            "dice_loss:-0.899112\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:259\n",
            "loss(total):-0.005012\n",
            "recons_loss:0.003099\n",
            "grad_loss:0.081050\n",
            "dice_loss:-0.892088\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:260\n",
            "loss(total):-0.003230\n",
            "recons_loss:0.004576\n",
            "grad_loss:0.108664\n",
            "dice_loss:-0.889209\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:261\n",
            "loss(total):-0.004005\n",
            "recons_loss:0.003913\n",
            "grad_loss:0.090149\n",
            "dice_loss:-0.881993\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:262\n",
            "loss(total):-0.004456\n",
            "recons_loss:0.003455\n",
            "grad_loss:0.087083\n",
            "dice_loss:-0.878132\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:263\n",
            "loss(total):-0.003274\n",
            "recons_loss:0.004678\n",
            "grad_loss:0.099722\n",
            "dice_loss:-0.894888\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:264\n",
            "loss(total):-0.003532\n",
            "recons_loss:0.004389\n",
            "grad_loss:0.104138\n",
            "dice_loss:-0.896238\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:265\n",
            "loss(total):-0.004027\n",
            "recons_loss:0.004062\n",
            "grad_loss:0.093224\n",
            "dice_loss:-0.902153\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:266\n",
            "loss(total):-0.003585\n",
            "recons_loss:0.004212\n",
            "grad_loss:0.090127\n",
            "dice_loss:-0.869893\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:267\n",
            "loss(total):-0.003729\n",
            "recons_loss:0.004313\n",
            "grad_loss:0.093869\n",
            "dice_loss:-0.898018\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:268\n",
            "loss(total):-0.002550\n",
            "recons_loss:0.005274\n",
            "grad_loss:0.104139\n",
            "dice_loss:-0.886516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:269\n",
            "loss(total):-0.003599\n",
            "recons_loss:0.004363\n",
            "grad_loss:0.102046\n",
            "dice_loss:-0.898293\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:0\n",
            "loss(total):-0.005077\n",
            "recons_loss:0.003190\n",
            "grad_loss:0.073586\n",
            "dice_loss:-0.900275\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:1\n",
            "loss(total):-0.004414\n",
            "recons_loss:0.003778\n",
            "grad_loss:0.078957\n",
            "dice_loss:-0.898143\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:2\n",
            "loss(total):-0.004126\n",
            "recons_loss:0.003945\n",
            "grad_loss:0.078950\n",
            "dice_loss:-0.886093\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:3\n",
            "loss(total):-0.001832\n",
            "recons_loss:0.005619\n",
            "grad_loss:0.139003\n",
            "dice_loss:-0.884136\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:4\n",
            "loss(total):-0.002779\n",
            "recons_loss:0.004976\n",
            "grad_loss:0.108308\n",
            "dice_loss:-0.883825\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:5\n",
            "loss(total):-0.003600\n",
            "recons_loss:0.004131\n",
            "grad_loss:0.092736\n",
            "dice_loss:-0.865827\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:6\n",
            "loss(total):-0.002903\n",
            "recons_loss:0.004802\n",
            "grad_loss:0.102331\n",
            "dice_loss:-0.872764\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:7\n",
            "loss(total):-0.003216\n",
            "recons_loss:0.004778\n",
            "grad_loss:0.092928\n",
            "dice_loss:-0.892414\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:8\n",
            "loss(total):-0.001734\n",
            "recons_loss:0.005650\n",
            "grad_loss:0.138717\n",
            "dice_loss:-0.877164\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:9\n",
            "loss(total):-0.003104\n",
            "recons_loss:0.004743\n",
            "grad_loss:0.105522\n",
            "dice_loss:-0.890278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:10\n",
            "loss(total):-0.004617\n",
            "recons_loss:0.003471\n",
            "grad_loss:0.101505\n",
            "dice_loss:-0.910253\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:11\n",
            "loss(total):-0.004579\n",
            "recons_loss:0.003663\n",
            "grad_loss:0.076900\n",
            "dice_loss:-0.901163\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:12\n",
            "loss(total):-0.001644\n",
            "recons_loss:0.005889\n",
            "grad_loss:0.123393\n",
            "dice_loss:-0.876729\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:13\n",
            "loss(total):-0.003368\n",
            "recons_loss:0.004540\n",
            "grad_loss:0.095580\n",
            "dice_loss:-0.886412\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:14\n",
            "loss(total):-0.004440\n",
            "recons_loss:0.003611\n",
            "grad_loss:0.086557\n",
            "dice_loss:-0.891684\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:15\n",
            "loss(total):-0.003785\n",
            "recons_loss:0.003986\n",
            "grad_loss:0.106589\n",
            "dice_loss:-0.883638\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:16\n",
            "loss(total):-0.004095\n",
            "recons_loss:0.003996\n",
            "grad_loss:0.078947\n",
            "dice_loss:-0.888121\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:17\n",
            "loss(total):-0.003370\n",
            "recons_loss:0.004754\n",
            "grad_loss:0.081601\n",
            "dice_loss:-0.894084\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:18\n",
            "loss(total):-0.003393\n",
            "recons_loss:0.004672\n",
            "grad_loss:0.097194\n",
            "dice_loss:-0.903677\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:19\n",
            "loss(total):-0.002725\n",
            "recons_loss:0.005076\n",
            "grad_loss:0.106213\n",
            "dice_loss:-0.886282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:20\n",
            "loss(total):-0.002735\n",
            "recons_loss:0.004812\n",
            "grad_loss:0.117907\n",
            "dice_loss:-0.872624\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:21\n",
            "loss(total):-0.001822\n",
            "recons_loss:0.005866\n",
            "grad_loss:0.114616\n",
            "dice_loss:-0.883365\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:22\n",
            "loss(total):-0.003000\n",
            "recons_loss:0.004741\n",
            "grad_loss:0.115782\n",
            "dice_loss:-0.889835\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:23\n",
            "loss(total):-0.004165\n",
            "recons_loss:0.003790\n",
            "grad_loss:0.098543\n",
            "dice_loss:-0.894113\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:24\n",
            "loss(total):-0.001872\n",
            "recons_loss:0.005662\n",
            "grad_loss:0.133649\n",
            "dice_loss:-0.887043\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:25\n",
            "loss(total):-0.003624\n",
            "recons_loss:0.004333\n",
            "grad_loss:0.092286\n",
            "dice_loss:-0.887984\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:26\n",
            "loss(total):-0.004282\n",
            "recons_loss:0.003801\n",
            "grad_loss:0.082308\n",
            "dice_loss:-0.890537\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:27\n",
            "loss(total):-0.002846\n",
            "recons_loss:0.004947\n",
            "grad_loss:0.101205\n",
            "dice_loss:-0.880524\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:28\n",
            "loss(total):-0.004678\n",
            "recons_loss:0.003381\n",
            "grad_loss:0.080431\n",
            "dice_loss:-0.886318\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:29\n",
            "loss(total):-0.003545\n",
            "recons_loss:0.004276\n",
            "grad_loss:0.099874\n",
            "dice_loss:-0.881937\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:30\n",
            "loss(total):-0.003070\n",
            "recons_loss:0.004783\n",
            "grad_loss:0.089221\n",
            "dice_loss:-0.874552\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:31\n",
            "loss(total):-0.002991\n",
            "recons_loss:0.004989\n",
            "grad_loss:0.090558\n",
            "dice_loss:-0.888623\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:32\n",
            "loss(total):-0.002411\n",
            "recons_loss:0.005206\n",
            "grad_loss:0.120935\n",
            "dice_loss:-0.882646\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:33\n",
            "loss(total):-0.003550\n",
            "recons_loss:0.004388\n",
            "grad_loss:0.101222\n",
            "dice_loss:-0.895042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:34\n",
            "loss(total):-0.004493\n",
            "recons_loss:0.003392\n",
            "grad_loss:0.107287\n",
            "dice_loss:-0.895783\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:35\n",
            "loss(total):-0.003123\n",
            "recons_loss:0.004663\n",
            "grad_loss:0.127620\n",
            "dice_loss:-0.906283\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:36\n",
            "loss(total):-0.003679\n",
            "recons_loss:0.004212\n",
            "grad_loss:0.112159\n",
            "dice_loss:-0.901210\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:37\n",
            "loss(total):-0.004014\n",
            "recons_loss:0.004141\n",
            "grad_loss:0.084634\n",
            "dice_loss:-0.900129\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:38\n",
            "loss(total):-0.004313\n",
            "recons_loss:0.003878\n",
            "grad_loss:0.074179\n",
            "dice_loss:-0.893239\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:39\n",
            "loss(total):-0.004061\n",
            "recons_loss:0.004035\n",
            "grad_loss:0.089817\n",
            "dice_loss:-0.899452\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:40\n",
            "loss(total):-0.003313\n",
            "recons_loss:0.004559\n",
            "grad_loss:0.109762\n",
            "dice_loss:-0.896957\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:41\n",
            "loss(total):-0.004845\n",
            "recons_loss:0.003322\n",
            "grad_loss:0.078819\n",
            "dice_loss:-0.895501\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:42\n",
            "loss(total):-0.002923\n",
            "recons_loss:0.004941\n",
            "grad_loss:0.094379\n",
            "dice_loss:-0.880692\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:43\n",
            "loss(total):-0.004574\n",
            "recons_loss:0.003570\n",
            "grad_loss:0.080704\n",
            "dice_loss:-0.895094\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:44\n",
            "loss(total):-0.005427\n",
            "recons_loss:0.002903\n",
            "grad_loss:0.074648\n",
            "dice_loss:-0.907640\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:45\n",
            "loss(total):-0.002818\n",
            "recons_loss:0.005044\n",
            "grad_loss:0.121873\n",
            "dice_loss:-0.908033\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:46\n",
            "loss(total):-0.003102\n",
            "recons_loss:0.004673\n",
            "grad_loss:0.111474\n",
            "dice_loss:-0.888942\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:47\n",
            "loss(total):-0.002439\n",
            "recons_loss:0.005431\n",
            "grad_loss:0.105199\n",
            "dice_loss:-0.892242\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:48\n",
            "loss(total):-0.000968\n",
            "recons_loss:0.006187\n",
            "grad_loss:0.157701\n",
            "dice_loss:-0.873219\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:49\n",
            "loss(total):-0.003463\n",
            "recons_loss:0.004436\n",
            "grad_loss:0.095346\n",
            "dice_loss:-0.885308\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:50\n",
            "loss(total):-0.005066\n",
            "recons_loss:0.003233\n",
            "grad_loss:0.069877\n",
            "dice_loss:-0.899812\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:51\n",
            "loss(total):-0.001615\n",
            "recons_loss:0.005870\n",
            "grad_loss:0.132339\n",
            "dice_loss:-0.880914\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:52\n",
            "loss(total):-0.003818\n",
            "recons_loss:0.004249\n",
            "grad_loss:0.091984\n",
            "dice_loss:-0.898749\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:53\n",
            "loss(total):-0.004662\n",
            "recons_loss:0.003401\n",
            "grad_loss:0.085942\n",
            "dice_loss:-0.892178\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:54\n",
            "loss(total):-0.004431\n",
            "recons_loss:0.003637\n",
            "grad_loss:0.102925\n",
            "dice_loss:-0.909759\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:55\n",
            "loss(total):-0.003736\n",
            "recons_loss:0.004160\n",
            "grad_loss:0.099196\n",
            "dice_loss:-0.888801\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:56\n",
            "loss(total):-0.003196\n",
            "recons_loss:0.004566\n",
            "grad_loss:0.095799\n",
            "dice_loss:-0.872086\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:57\n",
            "loss(total):-0.004438\n",
            "recons_loss:0.003672\n",
            "grad_loss:0.076951\n",
            "dice_loss:-0.887866\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:58\n",
            "loss(total):-0.001860\n",
            "recons_loss:0.005663\n",
            "grad_loss:0.137114\n",
            "dice_loss:-0.889455\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:59\n",
            "loss(total):-0.004017\n",
            "recons_loss:0.003873\n",
            "grad_loss:0.098489\n",
            "dice_loss:-0.887530\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:60\n",
            "loss(total):-0.004435\n",
            "recons_loss:0.003611\n",
            "grad_loss:0.082061\n",
            "dice_loss:-0.886634\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:61\n",
            "loss(total):-0.003540\n",
            "recons_loss:0.004524\n",
            "grad_loss:0.092272\n",
            "dice_loss:-0.898743\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:62\n",
            "loss(total):-0.004839\n",
            "recons_loss:0.003279\n",
            "grad_loss:0.078315\n",
            "dice_loss:-0.890180\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:63\n",
            "loss(total):-0.004247\n",
            "recons_loss:0.003904\n",
            "grad_loss:0.077541\n",
            "dice_loss:-0.892629\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:64\n",
            "loss(total):-0.005743\n",
            "recons_loss:0.002807\n",
            "grad_loss:0.061796\n",
            "dice_loss:-0.916718\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:65\n",
            "loss(total):-0.003499\n",
            "recons_loss:0.004598\n",
            "grad_loss:0.088376\n",
            "dice_loss:-0.898060\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:66\n",
            "loss(total):-0.004640\n",
            "recons_loss:0.003494\n",
            "grad_loss:0.079033\n",
            "dice_loss:-0.892527\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:67\n",
            "loss(total):-0.001396\n",
            "recons_loss:0.006104\n",
            "grad_loss:0.130614\n",
            "dice_loss:-0.880601\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:68\n",
            "loss(total):-0.003550\n",
            "recons_loss:0.004436\n",
            "grad_loss:0.098769\n",
            "dice_loss:-0.897378\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:69\n",
            "loss(total):-0.002940\n",
            "recons_loss:0.004901\n",
            "grad_loss:0.109888\n",
            "dice_loss:-0.893962\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:70\n",
            "loss(total):-0.004167\n",
            "recons_loss:0.003960\n",
            "grad_loss:0.079761\n",
            "dice_loss:-0.892411\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:71\n",
            "loss(total):-0.005665\n",
            "recons_loss:0.002696\n",
            "grad_loss:0.062521\n",
            "dice_loss:-0.898586\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:72\n",
            "loss(total):-0.002724\n",
            "recons_loss:0.005035\n",
            "grad_loss:0.107105\n",
            "dice_loss:-0.882990\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:73\n",
            "loss(total):-0.004409\n",
            "recons_loss:0.003712\n",
            "grad_loss:0.082968\n",
            "dice_loss:-0.895063\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:74\n",
            "loss(total):-0.002884\n",
            "recons_loss:0.004766\n",
            "grad_loss:0.123938\n",
            "dice_loss:-0.888961\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:75\n",
            "loss(total):-0.002907\n",
            "recons_loss:0.004873\n",
            "grad_loss:0.128469\n",
            "dice_loss:-0.906500\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:76\n",
            "loss(total):-0.003198\n",
            "recons_loss:0.004698\n",
            "grad_loss:0.101900\n",
            "dice_loss:-0.891517\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:77\n",
            "loss(total):-0.004346\n",
            "recons_loss:0.003637\n",
            "grad_loss:0.080220\n",
            "dice_loss:-0.878543\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:78\n",
            "loss(total):-0.003423\n",
            "recons_loss:0.004364\n",
            "grad_loss:0.097746\n",
            "dice_loss:-0.876413\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:79\n",
            "loss(total):-0.004551\n",
            "recons_loss:0.003602\n",
            "grad_loss:0.087986\n",
            "dice_loss:-0.903267\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:80\n",
            "loss(total):-0.004621\n",
            "recons_loss:0.003525\n",
            "grad_loss:0.079327\n",
            "dice_loss:-0.893903\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:81\n",
            "loss(total):-0.005745\n",
            "recons_loss:0.002750\n",
            "grad_loss:0.065545\n",
            "dice_loss:-0.915072\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:82\n",
            "loss(total):-0.003410\n",
            "recons_loss:0.004343\n",
            "grad_loss:0.111159\n",
            "dice_loss:-0.886471\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:83\n",
            "loss(total):-0.003311\n",
            "recons_loss:0.004654\n",
            "grad_loss:0.096613\n",
            "dice_loss:-0.893054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:84\n",
            "loss(total):-0.003958\n",
            "recons_loss:0.003974\n",
            "grad_loss:0.090099\n",
            "dice_loss:-0.883293\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:85\n",
            "loss(total):-0.003580\n",
            "recons_loss:0.004442\n",
            "grad_loss:0.091978\n",
            "dice_loss:-0.894116\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:86\n",
            "loss(total):-0.003280\n",
            "recons_loss:0.004684\n",
            "grad_loss:0.096034\n",
            "dice_loss:-0.892388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:87\n",
            "loss(total):-0.003896\n",
            "recons_loss:0.003904\n",
            "grad_loss:0.118604\n",
            "dice_loss:-0.898645\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:88\n",
            "loss(total):-0.004208\n",
            "recons_loss:0.003838\n",
            "grad_loss:0.102181\n",
            "dice_loss:-0.906784\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:89\n",
            "loss(total):-0.004508\n",
            "recons_loss:0.003527\n",
            "grad_loss:0.086699\n",
            "dice_loss:-0.890203\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:90\n",
            "loss(total):-0.003575\n",
            "recons_loss:0.004255\n",
            "grad_loss:0.105320\n",
            "dice_loss:-0.888322\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:91\n",
            "loss(total):-0.004628\n",
            "recons_loss:0.003452\n",
            "grad_loss:0.096933\n",
            "dice_loss:-0.904954\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:92\n",
            "loss(total):-0.003500\n",
            "recons_loss:0.004413\n",
            "grad_loss:0.091917\n",
            "dice_loss:-0.883276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:93\n",
            "loss(total):-0.004433\n",
            "recons_loss:0.003545\n",
            "grad_loss:0.084095\n",
            "dice_loss:-0.881911\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:94\n",
            "loss(total):-0.003902\n",
            "recons_loss:0.004105\n",
            "grad_loss:0.094870\n",
            "dice_loss:-0.895533\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:95\n",
            "loss(total):-0.003478\n",
            "recons_loss:0.004293\n",
            "grad_loss:0.102957\n",
            "dice_loss:-0.880021\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:96\n",
            "loss(total):-0.003930\n",
            "recons_loss:0.004183\n",
            "grad_loss:0.084967\n",
            "dice_loss:-0.896282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:97\n",
            "loss(total):-0.002676\n",
            "recons_loss:0.005111\n",
            "grad_loss:0.110183\n",
            "dice_loss:-0.888963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:98\n",
            "loss(total):-0.001504\n",
            "recons_loss:0.006083\n",
            "grad_loss:0.132369\n",
            "dice_loss:-0.891072\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:99\n",
            "loss(total):-0.004190\n",
            "recons_loss:0.003840\n",
            "grad_loss:0.091944\n",
            "dice_loss:-0.894875\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:100\n",
            "loss(total):-0.002254\n",
            "recons_loss:0.005604\n",
            "grad_loss:0.106519\n",
            "dice_loss:-0.892322\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:101\n",
            "loss(total):-0.003128\n",
            "recons_loss:0.004702\n",
            "grad_loss:0.109262\n",
            "dice_loss:-0.892227\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:102\n",
            "loss(total):-0.003590\n",
            "recons_loss:0.004481\n",
            "grad_loss:0.091407\n",
            "dice_loss:-0.898531\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:103\n",
            "loss(total):-0.004081\n",
            "recons_loss:0.004131\n",
            "grad_loss:0.072448\n",
            "dice_loss:-0.893606\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:104\n",
            "loss(total):-0.005154\n",
            "recons_loss:0.002948\n",
            "grad_loss:0.083780\n",
            "dice_loss:-0.893904\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:105\n",
            "loss(total):-0.003187\n",
            "recons_loss:0.004629\n",
            "grad_loss:0.110834\n",
            "dice_loss:-0.892513\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:106\n",
            "loss(total):-0.003591\n",
            "recons_loss:0.004189\n",
            "grad_loss:0.124869\n",
            "dice_loss:-0.902871\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:107\n",
            "loss(total):-0.003754\n",
            "recons_loss:0.004327\n",
            "grad_loss:0.096102\n",
            "dice_loss:-0.904177\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:108\n",
            "loss(total):-0.003819\n",
            "recons_loss:0.004109\n",
            "grad_loss:0.107731\n",
            "dice_loss:-0.900467\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:109\n",
            "loss(total):-0.002354\n",
            "recons_loss:0.005421\n",
            "grad_loss:0.117602\n",
            "dice_loss:-0.895108\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:110\n",
            "loss(total):-0.004125\n",
            "recons_loss:0.003744\n",
            "grad_loss:0.088166\n",
            "dice_loss:-0.875054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:111\n",
            "loss(total):-0.003738\n",
            "recons_loss:0.004155\n",
            "grad_loss:0.086962\n",
            "dice_loss:-0.876262\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:112\n",
            "loss(total):-0.004153\n",
            "recons_loss:0.003927\n",
            "grad_loss:0.090940\n",
            "dice_loss:-0.898959\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:113\n",
            "loss(total):-0.003313\n",
            "recons_loss:0.004545\n",
            "grad_loss:0.106214\n",
            "dice_loss:-0.891982\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:114\n",
            "loss(total):-0.004296\n",
            "recons_loss:0.003668\n",
            "grad_loss:0.089640\n",
            "dice_loss:-0.886055\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:115\n",
            "loss(total):-0.003553\n",
            "recons_loss:0.004244\n",
            "grad_loss:0.100801\n",
            "dice_loss:-0.880507\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:116\n",
            "loss(total):-0.002191\n",
            "recons_loss:0.005239\n",
            "grad_loss:0.142588\n",
            "dice_loss:-0.885658\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:117\n",
            "loss(total):-0.003811\n",
            "recons_loss:0.004039\n",
            "grad_loss:0.108612\n",
            "dice_loss:-0.893643\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:118\n",
            "loss(total):-0.003718\n",
            "recons_loss:0.004221\n",
            "grad_loss:0.097259\n",
            "dice_loss:-0.891159\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:119\n",
            "loss(total):-0.002924\n",
            "recons_loss:0.004847\n",
            "grad_loss:0.098175\n",
            "dice_loss:-0.875282\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:120\n",
            "loss(total):-0.004485\n",
            "recons_loss:0.003619\n",
            "grad_loss:0.093000\n",
            "dice_loss:-0.903412\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:121\n",
            "loss(total):-0.004285\n",
            "recons_loss:0.003801\n",
            "grad_loss:0.080747\n",
            "dice_loss:-0.889354\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:122\n",
            "loss(total):-0.002146\n",
            "recons_loss:0.005264\n",
            "grad_loss:0.129307\n",
            "dice_loss:-0.870276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:123\n",
            "loss(total):-0.003421\n",
            "recons_loss:0.004443\n",
            "grad_loss:0.113365\n",
            "dice_loss:-0.899826\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:124\n",
            "loss(total):-0.004244\n",
            "recons_loss:0.003892\n",
            "grad_loss:0.083264\n",
            "dice_loss:-0.896848\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:125\n",
            "loss(total):-0.002670\n",
            "recons_loss:0.005139\n",
            "grad_loss:0.098165\n",
            "dice_loss:-0.879049\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:126\n",
            "loss(total):-0.002875\n",
            "recons_loss:0.004764\n",
            "grad_loss:0.100393\n",
            "dice_loss:-0.864324\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:127\n",
            "loss(total):-0.003668\n",
            "recons_loss:0.004111\n",
            "grad_loss:0.098391\n",
            "dice_loss:-0.876308\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:128\n",
            "loss(total):-0.005227\n",
            "recons_loss:0.003280\n",
            "grad_loss:0.065918\n",
            "dice_loss:-0.916617\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:129\n",
            "loss(total):-0.003789\n",
            "recons_loss:0.003942\n",
            "grad_loss:0.099331\n",
            "dice_loss:-0.872475\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:130\n",
            "loss(total):-0.003623\n",
            "recons_loss:0.004266\n",
            "grad_loss:0.094836\n",
            "dice_loss:-0.883780\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:131\n",
            "loss(total):-0.003088\n",
            "recons_loss:0.004647\n",
            "grad_loss:0.116379\n",
            "dice_loss:-0.889794\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:132\n",
            "loss(total):-0.004166\n",
            "recons_loss:0.003932\n",
            "grad_loss:0.085657\n",
            "dice_loss:-0.895473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:133\n",
            "loss(total):-0.004511\n",
            "recons_loss:0.003531\n",
            "grad_loss:0.085673\n",
            "dice_loss:-0.889884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:134\n",
            "loss(total):-0.003384\n",
            "recons_loss:0.004542\n",
            "grad_loss:0.103947\n",
            "dice_loss:-0.896484\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:135\n",
            "loss(total):-0.003945\n",
            "recons_loss:0.004205\n",
            "grad_loss:0.085674\n",
            "dice_loss:-0.900678\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:136\n",
            "loss(total):-0.003134\n",
            "recons_loss:0.004850\n",
            "grad_loss:0.093678\n",
            "dice_loss:-0.892079\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:137\n",
            "loss(total):-0.003826\n",
            "recons_loss:0.004217\n",
            "grad_loss:0.088590\n",
            "dice_loss:-0.892934\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:138\n",
            "loss(total):-0.003581\n",
            "recons_loss:0.004282\n",
            "grad_loss:0.108440\n",
            "dice_loss:-0.894737\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:139\n",
            "loss(total):-0.003352\n",
            "recons_loss:0.004685\n",
            "grad_loss:0.100317\n",
            "dice_loss:-0.904028\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:140\n",
            "loss(total):-0.003693\n",
            "recons_loss:0.004178\n",
            "grad_loss:0.094383\n",
            "dice_loss:-0.881507\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:141\n",
            "loss(total):-0.002887\n",
            "recons_loss:0.004755\n",
            "grad_loss:0.115008\n",
            "dice_loss:-0.879201\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:142\n",
            "loss(total):-0.003361\n",
            "recons_loss:0.004509\n",
            "grad_loss:0.096386\n",
            "dice_loss:-0.883420\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:143\n",
            "loss(total):-0.004717\n",
            "recons_loss:0.003576\n",
            "grad_loss:0.068791\n",
            "dice_loss:-0.898129\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:144\n",
            "loss(total):-0.005629\n",
            "recons_loss:0.002590\n",
            "grad_loss:0.073040\n",
            "dice_loss:-0.894939\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:145\n",
            "loss(total):-0.004377\n",
            "recons_loss:0.003817\n",
            "grad_loss:0.074351\n",
            "dice_loss:-0.893758\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:146\n",
            "loss(total):-0.002213\n",
            "recons_loss:0.005246\n",
            "grad_loss:0.134577\n",
            "dice_loss:-0.880476\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:147\n",
            "loss(total):-0.004152\n",
            "recons_loss:0.003822\n",
            "grad_loss:0.101041\n",
            "dice_loss:-0.898370\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:148\n",
            "loss(total):-0.004149\n",
            "recons_loss:0.003920\n",
            "grad_loss:0.099429\n",
            "dice_loss:-0.906344\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:149\n",
            "loss(total):-0.001822\n",
            "recons_loss:0.005676\n",
            "grad_loss:0.141958\n",
            "dice_loss:-0.891753\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:150\n",
            "loss(total):-0.004739\n",
            "recons_loss:0.003496\n",
            "grad_loss:0.071542\n",
            "dice_loss:-0.895040\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:151\n",
            "loss(total):-0.005077\n",
            "recons_loss:0.003217\n",
            "grad_loss:0.064730\n",
            "dice_loss:-0.894153\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:152\n",
            "loss(total):-0.003027\n",
            "recons_loss:0.004910\n",
            "grad_loss:0.101342\n",
            "dice_loss:-0.895011\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:153\n",
            "loss(total):-0.003849\n",
            "recons_loss:0.004072\n",
            "grad_loss:0.089903\n",
            "dice_loss:-0.881972\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:154\n",
            "loss(total):-0.003107\n",
            "recons_loss:0.004737\n",
            "grad_loss:0.100544\n",
            "dice_loss:-0.884943\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:155\n",
            "loss(total):-0.003553\n",
            "recons_loss:0.004328\n",
            "grad_loss:0.097120\n",
            "dice_loss:-0.885265\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:156\n",
            "loss(total):-0.003917\n",
            "recons_loss:0.004092\n",
            "grad_loss:0.101201\n",
            "dice_loss:-0.902074\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:157\n",
            "loss(total):-0.002540\n",
            "recons_loss:0.005209\n",
            "grad_loss:0.101905\n",
            "dice_loss:-0.876875\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:158\n",
            "loss(total):-0.003270\n",
            "recons_loss:0.004693\n",
            "grad_loss:0.093574\n",
            "dice_loss:-0.889907\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:159\n",
            "loss(total):-0.003681\n",
            "recons_loss:0.004235\n",
            "grad_loss:0.096262\n",
            "dice_loss:-0.887812\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:160\n",
            "loss(total):-0.004103\n",
            "recons_loss:0.003801\n",
            "grad_loss:0.094016\n",
            "dice_loss:-0.884440\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:161\n",
            "loss(total):-0.003388\n",
            "recons_loss:0.004589\n",
            "grad_loss:0.085400\n",
            "dice_loss:-0.883091\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:162\n",
            "loss(total):-0.003809\n",
            "recons_loss:0.003994\n",
            "grad_loss:0.111529\n",
            "dice_loss:-0.891864\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:163\n",
            "loss(total):-0.002771\n",
            "recons_loss:0.004865\n",
            "grad_loss:0.126783\n",
            "dice_loss:-0.890424\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:164\n",
            "loss(total):-0.002539\n",
            "recons_loss:0.005164\n",
            "grad_loss:0.106964\n",
            "dice_loss:-0.877236\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:165\n",
            "loss(total):-0.003708\n",
            "recons_loss:0.004287\n",
            "grad_loss:0.104128\n",
            "dice_loss:-0.903623\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:166\n",
            "loss(total):-0.003955\n",
            "recons_loss:0.004069\n",
            "grad_loss:0.088556\n",
            "dice_loss:-0.891020\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:167\n",
            "loss(total):-0.004318\n",
            "recons_loss:0.003690\n",
            "grad_loss:0.091510\n",
            "dice_loss:-0.892272\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:168\n",
            "loss(total):-0.003481\n",
            "recons_loss:0.004336\n",
            "grad_loss:0.103678\n",
            "dice_loss:-0.885339\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:169\n",
            "loss(total):-0.003171\n",
            "recons_loss:0.004693\n",
            "grad_loss:0.096942\n",
            "dice_loss:-0.883356\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:170\n",
            "loss(total):-0.003793\n",
            "recons_loss:0.004214\n",
            "grad_loss:0.097230\n",
            "dice_loss:-0.897919\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:171\n",
            "loss(total):-0.003088\n",
            "recons_loss:0.004799\n",
            "grad_loss:0.101676\n",
            "dice_loss:-0.890314\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:172\n",
            "loss(total):-0.003744\n",
            "recons_loss:0.004179\n",
            "grad_loss:0.100964\n",
            "dice_loss:-0.893278\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:173\n",
            "loss(total):-0.004235\n",
            "recons_loss:0.003719\n",
            "grad_loss:0.102991\n",
            "dice_loss:-0.898382\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:174\n",
            "loss(total):-0.002774\n",
            "recons_loss:0.005117\n",
            "grad_loss:0.101679\n",
            "dice_loss:-0.890850\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:175\n",
            "loss(total):-0.003374\n",
            "recons_loss:0.004660\n",
            "grad_loss:0.092434\n",
            "dice_loss:-0.895853\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:176\n",
            "loss(total):-0.004922\n",
            "recons_loss:0.003606\n",
            "grad_loss:0.059390\n",
            "dice_loss:-0.912176\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:177\n",
            "loss(total):-0.003663\n",
            "recons_loss:0.004223\n",
            "grad_loss:0.110510\n",
            "dice_loss:-0.899059\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:178\n",
            "loss(total):-0.004179\n",
            "recons_loss:0.003972\n",
            "grad_loss:0.085804\n",
            "dice_loss:-0.900935\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:179\n",
            "loss(total):-0.003475\n",
            "recons_loss:0.004447\n",
            "grad_loss:0.098652\n",
            "dice_loss:-0.890789\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:180\n",
            "loss(total):-0.003303\n",
            "recons_loss:0.004523\n",
            "grad_loss:0.104038\n",
            "dice_loss:-0.886588\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:181\n",
            "loss(total):-0.003981\n",
            "recons_loss:0.004073\n",
            "grad_loss:0.084346\n",
            "dice_loss:-0.889727\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:182\n",
            "loss(total):-0.003588\n",
            "recons_loss:0.004160\n",
            "grad_loss:0.100128\n",
            "dice_loss:-0.874840\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:183\n",
            "loss(total):-0.003324\n",
            "recons_loss:0.004411\n",
            "grad_loss:0.112933\n",
            "dice_loss:-0.886433\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:184\n",
            "loss(total):-0.003531\n",
            "recons_loss:0.004350\n",
            "grad_loss:0.097856\n",
            "dice_loss:-0.885976\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:185\n",
            "loss(total):-0.003407\n",
            "recons_loss:0.004390\n",
            "grad_loss:0.117802\n",
            "dice_loss:-0.897486\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:186\n",
            "loss(total):-0.001811\n",
            "recons_loss:0.005847\n",
            "grad_loss:0.118403\n",
            "dice_loss:-0.884168\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:187\n",
            "loss(total):-0.002755\n",
            "recons_loss:0.004949\n",
            "grad_loss:0.122897\n",
            "dice_loss:-0.893337\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:188\n",
            "loss(total):-0.002999\n",
            "recons_loss:0.004600\n",
            "grad_loss:0.116229\n",
            "dice_loss:-0.876132\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:189\n",
            "loss(total):-0.002534\n",
            "recons_loss:0.005071\n",
            "grad_loss:0.135192\n",
            "dice_loss:-0.895717\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:190\n",
            "loss(total):-0.003679\n",
            "recons_loss:0.004179\n",
            "grad_loss:0.099422\n",
            "dice_loss:-0.885228\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:191\n",
            "loss(total):-0.002281\n",
            "recons_loss:0.005356\n",
            "grad_loss:0.119042\n",
            "dice_loss:-0.882764\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:192\n",
            "loss(total):-0.004397\n",
            "recons_loss:0.003644\n",
            "grad_loss:0.095332\n",
            "dice_loss:-0.899420\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:193\n",
            "loss(total):-0.002858\n",
            "recons_loss:0.004936\n",
            "grad_loss:0.105780\n",
            "dice_loss:-0.885167\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:194\n",
            "loss(total):-0.004995\n",
            "recons_loss:0.003260\n",
            "grad_loss:0.078066\n",
            "dice_loss:-0.903604\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:195\n",
            "loss(total):-0.004039\n",
            "recons_loss:0.003958\n",
            "grad_loss:0.092455\n",
            "dice_loss:-0.892194\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:196\n",
            "loss(total):-0.004201\n",
            "recons_loss:0.003816\n",
            "grad_loss:0.092137\n",
            "dice_loss:-0.893816\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:197\n",
            "loss(total):-0.003016\n",
            "recons_loss:0.004801\n",
            "grad_loss:0.107164\n",
            "dice_loss:-0.888887\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:198\n",
            "loss(total):-0.002136\n",
            "recons_loss:0.005566\n",
            "grad_loss:0.111329\n",
            "dice_loss:-0.881515\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:199\n",
            "loss(total):-0.003597\n",
            "recons_loss:0.004282\n",
            "grad_loss:0.091977\n",
            "dice_loss:-0.879825\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:200\n",
            "loss(total):-0.002850\n",
            "recons_loss:0.004772\n",
            "grad_loss:0.112570\n",
            "dice_loss:-0.874760\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:201\n",
            "loss(total):-0.002488\n",
            "recons_loss:0.005226\n",
            "grad_loss:0.121375\n",
            "dice_loss:-0.892792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:202\n",
            "loss(total):-0.004134\n",
            "recons_loss:0.003924\n",
            "grad_loss:0.093037\n",
            "dice_loss:-0.898832\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:203\n",
            "loss(total):-0.003411\n",
            "recons_loss:0.004485\n",
            "grad_loss:0.100352\n",
            "dice_loss:-0.889909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:204\n",
            "loss(total):-0.002756\n",
            "recons_loss:0.004918\n",
            "grad_loss:0.105563\n",
            "dice_loss:-0.873028\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:205\n",
            "loss(total):-0.004325\n",
            "recons_loss:0.003841\n",
            "grad_loss:0.090559\n",
            "dice_loss:-0.907147\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:206\n",
            "loss(total):-0.004015\n",
            "recons_loss:0.003999\n",
            "grad_loss:0.103959\n",
            "dice_loss:-0.905393\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:207\n",
            "loss(total):-0.004587\n",
            "recons_loss:0.003466\n",
            "grad_loss:0.080143\n",
            "dice_loss:-0.885388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:208\n",
            "loss(total):-0.004629\n",
            "recons_loss:0.003798\n",
            "grad_loss:0.060244\n",
            "dice_loss:-0.902910\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:209\n",
            "loss(total):-0.003951\n",
            "recons_loss:0.003979\n",
            "grad_loss:0.109652\n",
            "dice_loss:-0.902686\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:210\n",
            "loss(total):-0.003035\n",
            "recons_loss:0.004787\n",
            "grad_loss:0.105619\n",
            "dice_loss:-0.887786\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:211\n",
            "loss(total):-0.003934\n",
            "recons_loss:0.004075\n",
            "grad_loss:0.103951\n",
            "dice_loss:-0.904844\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:212\n",
            "loss(total):-0.004103\n",
            "recons_loss:0.004100\n",
            "grad_loss:0.085766\n",
            "dice_loss:-0.905988\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:213\n",
            "loss(total):-0.003498\n",
            "recons_loss:0.004268\n",
            "grad_loss:0.097066\n",
            "dice_loss:-0.873707\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:214\n",
            "loss(total):-0.004994\n",
            "recons_loss:0.003177\n",
            "grad_loss:0.086895\n",
            "dice_loss:-0.903997\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:215\n",
            "loss(total):-0.004467\n",
            "recons_loss:0.003595\n",
            "grad_loss:0.091728\n",
            "dice_loss:-0.897905\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:216\n",
            "loss(total):-0.003538\n",
            "recons_loss:0.004366\n",
            "grad_loss:0.096123\n",
            "dice_loss:-0.886535\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:217\n",
            "loss(total):-0.004057\n",
            "recons_loss:0.003958\n",
            "grad_loss:0.089116\n",
            "dice_loss:-0.890581\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:218\n",
            "loss(total):-0.003288\n",
            "recons_loss:0.004461\n",
            "grad_loss:0.112974\n",
            "dice_loss:-0.887784\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:219\n",
            "loss(total):-0.004572\n",
            "recons_loss:0.003615\n",
            "grad_loss:0.074909\n",
            "dice_loss:-0.893611\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:220\n",
            "loss(total):-0.002898\n",
            "recons_loss:0.004747\n",
            "grad_loss:0.112614\n",
            "dice_loss:-0.877094\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:221\n",
            "loss(total):-0.003098\n",
            "recons_loss:0.004523\n",
            "grad_loss:0.104854\n",
            "dice_loss:-0.866943\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:222\n",
            "loss(total):-0.002909\n",
            "recons_loss:0.004765\n",
            "grad_loss:0.117964\n",
            "dice_loss:-0.885341\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:223\n",
            "loss(total):-0.004930\n",
            "recons_loss:0.003264\n",
            "grad_loss:0.078746\n",
            "dice_loss:-0.898169\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:224\n",
            "loss(total):-0.004258\n",
            "recons_loss:0.003659\n",
            "grad_loss:0.092479\n",
            "dice_loss:-0.884171\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:225\n",
            "loss(total):-0.002513\n",
            "recons_loss:0.005248\n",
            "grad_loss:0.117127\n",
            "dice_loss:-0.893185\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:226\n",
            "loss(total):-0.002840\n",
            "recons_loss:0.004924\n",
            "grad_loss:0.108896\n",
            "dice_loss:-0.885339\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:227\n",
            "loss(total):-0.004479\n",
            "recons_loss:0.003621\n",
            "grad_loss:0.083879\n",
            "dice_loss:-0.893888\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:228\n",
            "loss(total):-0.004631\n",
            "recons_loss:0.003515\n",
            "grad_loss:0.078443\n",
            "dice_loss:-0.893018\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:229\n",
            "loss(total):-0.002080\n",
            "recons_loss:0.005605\n",
            "grad_loss:0.108164\n",
            "dice_loss:-0.876617\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:230\n",
            "loss(total):-0.003780\n",
            "recons_loss:0.004165\n",
            "grad_loss:0.088026\n",
            "dice_loss:-0.882503\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:231\n",
            "loss(total):-0.002378\n",
            "recons_loss:0.005452\n",
            "grad_loss:0.095383\n",
            "dice_loss:-0.878436\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:232\n",
            "loss(total):-0.003621\n",
            "recons_loss:0.004479\n",
            "grad_loss:0.090558\n",
            "dice_loss:-0.900538\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:233\n",
            "loss(total):-0.003504\n",
            "recons_loss:0.004340\n",
            "grad_loss:0.109513\n",
            "dice_loss:-0.893882\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:234\n",
            "loss(total):-0.003939\n",
            "recons_loss:0.003974\n",
            "grad_loss:0.095483\n",
            "dice_loss:-0.886831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:235\n",
            "loss(total):-0.002065\n",
            "recons_loss:0.005562\n",
            "grad_loss:0.125482\n",
            "dice_loss:-0.888177\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:236\n",
            "loss(total):-0.002524\n",
            "recons_loss:0.005102\n",
            "grad_loss:0.121646\n",
            "dice_loss:-0.884293\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:237\n",
            "loss(total):-0.003689\n",
            "recons_loss:0.004275\n",
            "grad_loss:0.099111\n",
            "dice_loss:-0.895457\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:238\n",
            "loss(total):-0.005151\n",
            "recons_loss:0.002947\n",
            "grad_loss:0.088315\n",
            "dice_loss:-0.898040\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:239\n",
            "loss(total):-0.002492\n",
            "recons_loss:0.005346\n",
            "grad_loss:0.110539\n",
            "dice_loss:-0.894355\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:240\n",
            "loss(total):-0.003610\n",
            "recons_loss:0.004324\n",
            "grad_loss:0.094671\n",
            "dice_loss:-0.888013\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:241\n",
            "loss(total):-0.002722\n",
            "recons_loss:0.005121\n",
            "grad_loss:0.099767\n",
            "dice_loss:-0.884001\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:242\n",
            "loss(total):-0.002432\n",
            "recons_loss:0.005181\n",
            "grad_loss:0.115954\n",
            "dice_loss:-0.877255\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:243\n",
            "loss(total):-0.003171\n",
            "recons_loss:0.004745\n",
            "grad_loss:0.099533\n",
            "dice_loss:-0.891107\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:244\n",
            "loss(total):-0.004351\n",
            "recons_loss:0.003636\n",
            "grad_loss:0.084424\n",
            "dice_loss:-0.883193\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:245\n",
            "loss(total):-0.002701\n",
            "recons_loss:0.005041\n",
            "grad_loss:0.126206\n",
            "dice_loss:-0.900363\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:246\n",
            "loss(total):-0.003876\n",
            "recons_loss:0.004091\n",
            "grad_loss:0.101882\n",
            "dice_loss:-0.898574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:247\n",
            "loss(total):-0.003168\n",
            "recons_loss:0.004789\n",
            "grad_loss:0.091267\n",
            "dice_loss:-0.886997\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:248\n",
            "loss(total):-0.003492\n",
            "recons_loss:0.004466\n",
            "grad_loss:0.106449\n",
            "dice_loss:-0.902189\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:249\n",
            "loss(total):-0.005198\n",
            "recons_loss:0.003005\n",
            "grad_loss:0.083274\n",
            "dice_loss:-0.903574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:250\n",
            "loss(total):-0.002481\n",
            "recons_loss:0.005290\n",
            "grad_loss:0.111705\n",
            "dice_loss:-0.888875\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:251\n",
            "loss(total):-0.002474\n",
            "recons_loss:0.005235\n",
            "grad_loss:0.112864\n",
            "dice_loss:-0.883753\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:252\n",
            "loss(total):-0.002803\n",
            "recons_loss:0.004849\n",
            "grad_loss:0.117450\n",
            "dice_loss:-0.882659\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:253\n",
            "loss(total):-0.005140\n",
            "recons_loss:0.002980\n",
            "grad_loss:0.078875\n",
            "dice_loss:-0.890875\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:254\n",
            "loss(total):-0.004485\n",
            "recons_loss:0.003588\n",
            "grad_loss:0.090341\n",
            "dice_loss:-0.897595\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:255\n",
            "loss(total):-0.003298\n",
            "recons_loss:0.004556\n",
            "grad_loss:0.111067\n",
            "dice_loss:-0.896475\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:256\n",
            "loss(total):-0.002734\n",
            "recons_loss:0.004886\n",
            "grad_loss:0.110711\n",
            "dice_loss:-0.872672\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:257\n",
            "loss(total):-0.003335\n",
            "recons_loss:0.004362\n",
            "grad_loss:0.112192\n",
            "dice_loss:-0.881900\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:258\n",
            "loss(total):-0.003341\n",
            "recons_loss:0.004265\n",
            "grad_loss:0.103061\n",
            "dice_loss:-0.863661\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:259\n",
            "loss(total):-0.003794\n",
            "recons_loss:0.004173\n",
            "grad_loss:0.100805\n",
            "dice_loss:-0.897572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:260\n",
            "loss(total):-0.003526\n",
            "recons_loss:0.004467\n",
            "grad_loss:0.098784\n",
            "dice_loss:-0.898041\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:261\n",
            "loss(total):-0.003042\n",
            "recons_loss:0.004681\n",
            "grad_loss:0.116558\n",
            "dice_loss:-0.888840\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:262\n",
            "loss(total):-0.002752\n",
            "recons_loss:0.005036\n",
            "grad_loss:0.108714\n",
            "dice_loss:-0.887479\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:263\n",
            "loss(total):-0.003473\n",
            "recons_loss:0.004328\n",
            "grad_loss:0.094970\n",
            "dice_loss:-0.875059\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:264\n",
            "loss(total):-0.004410\n",
            "recons_loss:0.003605\n",
            "grad_loss:0.096093\n",
            "dice_loss:-0.897588\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:265\n",
            "loss(total):-0.004093\n",
            "recons_loss:0.003871\n",
            "grad_loss:0.092269\n",
            "dice_loss:-0.888604\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:266\n",
            "loss(total):-0.004084\n",
            "recons_loss:0.003839\n",
            "grad_loss:0.091032\n",
            "dice_loss:-0.883300\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:267\n",
            "loss(total):-0.003268\n",
            "recons_loss:0.004605\n",
            "grad_loss:0.095171\n",
            "dice_loss:-0.882459\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:268\n",
            "loss(total):-0.004144\n",
            "recons_loss:0.003811\n",
            "grad_loss:0.100530\n",
            "dice_loss:-0.896031\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:269\n",
            "loss(total):-0.003817\n",
            "recons_loss:0.004170\n",
            "grad_loss:0.096211\n",
            "dice_loss:-0.894919\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:0\n",
            "loss(total):-0.003687\n",
            "recons_loss:0.004346\n",
            "grad_loss:0.097327\n",
            "dice_loss:-0.900579\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:1\n",
            "loss(total):-0.004630\n",
            "recons_loss:0.003477\n",
            "grad_loss:0.085877\n",
            "dice_loss:-0.896564\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:2\n",
            "loss(total):-0.004414\n",
            "recons_loss:0.003536\n",
            "grad_loss:0.100070\n",
            "dice_loss:-0.895102\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:3\n",
            "loss(total):-0.004171\n",
            "recons_loss:0.003927\n",
            "grad_loss:0.091458\n",
            "dice_loss:-0.901289\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:4\n",
            "loss(total):-0.003762\n",
            "recons_loss:0.004164\n",
            "grad_loss:0.108564\n",
            "dice_loss:-0.901189\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:5\n",
            "loss(total):-0.004125\n",
            "recons_loss:0.003975\n",
            "grad_loss:0.094181\n",
            "dice_loss:-0.904141\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:6\n",
            "loss(total):-0.002144\n",
            "recons_loss:0.005507\n",
            "grad_loss:0.119155\n",
            "dice_loss:-0.884236\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:7\n",
            "loss(total):-0.003396\n",
            "recons_loss:0.004246\n",
            "grad_loss:0.125049\n",
            "dice_loss:-0.889288\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:8\n",
            "loss(total):-0.003764\n",
            "recons_loss:0.004192\n",
            "grad_loss:0.090290\n",
            "dice_loss:-0.885838\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:9\n",
            "loss(total):-0.003642\n",
            "recons_loss:0.003997\n",
            "grad_loss:0.109411\n",
            "dice_loss:-0.873307\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:10\n",
            "loss(total):-0.003703\n",
            "recons_loss:0.004329\n",
            "grad_loss:0.092191\n",
            "dice_loss:-0.895398\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:11\n",
            "loss(total):-0.003614\n",
            "recons_loss:0.004380\n",
            "grad_loss:0.103682\n",
            "dice_loss:-0.903046\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:12\n",
            "loss(total):-0.003206\n",
            "recons_loss:0.004612\n",
            "grad_loss:0.107440\n",
            "dice_loss:-0.889156\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:13\n",
            "loss(total):-0.003840\n",
            "recons_loss:0.004024\n",
            "grad_loss:0.106051\n",
            "dice_loss:-0.892409\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:14\n",
            "loss(total):-0.004797\n",
            "recons_loss:0.003279\n",
            "grad_loss:0.080554\n",
            "dice_loss:-0.888233\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:15\n",
            "loss(total):-0.003410\n",
            "recons_loss:0.004280\n",
            "grad_loss:0.105778\n",
            "dice_loss:-0.874721\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:16\n",
            "loss(total):-0.003878\n",
            "recons_loss:0.004074\n",
            "grad_loss:0.100353\n",
            "dice_loss:-0.895572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:17\n",
            "loss(total):-0.005142\n",
            "recons_loss:0.002999\n",
            "grad_loss:0.084107\n",
            "dice_loss:-0.898247\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:18\n",
            "loss(total):-0.003849\n",
            "recons_loss:0.004218\n",
            "grad_loss:0.089611\n",
            "dice_loss:-0.896298\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:19\n",
            "loss(total):-0.004465\n",
            "recons_loss:0.003595\n",
            "grad_loss:0.088008\n",
            "dice_loss:-0.893982\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:20\n",
            "loss(total):-0.004709\n",
            "recons_loss:0.003392\n",
            "grad_loss:0.087626\n",
            "dice_loss:-0.897670\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:21\n",
            "loss(total):-0.003667\n",
            "recons_loss:0.004203\n",
            "grad_loss:0.100876\n",
            "dice_loss:-0.887869\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:22\n",
            "loss(total):-0.002716\n",
            "recons_loss:0.004976\n",
            "grad_loss:0.115280\n",
            "dice_loss:-0.884451\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:23\n",
            "loss(total):-0.004430\n",
            "recons_loss:0.003657\n",
            "grad_loss:0.080086\n",
            "dice_loss:-0.888716\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:24\n",
            "loss(total):-0.003045\n",
            "recons_loss:0.004946\n",
            "grad_loss:0.100528\n",
            "dice_loss:-0.899684\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:25\n",
            "loss(total):-0.004429\n",
            "recons_loss:0.003615\n",
            "grad_loss:0.075649\n",
            "dice_loss:-0.880053\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:26\n",
            "loss(total):-0.004283\n",
            "recons_loss:0.003833\n",
            "grad_loss:0.085371\n",
            "dice_loss:-0.896980\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:27\n",
            "loss(total):-0.003805\n",
            "recons_loss:0.004072\n",
            "grad_loss:0.108394\n",
            "dice_loss:-0.896103\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:28\n",
            "loss(total):-0.002995\n",
            "recons_loss:0.004749\n",
            "grad_loss:0.110120\n",
            "dice_loss:-0.884453\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:29\n",
            "loss(total):-0.004469\n",
            "recons_loss:0.003756\n",
            "grad_loss:0.069724\n",
            "dice_loss:-0.892264\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:30\n",
            "loss(total):-0.004414\n",
            "recons_loss:0.003506\n",
            "grad_loss:0.086807\n",
            "dice_loss:-0.878849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:31\n",
            "loss(total):-0.003948\n",
            "recons_loss:0.003932\n",
            "grad_loss:0.098322\n",
            "dice_loss:-0.886268\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:32\n",
            "loss(total):-0.004297\n",
            "recons_loss:0.003590\n",
            "grad_loss:0.110990\n",
            "dice_loss:-0.899635\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:33\n",
            "loss(total):-0.004568\n",
            "recons_loss:0.003411\n",
            "grad_loss:0.090534\n",
            "dice_loss:-0.888425\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:34\n",
            "loss(total):-0.003178\n",
            "recons_loss:0.004665\n",
            "grad_loss:0.110265\n",
            "dice_loss:-0.894584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:35\n",
            "loss(total):-0.004147\n",
            "recons_loss:0.003820\n",
            "grad_loss:0.084414\n",
            "dice_loss:-0.881115\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:36\n",
            "loss(total):-0.003207\n",
            "recons_loss:0.004591\n",
            "grad_loss:0.102540\n",
            "dice_loss:-0.882333\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:37\n",
            "loss(total):-0.003739\n",
            "recons_loss:0.004140\n",
            "grad_loss:0.085840\n",
            "dice_loss:-0.873735\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:38\n",
            "loss(total):-0.004632\n",
            "recons_loss:0.003405\n",
            "grad_loss:0.087192\n",
            "dice_loss:-0.890853\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:39\n",
            "loss(total):-0.003743\n",
            "recons_loss:0.004200\n",
            "grad_loss:0.103504\n",
            "dice_loss:-0.897766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:40\n",
            "loss(total):-0.005609\n",
            "recons_loss:0.002603\n",
            "grad_loss:0.077277\n",
            "dice_loss:-0.898522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:41\n",
            "loss(total):-0.003590\n",
            "recons_loss:0.004125\n",
            "grad_loss:0.115306\n",
            "dice_loss:-0.886808\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:42\n",
            "loss(total):-0.004628\n",
            "recons_loss:0.003600\n",
            "grad_loss:0.079828\n",
            "dice_loss:-0.902638\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:43\n",
            "loss(total):-0.003891\n",
            "recons_loss:0.004083\n",
            "grad_loss:0.091833\n",
            "dice_loss:-0.889223\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:44\n",
            "loss(total):-0.002384\n",
            "recons_loss:0.005282\n",
            "grad_loss:0.119123\n",
            "dice_loss:-0.885720\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:45\n",
            "loss(total):-0.001948\n",
            "recons_loss:0.005691\n",
            "grad_loss:0.124327\n",
            "dice_loss:-0.888241\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:46\n",
            "loss(total):-0.004038\n",
            "recons_loss:0.003892\n",
            "grad_loss:0.095616\n",
            "dice_loss:-0.888611\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:47\n",
            "loss(total):-0.003229\n",
            "recons_loss:0.004749\n",
            "grad_loss:0.086687\n",
            "dice_loss:-0.884488\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:48\n",
            "loss(total):-0.004114\n",
            "recons_loss:0.003991\n",
            "grad_loss:0.080284\n",
            "dice_loss:-0.890732\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:49\n",
            "loss(total):-0.002309\n",
            "recons_loss:0.005372\n",
            "grad_loss:0.124863\n",
            "dice_loss:-0.892939\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:50\n",
            "loss(total):-0.002622\n",
            "recons_loss:0.005220\n",
            "grad_loss:0.104298\n",
            "dice_loss:-0.888506\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:51\n",
            "loss(total):-0.003228\n",
            "recons_loss:0.004595\n",
            "grad_loss:0.098554\n",
            "dice_loss:-0.880864\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:52\n",
            "loss(total):-0.003555\n",
            "recons_loss:0.004211\n",
            "grad_loss:0.100340\n",
            "dice_loss:-0.876960\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:53\n",
            "loss(total):-0.002902\n",
            "recons_loss:0.004915\n",
            "grad_loss:0.109723\n",
            "dice_loss:-0.891473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:54\n",
            "loss(total):-0.002671\n",
            "recons_loss:0.005096\n",
            "grad_loss:0.108981\n",
            "dice_loss:-0.885663\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:55\n",
            "loss(total):-0.003576\n",
            "recons_loss:0.004260\n",
            "grad_loss:0.089840\n",
            "dice_loss:-0.873485\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:56\n",
            "loss(total):-0.002414\n",
            "recons_loss:0.005201\n",
            "grad_loss:0.126969\n",
            "dice_loss:-0.888491\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:57\n",
            "loss(total):-0.004627\n",
            "recons_loss:0.003573\n",
            "grad_loss:0.086041\n",
            "dice_loss:-0.905988\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:58\n",
            "loss(total):-0.003261\n",
            "recons_loss:0.004583\n",
            "grad_loss:0.104221\n",
            "dice_loss:-0.888551\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:59\n",
            "loss(total):-0.003190\n",
            "recons_loss:0.004865\n",
            "grad_loss:0.093579\n",
            "dice_loss:-0.899146\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:60\n",
            "loss(total):-0.004553\n",
            "recons_loss:0.003673\n",
            "grad_loss:0.080613\n",
            "dice_loss:-0.903209\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:61\n",
            "loss(total):-0.002177\n",
            "recons_loss:0.005494\n",
            "grad_loss:0.129448\n",
            "dice_loss:-0.896575\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:62\n",
            "loss(total):-0.003878\n",
            "recons_loss:0.003999\n",
            "grad_loss:0.091234\n",
            "dice_loss:-0.878891\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:63\n",
            "loss(total):-0.004058\n",
            "recons_loss:0.003881\n",
            "grad_loss:0.096766\n",
            "dice_loss:-0.890726\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:64\n",
            "loss(total):-0.003204\n",
            "recons_loss:0.004737\n",
            "grad_loss:0.095440\n",
            "dice_loss:-0.889481\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:65\n",
            "loss(total):-0.003459\n",
            "recons_loss:0.004471\n",
            "grad_loss:0.099769\n",
            "dice_loss:-0.892804\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:66\n",
            "loss(total):-0.004444\n",
            "recons_loss:0.003660\n",
            "grad_loss:0.091831\n",
            "dice_loss:-0.902154\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:67\n",
            "loss(total):-0.004027\n",
            "recons_loss:0.004057\n",
            "grad_loss:0.090800\n",
            "dice_loss:-0.899188\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:68\n",
            "loss(total):-0.003292\n",
            "recons_loss:0.004534\n",
            "grad_loss:0.103414\n",
            "dice_loss:-0.886025\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:69\n",
            "loss(total):-0.005140\n",
            "recons_loss:0.003094\n",
            "grad_loss:0.070528\n",
            "dice_loss:-0.893844\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:70\n",
            "loss(total):-0.002733\n",
            "recons_loss:0.005047\n",
            "grad_loss:0.110673\n",
            "dice_loss:-0.888658\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:71\n",
            "loss(total):-0.004448\n",
            "recons_loss:0.003641\n",
            "grad_loss:0.089377\n",
            "dice_loss:-0.898259\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:72\n",
            "loss(total):-0.002089\n",
            "recons_loss:0.005433\n",
            "grad_loss:0.126800\n",
            "dice_loss:-0.878953\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:73\n",
            "loss(total):-0.003691\n",
            "recons_loss:0.004334\n",
            "grad_loss:0.092125\n",
            "dice_loss:-0.894612\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:74\n",
            "loss(total):-0.004159\n",
            "recons_loss:0.003983\n",
            "grad_loss:0.089154\n",
            "dice_loss:-0.903419\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:75\n",
            "loss(total):-0.004194\n",
            "recons_loss:0.003794\n",
            "grad_loss:0.080963\n",
            "dice_loss:-0.879792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:76\n",
            "loss(total):-0.003341\n",
            "recons_loss:0.004433\n",
            "grad_loss:0.118800\n",
            "dice_loss:-0.896182\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:77\n",
            "loss(total):-0.004062\n",
            "recons_loss:0.003821\n",
            "grad_loss:0.099850\n",
            "dice_loss:-0.888135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:78\n",
            "loss(total):-0.002551\n",
            "recons_loss:0.005128\n",
            "grad_loss:0.117953\n",
            "dice_loss:-0.885842\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:79\n",
            "loss(total):-0.004932\n",
            "recons_loss:0.003418\n",
            "grad_loss:0.065822\n",
            "dice_loss:-0.900783\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:80\n",
            "loss(total):-0.004357\n",
            "recons_loss:0.003714\n",
            "grad_loss:0.088755\n",
            "dice_loss:-0.895824\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:81\n",
            "loss(total):-0.002886\n",
            "recons_loss:0.004720\n",
            "grad_loss:0.124188\n",
            "dice_loss:-0.884797\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:82\n",
            "loss(total):-0.004130\n",
            "recons_loss:0.003859\n",
            "grad_loss:0.094159\n",
            "dice_loss:-0.893096\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:83\n",
            "loss(total):-0.004732\n",
            "recons_loss:0.003420\n",
            "grad_loss:0.078301\n",
            "dice_loss:-0.893473\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:84\n",
            "loss(total):-0.005395\n",
            "recons_loss:0.002913\n",
            "grad_loss:0.068323\n",
            "dice_loss:-0.899055\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:85\n",
            "loss(total):-0.004432\n",
            "recons_loss:0.003764\n",
            "grad_loss:0.076422\n",
            "dice_loss:-0.896091\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:86\n",
            "loss(total):-0.004450\n",
            "recons_loss:0.003569\n",
            "grad_loss:0.108035\n",
            "dice_loss:-0.909899\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:87\n",
            "loss(total):-0.003904\n",
            "recons_loss:0.003993\n",
            "grad_loss:0.106251\n",
            "dice_loss:-0.896017\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:88\n",
            "loss(total):-0.002376\n",
            "recons_loss:0.005063\n",
            "grad_loss:0.129814\n",
            "dice_loss:-0.873680\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:89\n",
            "loss(total):-0.003382\n",
            "recons_loss:0.004344\n",
            "grad_loss:0.104746\n",
            "dice_loss:-0.877376\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:90\n",
            "loss(total):-0.003188\n",
            "recons_loss:0.004413\n",
            "grad_loss:0.127700\n",
            "dice_loss:-0.887801\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:91\n",
            "loss(total):-0.001913\n",
            "recons_loss:0.005569\n",
            "grad_loss:0.133561\n",
            "dice_loss:-0.881713\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:92\n",
            "loss(total):-0.003111\n",
            "recons_loss:0.004628\n",
            "grad_loss:0.095085\n",
            "dice_loss:-0.868922\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:93\n",
            "loss(total):-0.002342\n",
            "recons_loss:0.005310\n",
            "grad_loss:0.123616\n",
            "dice_loss:-0.888799\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:94\n",
            "loss(total):-0.003042\n",
            "recons_loss:0.004812\n",
            "grad_loss:0.113081\n",
            "dice_loss:-0.898495\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:95\n",
            "loss(total):-0.003716\n",
            "recons_loss:0.004144\n",
            "grad_loss:0.099225\n",
            "dice_loss:-0.885276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:96\n",
            "loss(total):-0.002653\n",
            "recons_loss:0.004910\n",
            "grad_loss:0.130389\n",
            "dice_loss:-0.886652\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:97\n",
            "loss(total):-0.002779\n",
            "recons_loss:0.004774\n",
            "grad_loss:0.126399\n",
            "dice_loss:-0.881754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:98\n",
            "loss(total):-0.003693\n",
            "recons_loss:0.004344\n",
            "grad_loss:0.093275\n",
            "dice_loss:-0.896928\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:99\n",
            "loss(total):-0.004514\n",
            "recons_loss:0.003431\n",
            "grad_loss:0.090157\n",
            "dice_loss:-0.884685\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:100\n",
            "loss(total):-0.003595\n",
            "recons_loss:0.004456\n",
            "grad_loss:0.084274\n",
            "dice_loss:-0.889381\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:101\n",
            "loss(total):-0.002991\n",
            "recons_loss:0.004814\n",
            "grad_loss:0.108622\n",
            "dice_loss:-0.889162\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:102\n",
            "loss(total):-0.002604\n",
            "recons_loss:0.005068\n",
            "grad_loss:0.117819\n",
            "dice_loss:-0.884947\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:103\n",
            "loss(total):-0.000912\n",
            "recons_loss:0.006419\n",
            "grad_loss:0.141680\n",
            "dice_loss:-0.874734\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:104\n",
            "loss(total):-0.002512\n",
            "recons_loss:0.005247\n",
            "grad_loss:0.104228\n",
            "dice_loss:-0.880102\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:105\n",
            "loss(total):-0.003679\n",
            "recons_loss:0.004225\n",
            "grad_loss:0.100998\n",
            "dice_loss:-0.891441\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:106\n",
            "loss(total):-0.004220\n",
            "recons_loss:0.003913\n",
            "grad_loss:0.082469\n",
            "dice_loss:-0.895805\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:107\n",
            "loss(total):-0.004663\n",
            "recons_loss:0.003619\n",
            "grad_loss:0.069734\n",
            "dice_loss:-0.897978\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:108\n",
            "loss(total):-0.003148\n",
            "recons_loss:0.004946\n",
            "grad_loss:0.102031\n",
            "dice_loss:-0.911504\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:109\n",
            "loss(total):-0.004419\n",
            "recons_loss:0.003706\n",
            "grad_loss:0.089454\n",
            "dice_loss:-0.901992\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:110\n",
            "loss(total):-0.002854\n",
            "recons_loss:0.004934\n",
            "grad_loss:0.111293\n",
            "dice_loss:-0.890036\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:111\n",
            "loss(total):-0.004220\n",
            "recons_loss:0.003810\n",
            "grad_loss:0.083431\n",
            "dice_loss:-0.886467\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:112\n",
            "loss(total):-0.002283\n",
            "recons_loss:0.005284\n",
            "grad_loss:0.123366\n",
            "dice_loss:-0.880040\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:113\n",
            "loss(total):-0.005823\n",
            "recons_loss:0.002563\n",
            "grad_loss:0.064865\n",
            "dice_loss:-0.903502\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:114\n",
            "loss(total):-0.004018\n",
            "recons_loss:0.004046\n",
            "grad_loss:0.093983\n",
            "dice_loss:-0.900358\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:115\n",
            "loss(total):-0.003984\n",
            "recons_loss:0.004015\n",
            "grad_loss:0.093083\n",
            "dice_loss:-0.892950\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:116\n",
            "loss(total):-0.002221\n",
            "recons_loss:0.005389\n",
            "grad_loss:0.123976\n",
            "dice_loss:-0.884967\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:117\n",
            "loss(total):-0.003282\n",
            "recons_loss:0.004624\n",
            "grad_loss:0.104274\n",
            "dice_loss:-0.894817\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:118\n",
            "loss(total):-0.004015\n",
            "recons_loss:0.004054\n",
            "grad_loss:0.088403\n",
            "dice_loss:-0.895292\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:119\n",
            "loss(total):-0.003107\n",
            "recons_loss:0.004502\n",
            "grad_loss:0.119696\n",
            "dice_loss:-0.880605\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:120\n",
            "loss(total):-0.002965\n",
            "recons_loss:0.004673\n",
            "grad_loss:0.118962\n",
            "dice_loss:-0.882823\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:121\n",
            "loss(total):-0.004260\n",
            "recons_loss:0.003871\n",
            "grad_loss:0.077219\n",
            "dice_loss:-0.890263\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:122\n",
            "loss(total):-0.004338\n",
            "recons_loss:0.003836\n",
            "grad_loss:0.083852\n",
            "dice_loss:-0.901245\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:123\n",
            "loss(total):-0.004281\n",
            "recons_loss:0.003905\n",
            "grad_loss:0.074171\n",
            "dice_loss:-0.892798\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:124\n",
            "loss(total):-0.002783\n",
            "recons_loss:0.005161\n",
            "grad_loss:0.105545\n",
            "dice_loss:-0.899952\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:125\n",
            "loss(total):-0.004471\n",
            "recons_loss:0.003653\n",
            "grad_loss:0.081180\n",
            "dice_loss:-0.893570\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:126\n",
            "loss(total):-0.003728\n",
            "recons_loss:0.004277\n",
            "grad_loss:0.084685\n",
            "dice_loss:-0.885143\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:127\n",
            "loss(total):-0.003313\n",
            "recons_loss:0.004645\n",
            "grad_loss:0.097655\n",
            "dice_loss:-0.893506\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:128\n",
            "loss(total):-0.003721\n",
            "recons_loss:0.004150\n",
            "grad_loss:0.102903\n",
            "dice_loss:-0.889991\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:129\n",
            "loss(total):-0.004536\n",
            "recons_loss:0.003644\n",
            "grad_loss:0.079652\n",
            "dice_loss:-0.897696\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:130\n",
            "loss(total):-0.002350\n",
            "recons_loss:0.005606\n",
            "grad_loss:0.099743\n",
            "dice_loss:-0.895373\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:131\n",
            "loss(total):-0.005185\n",
            "recons_loss:0.003104\n",
            "grad_loss:0.069242\n",
            "dice_loss:-0.898107\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:132\n",
            "loss(total):-0.004974\n",
            "recons_loss:0.003264\n",
            "grad_loss:0.076970\n",
            "dice_loss:-0.900792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:133\n",
            "loss(total):-0.003660\n",
            "recons_loss:0.004209\n",
            "grad_loss:0.103112\n",
            "dice_loss:-0.890043\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:134\n",
            "loss(total):-0.002454\n",
            "recons_loss:0.005127\n",
            "grad_loss:0.122782\n",
            "dice_loss:-0.880873\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:135\n",
            "loss(total):-0.004034\n",
            "recons_loss:0.003906\n",
            "grad_loss:0.086852\n",
            "dice_loss:-0.880912\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:136\n",
            "loss(total):-0.002500\n",
            "recons_loss:0.005208\n",
            "grad_loss:0.109721\n",
            "dice_loss:-0.880571\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:137\n",
            "loss(total):-0.001737\n",
            "recons_loss:0.006003\n",
            "grad_loss:0.111845\n",
            "dice_loss:-0.885834\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:138\n",
            "loss(total):-0.004499\n",
            "recons_loss:0.003612\n",
            "grad_loss:0.083098\n",
            "dice_loss:-0.894201\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:139\n",
            "loss(total):-0.004465\n",
            "recons_loss:0.003563\n",
            "grad_loss:0.084491\n",
            "dice_loss:-0.887368\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:140\n",
            "loss(total):-0.003060\n",
            "recons_loss:0.004649\n",
            "grad_loss:0.110568\n",
            "dice_loss:-0.881390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:141\n",
            "loss(total):-0.003640\n",
            "recons_loss:0.004327\n",
            "grad_loss:0.107615\n",
            "dice_loss:-0.904291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:142\n",
            "loss(total):-0.004337\n",
            "recons_loss:0.003668\n",
            "grad_loss:0.087390\n",
            "dice_loss:-0.887884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:143\n",
            "loss(total):-0.004004\n",
            "recons_loss:0.004005\n",
            "grad_loss:0.094175\n",
            "dice_loss:-0.895127\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:144\n",
            "loss(total):-0.004698\n",
            "recons_loss:0.003368\n",
            "grad_loss:0.095346\n",
            "dice_loss:-0.901963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:145\n",
            "loss(total):-0.003651\n",
            "recons_loss:0.004152\n",
            "grad_loss:0.116064\n",
            "dice_loss:-0.896388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:146\n",
            "loss(total):-0.004861\n",
            "recons_loss:0.003303\n",
            "grad_loss:0.077957\n",
            "dice_loss:-0.894397\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:147\n",
            "loss(total):-0.004517\n",
            "recons_loss:0.003620\n",
            "grad_loss:0.082658\n",
            "dice_loss:-0.896277\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:148\n",
            "loss(total):-0.003802\n",
            "recons_loss:0.004209\n",
            "grad_loss:0.098948\n",
            "dice_loss:-0.899996\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:149\n",
            "loss(total):-0.001357\n",
            "recons_loss:0.006161\n",
            "grad_loss:0.138310\n",
            "dice_loss:-0.890051\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:150\n",
            "loss(total):-0.001787\n",
            "recons_loss:0.005766\n",
            "grad_loss:0.131593\n",
            "dice_loss:-0.886872\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:151\n",
            "loss(total):-0.003695\n",
            "recons_loss:0.004403\n",
            "grad_loss:0.083440\n",
            "dice_loss:-0.893219\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:152\n",
            "loss(total):-0.004621\n",
            "recons_loss:0.003663\n",
            "grad_loss:0.078054\n",
            "dice_loss:-0.906426\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:153\n",
            "loss(total):-0.004094\n",
            "recons_loss:0.003987\n",
            "grad_loss:0.085047\n",
            "dice_loss:-0.893162\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:154\n",
            "loss(total):-0.003517\n",
            "recons_loss:0.004434\n",
            "grad_loss:0.089175\n",
            "dice_loss:-0.884306\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:155\n",
            "loss(total):-0.002904\n",
            "recons_loss:0.004636\n",
            "grad_loss:0.120581\n",
            "dice_loss:-0.874635\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:156\n",
            "loss(total):-0.002417\n",
            "recons_loss:0.005197\n",
            "grad_loss:0.126938\n",
            "dice_loss:-0.888306\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:157\n",
            "loss(total):-0.002103\n",
            "recons_loss:0.005422\n",
            "grad_loss:0.130837\n",
            "dice_loss:-0.883420\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:158\n",
            "loss(total):-0.004739\n",
            "recons_loss:0.003561\n",
            "grad_loss:0.073574\n",
            "dice_loss:-0.903586\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:159\n",
            "loss(total):-0.004281\n",
            "recons_loss:0.003935\n",
            "grad_loss:0.072455\n",
            "dice_loss:-0.894055\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:160\n",
            "loss(total):-0.003596\n",
            "recons_loss:0.004448\n",
            "grad_loss:0.091462\n",
            "dice_loss:-0.895948\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:161\n",
            "loss(total):-0.003173\n",
            "recons_loss:0.004788\n",
            "grad_loss:0.110370\n",
            "dice_loss:-0.906509\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:162\n",
            "loss(total):-0.003949\n",
            "recons_loss:0.004047\n",
            "grad_loss:0.090179\n",
            "dice_loss:-0.889747\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:163\n",
            "loss(total):-0.004447\n",
            "recons_loss:0.003537\n",
            "grad_loss:0.090627\n",
            "dice_loss:-0.888995\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:164\n",
            "loss(total):-0.002858\n",
            "recons_loss:0.004882\n",
            "grad_loss:0.109012\n",
            "dice_loss:-0.883055\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:165\n",
            "loss(total):-0.003667\n",
            "recons_loss:0.004213\n",
            "grad_loss:0.095522\n",
            "dice_loss:-0.883480\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:166\n",
            "loss(total):-0.002908\n",
            "recons_loss:0.004998\n",
            "grad_loss:0.112381\n",
            "dice_loss:-0.902972\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:167\n",
            "loss(total):-0.003866\n",
            "recons_loss:0.004211\n",
            "grad_loss:0.084174\n",
            "dice_loss:-0.891793\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:168\n",
            "loss(total):-0.002214\n",
            "recons_loss:0.005384\n",
            "grad_loss:0.127271\n",
            "dice_loss:-0.887110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:169\n",
            "loss(total):-0.003875\n",
            "recons_loss:0.004111\n",
            "grad_loss:0.091906\n",
            "dice_loss:-0.890508\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:170\n",
            "loss(total):-0.004818\n",
            "recons_loss:0.003305\n",
            "grad_loss:0.083557\n",
            "dice_loss:-0.895799\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:171\n",
            "loss(total):-0.003796\n",
            "recons_loss:0.003940\n",
            "grad_loss:0.109934\n",
            "dice_loss:-0.883578\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:172\n",
            "loss(total):-0.003961\n",
            "recons_loss:0.004096\n",
            "grad_loss:0.089888\n",
            "dice_loss:-0.895506\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:173\n",
            "loss(total):-0.004230\n",
            "recons_loss:0.003815\n",
            "grad_loss:0.087508\n",
            "dice_loss:-0.891963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:174\n",
            "loss(total):-0.004954\n",
            "recons_loss:0.003177\n",
            "grad_loss:0.076422\n",
            "dice_loss:-0.889529\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:175\n",
            "loss(total):-0.003864\n",
            "recons_loss:0.004097\n",
            "grad_loss:0.095810\n",
            "dice_loss:-0.891845\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:176\n",
            "loss(total):-0.003924\n",
            "recons_loss:0.004113\n",
            "grad_loss:0.105222\n",
            "dice_loss:-0.908909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:177\n",
            "loss(total):-0.003041\n",
            "recons_loss:0.004858\n",
            "grad_loss:0.097550\n",
            "dice_loss:-0.887388\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:178\n",
            "loss(total):-0.003554\n",
            "recons_loss:0.004350\n",
            "grad_loss:0.090718\n",
            "dice_loss:-0.881131\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:179\n",
            "loss(total):-0.003167\n",
            "recons_loss:0.004727\n",
            "grad_loss:0.104383\n",
            "dice_loss:-0.893817\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:180\n",
            "loss(total):-0.002549\n",
            "recons_loss:0.005084\n",
            "grad_loss:0.120286\n",
            "dice_loss:-0.883581\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:181\n",
            "loss(total):-0.003207\n",
            "recons_loss:0.004439\n",
            "grad_loss:0.120892\n",
            "dice_loss:-0.885522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:182\n",
            "loss(total):-0.004058\n",
            "recons_loss:0.003921\n",
            "grad_loss:0.093411\n",
            "dice_loss:-0.891341\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:183\n",
            "loss(total):-0.004339\n",
            "recons_loss:0.003820\n",
            "grad_loss:0.087468\n",
            "dice_loss:-0.903371\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:184\n",
            "loss(total):-0.003619\n",
            "recons_loss:0.004327\n",
            "grad_loss:0.093678\n",
            "dice_loss:-0.888251\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:185\n",
            "loss(total):-0.003347\n",
            "recons_loss:0.004532\n",
            "grad_loss:0.095124\n",
            "dice_loss:-0.882964\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:186\n",
            "loss(total):-0.003890\n",
            "recons_loss:0.003919\n",
            "grad_loss:0.103786\n",
            "dice_loss:-0.884700\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:187\n",
            "loss(total):-0.002106\n",
            "recons_loss:0.005380\n",
            "grad_loss:0.128214\n",
            "dice_loss:-0.876806\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:188\n",
            "loss(total):-0.003391\n",
            "recons_loss:0.004388\n",
            "grad_loss:0.102453\n",
            "dice_loss:-0.880380\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:189\n",
            "loss(total):-0.003957\n",
            "recons_loss:0.004130\n",
            "grad_loss:0.091979\n",
            "dice_loss:-0.900626\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:190\n",
            "loss(total):-0.004710\n",
            "recons_loss:0.003340\n",
            "grad_loss:0.087663\n",
            "dice_loss:-0.892665\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:191\n",
            "loss(total):-0.003691\n",
            "recons_loss:0.004161\n",
            "grad_loss:0.096262\n",
            "dice_loss:-0.881418\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:192\n",
            "loss(total):-0.002838\n",
            "recons_loss:0.004896\n",
            "grad_loss:0.121134\n",
            "dice_loss:-0.894578\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:193\n",
            "loss(total):-0.002353\n",
            "recons_loss:0.005296\n",
            "grad_loss:0.108265\n",
            "dice_loss:-0.873242\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:194\n",
            "loss(total):-0.003798\n",
            "recons_loss:0.004205\n",
            "grad_loss:0.098258\n",
            "dice_loss:-0.898574\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:195\n",
            "loss(total):-0.003539\n",
            "recons_loss:0.004389\n",
            "grad_loss:0.100816\n",
            "dice_loss:-0.893551\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:196\n",
            "loss(total):-0.001384\n",
            "recons_loss:0.006277\n",
            "grad_loss:0.122562\n",
            "dice_loss:-0.888623\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:197\n",
            "loss(total):-0.002738\n",
            "recons_loss:0.005025\n",
            "grad_loss:0.105462\n",
            "dice_loss:-0.881782\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:198\n",
            "loss(total):-0.003684\n",
            "recons_loss:0.004186\n",
            "grad_loss:0.087758\n",
            "dice_loss:-0.874777\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:199\n",
            "loss(total):-0.004323\n",
            "recons_loss:0.003766\n",
            "grad_loss:0.089062\n",
            "dice_loss:-0.897914\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:200\n",
            "loss(total):-0.003723\n",
            "recons_loss:0.004218\n",
            "grad_loss:0.096499\n",
            "dice_loss:-0.890653\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:201\n",
            "loss(total):-0.003438\n",
            "recons_loss:0.004430\n",
            "grad_loss:0.096698\n",
            "dice_loss:-0.883488\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:202\n",
            "loss(total):-0.002829\n",
            "recons_loss:0.004892\n",
            "grad_loss:0.113607\n",
            "dice_loss:-0.885677\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:203\n",
            "loss(total):-0.002465\n",
            "recons_loss:0.005177\n",
            "grad_loss:0.123332\n",
            "dice_loss:-0.887525\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:204\n",
            "loss(total):-0.002811\n",
            "recons_loss:0.005144\n",
            "grad_loss:0.102770\n",
            "dice_loss:-0.898286\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:205\n",
            "loss(total):-0.004096\n",
            "recons_loss:0.004117\n",
            "grad_loss:0.084792\n",
            "dice_loss:-0.906054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:206\n",
            "loss(total):-0.003385\n",
            "recons_loss:0.004517\n",
            "grad_loss:0.100651\n",
            "dice_loss:-0.890850\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:207\n",
            "loss(total):-0.003295\n",
            "recons_loss:0.004577\n",
            "grad_loss:0.105465\n",
            "dice_loss:-0.892639\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:208\n",
            "loss(total):-0.004561\n",
            "recons_loss:0.003571\n",
            "grad_loss:0.081744\n",
            "dice_loss:-0.894949\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:209\n",
            "loss(total):-0.006316\n",
            "recons_loss:0.002241\n",
            "grad_loss:0.059890\n",
            "dice_loss:-0.915586\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:210\n",
            "loss(total):-0.003854\n",
            "recons_loss:0.004113\n",
            "grad_loss:0.094167\n",
            "dice_loss:-0.890843\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:211\n",
            "loss(total):-0.005246\n",
            "recons_loss:0.002815\n",
            "grad_loss:0.077431\n",
            "dice_loss:-0.883573\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:212\n",
            "loss(total):-0.004534\n",
            "recons_loss:0.003770\n",
            "grad_loss:0.067136\n",
            "dice_loss:-0.897531\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:213\n",
            "loss(total):-0.003085\n",
            "recons_loss:0.004842\n",
            "grad_loss:0.102292\n",
            "dice_loss:-0.894930\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:214\n",
            "loss(total):-0.004195\n",
            "recons_loss:0.003827\n",
            "grad_loss:0.090378\n",
            "dice_loss:-0.892584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:215\n",
            "loss(total):-0.003966\n",
            "recons_loss:0.003935\n",
            "grad_loss:0.088598\n",
            "dice_loss:-0.878704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:216\n",
            "loss(total):-0.002057\n",
            "recons_loss:0.005667\n",
            "grad_loss:0.105233\n",
            "dice_loss:-0.877657\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:217\n",
            "loss(total):-0.003272\n",
            "recons_loss:0.004684\n",
            "grad_loss:0.091920\n",
            "dice_loss:-0.887449\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:218\n",
            "loss(total):-0.003187\n",
            "recons_loss:0.004742\n",
            "grad_loss:0.090181\n",
            "dice_loss:-0.883071\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:219\n",
            "loss(total):-0.004402\n",
            "recons_loss:0.003488\n",
            "grad_loss:0.081767\n",
            "dice_loss:-0.870835\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:220\n",
            "loss(total):-0.003034\n",
            "recons_loss:0.004959\n",
            "grad_loss:0.107304\n",
            "dice_loss:-0.906606\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:221\n",
            "loss(total):-0.003247\n",
            "recons_loss:0.004680\n",
            "grad_loss:0.100393\n",
            "dice_loss:-0.893135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:222\n",
            "loss(total):-0.005491\n",
            "recons_loss:0.002925\n",
            "grad_loss:0.077199\n",
            "dice_loss:-0.918825\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:223\n",
            "loss(total):-0.004432\n",
            "recons_loss:0.003621\n",
            "grad_loss:0.086466\n",
            "dice_loss:-0.891764\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:224\n",
            "loss(total):-0.003050\n",
            "recons_loss:0.004725\n",
            "grad_loss:0.111305\n",
            "dice_loss:-0.888806\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:225\n",
            "loss(total):-0.002828\n",
            "recons_loss:0.004749\n",
            "grad_loss:0.118915\n",
            "dice_loss:-0.876681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:226\n",
            "loss(total):-0.003089\n",
            "recons_loss:0.004798\n",
            "grad_loss:0.102398\n",
            "dice_loss:-0.891102\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:227\n",
            "loss(total):-0.003033\n",
            "recons_loss:0.004777\n",
            "grad_loss:0.102647\n",
            "dice_loss:-0.883693\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:228\n",
            "loss(total):-0.002620\n",
            "recons_loss:0.005162\n",
            "grad_loss:0.119948\n",
            "dice_loss:-0.898192\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:229\n",
            "loss(total):-0.003337\n",
            "recons_loss:0.004681\n",
            "grad_loss:0.089104\n",
            "dice_loss:-0.890865\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:230\n",
            "loss(total):-0.004338\n",
            "recons_loss:0.003589\n",
            "grad_loss:0.092035\n",
            "dice_loss:-0.884763\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:231\n",
            "loss(total):-0.003318\n",
            "recons_loss:0.004660\n",
            "grad_loss:0.099713\n",
            "dice_loss:-0.897443\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:232\n",
            "loss(total):-0.004399\n",
            "recons_loss:0.003709\n",
            "grad_loss:0.079545\n",
            "dice_loss:-0.890331\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:233\n",
            "loss(total):-0.003450\n",
            "recons_loss:0.004390\n",
            "grad_loss:0.102505\n",
            "dice_loss:-0.886411\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:234\n",
            "loss(total):-0.004044\n",
            "recons_loss:0.003777\n",
            "grad_loss:0.097077\n",
            "dice_loss:-0.879235\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:235\n",
            "loss(total):-0.003577\n",
            "recons_loss:0.004397\n",
            "grad_loss:0.094565\n",
            "dice_loss:-0.891900\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:236\n",
            "loss(total):-0.002372\n",
            "recons_loss:0.005307\n",
            "grad_loss:0.114712\n",
            "dice_loss:-0.882583\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:237\n",
            "loss(total):-0.001770\n",
            "recons_loss:0.005806\n",
            "grad_loss:0.129597\n",
            "dice_loss:-0.887229\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:238\n",
            "loss(total):-0.003234\n",
            "recons_loss:0.004650\n",
            "grad_loss:0.107472\n",
            "dice_loss:-0.895792\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:239\n",
            "loss(total):-0.005238\n",
            "recons_loss:0.002951\n",
            "grad_loss:0.082778\n",
            "dice_loss:-0.901708\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:240\n",
            "loss(total):-0.002832\n",
            "recons_loss:0.004923\n",
            "grad_loss:0.116761\n",
            "dice_loss:-0.892258\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:241\n",
            "loss(total):-0.003751\n",
            "recons_loss:0.004214\n",
            "grad_loss:0.088902\n",
            "dice_loss:-0.885390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:242\n",
            "loss(total):-0.004072\n",
            "recons_loss:0.004065\n",
            "grad_loss:0.087784\n",
            "dice_loss:-0.901480\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:243\n",
            "loss(total):-0.004033\n",
            "recons_loss:0.003986\n",
            "grad_loss:0.097953\n",
            "dice_loss:-0.899878\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:244\n",
            "loss(total):-0.002780\n",
            "recons_loss:0.004999\n",
            "grad_loss:0.120104\n",
            "dice_loss:-0.898005\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:245\n",
            "loss(total):-0.002322\n",
            "recons_loss:0.005221\n",
            "grad_loss:0.134096\n",
            "dice_loss:-0.888367\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:246\n",
            "loss(total):-0.003519\n",
            "recons_loss:0.004419\n",
            "grad_loss:0.086266\n",
            "dice_loss:-0.880011\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:247\n",
            "loss(total):-0.002846\n",
            "recons_loss:0.004855\n",
            "grad_loss:0.124362\n",
            "dice_loss:-0.894522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:248\n",
            "loss(total):-0.004063\n",
            "recons_loss:0.003911\n",
            "grad_loss:0.092990\n",
            "dice_loss:-0.890355\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:249\n",
            "loss(total):-0.004309\n",
            "recons_loss:0.003651\n",
            "grad_loss:0.098211\n",
            "dice_loss:-0.894236\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:250\n",
            "loss(total):-0.003693\n",
            "recons_loss:0.004314\n",
            "grad_loss:0.101441\n",
            "dice_loss:-0.902164\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:251\n",
            "loss(total):-0.004108\n",
            "recons_loss:0.003766\n",
            "grad_loss:0.090886\n",
            "dice_loss:-0.878333\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:252\n",
            "loss(total):-0.002531\n",
            "recons_loss:0.005059\n",
            "grad_loss:0.128607\n",
            "dice_loss:-0.887603\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:253\n",
            "loss(total):-0.004026\n",
            "recons_loss:0.003881\n",
            "grad_loss:0.103135\n",
            "dice_loss:-0.893821\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:254\n",
            "loss(total):-0.002826\n",
            "recons_loss:0.005003\n",
            "grad_loss:0.103652\n",
            "dice_loss:-0.886584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:255\n",
            "loss(total):-0.003646\n",
            "recons_loss:0.004296\n",
            "grad_loss:0.103010\n",
            "dice_loss:-0.897211\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:256\n",
            "loss(total):-0.003583\n",
            "recons_loss:0.004459\n",
            "grad_loss:0.101011\n",
            "dice_loss:-0.905273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:257\n",
            "loss(total):-0.004870\n",
            "recons_loss:0.003301\n",
            "grad_loss:0.086628\n",
            "dice_loss:-0.903741\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:258\n",
            "loss(total):-0.002724\n",
            "recons_loss:0.005094\n",
            "grad_loss:0.110022\n",
            "dice_loss:-0.891787\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:259\n",
            "loss(total):-0.003073\n",
            "recons_loss:0.004692\n",
            "grad_loss:0.113714\n",
            "dice_loss:-0.890279\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:260\n",
            "loss(total):-0.003478\n",
            "recons_loss:0.004390\n",
            "grad_loss:0.109342\n",
            "dice_loss:-0.896136\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:261\n",
            "loss(total):-0.002799\n",
            "recons_loss:0.004899\n",
            "grad_loss:0.124971\n",
            "dice_loss:-0.894711\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:262\n",
            "loss(total):-0.004023\n",
            "recons_loss:0.003916\n",
            "grad_loss:0.102842\n",
            "dice_loss:-0.896795\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:263\n",
            "loss(total):-0.003380\n",
            "recons_loss:0.004380\n",
            "grad_loss:0.110496\n",
            "dice_loss:-0.886524\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:264\n",
            "loss(total):-0.004778\n",
            "recons_loss:0.003390\n",
            "grad_loss:0.075079\n",
            "dice_loss:-0.891884\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:265\n",
            "loss(total):-0.001665\n",
            "recons_loss:0.005765\n",
            "grad_loss:0.125114\n",
            "dice_loss:-0.868087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:266\n",
            "loss(total):-0.003980\n",
            "recons_loss:0.004019\n",
            "grad_loss:0.096541\n",
            "dice_loss:-0.896392\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:267\n",
            "loss(total):-0.002918\n",
            "recons_loss:0.004923\n",
            "grad_loss:0.108155\n",
            "dice_loss:-0.892295\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:268\n",
            "loss(total):-0.003817\n",
            "recons_loss:0.003925\n",
            "grad_loss:0.119437\n",
            "dice_loss:-0.893650\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:269\n",
            "loss(total):-0.004984\n",
            "recons_loss:0.003251\n",
            "grad_loss:0.080636\n",
            "dice_loss:-0.904162\n",
            "---------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLcu7BkbPZCE",
        "outputId": "087e2aba-df22-487e-b297-39e55313c0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(losses_8[1:])\n",
        "plt.show"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H8UtqdkPbb6",
        "outputId": "418883c8-06d5-4bb8-b44f-77a0401e9441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(validation_8)\n",
        "plt.show"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yT1Aa2XPh7_"
      },
      "source": [
        "import csv\n",
        "with open('validation_8.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6pxvmZ1EmhH"
      },
      "source": [
        "for h in range(0,len(validation_0)):\n",
        "  with open('validation_8.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, validation_8[h].numpy()])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uapTkznTLOgw"
      },
      "source": [
        "import csv\n",
        "with open('loss_8.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n",
        "\n",
        "for h in range(0,len(losses_8)):\n",
        "  with open('loss_8.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h, losses_8[h].numpy()])"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxeMLYD1PnPx"
      },
      "source": [
        "'''Training - hold out fold 9 for validation'''\n",
        "#Training\n",
        "gpu='0'\n",
        "atlas_file='/content/drive/My Drive/2020/Thesis/Data/atlas.npz'\n",
        "lr=1e-4\n",
        "n_iter=5000\n",
        "data_loss='mse'\n",
        "model='vm2'\n",
        "reg_param=0.01\n",
        "batch_size=10\n",
        "n_save_iter=100\n",
        "model_dir='/content/drive/My Drive/2020/Thesis/Data/validation_0/'\n",
        "valid = fold_9\n",
        "train_names = set_9\n",
        "EPOCH=30"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5bpViBoPu7t",
        "outputId": "f5a8df72-d71e-4911-aa73-a7dcb6a3ba9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses_9, validation_9=validate.train(data_dir,\n",
        "          train_names,\n",
        "          atlas_file,\n",
        "          lr,\n",
        "          data_loss,\n",
        "          model,\n",
        "          reg_param, \n",
        "          batch_size,\n",
        "          n_save_iter,\n",
        "          model_dir,Net(),EPOCH, valid)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Batch_number:185\n",
            "loss(total):-0.004202\n",
            "recons_loss:0.004012\n",
            "grad_loss:0.076595\n",
            "dice_loss:-0.898003\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:186\n",
            "loss(total):-0.004387\n",
            "recons_loss:0.003618\n",
            "grad_loss:0.085838\n",
            "dice_loss:-0.886271\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:187\n",
            "loss(total):-0.002323\n",
            "recons_loss:0.005112\n",
            "grad_loss:0.140468\n",
            "dice_loss:-0.883881\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:188\n",
            "loss(total):-0.003159\n",
            "recons_loss:0.004703\n",
            "grad_loss:0.106914\n",
            "dice_loss:-0.893089\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:189\n",
            "loss(total):-0.003854\n",
            "recons_loss:0.003970\n",
            "grad_loss:0.102124\n",
            "dice_loss:-0.884557\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:190\n",
            "loss(total):-0.003718\n",
            "recons_loss:0.004099\n",
            "grad_loss:0.106399\n",
            "dice_loss:-0.888152\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:191\n",
            "loss(total):-0.003196\n",
            "recons_loss:0.004532\n",
            "grad_loss:0.123780\n",
            "dice_loss:-0.896614\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:192\n",
            "loss(total):-0.004000\n",
            "recons_loss:0.004062\n",
            "grad_loss:0.095392\n",
            "dice_loss:-0.901560\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:193\n",
            "loss(total):-0.004468\n",
            "recons_loss:0.003573\n",
            "grad_loss:0.092240\n",
            "dice_loss:-0.896318\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:194\n",
            "loss(total):-0.004080\n",
            "recons_loss:0.003919\n",
            "grad_loss:0.098320\n",
            "dice_loss:-0.898292\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:195\n",
            "loss(total):-0.004824\n",
            "recons_loss:0.003441\n",
            "grad_loss:0.076073\n",
            "dice_loss:-0.902606\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:196\n",
            "loss(total):-0.002859\n",
            "recons_loss:0.004803\n",
            "grad_loss:0.111394\n",
            "dice_loss:-0.877660\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:197\n",
            "loss(total):-0.003546\n",
            "recons_loss:0.004393\n",
            "grad_loss:0.089830\n",
            "dice_loss:-0.883734\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:198\n",
            "loss(total):-0.003781\n",
            "recons_loss:0.004076\n",
            "grad_loss:0.096042\n",
            "dice_loss:-0.881721\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:199\n",
            "loss(total):-0.003664\n",
            "recons_loss:0.004175\n",
            "grad_loss:0.106317\n",
            "dice_loss:-0.890168\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:200\n",
            "loss(total):-0.002972\n",
            "recons_loss:0.004776\n",
            "grad_loss:0.118888\n",
            "dice_loss:-0.893712\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:201\n",
            "loss(total):-0.004579\n",
            "recons_loss:0.003652\n",
            "grad_loss:0.079167\n",
            "dice_loss:-0.902279\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:202\n",
            "loss(total):-0.004474\n",
            "recons_loss:0.003618\n",
            "grad_loss:0.085786\n",
            "dice_loss:-0.894939\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:203\n",
            "loss(total):-0.003964\n",
            "recons_loss:0.003852\n",
            "grad_loss:0.105265\n",
            "dice_loss:-0.886895\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:204\n",
            "loss(total):-0.002640\n",
            "recons_loss:0.005005\n",
            "grad_loss:0.111219\n",
            "dice_loss:-0.875736\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:205\n",
            "loss(total):-0.004115\n",
            "recons_loss:0.003898\n",
            "grad_loss:0.094079\n",
            "dice_loss:-0.895361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:206\n",
            "loss(total):-0.003562\n",
            "recons_loss:0.004329\n",
            "grad_loss:0.103862\n",
            "dice_loss:-0.892966\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:207\n",
            "loss(total):-0.003034\n",
            "recons_loss:0.004650\n",
            "grad_loss:0.123990\n",
            "dice_loss:-0.892360\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:208\n",
            "loss(total):-0.004244\n",
            "recons_loss:0.003910\n",
            "grad_loss:0.080071\n",
            "dice_loss:-0.895501\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:209\n",
            "loss(total):-0.003352\n",
            "recons_loss:0.004419\n",
            "grad_loss:0.120178\n",
            "dice_loss:-0.897280\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:210\n",
            "loss(total):-0.003849\n",
            "recons_loss:0.004067\n",
            "grad_loss:0.101244\n",
            "dice_loss:-0.892845\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:211\n",
            "loss(total):-0.004494\n",
            "recons_loss:0.003440\n",
            "grad_loss:0.100202\n",
            "dice_loss:-0.893584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:212\n",
            "loss(total):-0.004151\n",
            "recons_loss:0.003734\n",
            "grad_loss:0.108722\n",
            "dice_loss:-0.897255\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:213\n",
            "loss(total):-0.003402\n",
            "recons_loss:0.004312\n",
            "grad_loss:0.111719\n",
            "dice_loss:-0.883159\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:214\n",
            "loss(total):-0.003094\n",
            "recons_loss:0.004682\n",
            "grad_loss:0.101310\n",
            "dice_loss:-0.878933\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:215\n",
            "loss(total):-0.005043\n",
            "recons_loss:0.003090\n",
            "grad_loss:0.077558\n",
            "dice_loss:-0.890832\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:216\n",
            "loss(total):-0.004300\n",
            "recons_loss:0.003692\n",
            "grad_loss:0.097510\n",
            "dice_loss:-0.896716\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:217\n",
            "loss(total):-0.002829\n",
            "recons_loss:0.004848\n",
            "grad_loss:0.115237\n",
            "dice_loss:-0.882947\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:218\n",
            "loss(total):-0.002334\n",
            "recons_loss:0.005440\n",
            "grad_loss:0.109012\n",
            "dice_loss:-0.886420\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:219\n",
            "loss(total):-0.004228\n",
            "recons_loss:0.003619\n",
            "grad_loss:0.105476\n",
            "dice_loss:-0.890194\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:220\n",
            "loss(total):-0.004013\n",
            "recons_loss:0.003967\n",
            "grad_loss:0.097887\n",
            "dice_loss:-0.895903\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:221\n",
            "loss(total):-0.004198\n",
            "recons_loss:0.003671\n",
            "grad_loss:0.106391\n",
            "dice_loss:-0.893338\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:222\n",
            "loss(total):-0.005670\n",
            "recons_loss:0.002555\n",
            "grad_loss:0.088585\n",
            "dice_loss:-0.911089\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:223\n",
            "loss(total):-0.005094\n",
            "recons_loss:0.003002\n",
            "grad_loss:0.087635\n",
            "dice_loss:-0.897294\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:224\n",
            "loss(total):-0.003159\n",
            "recons_loss:0.004735\n",
            "grad_loss:0.094993\n",
            "dice_loss:-0.884330\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:225\n",
            "loss(total):-0.003841\n",
            "recons_loss:0.004061\n",
            "grad_loss:0.113789\n",
            "dice_loss:-0.903948\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:226\n",
            "loss(total):-0.003799\n",
            "recons_loss:0.004111\n",
            "grad_loss:0.102953\n",
            "dice_loss:-0.894043\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:227\n",
            "loss(total):-0.003923\n",
            "recons_loss:0.004049\n",
            "grad_loss:0.093114\n",
            "dice_loss:-0.890287\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:228\n",
            "loss(total):-0.004375\n",
            "recons_loss:0.003701\n",
            "grad_loss:0.087299\n",
            "dice_loss:-0.894924\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:229\n",
            "loss(total):-0.004397\n",
            "recons_loss:0.003630\n",
            "grad_loss:0.085785\n",
            "dice_loss:-0.888510\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:230\n",
            "loss(total):-0.004766\n",
            "recons_loss:0.003461\n",
            "grad_loss:0.072750\n",
            "dice_loss:-0.895406\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:231\n",
            "loss(total):-0.003923\n",
            "recons_loss:0.003994\n",
            "grad_loss:0.102496\n",
            "dice_loss:-0.894156\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:232\n",
            "loss(total):-0.004306\n",
            "recons_loss:0.003710\n",
            "grad_loss:0.080544\n",
            "dice_loss:-0.882128\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:233\n",
            "loss(total):-0.003667\n",
            "recons_loss:0.004278\n",
            "grad_loss:0.099294\n",
            "dice_loss:-0.893824\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:234\n",
            "loss(total):-0.003744\n",
            "recons_loss:0.004318\n",
            "grad_loss:0.085916\n",
            "dice_loss:-0.892136\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:235\n",
            "loss(total):-0.004319\n",
            "recons_loss:0.003723\n",
            "grad_loss:0.095195\n",
            "dice_loss:-0.899470\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:236\n",
            "loss(total):-0.005133\n",
            "recons_loss:0.003207\n",
            "grad_loss:0.073710\n",
            "dice_loss:-0.907627\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:237\n",
            "loss(total):-0.004596\n",
            "recons_loss:0.003586\n",
            "grad_loss:0.075777\n",
            "dice_loss:-0.894005\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:238\n",
            "loss(total):-0.003254\n",
            "recons_loss:0.004507\n",
            "grad_loss:0.111159\n",
            "dice_loss:-0.887176\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:239\n",
            "loss(total):-0.004579\n",
            "recons_loss:0.003536\n",
            "grad_loss:0.098309\n",
            "dice_loss:-0.909731\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:240\n",
            "loss(total):-0.003565\n",
            "recons_loss:0.004225\n",
            "grad_loss:0.109601\n",
            "dice_loss:-0.888617\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:241\n",
            "loss(total):-0.004844\n",
            "recons_loss:0.003140\n",
            "grad_loss:0.081299\n",
            "dice_loss:-0.879655\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:242\n",
            "loss(total):-0.002920\n",
            "recons_loss:0.004806\n",
            "grad_loss:0.108292\n",
            "dice_loss:-0.880928\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:243\n",
            "loss(total):-0.002494\n",
            "recons_loss:0.004928\n",
            "grad_loss:0.130366\n",
            "dice_loss:-0.872606\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:244\n",
            "loss(total):-0.004374\n",
            "recons_loss:0.003576\n",
            "grad_loss:0.088206\n",
            "dice_loss:-0.883178\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:245\n",
            "loss(total):-0.004448\n",
            "recons_loss:0.003582\n",
            "grad_loss:0.094158\n",
            "dice_loss:-0.897105\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:246\n",
            "loss(total):-0.004492\n",
            "recons_loss:0.003481\n",
            "grad_loss:0.096923\n",
            "dice_loss:-0.894203\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:247\n",
            "loss(total):-0.002679\n",
            "recons_loss:0.005093\n",
            "grad_loss:0.112036\n",
            "dice_loss:-0.889261\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:248\n",
            "loss(total):-0.002537\n",
            "recons_loss:0.005120\n",
            "grad_loss:0.131770\n",
            "dice_loss:-0.897469\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:249\n",
            "loss(total):-0.002726\n",
            "recons_loss:0.005039\n",
            "grad_loss:0.106966\n",
            "dice_loss:-0.883558\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:250\n",
            "loss(total):-0.002816\n",
            "recons_loss:0.004560\n",
            "grad_loss:0.130767\n",
            "dice_loss:-0.868356\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:251\n",
            "loss(total):-0.005678\n",
            "recons_loss:0.002641\n",
            "grad_loss:0.064674\n",
            "dice_loss:-0.896585\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:252\n",
            "loss(total):-0.003666\n",
            "recons_loss:0.004232\n",
            "grad_loss:0.098324\n",
            "dice_loss:-0.888079\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:253\n",
            "loss(total):-0.004754\n",
            "recons_loss:0.003413\n",
            "grad_loss:0.077544\n",
            "dice_loss:-0.894285\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:254\n",
            "loss(total):-0.004102\n",
            "recons_loss:0.003914\n",
            "grad_loss:0.082845\n",
            "dice_loss:-0.884472\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:255\n",
            "loss(total):-0.004700\n",
            "recons_loss:0.003450\n",
            "grad_loss:0.080281\n",
            "dice_loss:-0.895276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:256\n",
            "loss(total):-0.004617\n",
            "recons_loss:0.003364\n",
            "grad_loss:0.085740\n",
            "dice_loss:-0.883898\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:257\n",
            "loss(total):-0.003636\n",
            "recons_loss:0.004302\n",
            "grad_loss:0.093235\n",
            "dice_loss:-0.887027\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:258\n",
            "loss(total):-0.004547\n",
            "recons_loss:0.003461\n",
            "grad_loss:0.085104\n",
            "dice_loss:-0.885905\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:259\n",
            "loss(total):-0.002787\n",
            "recons_loss:0.004838\n",
            "grad_loss:0.124987\n",
            "dice_loss:-0.887513\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:260\n",
            "loss(total):-0.002567\n",
            "recons_loss:0.005066\n",
            "grad_loss:0.122034\n",
            "dice_loss:-0.885291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:261\n",
            "loss(total):-0.002776\n",
            "recons_loss:0.004872\n",
            "grad_loss:0.124899\n",
            "dice_loss:-0.889712\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:262\n",
            "loss(total):-0.003821\n",
            "recons_loss:0.004264\n",
            "grad_loss:0.081047\n",
            "dice_loss:-0.889485\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:263\n",
            "loss(total):-0.004883\n",
            "recons_loss:0.003241\n",
            "grad_loss:0.096134\n",
            "dice_loss:-0.908483\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:264\n",
            "loss(total):-0.003783\n",
            "recons_loss:0.004263\n",
            "grad_loss:0.088963\n",
            "dice_loss:-0.893539\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:265\n",
            "loss(total):-0.003940\n",
            "recons_loss:0.004144\n",
            "grad_loss:0.077253\n",
            "dice_loss:-0.885673\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:266\n",
            "loss(total):-0.002631\n",
            "recons_loss:0.005104\n",
            "grad_loss:0.103002\n",
            "dice_loss:-0.876536\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:267\n",
            "loss(total):-0.003657\n",
            "recons_loss:0.004113\n",
            "grad_loss:0.108080\n",
            "dice_loss:-0.885087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:268\n",
            "loss(total):-0.003380\n",
            "recons_loss:0.004409\n",
            "grad_loss:0.109528\n",
            "dice_loss:-0.888376\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:27\n",
            "Batch_number:269\n",
            "loss(total):-0.002005\n",
            "recons_loss:0.005561\n",
            "grad_loss:0.123561\n",
            "dice_loss:-0.880179\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:0\n",
            "loss(total):-0.004438\n",
            "recons_loss:0.003533\n",
            "grad_loss:0.095442\n",
            "dice_loss:-0.892530\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:1\n",
            "loss(total):-0.004798\n",
            "recons_loss:0.003223\n",
            "grad_loss:0.089673\n",
            "dice_loss:-0.891736\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:2\n",
            "loss(total):-0.003906\n",
            "recons_loss:0.003957\n",
            "grad_loss:0.113464\n",
            "dice_loss:-0.899768\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:3\n",
            "loss(total):-0.003967\n",
            "recons_loss:0.004088\n",
            "grad_loss:0.093389\n",
            "dice_loss:-0.898849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:4\n",
            "loss(total):-0.003760\n",
            "recons_loss:0.004220\n",
            "grad_loss:0.102224\n",
            "dice_loss:-0.900250\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:5\n",
            "loss(total):-0.003734\n",
            "recons_loss:0.004123\n",
            "grad_loss:0.094117\n",
            "dice_loss:-0.879851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:6\n",
            "loss(total):-0.004393\n",
            "recons_loss:0.003707\n",
            "grad_loss:0.086658\n",
            "dice_loss:-0.896668\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:7\n",
            "loss(total):-0.005590\n",
            "recons_loss:0.002832\n",
            "grad_loss:0.063128\n",
            "dice_loss:-0.905367\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:8\n",
            "loss(total):-0.003844\n",
            "recons_loss:0.003977\n",
            "grad_loss:0.110605\n",
            "dice_loss:-0.892677\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:9\n",
            "loss(total):-0.004878\n",
            "recons_loss:0.003325\n",
            "grad_loss:0.082986\n",
            "dice_loss:-0.903308\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:10\n",
            "loss(total):-0.005962\n",
            "recons_loss:0.002568\n",
            "grad_loss:0.064316\n",
            "dice_loss:-0.917309\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:11\n",
            "loss(total):-0.003868\n",
            "recons_loss:0.003844\n",
            "grad_loss:0.106032\n",
            "dice_loss:-0.877266\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:12\n",
            "loss(total):-0.003760\n",
            "recons_loss:0.004232\n",
            "grad_loss:0.085922\n",
            "dice_loss:-0.885151\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:13\n",
            "loss(total):-0.002476\n",
            "recons_loss:0.005068\n",
            "grad_loss:0.117963\n",
            "dice_loss:-0.872392\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:14\n",
            "loss(total):-0.004101\n",
            "recons_loss:0.003953\n",
            "grad_loss:0.084380\n",
            "dice_loss:-0.889852\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:15\n",
            "loss(total):-0.003077\n",
            "recons_loss:0.004754\n",
            "grad_loss:0.106319\n",
            "dice_loss:-0.889487\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:16\n",
            "loss(total):-0.003095\n",
            "recons_loss:0.004617\n",
            "grad_loss:0.119611\n",
            "dice_loss:-0.890827\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:17\n",
            "loss(total):-0.003544\n",
            "recons_loss:0.004385\n",
            "grad_loss:0.098405\n",
            "dice_loss:-0.891320\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:18\n",
            "loss(total):-0.004492\n",
            "recons_loss:0.003607\n",
            "grad_loss:0.094710\n",
            "dice_loss:-0.904594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:19\n",
            "loss(total):-0.003907\n",
            "recons_loss:0.003907\n",
            "grad_loss:0.103585\n",
            "dice_loss:-0.884989\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:20\n",
            "loss(total):-0.003922\n",
            "recons_loss:0.004093\n",
            "grad_loss:0.086123\n",
            "dice_loss:-0.887637\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:21\n",
            "loss(total):-0.003720\n",
            "recons_loss:0.004272\n",
            "grad_loss:0.090487\n",
            "dice_loss:-0.889727\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:22\n",
            "loss(total):-0.004439\n",
            "recons_loss:0.003629\n",
            "grad_loss:0.093276\n",
            "dice_loss:-0.900065\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:23\n",
            "loss(total):-0.004643\n",
            "recons_loss:0.003530\n",
            "grad_loss:0.084043\n",
            "dice_loss:-0.901336\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:24\n",
            "loss(total):-0.003144\n",
            "recons_loss:0.004735\n",
            "grad_loss:0.102331\n",
            "dice_loss:-0.890217\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:25\n",
            "loss(total):-0.003599\n",
            "recons_loss:0.004475\n",
            "grad_loss:0.077286\n",
            "dice_loss:-0.884689\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:26\n",
            "loss(total):-0.004205\n",
            "recons_loss:0.003713\n",
            "grad_loss:0.099785\n",
            "dice_loss:-0.891640\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:27\n",
            "loss(total):-0.003482\n",
            "recons_loss:0.004372\n",
            "grad_loss:0.108539\n",
            "dice_loss:-0.893963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:28\n",
            "loss(total):-0.001215\n",
            "recons_loss:0.006431\n",
            "grad_loss:0.109542\n",
            "dice_loss:-0.874066\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:29\n",
            "loss(total):-0.003299\n",
            "recons_loss:0.004603\n",
            "grad_loss:0.100792\n",
            "dice_loss:-0.891074\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:30\n",
            "loss(total):-0.004165\n",
            "recons_loss:0.003865\n",
            "grad_loss:0.094453\n",
            "dice_loss:-0.897387\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:31\n",
            "loss(total):-0.004586\n",
            "recons_loss:0.003365\n",
            "grad_loss:0.092549\n",
            "dice_loss:-0.887646\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:32\n",
            "loss(total):-0.003198\n",
            "recons_loss:0.004435\n",
            "grad_loss:0.122276\n",
            "dice_loss:-0.885563\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:33\n",
            "loss(total):-0.004478\n",
            "recons_loss:0.003506\n",
            "grad_loss:0.093819\n",
            "dice_loss:-0.892196\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:34\n",
            "loss(total):-0.003844\n",
            "recons_loss:0.004172\n",
            "grad_loss:0.099465\n",
            "dice_loss:-0.901040\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:35\n",
            "loss(total):-0.005435\n",
            "recons_loss:0.002755\n",
            "grad_loss:0.070657\n",
            "dice_loss:-0.889637\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:36\n",
            "loss(total):-0.004453\n",
            "recons_loss:0.003669\n",
            "grad_loss:0.078884\n",
            "dice_loss:-0.891049\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:37\n",
            "loss(total):-0.002159\n",
            "recons_loss:0.005475\n",
            "grad_loss:0.123135\n",
            "dice_loss:-0.886580\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:38\n",
            "loss(total):-0.004018\n",
            "recons_loss:0.004032\n",
            "grad_loss:0.081283\n",
            "dice_loss:-0.886290\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:39\n",
            "loss(total):-0.003486\n",
            "recons_loss:0.004506\n",
            "grad_loss:0.084824\n",
            "dice_loss:-0.884020\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:40\n",
            "loss(total):-0.002826\n",
            "recons_loss:0.004769\n",
            "grad_loss:0.124319\n",
            "dice_loss:-0.883805\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:41\n",
            "loss(total):-0.003486\n",
            "recons_loss:0.004426\n",
            "grad_loss:0.105555\n",
            "dice_loss:-0.896755\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:42\n",
            "loss(total):-0.004176\n",
            "recons_loss:0.003934\n",
            "grad_loss:0.073493\n",
            "dice_loss:-0.884491\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:43\n",
            "loss(total):-0.004649\n",
            "recons_loss:0.003374\n",
            "grad_loss:0.082445\n",
            "dice_loss:-0.884731\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:44\n",
            "loss(total):-0.003862\n",
            "recons_loss:0.003852\n",
            "grad_loss:0.108247\n",
            "dice_loss:-0.879674\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:45\n",
            "loss(total):-0.004893\n",
            "recons_loss:0.003163\n",
            "grad_loss:0.089042\n",
            "dice_loss:-0.894710\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:46\n",
            "loss(total):-0.002998\n",
            "recons_loss:0.004686\n",
            "grad_loss:0.118140\n",
            "dice_loss:-0.886555\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:47\n",
            "loss(total):-0.003816\n",
            "recons_loss:0.004050\n",
            "grad_loss:0.092387\n",
            "dice_loss:-0.878956\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:48\n",
            "loss(total):-0.004392\n",
            "recons_loss:0.003602\n",
            "grad_loss:0.100780\n",
            "dice_loss:-0.900189\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:49\n",
            "loss(total):-0.002216\n",
            "recons_loss:0.005294\n",
            "grad_loss:0.132981\n",
            "dice_loss:-0.883960\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:50\n",
            "loss(total):-0.002733\n",
            "recons_loss:0.004783\n",
            "grad_loss:0.124105\n",
            "dice_loss:-0.875754\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:51\n",
            "loss(total):-0.004326\n",
            "recons_loss:0.003535\n",
            "grad_loss:0.100088\n",
            "dice_loss:-0.886171\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:52\n",
            "loss(total):-0.003259\n",
            "recons_loss:0.004433\n",
            "grad_loss:0.119026\n",
            "dice_loss:-0.888181\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:53\n",
            "loss(total):-0.005237\n",
            "recons_loss:0.003114\n",
            "grad_loss:0.073504\n",
            "dice_loss:-0.908615\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:54\n",
            "loss(total):-0.001847\n",
            "recons_loss:0.005697\n",
            "grad_loss:0.132110\n",
            "dice_loss:-0.886442\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:55\n",
            "loss(total):-0.003571\n",
            "recons_loss:0.004454\n",
            "grad_loss:0.090029\n",
            "dice_loss:-0.892569\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:56\n",
            "loss(total):-0.004049\n",
            "recons_loss:0.004080\n",
            "grad_loss:0.092546\n",
            "dice_loss:-0.905434\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:57\n",
            "loss(total):-0.003156\n",
            "recons_loss:0.004611\n",
            "grad_loss:0.123312\n",
            "dice_loss:-0.900012\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:58\n",
            "loss(total):-0.005019\n",
            "recons_loss:0.003232\n",
            "grad_loss:0.070748\n",
            "dice_loss:-0.895885\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:59\n",
            "loss(total):-0.004285\n",
            "recons_loss:0.003843\n",
            "grad_loss:0.080910\n",
            "dice_loss:-0.893673\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:60\n",
            "loss(total):-0.003728\n",
            "recons_loss:0.004360\n",
            "grad_loss:0.079430\n",
            "dice_loss:-0.888326\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:61\n",
            "loss(total):-0.002588\n",
            "recons_loss:0.005083\n",
            "grad_loss:0.116243\n",
            "dice_loss:-0.883395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:62\n",
            "loss(total):-0.003031\n",
            "recons_loss:0.004847\n",
            "grad_loss:0.089148\n",
            "dice_loss:-0.876972\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:63\n",
            "loss(total):-0.003795\n",
            "recons_loss:0.004144\n",
            "grad_loss:0.099418\n",
            "dice_loss:-0.893305\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:64\n",
            "loss(total):-0.004951\n",
            "recons_loss:0.003068\n",
            "grad_loss:0.087033\n",
            "dice_loss:-0.888881\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:65\n",
            "loss(total):-0.004565\n",
            "recons_loss:0.003498\n",
            "grad_loss:0.079259\n",
            "dice_loss:-0.885509\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:66\n",
            "loss(total):-0.003368\n",
            "recons_loss:0.004471\n",
            "grad_loss:0.101412\n",
            "dice_loss:-0.885273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:67\n",
            "loss(total):-0.003584\n",
            "recons_loss:0.004198\n",
            "grad_loss:0.116293\n",
            "dice_loss:-0.894501\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:68\n",
            "loss(total):-0.003245\n",
            "recons_loss:0.004681\n",
            "grad_loss:0.094489\n",
            "dice_loss:-0.887157\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:69\n",
            "loss(total):-0.005033\n",
            "recons_loss:0.003269\n",
            "grad_loss:0.072704\n",
            "dice_loss:-0.902824\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:70\n",
            "loss(total):-0.004376\n",
            "recons_loss:0.003752\n",
            "grad_loss:0.067823\n",
            "dice_loss:-0.880640\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:71\n",
            "loss(total):-0.002216\n",
            "recons_loss:0.005486\n",
            "grad_loss:0.118840\n",
            "dice_loss:-0.889003\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:72\n",
            "loss(total):-0.002879\n",
            "recons_loss:0.004882\n",
            "grad_loss:0.099948\n",
            "dice_loss:-0.876103\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:73\n",
            "loss(total):-0.004540\n",
            "recons_loss:0.003483\n",
            "grad_loss:0.089193\n",
            "dice_loss:-0.891548\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:74\n",
            "loss(total):-0.004549\n",
            "recons_loss:0.003600\n",
            "grad_loss:0.085119\n",
            "dice_loss:-0.900048\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:75\n",
            "loss(total):-0.003552\n",
            "recons_loss:0.004280\n",
            "grad_loss:0.105809\n",
            "dice_loss:-0.889071\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:76\n",
            "loss(total):-0.004233\n",
            "recons_loss:0.003894\n",
            "grad_loss:0.081358\n",
            "dice_loss:-0.893976\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:77\n",
            "loss(total):-0.004173\n",
            "recons_loss:0.003797\n",
            "grad_loss:0.088110\n",
            "dice_loss:-0.885112\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:78\n",
            "loss(total):-0.004109\n",
            "recons_loss:0.003982\n",
            "grad_loss:0.088184\n",
            "dice_loss:-0.897256\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:79\n",
            "loss(total):-0.004102\n",
            "recons_loss:0.003961\n",
            "grad_loss:0.094292\n",
            "dice_loss:-0.900595\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:80\n",
            "loss(total):-0.003260\n",
            "recons_loss:0.004522\n",
            "grad_loss:0.116398\n",
            "dice_loss:-0.894586\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:81\n",
            "loss(total):-0.003937\n",
            "recons_loss:0.003824\n",
            "grad_loss:0.120140\n",
            "dice_loss:-0.896172\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:82\n",
            "loss(total):-0.003784\n",
            "recons_loss:0.004183\n",
            "grad_loss:0.092122\n",
            "dice_loss:-0.888794\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:83\n",
            "loss(total):-0.003076\n",
            "recons_loss:0.004530\n",
            "grad_loss:0.114439\n",
            "dice_loss:-0.875098\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:84\n",
            "loss(total):-0.003844\n",
            "recons_loss:0.004054\n",
            "grad_loss:0.108084\n",
            "dice_loss:-0.897846\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:85\n",
            "loss(total):-0.004143\n",
            "recons_loss:0.003870\n",
            "grad_loss:0.088194\n",
            "dice_loss:-0.889518\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:86\n",
            "loss(total):-0.003291\n",
            "recons_loss:0.004389\n",
            "grad_loss:0.119210\n",
            "dice_loss:-0.887255\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:87\n",
            "loss(total):-0.003617\n",
            "recons_loss:0.004393\n",
            "grad_loss:0.098495\n",
            "dice_loss:-0.899485\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:88\n",
            "loss(total):-0.004694\n",
            "recons_loss:0.003363\n",
            "grad_loss:0.090916\n",
            "dice_loss:-0.896595\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:89\n",
            "loss(total):-0.002840\n",
            "recons_loss:0.004653\n",
            "grad_loss:0.112322\n",
            "dice_loss:-0.861607\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:90\n",
            "loss(total):-0.002750\n",
            "recons_loss:0.004709\n",
            "grad_loss:0.128108\n",
            "dice_loss:-0.873949\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:91\n",
            "loss(total):-0.004828\n",
            "recons_loss:0.003358\n",
            "grad_loss:0.077823\n",
            "dice_loss:-0.896433\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:92\n",
            "loss(total):-0.004001\n",
            "recons_loss:0.003961\n",
            "grad_loss:0.102010\n",
            "dice_loss:-0.898118\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:93\n",
            "loss(total):-0.004039\n",
            "recons_loss:0.003945\n",
            "grad_loss:0.100422\n",
            "dice_loss:-0.898791\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:94\n",
            "loss(total):-0.003608\n",
            "recons_loss:0.004391\n",
            "grad_loss:0.087457\n",
            "dice_loss:-0.887339\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:95\n",
            "loss(total):-0.003966\n",
            "recons_loss:0.004164\n",
            "grad_loss:0.080878\n",
            "dice_loss:-0.893910\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:96\n",
            "loss(total):-0.004610\n",
            "recons_loss:0.003370\n",
            "grad_loss:0.084371\n",
            "dice_loss:-0.882291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:97\n",
            "loss(total):-0.003693\n",
            "recons_loss:0.004157\n",
            "grad_loss:0.097592\n",
            "dice_loss:-0.882581\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:98\n",
            "loss(total):-0.003294\n",
            "recons_loss:0.004554\n",
            "grad_loss:0.088770\n",
            "dice_loss:-0.873546\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:99\n",
            "loss(total):-0.004290\n",
            "recons_loss:0.003835\n",
            "grad_loss:0.079314\n",
            "dice_loss:-0.891851\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:100\n",
            "loss(total):-0.004282\n",
            "recons_loss:0.003699\n",
            "grad_loss:0.090007\n",
            "dice_loss:-0.888107\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:101\n",
            "loss(total):-0.002992\n",
            "recons_loss:0.004976\n",
            "grad_loss:0.101762\n",
            "dice_loss:-0.898526\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:102\n",
            "loss(total):-0.004550\n",
            "recons_loss:0.003395\n",
            "grad_loss:0.105107\n",
            "dice_loss:-0.899639\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:103\n",
            "loss(total):-0.003905\n",
            "recons_loss:0.003963\n",
            "grad_loss:0.098111\n",
            "dice_loss:-0.884886\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:104\n",
            "loss(total):-0.004039\n",
            "recons_loss:0.003997\n",
            "grad_loss:0.092657\n",
            "dice_loss:-0.896194\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:105\n",
            "loss(total):-0.003680\n",
            "recons_loss:0.004272\n",
            "grad_loss:0.087691\n",
            "dice_loss:-0.882910\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:106\n",
            "loss(total):-0.004599\n",
            "recons_loss:0.003421\n",
            "grad_loss:0.085118\n",
            "dice_loss:-0.887077\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:107\n",
            "loss(total):-0.004601\n",
            "recons_loss:0.003518\n",
            "grad_loss:0.077753\n",
            "dice_loss:-0.889677\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:108\n",
            "loss(total):-0.003985\n",
            "recons_loss:0.004055\n",
            "grad_loss:0.099105\n",
            "dice_loss:-0.903089\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:109\n",
            "loss(total):-0.004140\n",
            "recons_loss:0.003967\n",
            "grad_loss:0.083555\n",
            "dice_loss:-0.894250\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:110\n",
            "loss(total):-0.003050\n",
            "recons_loss:0.004641\n",
            "grad_loss:0.112146\n",
            "dice_loss:-0.881285\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:111\n",
            "loss(total):-0.003567\n",
            "recons_loss:0.004171\n",
            "grad_loss:0.109594\n",
            "dice_loss:-0.883445\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:112\n",
            "loss(total):-0.004132\n",
            "recons_loss:0.003865\n",
            "grad_loss:0.101652\n",
            "dice_loss:-0.901337\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:113\n",
            "loss(total):-0.004264\n",
            "recons_loss:0.003606\n",
            "grad_loss:0.100468\n",
            "dice_loss:-0.887452\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:114\n",
            "loss(total):-0.004404\n",
            "recons_loss:0.003754\n",
            "grad_loss:0.078441\n",
            "dice_loss:-0.894172\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:115\n",
            "loss(total):-0.003899\n",
            "recons_loss:0.003906\n",
            "grad_loss:0.105768\n",
            "dice_loss:-0.886208\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:116\n",
            "loss(total):-0.002649\n",
            "recons_loss:0.004827\n",
            "grad_loss:0.132036\n",
            "dice_loss:-0.879617\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:117\n",
            "loss(total):-0.003879\n",
            "recons_loss:0.004157\n",
            "grad_loss:0.095184\n",
            "dice_loss:-0.898716\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:118\n",
            "loss(total):-0.002888\n",
            "recons_loss:0.004684\n",
            "grad_loss:0.125406\n",
            "dice_loss:-0.882634\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:119\n",
            "loss(total):-0.003676\n",
            "recons_loss:0.004246\n",
            "grad_loss:0.088244\n",
            "dice_loss:-0.880433\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:120\n",
            "loss(total):-0.002057\n",
            "recons_loss:0.005420\n",
            "grad_loss:0.131754\n",
            "dice_loss:-0.879416\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:121\n",
            "loss(total):-0.004370\n",
            "recons_loss:0.003561\n",
            "grad_loss:0.100514\n",
            "dice_loss:-0.893619\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:122\n",
            "loss(total):-0.004194\n",
            "recons_loss:0.003887\n",
            "grad_loss:0.075582\n",
            "dice_loss:-0.883741\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:123\n",
            "loss(total):-0.003689\n",
            "recons_loss:0.004346\n",
            "grad_loss:0.095878\n",
            "dice_loss:-0.899361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:124\n",
            "loss(total):-0.004177\n",
            "recons_loss:0.003839\n",
            "grad_loss:0.088388\n",
            "dice_loss:-0.890047\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:125\n",
            "loss(total):-0.002762\n",
            "recons_loss:0.004898\n",
            "grad_loss:0.119922\n",
            "dice_loss:-0.886008\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:126\n",
            "loss(total):-0.005306\n",
            "recons_loss:0.002811\n",
            "grad_loss:0.091046\n",
            "dice_loss:-0.902788\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:127\n",
            "loss(total):-0.002439\n",
            "recons_loss:0.005099\n",
            "grad_loss:0.128764\n",
            "dice_loss:-0.882613\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:128\n",
            "loss(total):-0.003572\n",
            "recons_loss:0.004190\n",
            "grad_loss:0.109787\n",
            "dice_loss:-0.886064\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:129\n",
            "loss(total):-0.004211\n",
            "recons_loss:0.003785\n",
            "grad_loss:0.095914\n",
            "dice_loss:-0.895524\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:130\n",
            "loss(total):-0.004238\n",
            "recons_loss:0.003720\n",
            "grad_loss:0.095356\n",
            "dice_loss:-0.891192\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:131\n",
            "loss(total):-0.004242\n",
            "recons_loss:0.003720\n",
            "grad_loss:0.090201\n",
            "dice_loss:-0.886351\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:132\n",
            "loss(total):-0.003382\n",
            "recons_loss:0.004387\n",
            "grad_loss:0.112037\n",
            "dice_loss:-0.888871\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:133\n",
            "loss(total):-0.002707\n",
            "recons_loss:0.005007\n",
            "grad_loss:0.114776\n",
            "dice_loss:-0.886150\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:134\n",
            "loss(total):-0.004351\n",
            "recons_loss:0.003778\n",
            "grad_loss:0.089527\n",
            "dice_loss:-0.902395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:135\n",
            "loss(total):-0.003636\n",
            "recons_loss:0.004343\n",
            "grad_loss:0.098674\n",
            "dice_loss:-0.896562\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:136\n",
            "loss(total):-0.002844\n",
            "recons_loss:0.004823\n",
            "grad_loss:0.118268\n",
            "dice_loss:-0.885023\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:137\n",
            "loss(total):-0.002958\n",
            "recons_loss:0.004857\n",
            "grad_loss:0.107528\n",
            "dice_loss:-0.889030\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:138\n",
            "loss(total):-0.004226\n",
            "recons_loss:0.003962\n",
            "grad_loss:0.083770\n",
            "dice_loss:-0.902592\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:139\n",
            "loss(total):-0.003432\n",
            "recons_loss:0.004538\n",
            "grad_loss:0.098876\n",
            "dice_loss:-0.895870\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:140\n",
            "loss(total):-0.004662\n",
            "recons_loss:0.003416\n",
            "grad_loss:0.090148\n",
            "dice_loss:-0.897896\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:141\n",
            "loss(total):-0.004063\n",
            "recons_loss:0.003842\n",
            "grad_loss:0.098518\n",
            "dice_loss:-0.889009\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:142\n",
            "loss(total):-0.004124\n",
            "recons_loss:0.003722\n",
            "grad_loss:0.106644\n",
            "dice_loss:-0.891247\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:143\n",
            "loss(total):-0.003740\n",
            "recons_loss:0.004026\n",
            "grad_loss:0.118631\n",
            "dice_loss:-0.895176\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:144\n",
            "loss(total):-0.003304\n",
            "recons_loss:0.004433\n",
            "grad_loss:0.102936\n",
            "dice_loss:-0.876695\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:145\n",
            "loss(total):-0.003918\n",
            "recons_loss:0.003981\n",
            "grad_loss:0.103748\n",
            "dice_loss:-0.893677\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:146\n",
            "loss(total):-0.003405\n",
            "recons_loss:0.004449\n",
            "grad_loss:0.096063\n",
            "dice_loss:-0.881428\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:147\n",
            "loss(total):-0.004646\n",
            "recons_loss:0.003514\n",
            "grad_loss:0.082421\n",
            "dice_loss:-0.898361\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:148\n",
            "loss(total):-0.004223\n",
            "recons_loss:0.003702\n",
            "grad_loss:0.093653\n",
            "dice_loss:-0.886117\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:149\n",
            "loss(total):-0.002968\n",
            "recons_loss:0.004819\n",
            "grad_loss:0.101954\n",
            "dice_loss:-0.880621\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:150\n",
            "loss(total):-0.003725\n",
            "recons_loss:0.003978\n",
            "grad_loss:0.120516\n",
            "dice_loss:-0.890731\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:151\n",
            "loss(total):-0.004066\n",
            "recons_loss:0.003979\n",
            "grad_loss:0.088113\n",
            "dice_loss:-0.892591\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:152\n",
            "loss(total):-0.004942\n",
            "recons_loss:0.003365\n",
            "grad_loss:0.068986\n",
            "dice_loss:-0.899734\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:153\n",
            "loss(total):-0.003407\n",
            "recons_loss:0.004447\n",
            "grad_loss:0.110866\n",
            "dice_loss:-0.896289\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:154\n",
            "loss(total):-0.004032\n",
            "recons_loss:0.004020\n",
            "grad_loss:0.088938\n",
            "dice_loss:-0.894190\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:155\n",
            "loss(total):-0.003873\n",
            "recons_loss:0.004072\n",
            "grad_loss:0.099177\n",
            "dice_loss:-0.893624\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:156\n",
            "loss(total):-0.002841\n",
            "recons_loss:0.004948\n",
            "grad_loss:0.112242\n",
            "dice_loss:-0.891066\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:157\n",
            "loss(total):-0.004310\n",
            "recons_loss:0.003639\n",
            "grad_loss:0.103879\n",
            "dice_loss:-0.898759\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:158\n",
            "loss(total):-0.003880\n",
            "recons_loss:0.004138\n",
            "grad_loss:0.090624\n",
            "dice_loss:-0.892486\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:159\n",
            "loss(total):-0.003215\n",
            "recons_loss:0.004695\n",
            "grad_loss:0.094005\n",
            "dice_loss:-0.884983\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:160\n",
            "loss(total):-0.003769\n",
            "recons_loss:0.004231\n",
            "grad_loss:0.086374\n",
            "dice_loss:-0.886334\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:161\n",
            "loss(total):-0.003298\n",
            "recons_loss:0.004705\n",
            "grad_loss:0.098292\n",
            "dice_loss:-0.898686\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:162\n",
            "loss(total):-0.004646\n",
            "recons_loss:0.003536\n",
            "grad_loss:0.071764\n",
            "dice_loss:-0.889973\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:163\n",
            "loss(total):-0.004792\n",
            "recons_loss:0.003321\n",
            "grad_loss:0.080991\n",
            "dice_loss:-0.892364\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:164\n",
            "loss(total):-0.002810\n",
            "recons_loss:0.004925\n",
            "grad_loss:0.115835\n",
            "dice_loss:-0.889347\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:165\n",
            "loss(total):-0.003332\n",
            "recons_loss:0.004677\n",
            "grad_loss:0.087497\n",
            "dice_loss:-0.888426\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:166\n",
            "loss(total):-0.004376\n",
            "recons_loss:0.003617\n",
            "grad_loss:0.084144\n",
            "dice_loss:-0.883426\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:167\n",
            "loss(total):-0.003274\n",
            "recons_loss:0.004707\n",
            "grad_loss:0.097498\n",
            "dice_loss:-0.895565\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:168\n",
            "loss(total):-0.003579\n",
            "recons_loss:0.004227\n",
            "grad_loss:0.106019\n",
            "dice_loss:-0.886584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:169\n",
            "loss(total):-0.004496\n",
            "recons_loss:0.003600\n",
            "grad_loss:0.096124\n",
            "dice_loss:-0.905763\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:170\n",
            "loss(total):-0.004682\n",
            "recons_loss:0.003359\n",
            "grad_loss:0.083818\n",
            "dice_loss:-0.887876\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:171\n",
            "loss(total):-0.003662\n",
            "recons_loss:0.004137\n",
            "grad_loss:0.112126\n",
            "dice_loss:-0.892000\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:172\n",
            "loss(total):-0.003016\n",
            "recons_loss:0.004731\n",
            "grad_loss:0.108920\n",
            "dice_loss:-0.883608\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:173\n",
            "loss(total):-0.003921\n",
            "recons_loss:0.003926\n",
            "grad_loss:0.104237\n",
            "dice_loss:-0.888983\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:174\n",
            "loss(total):-0.002364\n",
            "recons_loss:0.005349\n",
            "grad_loss:0.116185\n",
            "dice_loss:-0.887429\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:175\n",
            "loss(total):-0.004271\n",
            "recons_loss:0.003732\n",
            "grad_loss:0.095226\n",
            "dice_loss:-0.895566\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:176\n",
            "loss(total):-0.003609\n",
            "recons_loss:0.004247\n",
            "grad_loss:0.114869\n",
            "dice_loss:-0.900534\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:177\n",
            "loss(total):-0.002827\n",
            "recons_loss:0.004804\n",
            "grad_loss:0.123959\n",
            "dice_loss:-0.887085\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:178\n",
            "loss(total):-0.003821\n",
            "recons_loss:0.004033\n",
            "grad_loss:0.100919\n",
            "dice_loss:-0.886357\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:179\n",
            "loss(total):-0.002613\n",
            "recons_loss:0.005000\n",
            "grad_loss:0.122082\n",
            "dice_loss:-0.883406\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:180\n",
            "loss(total):-0.002667\n",
            "recons_loss:0.005205\n",
            "grad_loss:0.092665\n",
            "dice_loss:-0.879923\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:181\n",
            "loss(total):-0.004058\n",
            "recons_loss:0.004067\n",
            "grad_loss:0.081678\n",
            "dice_loss:-0.894211\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:182\n",
            "loss(total):-0.004250\n",
            "recons_loss:0.003713\n",
            "grad_loss:0.100086\n",
            "dice_loss:-0.896402\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:183\n",
            "loss(total):-0.004534\n",
            "recons_loss:0.003532\n",
            "grad_loss:0.083313\n",
            "dice_loss:-0.889942\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:184\n",
            "loss(total):-0.004650\n",
            "recons_loss:0.003264\n",
            "grad_loss:0.102148\n",
            "dice_loss:-0.893506\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:185\n",
            "loss(total):-0.002716\n",
            "recons_loss:0.004989\n",
            "grad_loss:0.119140\n",
            "dice_loss:-0.889592\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:186\n",
            "loss(total):-0.004594\n",
            "recons_loss:0.003470\n",
            "grad_loss:0.079651\n",
            "dice_loss:-0.886050\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:187\n",
            "loss(total):-0.003175\n",
            "recons_loss:0.004499\n",
            "grad_loss:0.123486\n",
            "dice_loss:-0.890797\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:188\n",
            "loss(total):-0.003575\n",
            "recons_loss:0.004373\n",
            "grad_loss:0.089384\n",
            "dice_loss:-0.884170\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:189\n",
            "loss(total):-0.004050\n",
            "recons_loss:0.003914\n",
            "grad_loss:0.100686\n",
            "dice_loss:-0.897053\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:190\n",
            "loss(total):-0.002878\n",
            "recons_loss:0.004749\n",
            "grad_loss:0.120647\n",
            "dice_loss:-0.883346\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:191\n",
            "loss(total):-0.003587\n",
            "recons_loss:0.004369\n",
            "grad_loss:0.107501\n",
            "dice_loss:-0.903077\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:192\n",
            "loss(total):-0.003019\n",
            "recons_loss:0.004672\n",
            "grad_loss:0.113441\n",
            "dice_loss:-0.882526\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:193\n",
            "loss(total):-0.003147\n",
            "recons_loss:0.004724\n",
            "grad_loss:0.112716\n",
            "dice_loss:-0.899761\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:194\n",
            "loss(total):-0.003512\n",
            "recons_loss:0.004353\n",
            "grad_loss:0.106107\n",
            "dice_loss:-0.892534\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:195\n",
            "loss(total):-0.002276\n",
            "recons_loss:0.005255\n",
            "grad_loss:0.128847\n",
            "dice_loss:-0.881934\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:196\n",
            "loss(total):-0.003607\n",
            "recons_loss:0.004243\n",
            "grad_loss:0.101513\n",
            "dice_loss:-0.886570\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:197\n",
            "loss(total):-0.004776\n",
            "recons_loss:0.003332\n",
            "grad_loss:0.073531\n",
            "dice_loss:-0.884291\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:198\n",
            "loss(total):-0.002939\n",
            "recons_loss:0.004875\n",
            "grad_loss:0.116846\n",
            "dice_loss:-0.898207\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:199\n",
            "loss(total):-0.003554\n",
            "recons_loss:0.004310\n",
            "grad_loss:0.109535\n",
            "dice_loss:-0.895898\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:200\n",
            "loss(total):-0.002778\n",
            "recons_loss:0.004989\n",
            "grad_loss:0.109462\n",
            "dice_loss:-0.886120\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:201\n",
            "loss(total):-0.004780\n",
            "recons_loss:0.003225\n",
            "grad_loss:0.092830\n",
            "dice_loss:-0.893275\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:202\n",
            "loss(total):-0.003125\n",
            "recons_loss:0.004755\n",
            "grad_loss:0.099629\n",
            "dice_loss:-0.887649\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:203\n",
            "loss(total):-0.004511\n",
            "recons_loss:0.003413\n",
            "grad_loss:0.091730\n",
            "dice_loss:-0.884149\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:204\n",
            "loss(total):-0.004460\n",
            "recons_loss:0.003454\n",
            "grad_loss:0.100571\n",
            "dice_loss:-0.891966\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:205\n",
            "loss(total):-0.004940\n",
            "recons_loss:0.003175\n",
            "grad_loss:0.081706\n",
            "dice_loss:-0.893134\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:206\n",
            "loss(total):-0.003575\n",
            "recons_loss:0.004360\n",
            "grad_loss:0.099808\n",
            "dice_loss:-0.893336\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:207\n",
            "loss(total):-0.003490\n",
            "recons_loss:0.004561\n",
            "grad_loss:0.092877\n",
            "dice_loss:-0.897937\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:208\n",
            "loss(total):-0.003906\n",
            "recons_loss:0.003949\n",
            "grad_loss:0.113656\n",
            "dice_loss:-0.899147\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:209\n",
            "loss(total):-0.004798\n",
            "recons_loss:0.003365\n",
            "grad_loss:0.075067\n",
            "dice_loss:-0.891338\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:210\n",
            "loss(total):-0.003998\n",
            "recons_loss:0.003922\n",
            "grad_loss:0.098009\n",
            "dice_loss:-0.890032\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:211\n",
            "loss(total):-0.005617\n",
            "recons_loss:0.002646\n",
            "grad_loss:0.073751\n",
            "dice_loss:-0.899989\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:212\n",
            "loss(total):-0.003607\n",
            "recons_loss:0.004246\n",
            "grad_loss:0.111906\n",
            "dice_loss:-0.897195\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:213\n",
            "loss(total):-0.003411\n",
            "recons_loss:0.004196\n",
            "grad_loss:0.134570\n",
            "dice_loss:-0.895300\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:214\n",
            "loss(total):-0.002965\n",
            "recons_loss:0.004740\n",
            "grad_loss:0.127998\n",
            "dice_loss:-0.898536\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:215\n",
            "loss(total):-0.004376\n",
            "recons_loss:0.003623\n",
            "grad_loss:0.095092\n",
            "dice_loss:-0.895025\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:216\n",
            "loss(total):-0.004353\n",
            "recons_loss:0.003762\n",
            "grad_loss:0.095834\n",
            "dice_loss:-0.907329\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:217\n",
            "loss(total):-0.003556\n",
            "recons_loss:0.004360\n",
            "grad_loss:0.104669\n",
            "dice_loss:-0.896297\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:218\n",
            "loss(total):-0.004358\n",
            "recons_loss:0.003755\n",
            "grad_loss:0.087315\n",
            "dice_loss:-0.898559\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:219\n",
            "loss(total):-0.004020\n",
            "recons_loss:0.003886\n",
            "grad_loss:0.106323\n",
            "dice_loss:-0.896910\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:220\n",
            "loss(total):-0.004940\n",
            "recons_loss:0.003268\n",
            "grad_loss:0.080465\n",
            "dice_loss:-0.901310\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:221\n",
            "loss(total):-0.003444\n",
            "recons_loss:0.004434\n",
            "grad_loss:0.103006\n",
            "dice_loss:-0.890795\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:222\n",
            "loss(total):-0.002012\n",
            "recons_loss:0.005382\n",
            "grad_loss:0.134398\n",
            "dice_loss:-0.873814\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:223\n",
            "loss(total):-0.003568\n",
            "recons_loss:0.004423\n",
            "grad_loss:0.097650\n",
            "dice_loss:-0.896751\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:224\n",
            "loss(total):-0.003100\n",
            "recons_loss:0.004720\n",
            "grad_loss:0.104442\n",
            "dice_loss:-0.886416\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:225\n",
            "loss(total):-0.004945\n",
            "recons_loss:0.003365\n",
            "grad_loss:0.071112\n",
            "dice_loss:-0.902153\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:226\n",
            "loss(total):-0.003130\n",
            "recons_loss:0.004576\n",
            "grad_loss:0.122800\n",
            "dice_loss:-0.893416\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:227\n",
            "loss(total):-0.004241\n",
            "recons_loss:0.003617\n",
            "grad_loss:0.108659\n",
            "dice_loss:-0.894475\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:228\n",
            "loss(total):-0.004858\n",
            "recons_loss:0.003283\n",
            "grad_loss:0.081878\n",
            "dice_loss:-0.895909\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:229\n",
            "loss(total):-0.004074\n",
            "recons_loss:0.004014\n",
            "grad_loss:0.077128\n",
            "dice_loss:-0.885917\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:230\n",
            "loss(total):-0.002492\n",
            "recons_loss:0.004940\n",
            "grad_loss:0.149882\n",
            "dice_loss:-0.893130\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:231\n",
            "loss(total):-0.003150\n",
            "recons_loss:0.004542\n",
            "grad_loss:0.109391\n",
            "dice_loss:-0.878531\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:232\n",
            "loss(total):-0.004115\n",
            "recons_loss:0.003757\n",
            "grad_loss:0.105369\n",
            "dice_loss:-0.892641\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:233\n",
            "loss(total):-0.003166\n",
            "recons_loss:0.004838\n",
            "grad_loss:0.091557\n",
            "dice_loss:-0.891945\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:234\n",
            "loss(total):-0.003766\n",
            "recons_loss:0.004072\n",
            "grad_loss:0.102633\n",
            "dice_loss:-0.886513\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:235\n",
            "loss(total):-0.002542\n",
            "recons_loss:0.005166\n",
            "grad_loss:0.118377\n",
            "dice_loss:-0.889131\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:236\n",
            "loss(total):-0.002857\n",
            "recons_loss:0.004956\n",
            "grad_loss:0.100414\n",
            "dice_loss:-0.881696\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:237\n",
            "loss(total):-0.003767\n",
            "recons_loss:0.004310\n",
            "grad_loss:0.088964\n",
            "dice_loss:-0.896665\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:238\n",
            "loss(total):-0.003005\n",
            "recons_loss:0.004771\n",
            "grad_loss:0.105401\n",
            "dice_loss:-0.883054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:239\n",
            "loss(total):-0.003346\n",
            "recons_loss:0.004481\n",
            "grad_loss:0.106526\n",
            "dice_loss:-0.889194\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:240\n",
            "loss(total):-0.001631\n",
            "recons_loss:0.005741\n",
            "grad_loss:0.137985\n",
            "dice_loss:-0.875228\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:241\n",
            "loss(total):-0.002676\n",
            "recons_loss:0.005121\n",
            "grad_loss:0.111639\n",
            "dice_loss:-0.891401\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:242\n",
            "loss(total):-0.004145\n",
            "recons_loss:0.003785\n",
            "grad_loss:0.093653\n",
            "dice_loss:-0.886681\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:243\n",
            "loss(total):-0.004906\n",
            "recons_loss:0.003207\n",
            "grad_loss:0.084945\n",
            "dice_loss:-0.896256\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:244\n",
            "loss(total):-0.003777\n",
            "recons_loss:0.004174\n",
            "grad_loss:0.085822\n",
            "dice_loss:-0.880963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:245\n",
            "loss(total):-0.002269\n",
            "recons_loss:0.005271\n",
            "grad_loss:0.125817\n",
            "dice_loss:-0.879782\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:246\n",
            "loss(total):-0.003669\n",
            "recons_loss:0.004065\n",
            "grad_loss:0.105324\n",
            "dice_loss:-0.878641\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:247\n",
            "loss(total):-0.003110\n",
            "recons_loss:0.004492\n",
            "grad_loss:0.122712\n",
            "dice_loss:-0.882902\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:248\n",
            "loss(total):-0.004194\n",
            "recons_loss:0.003974\n",
            "grad_loss:0.083085\n",
            "dice_loss:-0.899900\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:249\n",
            "loss(total):-0.004196\n",
            "recons_loss:0.003728\n",
            "grad_loss:0.098891\n",
            "dice_loss:-0.891301\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:250\n",
            "loss(total):-0.003684\n",
            "recons_loss:0.004030\n",
            "grad_loss:0.101792\n",
            "dice_loss:-0.873197\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:251\n",
            "loss(total):-0.004714\n",
            "recons_loss:0.003517\n",
            "grad_loss:0.075899\n",
            "dice_loss:-0.898999\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:252\n",
            "loss(total):-0.004044\n",
            "recons_loss:0.003943\n",
            "grad_loss:0.089916\n",
            "dice_loss:-0.888602\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:253\n",
            "loss(total):-0.004284\n",
            "recons_loss:0.003653\n",
            "grad_loss:0.091843\n",
            "dice_loss:-0.885529\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:254\n",
            "loss(total):-0.004820\n",
            "recons_loss:0.003323\n",
            "grad_loss:0.084143\n",
            "dice_loss:-0.898523\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:255\n",
            "loss(total):-0.003249\n",
            "recons_loss:0.004572\n",
            "grad_loss:0.102207\n",
            "dice_loss:-0.884269\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:256\n",
            "loss(total):-0.002595\n",
            "recons_loss:0.004937\n",
            "grad_loss:0.131217\n",
            "dice_loss:-0.884437\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:257\n",
            "loss(total):-0.003162\n",
            "recons_loss:0.004592\n",
            "grad_loss:0.114792\n",
            "dice_loss:-0.890140\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:258\n",
            "loss(total):-0.003886\n",
            "recons_loss:0.004095\n",
            "grad_loss:0.079747\n",
            "dice_loss:-0.877849\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:259\n",
            "loss(total):-0.004530\n",
            "recons_loss:0.003567\n",
            "grad_loss:0.080099\n",
            "dice_loss:-0.889831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:260\n",
            "loss(total):-0.004300\n",
            "recons_loss:0.003657\n",
            "grad_loss:0.082666\n",
            "dice_loss:-0.878414\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:261\n",
            "loss(total):-0.004512\n",
            "recons_loss:0.003592\n",
            "grad_loss:0.083544\n",
            "dice_loss:-0.893963\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:262\n",
            "loss(total):-0.003264\n",
            "recons_loss:0.004629\n",
            "grad_loss:0.105386\n",
            "dice_loss:-0.894701\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:263\n",
            "loss(total):-0.003103\n",
            "recons_loss:0.004593\n",
            "grad_loss:0.110823\n",
            "dice_loss:-0.880392\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:264\n",
            "loss(total):-0.003870\n",
            "recons_loss:0.004050\n",
            "grad_loss:0.105251\n",
            "dice_loss:-0.897211\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:265\n",
            "loss(total):-0.003997\n",
            "recons_loss:0.004116\n",
            "grad_loss:0.101913\n",
            "dice_loss:-0.913167\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:266\n",
            "loss(total):-0.002858\n",
            "recons_loss:0.004864\n",
            "grad_loss:0.116613\n",
            "dice_loss:-0.888820\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:267\n",
            "loss(total):-0.003607\n",
            "recons_loss:0.004256\n",
            "grad_loss:0.105235\n",
            "dice_loss:-0.891605\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:268\n",
            "loss(total):-0.005233\n",
            "recons_loss:0.003080\n",
            "grad_loss:0.069668\n",
            "dice_loss:-0.901014\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:28\n",
            "Batch_number:269\n",
            "loss(total):-0.005093\n",
            "recons_loss:0.003050\n",
            "grad_loss:0.082301\n",
            "dice_loss:-0.896611\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:0\n",
            "loss(total):-0.004189\n",
            "recons_loss:0.003783\n",
            "grad_loss:0.095996\n",
            "dice_loss:-0.893204\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:1\n",
            "loss(total):-0.005377\n",
            "recons_loss:0.002809\n",
            "grad_loss:0.079266\n",
            "dice_loss:-0.897920\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:2\n",
            "loss(total):-0.002142\n",
            "recons_loss:0.005423\n",
            "grad_loss:0.132672\n",
            "dice_loss:-0.889158\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:3\n",
            "loss(total):-0.002820\n",
            "recons_loss:0.004883\n",
            "grad_loss:0.112439\n",
            "dice_loss:-0.882766\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:4\n",
            "loss(total):-0.004298\n",
            "recons_loss:0.003710\n",
            "grad_loss:0.085333\n",
            "dice_loss:-0.886087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:5\n",
            "loss(total):-0.004520\n",
            "recons_loss:0.003533\n",
            "grad_loss:0.084944\n",
            "dice_loss:-0.890267\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:6\n",
            "loss(total):-0.004261\n",
            "recons_loss:0.003854\n",
            "grad_loss:0.083452\n",
            "dice_loss:-0.894889\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:7\n",
            "loss(total):-0.004606\n",
            "recons_loss:0.003560\n",
            "grad_loss:0.076688\n",
            "dice_loss:-0.893276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:8\n",
            "loss(total):-0.003546\n",
            "recons_loss:0.004334\n",
            "grad_loss:0.095115\n",
            "dice_loss:-0.883062\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:9\n",
            "loss(total):-0.004246\n",
            "recons_loss:0.003675\n",
            "grad_loss:0.090894\n",
            "dice_loss:-0.883034\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:10\n",
            "loss(total):-0.005257\n",
            "recons_loss:0.002902\n",
            "grad_loss:0.085427\n",
            "dice_loss:-0.901370\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:11\n",
            "loss(total):-0.005180\n",
            "recons_loss:0.002946\n",
            "grad_loss:0.080788\n",
            "dice_loss:-0.893406\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:12\n",
            "loss(total):-0.002808\n",
            "recons_loss:0.004874\n",
            "grad_loss:0.117381\n",
            "dice_loss:-0.885552\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:13\n",
            "loss(total):-0.002701\n",
            "recons_loss:0.004978\n",
            "grad_loss:0.118927\n",
            "dice_loss:-0.886833\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:14\n",
            "loss(total):-0.003157\n",
            "recons_loss:0.004554\n",
            "grad_loss:0.121118\n",
            "dice_loss:-0.892173\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:15\n",
            "loss(total):-0.002601\n",
            "recons_loss:0.004827\n",
            "grad_loss:0.133290\n",
            "dice_loss:-0.876124\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:16\n",
            "loss(total):-0.004021\n",
            "recons_loss:0.003820\n",
            "grad_loss:0.100041\n",
            "dice_loss:-0.884202\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:17\n",
            "loss(total):-0.003821\n",
            "recons_loss:0.004221\n",
            "grad_loss:0.093209\n",
            "dice_loss:-0.897414\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:18\n",
            "loss(total):-0.004847\n",
            "recons_loss:0.003449\n",
            "grad_loss:0.073946\n",
            "dice_loss:-0.903503\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:19\n",
            "loss(total):-0.004590\n",
            "recons_loss:0.003593\n",
            "grad_loss:0.084183\n",
            "dice_loss:-0.902513\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:20\n",
            "loss(total):-0.004597\n",
            "recons_loss:0.003506\n",
            "grad_loss:0.085806\n",
            "dice_loss:-0.896113\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:21\n",
            "loss(total):-0.002705\n",
            "recons_loss:0.004996\n",
            "grad_loss:0.118705\n",
            "dice_loss:-0.888718\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:22\n",
            "loss(total):-0.003016\n",
            "recons_loss:0.004657\n",
            "grad_loss:0.123787\n",
            "dice_loss:-0.891032\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:23\n",
            "loss(total):-0.004462\n",
            "recons_loss:0.003469\n",
            "grad_loss:0.098711\n",
            "dice_loss:-0.891795\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:24\n",
            "loss(total):-0.004941\n",
            "recons_loss:0.003312\n",
            "grad_loss:0.084545\n",
            "dice_loss:-0.909773\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:25\n",
            "loss(total):-0.005305\n",
            "recons_loss:0.003181\n",
            "grad_loss:0.065247\n",
            "dice_loss:-0.913813\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:26\n",
            "loss(total):-0.004133\n",
            "recons_loss:0.003940\n",
            "grad_loss:0.091748\n",
            "dice_loss:-0.899054\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:27\n",
            "loss(total):-0.004738\n",
            "recons_loss:0.003309\n",
            "grad_loss:0.089608\n",
            "dice_loss:-0.894268\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:28\n",
            "loss(total):-0.004607\n",
            "recons_loss:0.003496\n",
            "grad_loss:0.090306\n",
            "dice_loss:-0.900528\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:29\n",
            "loss(total):-0.003428\n",
            "recons_loss:0.004336\n",
            "grad_loss:0.116368\n",
            "dice_loss:-0.892742\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:30\n",
            "loss(total):-0.003013\n",
            "recons_loss:0.004695\n",
            "grad_loss:0.120138\n",
            "dice_loss:-0.890943\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:31\n",
            "loss(total):-0.004946\n",
            "recons_loss:0.003180\n",
            "grad_loss:0.088670\n",
            "dice_loss:-0.901294\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:32\n",
            "loss(total):-0.004091\n",
            "recons_loss:0.003801\n",
            "grad_loss:0.106850\n",
            "dice_loss:-0.896061\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:33\n",
            "loss(total):-0.005031\n",
            "recons_loss:0.003040\n",
            "grad_loss:0.087204\n",
            "dice_loss:-0.894347\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:34\n",
            "loss(total):-0.004832\n",
            "recons_loss:0.003239\n",
            "grad_loss:0.081776\n",
            "dice_loss:-0.888927\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:35\n",
            "loss(total):-0.004694\n",
            "recons_loss:0.003450\n",
            "grad_loss:0.081122\n",
            "dice_loss:-0.895522\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:36\n",
            "loss(total):-0.003928\n",
            "recons_loss:0.004082\n",
            "grad_loss:0.092066\n",
            "dice_loss:-0.893088\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:37\n",
            "loss(total):-0.004126\n",
            "recons_loss:0.003721\n",
            "grad_loss:0.098779\n",
            "dice_loss:-0.883476\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:38\n",
            "loss(total):-0.003928\n",
            "recons_loss:0.004003\n",
            "grad_loss:0.100152\n",
            "dice_loss:-0.893302\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:39\n",
            "loss(total):-0.004251\n",
            "recons_loss:0.003821\n",
            "grad_loss:0.077634\n",
            "dice_loss:-0.884923\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:40\n",
            "loss(total):-0.002850\n",
            "recons_loss:0.004714\n",
            "grad_loss:0.130059\n",
            "dice_loss:-0.886483\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:41\n",
            "loss(total):-0.004662\n",
            "recons_loss:0.003408\n",
            "grad_loss:0.090093\n",
            "dice_loss:-0.897181\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:42\n",
            "loss(total):-0.004931\n",
            "recons_loss:0.003273\n",
            "grad_loss:0.086618\n",
            "dice_loss:-0.906982\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:43\n",
            "loss(total):-0.005463\n",
            "recons_loss:0.002934\n",
            "grad_loss:0.069338\n",
            "dice_loss:-0.909122\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:44\n",
            "loss(total):-0.003384\n",
            "recons_loss:0.004368\n",
            "grad_loss:0.112339\n",
            "dice_loss:-0.887562\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:45\n",
            "loss(total):-0.004110\n",
            "recons_loss:0.003839\n",
            "grad_loss:0.090944\n",
            "dice_loss:-0.885846\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:46\n",
            "loss(total):-0.002340\n",
            "recons_loss:0.005224\n",
            "grad_loss:0.133781\n",
            "dice_loss:-0.890193\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:47\n",
            "loss(total):-0.004998\n",
            "recons_loss:0.003087\n",
            "grad_loss:0.081572\n",
            "dice_loss:-0.890044\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:48\n",
            "loss(total):-0.004732\n",
            "recons_loss:0.003421\n",
            "grad_loss:0.078161\n",
            "dice_loss:-0.893406\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:49\n",
            "loss(total):-0.003401\n",
            "recons_loss:0.004387\n",
            "grad_loss:0.112836\n",
            "dice_loss:-0.891666\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:50\n",
            "loss(total):-0.004149\n",
            "recons_loss:0.003928\n",
            "grad_loss:0.087268\n",
            "dice_loss:-0.895018\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:51\n",
            "loss(total):-0.004451\n",
            "recons_loss:0.003701\n",
            "grad_loss:0.085961\n",
            "dice_loss:-0.901110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:52\n",
            "loss(total):-0.004165\n",
            "recons_loss:0.003795\n",
            "grad_loss:0.097214\n",
            "dice_loss:-0.893198\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:53\n",
            "loss(total):-0.004406\n",
            "recons_loss:0.003606\n",
            "grad_loss:0.093174\n",
            "dice_loss:-0.894363\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:54\n",
            "loss(total):-0.003950\n",
            "recons_loss:0.003953\n",
            "grad_loss:0.101716\n",
            "dice_loss:-0.892006\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:55\n",
            "loss(total):-0.003362\n",
            "recons_loss:0.004530\n",
            "grad_loss:0.098041\n",
            "dice_loss:-0.887311\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:56\n",
            "loss(total):-0.004009\n",
            "recons_loss:0.003946\n",
            "grad_loss:0.095036\n",
            "dice_loss:-0.890589\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:57\n",
            "loss(total):-0.002247\n",
            "recons_loss:0.005521\n",
            "grad_loss:0.116182\n",
            "dice_loss:-0.893001\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:58\n",
            "loss(total):-0.003741\n",
            "recons_loss:0.004242\n",
            "grad_loss:0.095957\n",
            "dice_loss:-0.894173\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:59\n",
            "loss(total):-0.003805\n",
            "recons_loss:0.004019\n",
            "grad_loss:0.106794\n",
            "dice_loss:-0.889172\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:60\n",
            "loss(total):-0.004993\n",
            "recons_loss:0.003177\n",
            "grad_loss:0.085021\n",
            "dice_loss:-0.902010\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:61\n",
            "loss(total):-0.004574\n",
            "recons_loss:0.003431\n",
            "grad_loss:0.092733\n",
            "dice_loss:-0.893277\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:62\n",
            "loss(total):-0.003597\n",
            "recons_loss:0.004319\n",
            "grad_loss:0.107357\n",
            "dice_loss:-0.899006\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:63\n",
            "loss(total):-0.003676\n",
            "recons_loss:0.004160\n",
            "grad_loss:0.104984\n",
            "dice_loss:-0.888613\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:64\n",
            "loss(total):-0.003358\n",
            "recons_loss:0.004505\n",
            "grad_loss:0.091541\n",
            "dice_loss:-0.877844\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:65\n",
            "loss(total):-0.003450\n",
            "recons_loss:0.004511\n",
            "grad_loss:0.092766\n",
            "dice_loss:-0.888880\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:66\n",
            "loss(total):-0.003854\n",
            "recons_loss:0.004106\n",
            "grad_loss:0.104718\n",
            "dice_loss:-0.900742\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:67\n",
            "loss(total):-0.003913\n",
            "recons_loss:0.004058\n",
            "grad_loss:0.095163\n",
            "dice_loss:-0.892254\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:68\n",
            "loss(total):-0.004088\n",
            "recons_loss:0.003827\n",
            "grad_loss:0.097637\n",
            "dice_loss:-0.889174\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:69\n",
            "loss(total):-0.003459\n",
            "recons_loss:0.004244\n",
            "grad_loss:0.110346\n",
            "dice_loss:-0.880656\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:70\n",
            "loss(total):-0.003968\n",
            "recons_loss:0.004097\n",
            "grad_loss:0.092917\n",
            "dice_loss:-0.899362\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:71\n",
            "loss(total):-0.004565\n",
            "recons_loss:0.003485\n",
            "grad_loss:0.087000\n",
            "dice_loss:-0.891920\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:72\n",
            "loss(total):-0.002469\n",
            "recons_loss:0.004921\n",
            "grad_loss:0.145236\n",
            "dice_loss:-0.884236\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:73\n",
            "loss(total):-0.003196\n",
            "recons_loss:0.004520\n",
            "grad_loss:0.103291\n",
            "dice_loss:-0.874886\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:74\n",
            "loss(total):-0.004732\n",
            "recons_loss:0.003362\n",
            "grad_loss:0.088886\n",
            "dice_loss:-0.898318\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:75\n",
            "loss(total):-0.003718\n",
            "recons_loss:0.004220\n",
            "grad_loss:0.102059\n",
            "dice_loss:-0.895787\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:76\n",
            "loss(total):-0.004744\n",
            "recons_loss:0.003356\n",
            "grad_loss:0.095070\n",
            "dice_loss:-0.905144\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:77\n",
            "loss(total):-0.003063\n",
            "recons_loss:0.004536\n",
            "grad_loss:0.121573\n",
            "dice_loss:-0.881485\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:78\n",
            "loss(total):-0.003716\n",
            "recons_loss:0.004272\n",
            "grad_loss:0.095259\n",
            "dice_loss:-0.894135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:79\n",
            "loss(total):-0.003942\n",
            "recons_loss:0.003905\n",
            "grad_loss:0.109536\n",
            "dice_loss:-0.894246\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:80\n",
            "loss(total):-0.003349\n",
            "recons_loss:0.004463\n",
            "grad_loss:0.111073\n",
            "dice_loss:-0.892187\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:81\n",
            "loss(total):-0.001804\n",
            "recons_loss:0.005527\n",
            "grad_loss:0.144378\n",
            "dice_loss:-0.877523\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:82\n",
            "loss(total):-0.003469\n",
            "recons_loss:0.004083\n",
            "grad_loss:0.132073\n",
            "dice_loss:-0.887275\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:83\n",
            "loss(total):-0.003421\n",
            "recons_loss:0.004283\n",
            "grad_loss:0.114741\n",
            "dice_loss:-0.885065\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:84\n",
            "loss(total):-0.004750\n",
            "recons_loss:0.003367\n",
            "grad_loss:0.095027\n",
            "dice_loss:-0.906728\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:85\n",
            "loss(total):-0.003843\n",
            "recons_loss:0.004207\n",
            "grad_loss:0.093065\n",
            "dice_loss:-0.898038\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:86\n",
            "loss(total):-0.004265\n",
            "recons_loss:0.003799\n",
            "grad_loss:0.079963\n",
            "dice_loss:-0.886345\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:87\n",
            "loss(total):-0.002640\n",
            "recons_loss:0.005173\n",
            "grad_loss:0.113430\n",
            "dice_loss:-0.894729\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:88\n",
            "loss(total):-0.005015\n",
            "recons_loss:0.003151\n",
            "grad_loss:0.081691\n",
            "dice_loss:-0.898381\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:89\n",
            "loss(total):-0.003244\n",
            "recons_loss:0.004645\n",
            "grad_loss:0.105969\n",
            "dice_loss:-0.894935\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:90\n",
            "loss(total):-0.005112\n",
            "recons_loss:0.003050\n",
            "grad_loss:0.078825\n",
            "dice_loss:-0.895032\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:91\n",
            "loss(total):-0.002680\n",
            "recons_loss:0.004980\n",
            "grad_loss:0.116743\n",
            "dice_loss:-0.882715\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:92\n",
            "loss(total):-0.002396\n",
            "recons_loss:0.005093\n",
            "grad_loss:0.128626\n",
            "dice_loss:-0.877489\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:93\n",
            "loss(total):-0.004205\n",
            "recons_loss:0.003451\n",
            "grad_loss:0.118390\n",
            "dice_loss:-0.883925\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:94\n",
            "loss(total):-0.004137\n",
            "recons_loss:0.003811\n",
            "grad_loss:0.100326\n",
            "dice_loss:-0.895141\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:95\n",
            "loss(total):-0.001906\n",
            "recons_loss:0.005601\n",
            "grad_loss:0.119652\n",
            "dice_loss:-0.870329\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:96\n",
            "loss(total):-0.002953\n",
            "recons_loss:0.004717\n",
            "grad_loss:0.119379\n",
            "dice_loss:-0.886378\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:97\n",
            "loss(total):-0.003156\n",
            "recons_loss:0.004625\n",
            "grad_loss:0.112619\n",
            "dice_loss:-0.890791\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:98\n",
            "loss(total):-0.002075\n",
            "recons_loss:0.005465\n",
            "grad_loss:0.133032\n",
            "dice_loss:-0.887005\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:99\n",
            "loss(total):-0.003535\n",
            "recons_loss:0.004252\n",
            "grad_loss:0.105137\n",
            "dice_loss:-0.883787\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:100\n",
            "loss(total):-0.003548\n",
            "recons_loss:0.004471\n",
            "grad_loss:0.091700\n",
            "dice_loss:-0.893584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:101\n",
            "loss(total):-0.003774\n",
            "recons_loss:0.004251\n",
            "grad_loss:0.084913\n",
            "dice_loss:-0.887407\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:102\n",
            "loss(total):-0.004323\n",
            "recons_loss:0.003864\n",
            "grad_loss:0.083915\n",
            "dice_loss:-0.902588\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:103\n",
            "loss(total):-0.003863\n",
            "recons_loss:0.004196\n",
            "grad_loss:0.076605\n",
            "dice_loss:-0.882537\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:104\n",
            "loss(total):-0.002634\n",
            "recons_loss:0.004903\n",
            "grad_loss:0.122152\n",
            "dice_loss:-0.875828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:105\n",
            "loss(total):-0.003401\n",
            "recons_loss:0.004294\n",
            "grad_loss:0.113717\n",
            "dice_loss:-0.883233\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:106\n",
            "loss(total):-0.002688\n",
            "recons_loss:0.004906\n",
            "grad_loss:0.125111\n",
            "dice_loss:-0.884491\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:107\n",
            "loss(total):-0.002882\n",
            "recons_loss:0.004766\n",
            "grad_loss:0.132382\n",
            "dice_loss:-0.897205\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:108\n",
            "loss(total):-0.004608\n",
            "recons_loss:0.003418\n",
            "grad_loss:0.093854\n",
            "dice_loss:-0.896457\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:109\n",
            "loss(total):-0.003189\n",
            "recons_loss:0.004578\n",
            "grad_loss:0.103226\n",
            "dice_loss:-0.879962\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:110\n",
            "loss(total):-0.002727\n",
            "recons_loss:0.004836\n",
            "grad_loss:0.120314\n",
            "dice_loss:-0.876654\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:111\n",
            "loss(total):-0.003670\n",
            "recons_loss:0.004101\n",
            "grad_loss:0.107807\n",
            "dice_loss:-0.884919\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:112\n",
            "loss(total):-0.004920\n",
            "recons_loss:0.003218\n",
            "grad_loss:0.086817\n",
            "dice_loss:-0.900558\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:113\n",
            "loss(total):-0.004800\n",
            "recons_loss:0.003466\n",
            "grad_loss:0.073645\n",
            "dice_loss:-0.900257\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:114\n",
            "loss(total):-0.002922\n",
            "recons_loss:0.004773\n",
            "grad_loss:0.102919\n",
            "dice_loss:-0.872402\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:115\n",
            "loss(total):-0.003868\n",
            "recons_loss:0.003991\n",
            "grad_loss:0.097578\n",
            "dice_loss:-0.883395\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:116\n",
            "loss(total):-0.004536\n",
            "recons_loss:0.003497\n",
            "grad_loss:0.084761\n",
            "dice_loss:-0.888110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:117\n",
            "loss(total):-0.004285\n",
            "recons_loss:0.003596\n",
            "grad_loss:0.104195\n",
            "dice_loss:-0.892221\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:118\n",
            "loss(total):-0.004644\n",
            "recons_loss:0.003432\n",
            "grad_loss:0.087530\n",
            "dice_loss:-0.895205\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:119\n",
            "loss(total):-0.004063\n",
            "recons_loss:0.003763\n",
            "grad_loss:0.100715\n",
            "dice_loss:-0.883334\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:120\n",
            "loss(total):-0.003787\n",
            "recons_loss:0.004007\n",
            "grad_loss:0.107107\n",
            "dice_loss:-0.886482\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:121\n",
            "loss(total):-0.003998\n",
            "recons_loss:0.004005\n",
            "grad_loss:0.096463\n",
            "dice_loss:-0.896818\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:122\n",
            "loss(total):-0.003796\n",
            "recons_loss:0.004249\n",
            "grad_loss:0.081015\n",
            "dice_loss:-0.885542\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:123\n",
            "loss(total):-0.004188\n",
            "recons_loss:0.003897\n",
            "grad_loss:0.092348\n",
            "dice_loss:-0.900827\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:124\n",
            "loss(total):-0.002989\n",
            "recons_loss:0.004721\n",
            "grad_loss:0.121710\n",
            "dice_loss:-0.892682\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:125\n",
            "loss(total):-0.003664\n",
            "recons_loss:0.004328\n",
            "grad_loss:0.097290\n",
            "dice_loss:-0.896559\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:126\n",
            "loss(total):-0.003819\n",
            "recons_loss:0.004136\n",
            "grad_loss:0.087658\n",
            "dice_loss:-0.883083\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:127\n",
            "loss(total):-0.003796\n",
            "recons_loss:0.004240\n",
            "grad_loss:0.089731\n",
            "dice_loss:-0.893295\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:128\n",
            "loss(total):-0.004746\n",
            "recons_loss:0.003341\n",
            "grad_loss:0.077224\n",
            "dice_loss:-0.885910\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:129\n",
            "loss(total):-0.002246\n",
            "recons_loss:0.005343\n",
            "grad_loss:0.126596\n",
            "dice_loss:-0.885490\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:130\n",
            "loss(total):-0.003003\n",
            "recons_loss:0.004854\n",
            "grad_loss:0.106934\n",
            "dice_loss:-0.892615\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:131\n",
            "loss(total):-0.003673\n",
            "recons_loss:0.004211\n",
            "grad_loss:0.105490\n",
            "dice_loss:-0.893902\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:132\n",
            "loss(total):-0.003922\n",
            "recons_loss:0.003930\n",
            "grad_loss:0.098584\n",
            "dice_loss:-0.883755\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:133\n",
            "loss(total):-0.003708\n",
            "recons_loss:0.004152\n",
            "grad_loss:0.104082\n",
            "dice_loss:-0.890087\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:134\n",
            "loss(total):-0.003261\n",
            "recons_loss:0.004552\n",
            "grad_loss:0.117651\n",
            "dice_loss:-0.898959\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:135\n",
            "loss(total):-0.003199\n",
            "recons_loss:0.004537\n",
            "grad_loss:0.104518\n",
            "dice_loss:-0.878185\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:136\n",
            "loss(total):-0.004783\n",
            "recons_loss:0.003401\n",
            "grad_loss:0.082671\n",
            "dice_loss:-0.901110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:137\n",
            "loss(total):-0.003938\n",
            "recons_loss:0.004044\n",
            "grad_loss:0.091926\n",
            "dice_loss:-0.890113\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:138\n",
            "loss(total):-0.003052\n",
            "recons_loss:0.004777\n",
            "grad_loss:0.095767\n",
            "dice_loss:-0.878673\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:139\n",
            "loss(total):-0.004391\n",
            "recons_loss:0.003553\n",
            "grad_loss:0.095026\n",
            "dice_loss:-0.889355\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:140\n",
            "loss(total):-0.004074\n",
            "recons_loss:0.003804\n",
            "grad_loss:0.099730\n",
            "dice_loss:-0.887546\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:141\n",
            "loss(total):-0.003048\n",
            "recons_loss:0.004708\n",
            "grad_loss:0.114563\n",
            "dice_loss:-0.890100\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:142\n",
            "loss(total):-0.004865\n",
            "recons_loss:0.003378\n",
            "grad_loss:0.084537\n",
            "dice_loss:-0.908816\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:143\n",
            "loss(total):-0.005088\n",
            "recons_loss:0.002960\n",
            "grad_loss:0.078194\n",
            "dice_loss:-0.882976\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:144\n",
            "loss(total):-0.003840\n",
            "recons_loss:0.004097\n",
            "grad_loss:0.106804\n",
            "dice_loss:-0.900547\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:145\n",
            "loss(total):-0.004595\n",
            "recons_loss:0.003518\n",
            "grad_loss:0.079998\n",
            "dice_loss:-0.891276\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:146\n",
            "loss(total):-0.004974\n",
            "recons_loss:0.003120\n",
            "grad_loss:0.085360\n",
            "dice_loss:-0.894780\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:147\n",
            "loss(total):-0.004240\n",
            "recons_loss:0.003734\n",
            "grad_loss:0.085121\n",
            "dice_loss:-0.882502\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:148\n",
            "loss(total):-0.003834\n",
            "recons_loss:0.004010\n",
            "grad_loss:0.100987\n",
            "dice_loss:-0.885386\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:149\n",
            "loss(total):-0.004670\n",
            "recons_loss:0.003508\n",
            "grad_loss:0.077615\n",
            "dice_loss:-0.895437\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:150\n",
            "loss(total):-0.004299\n",
            "recons_loss:0.003856\n",
            "grad_loss:0.077021\n",
            "dice_loss:-0.892516\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:151\n",
            "loss(total):-0.002184\n",
            "recons_loss:0.005518\n",
            "grad_loss:0.115482\n",
            "dice_loss:-0.885712\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:152\n",
            "loss(total):-0.004460\n",
            "recons_loss:0.003542\n",
            "grad_loss:0.085052\n",
            "dice_loss:-0.885252\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:153\n",
            "loss(total):-0.004866\n",
            "recons_loss:0.003225\n",
            "grad_loss:0.081945\n",
            "dice_loss:-0.891042\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:154\n",
            "loss(total):-0.005116\n",
            "recons_loss:0.003046\n",
            "grad_loss:0.084965\n",
            "dice_loss:-0.901155\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:155\n",
            "loss(total):-0.002143\n",
            "recons_loss:0.005237\n",
            "grad_loss:0.129181\n",
            "dice_loss:-0.867245\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:156\n",
            "loss(total):-0.003849\n",
            "recons_loss:0.004121\n",
            "grad_loss:0.095599\n",
            "dice_loss:-0.892583\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:157\n",
            "loss(total):-0.004116\n",
            "recons_loss:0.003867\n",
            "grad_loss:0.091842\n",
            "dice_loss:-0.890187\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:158\n",
            "loss(total):-0.002973\n",
            "recons_loss:0.004749\n",
            "grad_loss:0.118092\n",
            "dice_loss:-0.890298\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:159\n",
            "loss(total):-0.003794\n",
            "recons_loss:0.004064\n",
            "grad_loss:0.099526\n",
            "dice_loss:-0.885266\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:160\n",
            "loss(total):-0.003806\n",
            "recons_loss:0.004133\n",
            "grad_loss:0.104942\n",
            "dice_loss:-0.898813\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:161\n",
            "loss(total):-0.003158\n",
            "recons_loss:0.004579\n",
            "grad_loss:0.102384\n",
            "dice_loss:-0.876102\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:162\n",
            "loss(total):-0.004274\n",
            "recons_loss:0.003677\n",
            "grad_loss:0.109215\n",
            "dice_loss:-0.904386\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:163\n",
            "loss(total):-0.002502\n",
            "recons_loss:0.005226\n",
            "grad_loss:0.114639\n",
            "dice_loss:-0.887423\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:164\n",
            "loss(total):-0.003828\n",
            "recons_loss:0.004069\n",
            "grad_loss:0.104060\n",
            "dice_loss:-0.893846\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:165\n",
            "loss(total):-0.003460\n",
            "recons_loss:0.004358\n",
            "grad_loss:0.111153\n",
            "dice_loss:-0.893013\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:166\n",
            "loss(total):-0.004236\n",
            "recons_loss:0.003699\n",
            "grad_loss:0.094966\n",
            "dice_loss:-0.888526\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:167\n",
            "loss(total):-0.003733\n",
            "recons_loss:0.003992\n",
            "grad_loss:0.114736\n",
            "dice_loss:-0.887288\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:168\n",
            "loss(total):-0.004122\n",
            "recons_loss:0.003858\n",
            "grad_loss:0.093967\n",
            "dice_loss:-0.891929\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:169\n",
            "loss(total):-0.003138\n",
            "recons_loss:0.004605\n",
            "grad_loss:0.111060\n",
            "dice_loss:-0.885392\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:170\n",
            "loss(total):-0.004014\n",
            "recons_loss:0.003995\n",
            "grad_loss:0.082236\n",
            "dice_loss:-0.883182\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:171\n",
            "loss(total):-0.002858\n",
            "recons_loss:0.005016\n",
            "grad_loss:0.110346\n",
            "dice_loss:-0.897729\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:172\n",
            "loss(total):-0.004180\n",
            "recons_loss:0.003924\n",
            "grad_loss:0.087181\n",
            "dice_loss:-0.897660\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:173\n",
            "loss(total):-0.004836\n",
            "recons_loss:0.003336\n",
            "grad_loss:0.091059\n",
            "dice_loss:-0.908240\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:174\n",
            "loss(total):-0.002275\n",
            "recons_loss:0.005215\n",
            "grad_loss:0.134519\n",
            "dice_loss:-0.883583\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:175\n",
            "loss(total):-0.004532\n",
            "recons_loss:0.003659\n",
            "grad_loss:0.072400\n",
            "dice_loss:-0.891454\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:176\n",
            "loss(total):-0.003341\n",
            "recons_loss:0.004488\n",
            "grad_loss:0.101906\n",
            "dice_loss:-0.884828\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:177\n",
            "loss(total):-0.003977\n",
            "recons_loss:0.003998\n",
            "grad_loss:0.095565\n",
            "dice_loss:-0.893018\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:178\n",
            "loss(total):-0.003368\n",
            "recons_loss:0.004671\n",
            "grad_loss:0.090338\n",
            "dice_loss:-0.894271\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:179\n",
            "loss(total):-0.002679\n",
            "recons_loss:0.005102\n",
            "grad_loss:0.109220\n",
            "dice_loss:-0.887385\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:180\n",
            "loss(total):-0.002676\n",
            "recons_loss:0.005179\n",
            "grad_loss:0.101244\n",
            "dice_loss:-0.886722\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:181\n",
            "loss(total):-0.003557\n",
            "recons_loss:0.004312\n",
            "grad_loss:0.094953\n",
            "dice_loss:-0.881795\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:182\n",
            "loss(total):-0.001756\n",
            "recons_loss:0.005742\n",
            "grad_loss:0.127024\n",
            "dice_loss:-0.876858\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:183\n",
            "loss(total):-0.003566\n",
            "recons_loss:0.004369\n",
            "grad_loss:0.097504\n",
            "dice_loss:-0.890967\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:184\n",
            "loss(total):-0.003873\n",
            "recons_loss:0.004116\n",
            "grad_loss:0.084765\n",
            "dice_loss:-0.883662\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:185\n",
            "loss(total):-0.004230\n",
            "recons_loss:0.003754\n",
            "grad_loss:0.082874\n",
            "dice_loss:-0.881296\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:186\n",
            "loss(total):-0.004291\n",
            "recons_loss:0.003635\n",
            "grad_loss:0.091183\n",
            "dice_loss:-0.883831\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:187\n",
            "loss(total):-0.004079\n",
            "recons_loss:0.003825\n",
            "grad_loss:0.088223\n",
            "dice_loss:-0.878668\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:188\n",
            "loss(total):-0.003935\n",
            "recons_loss:0.004101\n",
            "grad_loss:0.093732\n",
            "dice_loss:-0.897274\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:189\n",
            "loss(total):-0.005290\n",
            "recons_loss:0.003091\n",
            "grad_loss:0.063535\n",
            "dice_loss:-0.901690\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:190\n",
            "loss(total):-0.004496\n",
            "recons_loss:0.003530\n",
            "grad_loss:0.094877\n",
            "dice_loss:-0.897462\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:191\n",
            "loss(total):-0.003187\n",
            "recons_loss:0.004587\n",
            "grad_loss:0.112972\n",
            "dice_loss:-0.890319\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:192\n",
            "loss(total):-0.003700\n",
            "recons_loss:0.004177\n",
            "grad_loss:0.108184\n",
            "dice_loss:-0.895845\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:193\n",
            "loss(total):-0.004142\n",
            "recons_loss:0.003946\n",
            "grad_loss:0.086649\n",
            "dice_loss:-0.895482\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:194\n",
            "loss(total):-0.003895\n",
            "recons_loss:0.003938\n",
            "grad_loss:0.110410\n",
            "dice_loss:-0.893747\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:195\n",
            "loss(total):-0.003363\n",
            "recons_loss:0.004469\n",
            "grad_loss:0.096710\n",
            "dice_loss:-0.879923\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:196\n",
            "loss(total):-0.003969\n",
            "recons_loss:0.003895\n",
            "grad_loss:0.109101\n",
            "dice_loss:-0.895509\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:197\n",
            "loss(total):-0.002550\n",
            "recons_loss:0.005250\n",
            "grad_loss:0.109886\n",
            "dice_loss:-0.889818\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:198\n",
            "loss(total):-0.003932\n",
            "recons_loss:0.003919\n",
            "grad_loss:0.092997\n",
            "dice_loss:-0.878079\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:199\n",
            "loss(total):-0.002999\n",
            "recons_loss:0.004535\n",
            "grad_loss:0.126215\n",
            "dice_loss:-0.879651\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:200\n",
            "loss(total):-0.004255\n",
            "recons_loss:0.003551\n",
            "grad_loss:0.102523\n",
            "dice_loss:-0.883110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:201\n",
            "loss(total):-0.004482\n",
            "recons_loss:0.003529\n",
            "grad_loss:0.086810\n",
            "dice_loss:-0.887939\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:202\n",
            "loss(total):-0.003247\n",
            "recons_loss:0.004494\n",
            "grad_loss:0.111204\n",
            "dice_loss:-0.885303\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:203\n",
            "loss(total):-0.003113\n",
            "recons_loss:0.004621\n",
            "grad_loss:0.118310\n",
            "dice_loss:-0.891735\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:204\n",
            "loss(total):-0.003172\n",
            "recons_loss:0.004454\n",
            "grad_loss:0.122571\n",
            "dice_loss:-0.885117\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:205\n",
            "loss(total):-0.002736\n",
            "recons_loss:0.004935\n",
            "grad_loss:0.123257\n",
            "dice_loss:-0.890375\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:206\n",
            "loss(total):-0.004540\n",
            "recons_loss:0.003341\n",
            "grad_loss:0.103831\n",
            "dice_loss:-0.891955\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:207\n",
            "loss(total):-0.004732\n",
            "recons_loss:0.003307\n",
            "grad_loss:0.081894\n",
            "dice_loss:-0.885793\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:208\n",
            "loss(total):-0.003935\n",
            "recons_loss:0.003922\n",
            "grad_loss:0.095252\n",
            "dice_loss:-0.880973\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:209\n",
            "loss(total):-0.004205\n",
            "recons_loss:0.003715\n",
            "grad_loss:0.099059\n",
            "dice_loss:-0.891110\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:210\n",
            "loss(total):-0.004027\n",
            "recons_loss:0.003832\n",
            "grad_loss:0.103236\n",
            "dice_loss:-0.889126\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:211\n",
            "loss(total):-0.004682\n",
            "recons_loss:0.003527\n",
            "grad_loss:0.087165\n",
            "dice_loss:-0.908031\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:212\n",
            "loss(total):-0.003527\n",
            "recons_loss:0.004480\n",
            "grad_loss:0.092006\n",
            "dice_loss:-0.892650\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:213\n",
            "loss(total):-0.002800\n",
            "recons_loss:0.004871\n",
            "grad_loss:0.124605\n",
            "dice_loss:-0.891711\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:214\n",
            "loss(total):-0.003678\n",
            "recons_loss:0.004255\n",
            "grad_loss:0.096575\n",
            "dice_loss:-0.889887\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:215\n",
            "loss(total):-0.002275\n",
            "recons_loss:0.005533\n",
            "grad_loss:0.108459\n",
            "dice_loss:-0.889254\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:216\n",
            "loss(total):-0.004751\n",
            "recons_loss:0.003355\n",
            "grad_loss:0.081142\n",
            "dice_loss:-0.891777\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:217\n",
            "loss(total):-0.003983\n",
            "recons_loss:0.004012\n",
            "grad_loss:0.100201\n",
            "dice_loss:-0.899667\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:218\n",
            "loss(total):-0.005093\n",
            "recons_loss:0.003180\n",
            "grad_loss:0.078424\n",
            "dice_loss:-0.905704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:219\n",
            "loss(total):-0.003591\n",
            "recons_loss:0.004412\n",
            "grad_loss:0.109468\n",
            "dice_loss:-0.909762\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:220\n",
            "loss(total):-0.003745\n",
            "recons_loss:0.004159\n",
            "grad_loss:0.101648\n",
            "dice_loss:-0.892092\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:221\n",
            "loss(total):-0.003658\n",
            "recons_loss:0.004127\n",
            "grad_loss:0.109767\n",
            "dice_loss:-0.888315\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:222\n",
            "loss(total):-0.003970\n",
            "recons_loss:0.003923\n",
            "grad_loss:0.088027\n",
            "dice_loss:-0.877379\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:223\n",
            "loss(total):-0.004015\n",
            "recons_loss:0.004041\n",
            "grad_loss:0.088034\n",
            "dice_loss:-0.893702\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:224\n",
            "loss(total):-0.003585\n",
            "recons_loss:0.004163\n",
            "grad_loss:0.111942\n",
            "dice_loss:-0.886771\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:225\n",
            "loss(total):-0.003428\n",
            "recons_loss:0.004510\n",
            "grad_loss:0.098651\n",
            "dice_loss:-0.892428\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:226\n",
            "loss(total):-0.003014\n",
            "recons_loss:0.004590\n",
            "grad_loss:0.121339\n",
            "dice_loss:-0.881695\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:227\n",
            "loss(total):-0.003469\n",
            "recons_loss:0.004264\n",
            "grad_loss:0.107016\n",
            "dice_loss:-0.880331\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:228\n",
            "loss(total):-0.003146\n",
            "recons_loss:0.004484\n",
            "grad_loss:0.109275\n",
            "dice_loss:-0.872292\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:229\n",
            "loss(total):-0.004524\n",
            "recons_loss:0.003490\n",
            "grad_loss:0.086098\n",
            "dice_loss:-0.887538\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:230\n",
            "loss(total):-0.003620\n",
            "recons_loss:0.004081\n",
            "grad_loss:0.118038\n",
            "dice_loss:-0.888135\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:231\n",
            "loss(total):-0.004012\n",
            "recons_loss:0.003865\n",
            "grad_loss:0.101828\n",
            "dice_loss:-0.889495\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:232\n",
            "loss(total):-0.004143\n",
            "recons_loss:0.003694\n",
            "grad_loss:0.090217\n",
            "dice_loss:-0.873917\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:233\n",
            "loss(total):-0.004339\n",
            "recons_loss:0.003727\n",
            "grad_loss:0.094032\n",
            "dice_loss:-0.900704\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:234\n",
            "loss(total):-0.003498\n",
            "recons_loss:0.004338\n",
            "grad_loss:0.108570\n",
            "dice_loss:-0.892122\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:235\n",
            "loss(total):-0.004156\n",
            "recons_loss:0.003767\n",
            "grad_loss:0.114492\n",
            "dice_loss:-0.906804\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:236\n",
            "loss(total):-0.004572\n",
            "recons_loss:0.003517\n",
            "grad_loss:0.093908\n",
            "dice_loss:-0.902834\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:237\n",
            "loss(total):-0.004133\n",
            "recons_loss:0.003786\n",
            "grad_loss:0.100616\n",
            "dice_loss:-0.892566\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:238\n",
            "loss(total):-0.003598\n",
            "recons_loss:0.004218\n",
            "grad_loss:0.110775\n",
            "dice_loss:-0.892372\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:239\n",
            "loss(total):-0.003616\n",
            "recons_loss:0.004149\n",
            "grad_loss:0.108597\n",
            "dice_loss:-0.885072\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:240\n",
            "loss(total):-0.004229\n",
            "recons_loss:0.003864\n",
            "grad_loss:0.093032\n",
            "dice_loss:-0.902274\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:241\n",
            "loss(total):-0.004854\n",
            "recons_loss:0.003418\n",
            "grad_loss:0.079431\n",
            "dice_loss:-0.906717\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:242\n",
            "loss(total):-0.004963\n",
            "recons_loss:0.003126\n",
            "grad_loss:0.101111\n",
            "dice_loss:-0.910049\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:243\n",
            "loss(total):-0.004795\n",
            "recons_loss:0.003289\n",
            "grad_loss:0.089311\n",
            "dice_loss:-0.897662\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:244\n",
            "loss(total):-0.004013\n",
            "recons_loss:0.004210\n",
            "grad_loss:0.071396\n",
            "dice_loss:-0.893730\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:245\n",
            "loss(total):-0.004159\n",
            "recons_loss:0.003887\n",
            "grad_loss:0.080572\n",
            "dice_loss:-0.885207\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:246\n",
            "loss(total):-0.003934\n",
            "recons_loss:0.003899\n",
            "grad_loss:0.100632\n",
            "dice_loss:-0.883937\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:247\n",
            "loss(total):-0.005115\n",
            "recons_loss:0.003082\n",
            "grad_loss:0.085683\n",
            "dice_loss:-0.905390\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:248\n",
            "loss(total):-0.004545\n",
            "recons_loss:0.003658\n",
            "grad_loss:0.067973\n",
            "dice_loss:-0.888186\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:249\n",
            "loss(total):-0.004918\n",
            "recons_loss:0.003149\n",
            "grad_loss:0.088062\n",
            "dice_loss:-0.894819\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:250\n",
            "loss(total):-0.003942\n",
            "recons_loss:0.003895\n",
            "grad_loss:0.104145\n",
            "dice_loss:-0.887804\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:251\n",
            "loss(total):-0.003325\n",
            "recons_loss:0.004516\n",
            "grad_loss:0.099638\n",
            "dice_loss:-0.883684\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:252\n",
            "loss(total):-0.004161\n",
            "recons_loss:0.003877\n",
            "grad_loss:0.095408\n",
            "dice_loss:-0.899249\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:253\n",
            "loss(total):-0.004495\n",
            "recons_loss:0.003658\n",
            "grad_loss:0.081249\n",
            "dice_loss:-0.896572\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:254\n",
            "loss(total):-0.004374\n",
            "recons_loss:0.003604\n",
            "grad_loss:0.088341\n",
            "dice_loss:-0.886102\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:255\n",
            "loss(total):-0.004114\n",
            "recons_loss:0.003845\n",
            "grad_loss:0.099501\n",
            "dice_loss:-0.895433\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:256\n",
            "loss(total):-0.005905\n",
            "recons_loss:0.002498\n",
            "grad_loss:0.072989\n",
            "dice_loss:-0.913273\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:257\n",
            "loss(total):-0.002487\n",
            "recons_loss:0.005025\n",
            "grad_loss:0.135648\n",
            "dice_loss:-0.886921\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:258\n",
            "loss(total):-0.004710\n",
            "recons_loss:0.003407\n",
            "grad_loss:0.083550\n",
            "dice_loss:-0.895248\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:259\n",
            "loss(total):-0.003979\n",
            "recons_loss:0.003981\n",
            "grad_loss:0.103033\n",
            "dice_loss:-0.898975\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:260\n",
            "loss(total):-0.004821\n",
            "recons_loss:0.003393\n",
            "grad_loss:0.085078\n",
            "dice_loss:-0.906460\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:261\n",
            "loss(total):-0.004577\n",
            "recons_loss:0.003394\n",
            "grad_loss:0.093551\n",
            "dice_loss:-0.890594\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:262\n",
            "loss(total):-0.004184\n",
            "recons_loss:0.003787\n",
            "grad_loss:0.093792\n",
            "dice_loss:-0.890904\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:263\n",
            "loss(total):-0.004580\n",
            "recons_loss:0.003481\n",
            "grad_loss:0.090732\n",
            "dice_loss:-0.896802\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:264\n",
            "loss(total):-0.005190\n",
            "recons_loss:0.003147\n",
            "grad_loss:0.070247\n",
            "dice_loss:-0.903984\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:265\n",
            "loss(total):-0.003268\n",
            "recons_loss:0.004522\n",
            "grad_loss:0.118203\n",
            "dice_loss:-0.897127\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:266\n",
            "loss(total):-0.004230\n",
            "recons_loss:0.003705\n",
            "grad_loss:0.092132\n",
            "dice_loss:-0.885584\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:267\n",
            "loss(total):-0.003928\n",
            "recons_loss:0.003903\n",
            "grad_loss:0.102731\n",
            "dice_loss:-0.885871\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:268\n",
            "loss(total):-0.004090\n",
            "recons_loss:0.003754\n",
            "grad_loss:0.091514\n",
            "dice_loss:-0.875926\n",
            "---------------------------------------\n",
            "\n",
            "Epoch:29\n",
            "Batch_number:269\n",
            "loss(total):-0.002454\n",
            "recons_loss:0.005186\n",
            "grad_loss:0.111955\n",
            "dice_loss:-0.875911\n",
            "---------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb0Uy4cvTqL6",
        "outputId": "804284a8-1721-481a-d969-ef1c6cb11f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(losses_9[1:])\n",
        "plt.show"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hni2JboTsyH",
        "outputId": "617f0d9b-d203-4afb-c17b-9bc0b306aced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(validation_9)\n",
        "plt.show"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA7XcHLdTnja"
      },
      "source": [
        "import csv\n",
        "with open('validation_9.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCSVWJYDH7Cl"
      },
      "source": [
        "for h in range(0,len(validation_0)):\n",
        "  with open('validation_9.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, validation_9[h].numpy()])"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGnJH7IoLTdj"
      },
      "source": [
        "import csv\n",
        "with open('loss_9.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])\n",
        "\n",
        "for h in range(0,len(losses_9)):\n",
        "  with open('loss_9.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h, losses_9[h].numpy()])"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dp3th_9oOFL"
      },
      "source": [
        "import statistics"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRppIu3woQTi"
      },
      "source": [
        "res=[statistics.mean(k) for k in zip(np.array(validation_9), np.array(validation_8),\n",
        "                                     np.array(validation_7),np.array(validation_6),\n",
        "                                     np.array(validation_5),np.array(validation_4),\n",
        "                                     np.array(validation_3),np.array(validation_2),\n",
        "                                     np.array(validation_1),np.array(validation_0))]"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NLFRVRcJYp6"
      },
      "source": [
        "with open('validation_mean.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgz1kSfJJfFJ"
      },
      "source": [
        "for h in range(0,len(res)):\n",
        "  with open('validation_mean.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, res[h]])"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPfaFYYxLdZ7"
      },
      "source": [
        "res_L=[statistics.mean(k) for k in zip(np.array(losses_9), np.array(losses_8),\n",
        "                                     np.array(losses_7),np.array(losses_6),\n",
        "                                     np.array(losses_5),np.array(losses_4),\n",
        "                                     np.array(losses_3),np.array(losses_2),\n",
        "                                     np.array(losses_1),np.array(losses_0))]"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdMBaln0L7TU"
      },
      "source": [
        "with open('loss_mean.csv', 'a', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(['batch', 'loss'])"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr6BTDNqL_Ll"
      },
      "source": [
        "for h in range(0,len(res_L)):\n",
        "  with open('loss_mean.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow([h*100, res_L[h]])"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B3lBtKrJotu"
      },
      "source": [
        "v = pd.read_csv(\"/content/loss_mean.csv\")"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss4-hIU8Jr6G",
        "outputId": "148aa271-7788-463f-ead7-b61cf9b76531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "v"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-25.146187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>0.024488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200</td>\n",
              "      <td>0.023011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>300</td>\n",
              "      <td>0.022135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>400</td>\n",
              "      <td>0.022822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8096</th>\n",
              "      <td>809600</td>\n",
              "      <td>-0.003227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8097</th>\n",
              "      <td>809700</td>\n",
              "      <td>-0.003942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8098</th>\n",
              "      <td>809800</td>\n",
              "      <td>-0.003954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8099</th>\n",
              "      <td>809900</td>\n",
              "      <td>-0.003229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8100</th>\n",
              "      <td>810000</td>\n",
              "      <td>-0.003512</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8101 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       batch       loss\n",
              "0          0 -25.146187\n",
              "1        100   0.024488\n",
              "2        200   0.023011\n",
              "3        300   0.022135\n",
              "4        400   0.022822\n",
              "...      ...        ...\n",
              "8096  809600  -0.003227\n",
              "8097  809700  -0.003942\n",
              "8098  809800  -0.003954\n",
              "8099  809900  -0.003229\n",
              "8100  810000  -0.003512\n",
              "\n",
              "[8101 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGW0xEbtMLTP",
        "outputId": "d9ad75c8-0c00-453a-ec56-834565160383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(res_L[1:])\n",
        "plt.show"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKcmrv2ZMUSz",
        "outputId": "20458ebc-ba26-4ce0-cff1-31d54a2cc4fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "fig=plt.figure(figsize=(8,8),dpi=80,facecolor='w',edgecolor='k')\n",
        "plt.plot(res)\n",
        "plt.show"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x640 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}